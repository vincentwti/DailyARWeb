import {
  CSS3DRenderer,
  M,
  require_fs,
  y
} from "./chunk-DG67V5KT.js";
import {
  Group,
  Matrix4,
  PerspectiveCamera,
  Quaternion,
  Scene,
  Vector3,
  WebGLRenderer,
  __commonJS,
  sRGBEncoding
} from "./chunk-EHRDRPS4.js";

// node_modules/node-fetch/browser.js
var require_browser = __commonJS({
  "node_modules/node-fetch/browser.js"(exports, module) {
    "use strict";
    var getGlobal = function() {
      if (typeof self !== "undefined") {
        return self;
      }
      if (typeof window !== "undefined") {
        return window;
      }
      if (typeof global !== "undefined") {
        return global;
      }
      throw new Error("unable to locate global object");
    };
    var globalObject = getGlobal();
    module.exports = exports = globalObject.fetch;
    if (globalObject.fetch) {
      exports.default = globalObject.fetch.bind(globalObject);
    }
    exports.Headers = globalObject.Headers;
    exports.Request = globalObject.Request;
    exports.Response = globalObject.Response;
  }
});

// browser-external:util
var require_util = __commonJS({
  "browser-external:util"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_6, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "util" has been externalized for browser compatibility. Cannot access "util.${key}" in client code. See https://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:buffer
var require_buffer = __commonJS({
  "browser-external:buffer"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_6, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "buffer" has been externalized for browser compatibility. Cannot access "buffer.${key}" in client code. See https://vitejs.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/safe-buffer/index.js
var require_safe_buffer = __commonJS({
  "node_modules/safe-buffer/index.js"(exports, module) {
    var buffer = require_buffer();
    var Buffer2 = buffer.Buffer;
    function copyProps(src, dst) {
      for (var key in src) {
        dst[key] = src[key];
      }
    }
    if (Buffer2.from && Buffer2.alloc && Buffer2.allocUnsafe && Buffer2.allocUnsafeSlow) {
      module.exports = buffer;
    } else {
      copyProps(buffer, exports);
      exports.Buffer = SafeBuffer;
    }
    function SafeBuffer(arg, encodingOrOffset, length) {
      return Buffer2(arg, encodingOrOffset, length);
    }
    SafeBuffer.prototype = Object.create(Buffer2.prototype);
    copyProps(Buffer2, SafeBuffer);
    SafeBuffer.from = function(arg, encodingOrOffset, length) {
      if (typeof arg === "number") {
        throw new TypeError("Argument must not be a number");
      }
      return Buffer2(arg, encodingOrOffset, length);
    };
    SafeBuffer.alloc = function(size, fill, encoding) {
      if (typeof size !== "number") {
        throw new TypeError("Argument must be a number");
      }
      var buf = Buffer2(size);
      if (fill !== void 0) {
        if (typeof encoding === "string") {
          buf.fill(fill, encoding);
        } else {
          buf.fill(fill);
        }
      } else {
        buf.fill(0);
      }
      return buf;
    };
    SafeBuffer.allocUnsafe = function(size) {
      if (typeof size !== "number") {
        throw new TypeError("Argument must be a number");
      }
      return Buffer2(size);
    };
    SafeBuffer.allocUnsafeSlow = function(size) {
      if (typeof size !== "number") {
        throw new TypeError("Argument must be a number");
      }
      return buffer.SlowBuffer(size);
    };
  }
});

// node_modules/string_decoder/lib/string_decoder.js
var require_string_decoder = __commonJS({
  "node_modules/string_decoder/lib/string_decoder.js"(exports) {
    "use strict";
    var Buffer2 = require_safe_buffer().Buffer;
    var isEncoding = Buffer2.isEncoding || function(encoding) {
      encoding = "" + encoding;
      switch (encoding && encoding.toLowerCase()) {
        case "hex":
        case "utf8":
        case "utf-8":
        case "ascii":
        case "binary":
        case "base64":
        case "ucs2":
        case "ucs-2":
        case "utf16le":
        case "utf-16le":
        case "raw":
          return true;
        default:
          return false;
      }
    };
    function _normalizeEncoding(enc) {
      if (!enc)
        return "utf8";
      var retried;
      while (true) {
        switch (enc) {
          case "utf8":
          case "utf-8":
            return "utf8";
          case "ucs2":
          case "ucs-2":
          case "utf16le":
          case "utf-16le":
            return "utf16le";
          case "latin1":
          case "binary":
            return "latin1";
          case "base64":
          case "ascii":
          case "hex":
            return enc;
          default:
            if (retried)
              return;
            enc = ("" + enc).toLowerCase();
            retried = true;
        }
      }
    }
    function normalizeEncoding(enc) {
      var nenc = _normalizeEncoding(enc);
      if (typeof nenc !== "string" && (Buffer2.isEncoding === isEncoding || !isEncoding(enc)))
        throw new Error("Unknown encoding: " + enc);
      return nenc || enc;
    }
    exports.StringDecoder = StringDecoder;
    function StringDecoder(encoding) {
      this.encoding = normalizeEncoding(encoding);
      var nb3;
      switch (this.encoding) {
        case "utf16le":
          this.text = utf16Text;
          this.end = utf16End;
          nb3 = 4;
          break;
        case "utf8":
          this.fillLast = utf8FillLast;
          nb3 = 4;
          break;
        case "base64":
          this.text = base64Text;
          this.end = base64End;
          nb3 = 3;
          break;
        default:
          this.write = simpleWrite;
          this.end = simpleEnd;
          return;
      }
      this.lastNeed = 0;
      this.lastTotal = 0;
      this.lastChar = Buffer2.allocUnsafe(nb3);
    }
    StringDecoder.prototype.write = function(buf) {
      if (buf.length === 0)
        return "";
      var r;
      var i6;
      if (this.lastNeed) {
        r = this.fillLast(buf);
        if (r === void 0)
          return "";
        i6 = this.lastNeed;
        this.lastNeed = 0;
      } else {
        i6 = 0;
      }
      if (i6 < buf.length)
        return r ? r + this.text(buf, i6) : this.text(buf, i6);
      return r || "";
    };
    StringDecoder.prototype.end = utf8End;
    StringDecoder.prototype.text = utf8Text;
    StringDecoder.prototype.fillLast = function(buf) {
      if (this.lastNeed <= buf.length) {
        buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
        return this.lastChar.toString(this.encoding, 0, this.lastTotal);
      }
      buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
      this.lastNeed -= buf.length;
    };
    function utf8CheckByte(byte) {
      if (byte <= 127)
        return 0;
      else if (byte >> 5 === 6)
        return 2;
      else if (byte >> 4 === 14)
        return 3;
      else if (byte >> 3 === 30)
        return 4;
      return byte >> 6 === 2 ? -1 : -2;
    }
    function utf8CheckIncomplete(self2, buf, i6) {
      var j = buf.length - 1;
      if (j < i6)
        return 0;
      var nb3 = utf8CheckByte(buf[j]);
      if (nb3 >= 0) {
        if (nb3 > 0)
          self2.lastNeed = nb3 - 1;
        return nb3;
      }
      if (--j < i6 || nb3 === -2)
        return 0;
      nb3 = utf8CheckByte(buf[j]);
      if (nb3 >= 0) {
        if (nb3 > 0)
          self2.lastNeed = nb3 - 2;
        return nb3;
      }
      if (--j < i6 || nb3 === -2)
        return 0;
      nb3 = utf8CheckByte(buf[j]);
      if (nb3 >= 0) {
        if (nb3 > 0) {
          if (nb3 === 2)
            nb3 = 0;
          else
            self2.lastNeed = nb3 - 3;
        }
        return nb3;
      }
      return 0;
    }
    function utf8CheckExtraBytes(self2, buf, p) {
      if ((buf[0] & 192) !== 128) {
        self2.lastNeed = 0;
        return "�";
      }
      if (self2.lastNeed > 1 && buf.length > 1) {
        if ((buf[1] & 192) !== 128) {
          self2.lastNeed = 1;
          return "�";
        }
        if (self2.lastNeed > 2 && buf.length > 2) {
          if ((buf[2] & 192) !== 128) {
            self2.lastNeed = 2;
            return "�";
          }
        }
      }
    }
    function utf8FillLast(buf) {
      var p = this.lastTotal - this.lastNeed;
      var r = utf8CheckExtraBytes(this, buf, p);
      if (r !== void 0)
        return r;
      if (this.lastNeed <= buf.length) {
        buf.copy(this.lastChar, p, 0, this.lastNeed);
        return this.lastChar.toString(this.encoding, 0, this.lastTotal);
      }
      buf.copy(this.lastChar, p, 0, buf.length);
      this.lastNeed -= buf.length;
    }
    function utf8Text(buf, i6) {
      var total = utf8CheckIncomplete(this, buf, i6);
      if (!this.lastNeed)
        return buf.toString("utf8", i6);
      this.lastTotal = total;
      var end = buf.length - (total - this.lastNeed);
      buf.copy(this.lastChar, 0, end);
      return buf.toString("utf8", i6, end);
    }
    function utf8End(buf) {
      var r = buf && buf.length ? this.write(buf) : "";
      if (this.lastNeed)
        return r + "�";
      return r;
    }
    function utf16Text(buf, i6) {
      if ((buf.length - i6) % 2 === 0) {
        var r = buf.toString("utf16le", i6);
        if (r) {
          var c = r.charCodeAt(r.length - 1);
          if (c >= 55296 && c <= 56319) {
            this.lastNeed = 2;
            this.lastTotal = 4;
            this.lastChar[0] = buf[buf.length - 2];
            this.lastChar[1] = buf[buf.length - 1];
            return r.slice(0, -1);
          }
        }
        return r;
      }
      this.lastNeed = 1;
      this.lastTotal = 2;
      this.lastChar[0] = buf[buf.length - 1];
      return buf.toString("utf16le", i6, buf.length - 1);
    }
    function utf16End(buf) {
      var r = buf && buf.length ? this.write(buf) : "";
      if (this.lastNeed) {
        var end = this.lastTotal - this.lastNeed;
        return r + this.lastChar.toString("utf16le", 0, end);
      }
      return r;
    }
    function base64Text(buf, i6) {
      var n = (buf.length - i6) % 3;
      if (n === 0)
        return buf.toString("base64", i6);
      this.lastNeed = 3 - n;
      this.lastTotal = 3;
      if (n === 1) {
        this.lastChar[0] = buf[buf.length - 1];
      } else {
        this.lastChar[0] = buf[buf.length - 2];
        this.lastChar[1] = buf[buf.length - 1];
      }
      return buf.toString("base64", i6, buf.length - n);
    }
    function base64End(buf) {
      var r = buf && buf.length ? this.write(buf) : "";
      if (this.lastNeed)
        return r + this.lastChar.toString("base64", 0, 3 - this.lastNeed);
      return r;
    }
    function simpleWrite(buf) {
      return buf.toString(this.encoding);
    }
    function simpleEnd(buf) {
      return buf && buf.length ? this.write(buf) : "";
    }
  }
});

// node_modules/mind-ar/dist/controller-mGt1s8dJ.js
function DC(n, t) {
  for (var e = 0; e < t.length; e++) {
    const s = t[e];
    if (typeof s != "string" && !Array.isArray(s)) {
      for (const o in s)
        if (o !== "default" && !(o in n)) {
          const r = Object.getOwnPropertyDescriptor(s, o);
          r && Object.defineProperty(n, o, r.get ? r : {
            enumerable: true,
            get: () => s[o]
          });
        }
    }
  }
  return Object.freeze(Object.defineProperty(n, Symbol.toStringTag, { value: "Module" }));
}
var FC = 1e-7;
var VC = 1e-4;
var qg = class {
  constructor(t, e) {
    this.backend = t, this.dataMover = e, this.data = /* @__PURE__ */ new WeakMap(), this.dataIdsCount = 0;
  }
  get(t) {
    return this.data.has(t) || this.dataMover.moveData(this.backend, t), this.data.get(t);
  }
  set(t, e) {
    this.dataIdsCount++, this.data.set(t, e);
  }
  has(t) {
    return this.data.has(t);
  }
  delete(t) {
    return this.dataIdsCount--, this.data.delete(t);
  }
  numDataIds() {
    return this.dataIdsCount;
  }
};
var _d = class {
  refCount(t) {
    return Qe("refCount");
  }
  incRef(t) {
    return Qe("incRef");
  }
  timerAvailable() {
    return true;
  }
  time(t) {
    return Qe("time");
  }
  read(t) {
    return Qe("read");
  }
  readSync(t) {
    return Qe("readSync");
  }
  readToGPU(t, e) {
    return Qe("readToGPU");
  }
  numDataIds() {
    return Qe("numDataIds");
  }
  disposeData(t, e) {
    return Qe("disposeData");
  }
  write(t, e, s) {
    return Qe("write");
  }
  move(t, e, s, o, r) {
    return Qe("move");
  }
  createTensorFromGPUData(t, e, s) {
    return Qe("createTensorFromGPUData");
  }
  memory() {
    return Qe("memory");
  }
  /** Returns the highest precision for floats in bits (e.g. 16 or 32) */
  floatPrecision() {
    return Qe("floatPrecision");
  }
  /** Returns the smallest representable number.  */
  epsilon() {
    return this.floatPrecision() === 32 ? FC : VC;
  }
  dispose() {
    return Qe("dispose");
  }
};
function Qe(n) {
  throw new Error(`'${n}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
}
function Ud(n) {
  let t = n.length, e = 0;
  for (; t > 0; )
    e = Math.random() * t | 0, t--, ds(n, t, e);
}
function zC(n, t) {
  if (n.length !== t.length)
    throw new Error(`Array sizes must match to be shuffled together First array length was ${n.length}Second array length was ${t.length}`);
  let e = n.length, s = 0;
  for (; e > 0; )
    s = Math.random() * e | 0, e--, ds(n, e, s), ds(t, e, s);
}
function Os(n, t, e) {
  return Math.max(n, Math.min(t, e));
}
function Bl(n) {
  return n % 2 === 0 ? n : n + 1;
}
function ds(n, t, e) {
  const s = n[t];
  n[t] = n[e], n[e] = s;
}
function tb(n) {
  let t = 0;
  for (let e = 0; e < n.length; e++)
    t += n[e];
  return t;
}
function PC(n, t) {
  const e = Math.random();
  return t * e + (1 - e) * n;
}
function AC(n, t) {
  let e = 0;
  for (let s = 0; s < n.length; s++) {
    const o = Number(n[s]) - Number(t[s]);
    e += o * o;
  }
  return e;
}
function C(n, t) {
  if (!n)
    throw new Error(typeof t == "string" ? t : t());
}
function Pe(n, t, e = "") {
  C($t(n, t), () => e + ` Shapes ${n} and ${t} must match`);
}
function Hl(n) {
  C(n != null, () => "The input to the tensor constructor must be a non-null value.");
}
function X(n) {
  if (n.length === 0)
    return 1;
  let t = n[0];
  for (let e = 1; e < n.length; e++)
    t *= n[e];
  return t;
}
function OC(n) {
  return n.length === 0;
}
function XC(n, t) {
  if (n === t)
    return true;
  if (n == null || t == null || n.length !== t.length)
    return false;
  for (let e = 0; e < n.length; e++)
    if (n[e] !== null && t[e] !== null && n[e] !== t[e])
      return false;
  return true;
}
function $t(n, t) {
  if (n === t)
    return true;
  if (n == null || t == null || n.length !== t.length)
    return false;
  for (let e = 0; e < n.length; e++)
    if (n[e] !== t[e])
      return false;
  return true;
}
function Co(n) {
  return n % 1 === 0;
}
function KC(n) {
  if (Math.tanh != null)
    return Math.tanh(n);
  if (n === 1 / 0)
    return 1;
  if (n === -1 / 0)
    return -1;
  {
    const t = Math.exp(2 * n);
    return (t - 1) / (t + 1);
  }
}
function hl(n) {
  const t = Math.ceil(Math.sqrt(n));
  return [t, Math.ceil(n / t)];
}
function ZC(n) {
  const t = new Uint32Array(n);
  for (let e = 0; e < n; ++e)
    t[e] = e;
  return Ud(t), t;
}
function xo(n, t) {
  return t <= n.length ? n : n + " ".repeat(t - n.length);
}
function id(n, t = (o) => 0, e, s) {
  return new Promise((o, r) => {
    let i6 = 0;
    const a = () => {
      if (n()) {
        o();
        return;
      }
      i6++;
      const l = t(i6);
      if (e != null && i6 >= e) {
        r();
        return;
      }
      s != null ? s(a, l) : setTimeout(a, l);
    };
    a();
  });
}
function Yd(n, t) {
  let e = 1, s = -1;
  for (let r = 0; r < n.length; ++r)
    if (n[r] >= 0)
      e *= n[r];
    else if (n[r] === -1) {
      if (s !== -1)
        throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${s} and dim ${r}`);
      s = r;
    } else if (n[r] < 0)
      throw Error(`Shapes can not be < 0. Found ${n[r]} at dim ${r}`);
  if (s === -1) {
    if (t > 0 && t !== e)
      throw Error(`Size(${t}) must match the product of shape ${n}`);
    return n;
  }
  if (e === 0)
    throw Error(`Cannot infer the missing size in [${n}] when there are 0 elements`);
  if (t % e !== 0)
    throw Error(`The implicit shape can't be a fractional number. Got ${t} / ${e}`);
  const o = n.slice();
  return o[s] = t / e, o;
}
function Ct(n, t) {
  const e = t.length;
  return n = n == null ? t.map((s, o) => o) : [].concat(n), C(n.every((s) => s >= -e && s < e), () => `All values in axis param must be in range [-${e}, ${e}) but got axis ${n}`), C(n.every((s) => Co(s)), () => `All values in axis param must be integers but got axis ${n}`), n.map((s) => s < 0 ? e + s : s);
}
function ws(n, t) {
  const e = [], s = [], o = t != null && Array.isArray(t) && t.length === 0, r = t == null || o ? null : Ct(t, n).sort();
  let i6 = 0;
  for (let a = 0; a < n.length; ++a) {
    if (r != null) {
      if (r[i6] === a && n[a] !== 1)
        throw new Error(`Can't squeeze axis ${a} since its dim '${n[a]}' is not 1`);
      (r[i6] == null || r[i6] > a) && n[a] === 1 && (e.push(n[a]), s.push(a)), r[i6] <= a && i6++;
    }
    n[a] !== 1 && (e.push(n[a]), s.push(a));
  }
  return { newShape: e, keptDims: s };
}
function Se(n, t) {
  return ne(n, t);
}
function ne(n, t) {
  let e = null;
  if (n == null || n === "float32")
    e = new Float32Array(t);
  else if (n === "int32")
    e = new Int32Array(t);
  else if (n === "bool")
    e = new Uint8Array(t);
  else if (n === "string")
    e = new Array(t);
  else
    throw new Error(`Unknown data type ${n}`);
  return e;
}
function eb(n, t) {
  for (let e = 0; e < n.length; e++) {
    const s = n[e];
    if (isNaN(s) || !isFinite(s))
      throw Error(`A tensor of type ${t} being uploaded contains ${s}.`);
  }
}
function nb(n) {
  return n === "bool" || n === "complex64" || n === "float32" || n === "int32" || n === "string";
}
function Qd(n, t) {
  return !(t === "complex64" || t === "float32" && n !== "complex64" || t === "int32" && n !== "float32" && n !== "complex64" || t === "bool" && n === "bool");
}
function ri(n) {
  if (n === "float32" || n === "int32")
    return 4;
  if (n === "complex64")
    return 8;
  if (n === "bool")
    return 1;
  throw new Error(`Unknown dtype ${n}`);
}
function sb(n) {
  if (n == null)
    return 0;
  let t = 0;
  return n.forEach((e) => t += e.length), t;
}
function vr(n) {
  return typeof n == "string" || n instanceof String;
}
function ob(n) {
  return typeof n == "boolean";
}
function pl(n) {
  return typeof n == "number";
}
function Oo(n) {
  return Array.isArray(n) ? Oo(n[0]) : n instanceof Float32Array ? "float32" : n instanceof Int32Array || n instanceof Uint8Array || n instanceof Uint8ClampedArray ? "int32" : pl(n) ? "float32" : vr(n) ? "string" : ob(n) ? "bool" : "float32";
}
function Xs(n) {
  return !!(n && n.constructor && n.call && n.apply);
}
function fl(n, t) {
  for (let e = t; e < n; ++e)
    if (n % e === 0)
      return e;
  return n;
}
function dt(n) {
  const t = n.length;
  if (t < 2)
    return [];
  const e = new Array(t - 1);
  e[t - 2] = n[t - 1];
  for (let s = t - 3; s >= 0; --s)
    e[s] = e[s + 1] * n[s + 1];
  return e;
}
function rb(n, t, e, s = false) {
  const o = new Array();
  if (t.length === 1) {
    const r = t[0] * (s ? 2 : 1);
    for (let i6 = 0; i6 < r; i6++)
      o[i6] = e[n + i6];
  } else {
    const r = t[0], i6 = t.slice(1), a = i6.reduce((l, c) => l * c) * (s ? 2 : 1);
    for (let l = 0; l < r; l++)
      o[l] = rb(n + l * a, i6, e, s);
  }
  return o;
}
function kn(n, t, e = false) {
  if (n.length === 0)
    return t[0];
  const s = n.reduce((o, r) => o * r) * (e ? 2 : 1);
  if (s === 0)
    return [];
  if (s !== t.length)
    throw new Error(`[${n}] does not match the input size ${t.length}${e ? " for a complex tensor" : ""}.`);
  return rb(0, n, t, e);
}
function ib(n, t) {
  if (Array.isArray(n))
    return n;
  if (t === "float32")
    return n instanceof Float32Array ? n : new Float32Array(n);
  if (t === "int32")
    return n instanceof Int32Array ? n : new Int32Array(n);
  if (t === "bool" || t === "string")
    return Uint8Array.from(new Int32Array(n));
  throw new Error(`Unknown dtype ${t}`);
}
function _l(n, t) {
  const e = ke(n, t);
  for (let s = 0; s < e.length; s++)
    e[s] = 1;
  return e;
}
function ke(n, t) {
  if (t == null || t === "float32" || t === "complex64")
    return new Float32Array(n);
  if (t === "int32")
    return new Int32Array(n);
  if (t === "bool")
    return new Uint8Array(n);
  throw new Error(`Unknown data type ${t}`);
}
function Jd(n, t) {
  const e = n.reduce((s, o) => s * o, 1);
  if (t == null || t === "float32")
    return kn(n, new Float32Array(e));
  if (t === "int32")
    return kn(n, new Int32Array(e));
  if (t === "bool")
    return kn(n, new Uint8Array(e));
  throw new Error(`Unknown data type ${t}`);
}
function is(n) {
  n.forEach((t) => {
    C(Number.isInteger(t) && t >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${n}].`);
  });
}
function zn(n, t, e) {
  if (t === 0)
    return 0;
  if (t === 1)
    return n[0];
  let s = n[n.length - 1];
  for (let o = 0; o < n.length - 1; ++o)
    s += e[o] * n[o];
  return s;
}
function Xo(n, t, e) {
  if (t === 0)
    return [];
  if (t === 1)
    return [n];
  const s = new Array(t);
  for (let o = 0; o < s.length - 1; ++o)
    s[o] = Math.floor(n / e[o]), n -= s[o] * e[o];
  return s[s.length - 1] = n, s;
}
function Ci(n) {
  return n && n.then && typeof n.then == "function";
}
var um = "tfjsflags";
var BC = class {
  // tslint:disable-next-line: no-any
  constructor(t) {
    this.global = t, this.flags = {}, this.flagRegistry = {}, this.urlFlags = {}, this.getQueryParams = HC, this.populateURLFlags();
  }
  setPlatform(t, e) {
    this.platform != null && (F().getBool("IS_TEST") || F().getBool("PROD") || console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${t}.`)), this.platformName = t, this.platform = e;
  }
  registerFlag(t, e, s) {
    if (this.flagRegistry[t] = { evaluationFn: e, setHook: s }, this.urlFlags[t] != null) {
      const o = this.urlFlags[t];
      F().getBool("IS_TEST") || F().getBool("PROD") || console.warn(`Setting feature override from URL ${t}: ${o}.`), this.set(t, o);
    }
  }
  async getAsync(t) {
    return t in this.flags ? this.flags[t] : (this.flags[t] = await this.evaluateFlag(t), this.flags[t]);
  }
  get(t) {
    if (t in this.flags)
      return this.flags[t];
    const e = this.evaluateFlag(t);
    if (Ci(e))
      throw new Error(`Flag ${t} cannot be synchronously evaluated. Please use getAsync() instead.`);
    return this.flags[t] = e, this.flags[t];
  }
  getNumber(t) {
    return this.get(t);
  }
  getBool(t) {
    return this.get(t);
  }
  getString(t) {
    return this.get(t);
  }
  getFlags() {
    return this.flags;
  }
  // For backwards compatibility.
  get features() {
    return this.flags;
  }
  set(t, e) {
    if (this.flagRegistry[t] == null)
      throw new Error(`Cannot set flag ${t} as it has not been registered.`);
    this.flags[t] = e, this.flagRegistry[t].setHook != null && this.flagRegistry[t].setHook(e);
  }
  evaluateFlag(t) {
    if (this.flagRegistry[t] == null)
      throw new Error(`Cannot evaluate flag '${t}': no evaluation function found.`);
    return this.flagRegistry[t].evaluationFn();
  }
  setFlags(t) {
    this.flags = Object.assign({}, t);
  }
  reset() {
    this.flags = {}, this.urlFlags = {}, this.populateURLFlags();
  }
  populateURLFlags() {
    if (typeof this.global > "u" || typeof this.global.location > "u" || typeof this.global.location.search > "u")
      return;
    const t = this.getQueryParams(this.global.location.search);
    um in t && t[um].split(",").forEach((s) => {
      const [o, r] = s.split(":");
      this.urlFlags[o] = UC(o, r);
    });
  }
};
function HC(n) {
  const t = {};
  return n.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (e, ...s) => (_C(t, s[0], s[1]), s.join("="))), t;
}
function _C(n, t, e) {
  n[decodeURIComponent(t)] = decodeURIComponent(e || "");
}
function UC(n, t) {
  const e = t.toLowerCase();
  return e === "true" || e === "false" ? e === "true" : `${+e}` === e ? +e : t;
}
function F() {
  return ab;
}
var ab = null;
function YC(n) {
  ab = n;
}
var $u;
function lb() {
  if ($u == null) {
    let n;
    if (typeof window < "u")
      n = window;
    else if (typeof global < "u")
      n = global;
    else if (typeof process < "u")
      n = process;
    else if (typeof self < "u")
      n = self;
    else
      throw new Error("Could not find a global object");
    $u = n;
  }
  return $u;
}
function QC() {
  const n = lb();
  return n._tfGlobals == null && (n._tfGlobals = /* @__PURE__ */ new Map()), n._tfGlobals;
}
function jd(n, t) {
  const e = QC();
  if (e.has(n))
    return e.get(n);
  {
    const s = t();
    return e.set(n, s), e.get(n);
  }
}
var Ul = "Abs";
var vi = "Acos";
var Si = "Acosh";
var Sr = "Add";
var qd = "AddN";
var th = "All";
var eh = "Any";
var Yl = "ArgMax";
var Ql = "ArgMin";
var ki = "Asin";
var Ti = "Asinh";
var Ni = "Atan";
var Ri = "Atanh";
var $i = "Atan2";
var Jl = "AvgPool";
var nh = "AvgPoolGrad";
var jl = "AvgPool3D";
var sh = "AvgPool3DGrad";
var ql = "BatchMatMul";
var tc = "BatchToSpaceND";
var oh = "Bincount";
var rh = "BitwiseAnd";
var JC = "BroadcastTo";
var cb = "BroadcastArgs";
var Gi = "Cast";
var Ei = "Ceil";
var Li = "ClipByValue";
var ih = "Complex";
var ec = "ComplexAbs";
var nc = "Concat";
var sc = "Conv2D";
var ah = "Conv2DBackpropFilter";
var oc = "Conv2DBackpropInput";
var rc = "Conv3D";
var lh = "Conv3DBackpropFilterV2";
var ch = "Conv3DBackpropInputV2";
var Mi = "Cos";
var Wi = "Cosh";
var uh = "Cumprod";
var ic = "Cumsum";
var dh = "CropAndResize";
var hh = "DenseBincount";
var ph = "DepthToSpace";
var ac = "DepthwiseConv2dNative";
var fh = "DepthwiseConv2dNativeBackpropFilter";
var mh = "DepthwiseConv2dNativeBackpropInput";
var ub = "Diag";
var lc = "Dilation2D";
var ad = "Dilation2DBackpropInput";
var ld = "Dilation2DBackpropFilter";
var gh = "Draw";
var Di = "RealDiv";
var bh = "Einsum";
var Fi = "Elu";
var xh = "EluGrad";
var Vi = "Erf";
var cc = "Equal";
var zi = "Exp";
var uc = "ExpandDims";
var Pi = "Expm1";
var yh = "FFT";
var wh = "Fill";
var Ih = "FlipLeftRight";
var Ai = "Floor";
var Oi = "FloorDiv";
var dc = "FusedBatchNorm";
var hc = "GatherV2";
var db = "GatherNd";
var pc = "Greater";
var Xi = "GreaterEqual";
var Ki = "Identity";
var Ch = "IFFT";
var vh = "Imag";
var Zi = "IsFinite";
var Bi = "IsInf";
var Hi = "IsNan";
var fc = "LeakyRelu";
var mc = "Less";
var gc = "LessEqual";
var hb = "LinSpace";
var _i = "Log";
var Ui = "Log1p";
var bc = "LogicalAnd";
var xc = "LogicalNot";
var yc = "LogicalOr";
var XY = "LogicalXor";
var jC = "LogSoftmax";
var KY = "LowerBound";
var wc = "LRN";
var Sh = "LRNGrad";
var ZY = "MatrixBandPart";
var Ic = "Max";
var Yi = "Maximum";
var Cc = "MaxPool";
var kh = "MaxPoolGrad";
var vc = "MaxPool3D";
var Th = "MaxPool3DGrad";
var pb = "MaxPoolWithArgmax";
var Sc = "Mean";
var kc = "Min";
var Qi = "Minimum";
var Tc = "MirrorPad";
var Ji = "Mod";
var fb = "Multinomial";
var ji = "Multiply";
var Nc = "Neg";
var Rc = "NotEqual";
var Nh = "NonMaxSuppressionV3";
var Rh = "NonMaxSuppressionV4";
var $h = "NonMaxSuppressionV5";
var $c = "OnesLike";
var Gc = "OneHot";
var Ec = "Pack";
var Lc = "PadV2";
var BY = "Pool";
var qi = "Pow";
var Mc = "Prelu";
var Wc = "Prod";
var mb = "RaggedGather";
var gb = "RaggedRange";
var bb = "RaggedTensorToTensor";
var Gh = "Range";
var Eh = "Real";
var ta = "Reciprocal";
var ea = "Relu";
var Dc = "Reshape";
var Fc = "ResizeNearestNeighbor";
var Lh = "ResizeNearestNeighborGrad";
var Vc = "ResizeBilinear";
var Mh = "ResizeBilinearGrad";
var na = "Relu6";
var zc = "Reverse";
var sa = "Round";
var oa = "Rsqrt";
var xb = "ScatterNd";
var yb = "TensorScatterUpdate";
var wb = "SearchSorted";
var Pc = "Select";
var ra = "Selu";
var Ac = "Slice";
var ia = "Sin";
var aa = "Sinh";
var la = "Sign";
var ca = "Sigmoid";
var ua = "Softplus";
var da = "Sqrt";
var Oc = "Sum";
var Xc = "SpaceToBatchND";
var Kc = "SplitV";
var Zc = "Softmax";
var Wh = "SparseFillEmptyRows";
var Dh = "SparseReshape";
var Fh = "SparseSegmentMean";
var Vh = "SparseSegmentSum";
var Ib = "SparseToDense";
var ha = "SquaredDifference";
var zh = "Square";
var Bc = "StaticRegexReplace";
var Ph = "StridedSlice";
var Ah = "StringNGrams";
var Oh = "StringSplit";
var Xh = "StringToHashBucketFast";
var pa = "Sub";
var fa = "Tan";
var ma = "Tanh";
var ga = "Tile";
var Kh = "TopK";
var Zh = "Transform";
var ar = "Transpose";
var Bh = "Unique";
var Hc = "Unpack";
var _c = "UnsortedSegmentSum";
var HY = "UpperBound";
var Uc = "ZerosLike";
var ba = "Step";
var cd = "FromPixels";
var Hh = "RotateWithOffset";
var ml = "_FusedMatMul";
var gl = "FusedConv2D";
var Cb = "FusedDepthwiseConv2D";
function ln(...n) {
  F().getBool("IS_TEST") || F().getBool("PROD") || console.warn(...n);
}
function qC(...n) {
  F().getBool("IS_TEST") || F().getBool("PROD") || console.log(...n);
}
var pr = jd("kernelRegistry", () => /* @__PURE__ */ new Map());
var ii = jd("gradRegistry", () => /* @__PURE__ */ new Map());
function bl(n, t) {
  const e = _h(n, t);
  return pr.get(e);
}
function dm(n) {
  return ii.get(n);
}
function ud(n) {
  const t = pr.entries(), e = [];
  for (; ; ) {
    const { done: s, value: o } = t.next();
    if (s)
      break;
    const [r, i6] = o, [a] = r.split("_");
    a === n && e.push(i6);
  }
  return e;
}
function sn(n) {
  const { kernelName: t, backendName: e } = n, s = _h(t, e);
  pr.has(s) && ln(`The kernel '${t}' for backend '${e}' is already registered`), pr.set(s, n);
}
function t2(n) {
  const { kernelName: t } = n;
  ii.has(t) && F().getBool("DEBUG") && ln(`Overriding the gradient for '${t}'`), ii.set(t, n);
}
function _Y(n, t) {
  const e = _h(n, t);
  if (!pr.has(e))
    throw new Error(`The kernel '${n}' for backend '${t}' is not registered`);
  pr.delete(e);
}
function UY(n) {
  if (!ii.has(n))
    throw new Error(`The gradient '${n}' for backend is not registered`);
  ii.delete(n);
}
function YY(n, t) {
  ud(n).forEach((s) => {
    const o = Object.assign({}, s, { backendName: t });
    sn(o);
  });
}
function _h(n, t) {
  return `${t}_${n}`;
}
function vb(n) {
  return n instanceof Float32Array || n instanceof Int32Array || n instanceof Uint8Array || n instanceof Uint8ClampedArray;
}
var Ko = typeof globalThis < "u" ? globalThis : typeof window < "u" ? window : typeof global < "u" ? global : typeof self < "u" ? self : {};
function e2(n) {
  return n && n.__esModule && Object.prototype.hasOwnProperty.call(n, "default") ? n.default : n;
}
function n2(n) {
  if (n.__esModule)
    return n;
  var t = n.default;
  if (typeof t == "function") {
    var e = function s() {
      return this instanceof s ? Reflect.construct(t, arguments, this.constructor) : t.apply(this, arguments);
    };
    e.prototype = t.prototype;
  } else
    e = {};
  return Object.defineProperty(e, "__esModule", { value: true }), Object.keys(n).forEach(function(s) {
    var o = Object.getOwnPropertyDescriptor(n, s);
    Object.defineProperty(e, s, o.get ? o : {
      enumerable: true,
      get: function() {
        return n[s];
      }
    });
  }), e;
}
var Sb = Bt;
var In = null;
try {
  In = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
    0,
    97,
    115,
    109,
    1,
    0,
    0,
    0,
    1,
    13,
    2,
    96,
    0,
    1,
    127,
    96,
    4,
    127,
    127,
    127,
    127,
    1,
    127,
    3,
    7,
    6,
    0,
    1,
    1,
    1,
    1,
    1,
    6,
    6,
    1,
    127,
    1,
    65,
    0,
    11,
    7,
    50,
    6,
    3,
    109,
    117,
    108,
    0,
    1,
    5,
    100,
    105,
    118,
    95,
    115,
    0,
    2,
    5,
    100,
    105,
    118,
    95,
    117,
    0,
    3,
    5,
    114,
    101,
    109,
    95,
    115,
    0,
    4,
    5,
    114,
    101,
    109,
    95,
    117,
    0,
    5,
    8,
    103,
    101,
    116,
    95,
    104,
    105,
    103,
    104,
    0,
    0,
    10,
    191,
    1,
    6,
    4,
    0,
    35,
    0,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    126,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    127,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    128,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    129,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11,
    36,
    1,
    1,
    126,
    32,
    0,
    173,
    32,
    1,
    173,
    66,
    32,
    134,
    132,
    32,
    2,
    173,
    32,
    3,
    173,
    66,
    32,
    134,
    132,
    130,
    34,
    4,
    66,
    32,
    135,
    167,
    36,
    0,
    32,
    4,
    167,
    11
  ])), {}).exports;
} catch {
}
function Bt(n, t, e) {
  this.low = n | 0, this.high = t | 0, this.unsigned = !!e;
}
Bt.prototype.__isLong__;
Object.defineProperty(Bt.prototype, "__isLong__", { value: true });
function on(n) {
  return (n && n.__isLong__) === true;
}
Bt.isLong = on;
var hm = {};
var pm = {};
function Zo(n, t) {
  var e, s, o;
  return t ? (n >>>= 0, (o = 0 <= n && n < 256) && (s = pm[n], s) ? s : (e = Ht(n, (n | 0) < 0 ? -1 : 0, true), o && (pm[n] = e), e)) : (n |= 0, (o = -128 <= n && n < 128) && (s = hm[n], s) ? s : (e = Ht(n, n < 0 ? -1 : 0, false), o && (hm[n] = e), e));
}
Bt.fromInt = Zo;
function Cn(n, t) {
  if (isNaN(n))
    return t ? mo : vn;
  if (t) {
    if (n < 0)
      return mo;
    if (n >= kb)
      return Rb;
  } else {
    if (n <= -mm)
      return je;
    if (n + 1 >= mm)
      return Nb;
  }
  return n < 0 ? Cn(-n, t).neg() : Ht(n % fr | 0, n / fr | 0, t);
}
Bt.fromNumber = Cn;
function Ht(n, t, e) {
  return new Bt(n, t, e);
}
Bt.fromBits = Ht;
var xl = Math.pow;
function Uh(n, t, e) {
  if (n.length === 0)
    throw Error("empty string");
  if (n === "NaN" || n === "Infinity" || n === "+Infinity" || n === "-Infinity")
    return vn;
  if (typeof t == "number" ? (e = t, t = false) : t = !!t, e = e || 10, e < 2 || 36 < e)
    throw RangeError("radix");
  var s;
  if ((s = n.indexOf("-")) > 0)
    throw Error("interior hyphen");
  if (s === 0)
    return Uh(n.substring(1), t, e).neg();
  for (var o = Cn(xl(e, 8)), r = vn, i6 = 0; i6 < n.length; i6 += 8) {
    var a = Math.min(8, n.length - i6), l = parseInt(n.substring(i6, i6 + a), e);
    if (a < 8) {
      var c = Cn(xl(e, a));
      r = r.mul(c).add(Cn(l));
    } else
      r = r.mul(o), r = r.add(Cn(l));
  }
  return r.unsigned = t, r;
}
Bt.fromString = Uh;
function Hn(n, t) {
  return typeof n == "number" ? Cn(n, t) : typeof n == "string" ? Uh(n, t) : Ht(n.low, n.high, typeof t == "boolean" ? t : n.unsigned);
}
Bt.fromValue = Hn;
var fm = 65536;
var s2 = 1 << 24;
var fr = fm * fm;
var kb = fr * fr;
var mm = kb / 2;
var gm = Zo(s2);
var vn = Zo(0);
Bt.ZERO = vn;
var mo = Zo(0, true);
Bt.UZERO = mo;
var ir = Zo(1);
Bt.ONE = ir;
var Tb = Zo(1, true);
Bt.UONE = Tb;
var dd = Zo(-1);
Bt.NEG_ONE = dd;
var Nb = Ht(-1, 2147483647, false);
Bt.MAX_VALUE = Nb;
var Rb = Ht(-1, -1, true);
Bt.MAX_UNSIGNED_VALUE = Rb;
var je = Ht(0, -2147483648, false);
Bt.MIN_VALUE = je;
var st = Bt.prototype;
st.toInt = function() {
  return this.unsigned ? this.low >>> 0 : this.low;
};
st.toNumber = function() {
  return this.unsigned ? (this.high >>> 0) * fr + (this.low >>> 0) : this.high * fr + (this.low >>> 0);
};
st.toString = function(t) {
  if (t = t || 10, t < 2 || 36 < t)
    throw RangeError("radix");
  if (this.isZero())
    return "0";
  if (this.isNegative())
    if (this.eq(je)) {
      var e = Cn(t), s = this.div(e), o = s.mul(e).sub(this);
      return s.toString(t) + o.toInt().toString(t);
    } else
      return "-" + this.neg().toString(t);
  for (var r = Cn(xl(t, 6), this.unsigned), i6 = this, a = ""; ; ) {
    var l = i6.div(r), c = i6.sub(l.mul(r)).toInt() >>> 0, u = c.toString(t);
    if (i6 = l, i6.isZero())
      return u + a;
    for (; u.length < 6; )
      u = "0" + u;
    a = "" + u + a;
  }
};
st.getHighBits = function() {
  return this.high;
};
st.getHighBitsUnsigned = function() {
  return this.high >>> 0;
};
st.getLowBits = function() {
  return this.low;
};
st.getLowBitsUnsigned = function() {
  return this.low >>> 0;
};
st.getNumBitsAbs = function() {
  if (this.isNegative())
    return this.eq(je) ? 64 : this.neg().getNumBitsAbs();
  for (var t = this.high != 0 ? this.high : this.low, e = 31; e > 0 && !(t & 1 << e); e--)
    ;
  return this.high != 0 ? e + 33 : e + 1;
};
st.isZero = function() {
  return this.high === 0 && this.low === 0;
};
st.eqz = st.isZero;
st.isNegative = function() {
  return !this.unsigned && this.high < 0;
};
st.isPositive = function() {
  return this.unsigned || this.high >= 0;
};
st.isOdd = function() {
  return (this.low & 1) === 1;
};
st.isEven = function() {
  return (this.low & 1) === 0;
};
st.equals = function(t) {
  return on(t) || (t = Hn(t)), this.unsigned !== t.unsigned && this.high >>> 31 === 1 && t.high >>> 31 === 1 ? false : this.high === t.high && this.low === t.low;
};
st.eq = st.equals;
st.notEquals = function(t) {
  return !this.eq(
    /* validates */
    t
  );
};
st.neq = st.notEquals;
st.ne = st.notEquals;
st.lessThan = function(t) {
  return this.comp(
    /* validates */
    t
  ) < 0;
};
st.lt = st.lessThan;
st.lessThanOrEqual = function(t) {
  return this.comp(
    /* validates */
    t
  ) <= 0;
};
st.lte = st.lessThanOrEqual;
st.le = st.lessThanOrEqual;
st.greaterThan = function(t) {
  return this.comp(
    /* validates */
    t
  ) > 0;
};
st.gt = st.greaterThan;
st.greaterThanOrEqual = function(t) {
  return this.comp(
    /* validates */
    t
  ) >= 0;
};
st.gte = st.greaterThanOrEqual;
st.ge = st.greaterThanOrEqual;
st.compare = function(t) {
  if (on(t) || (t = Hn(t)), this.eq(t))
    return 0;
  var e = this.isNegative(), s = t.isNegative();
  return e && !s ? -1 : !e && s ? 1 : this.unsigned ? t.high >>> 0 > this.high >>> 0 || t.high === this.high && t.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(t).isNegative() ? -1 : 1;
};
st.comp = st.compare;
st.negate = function() {
  return !this.unsigned && this.eq(je) ? je : this.not().add(ir);
};
st.neg = st.negate;
st.add = function(t) {
  on(t) || (t = Hn(t));
  var e = this.high >>> 16, s = this.high & 65535, o = this.low >>> 16, r = this.low & 65535, i6 = t.high >>> 16, a = t.high & 65535, l = t.low >>> 16, c = t.low & 65535, u = 0, d = 0, h = 0, p = 0;
  return p += r + c, h += p >>> 16, p &= 65535, h += o + l, d += h >>> 16, h &= 65535, d += s + a, u += d >>> 16, d &= 65535, u += e + i6, u &= 65535, Ht(h << 16 | p, u << 16 | d, this.unsigned);
};
st.subtract = function(t) {
  return on(t) || (t = Hn(t)), this.add(t.neg());
};
st.sub = st.subtract;
st.multiply = function(t) {
  if (this.isZero())
    return vn;
  if (on(t) || (t = Hn(t)), In) {
    var e = In.mul(
      this.low,
      this.high,
      t.low,
      t.high
    );
    return Ht(e, In.get_high(), this.unsigned);
  }
  if (t.isZero())
    return vn;
  if (this.eq(je))
    return t.isOdd() ? je : vn;
  if (t.eq(je))
    return this.isOdd() ? je : vn;
  if (this.isNegative())
    return t.isNegative() ? this.neg().mul(t.neg()) : this.neg().mul(t).neg();
  if (t.isNegative())
    return this.mul(t.neg()).neg();
  if (this.lt(gm) && t.lt(gm))
    return Cn(this.toNumber() * t.toNumber(), this.unsigned);
  var s = this.high >>> 16, o = this.high & 65535, r = this.low >>> 16, i6 = this.low & 65535, a = t.high >>> 16, l = t.high & 65535, c = t.low >>> 16, u = t.low & 65535, d = 0, h = 0, p = 0, f = 0;
  return f += i6 * u, p += f >>> 16, f &= 65535, p += r * u, h += p >>> 16, p &= 65535, p += i6 * c, h += p >>> 16, p &= 65535, h += o * u, d += h >>> 16, h &= 65535, h += r * c, d += h >>> 16, h &= 65535, h += i6 * l, d += h >>> 16, h &= 65535, d += s * u + o * c + r * l + i6 * a, d &= 65535, Ht(p << 16 | f, d << 16 | h, this.unsigned);
};
st.mul = st.multiply;
st.divide = function(t) {
  if (on(t) || (t = Hn(t)), t.isZero())
    throw Error("division by zero");
  if (In) {
    if (!this.unsigned && this.high === -2147483648 && t.low === -1 && t.high === -1)
      return this;
    var e = (this.unsigned ? In.div_u : In.div_s)(
      this.low,
      this.high,
      t.low,
      t.high
    );
    return Ht(e, In.get_high(), this.unsigned);
  }
  if (this.isZero())
    return this.unsigned ? mo : vn;
  var s, o, r;
  if (this.unsigned) {
    if (t.unsigned || (t = t.toUnsigned()), t.gt(this))
      return mo;
    if (t.gt(this.shru(1)))
      return Tb;
    r = mo;
  } else {
    if (this.eq(je)) {
      if (t.eq(ir) || t.eq(dd))
        return je;
      if (t.eq(je))
        return ir;
      var i6 = this.shr(1);
      return s = i6.div(t).shl(1), s.eq(vn) ? t.isNegative() ? ir : dd : (o = this.sub(t.mul(s)), r = s.add(o.div(t)), r);
    } else if (t.eq(je))
      return this.unsigned ? mo : vn;
    if (this.isNegative())
      return t.isNegative() ? this.neg().div(t.neg()) : this.neg().div(t).neg();
    if (t.isNegative())
      return this.div(t.neg()).neg();
    r = vn;
  }
  for (o = this; o.gte(t); ) {
    s = Math.max(1, Math.floor(o.toNumber() / t.toNumber()));
    for (var a = Math.ceil(Math.log(s) / Math.LN2), l = a <= 48 ? 1 : xl(2, a - 48), c = Cn(s), u = c.mul(t); u.isNegative() || u.gt(o); )
      s -= l, c = Cn(s, this.unsigned), u = c.mul(t);
    c.isZero() && (c = ir), r = r.add(c), o = o.sub(u);
  }
  return r;
};
st.div = st.divide;
st.modulo = function(t) {
  if (on(t) || (t = Hn(t)), In) {
    var e = (this.unsigned ? In.rem_u : In.rem_s)(
      this.low,
      this.high,
      t.low,
      t.high
    );
    return Ht(e, In.get_high(), this.unsigned);
  }
  return this.sub(this.div(t).mul(t));
};
st.mod = st.modulo;
st.rem = st.modulo;
st.not = function() {
  return Ht(~this.low, ~this.high, this.unsigned);
};
st.and = function(t) {
  return on(t) || (t = Hn(t)), Ht(this.low & t.low, this.high & t.high, this.unsigned);
};
st.or = function(t) {
  return on(t) || (t = Hn(t)), Ht(this.low | t.low, this.high | t.high, this.unsigned);
};
st.xor = function(t) {
  return on(t) || (t = Hn(t)), Ht(this.low ^ t.low, this.high ^ t.high, this.unsigned);
};
st.shiftLeft = function(t) {
  return on(t) && (t = t.toInt()), (t &= 63) === 0 ? this : t < 32 ? Ht(this.low << t, this.high << t | this.low >>> 32 - t, this.unsigned) : Ht(0, this.low << t - 32, this.unsigned);
};
st.shl = st.shiftLeft;
st.shiftRight = function(t) {
  return on(t) && (t = t.toInt()), (t &= 63) === 0 ? this : t < 32 ? Ht(this.low >>> t | this.high << 32 - t, this.high >> t, this.unsigned) : Ht(this.high >> t - 32, this.high >= 0 ? 0 : -1, this.unsigned);
};
st.shr = st.shiftRight;
st.shiftRightUnsigned = function(t) {
  if (on(t) && (t = t.toInt()), t &= 63, t === 0)
    return this;
  var e = this.high;
  if (t < 32) {
    var s = this.low;
    return Ht(s >>> t | e << 32 - t, e >>> t, this.unsigned);
  } else
    return t === 32 ? Ht(e, 0, this.unsigned) : Ht(e >>> t - 32, 0, this.unsigned);
};
st.shru = st.shiftRightUnsigned;
st.shr_u = st.shiftRightUnsigned;
st.toSigned = function() {
  return this.unsigned ? Ht(this.low, this.high, false) : this;
};
st.toUnsigned = function() {
  return this.unsigned ? this : Ht(this.low, this.high, true);
};
st.toBytes = function(t) {
  return t ? this.toBytesLE() : this.toBytesBE();
};
st.toBytesLE = function() {
  var t = this.high, e = this.low;
  return [
    e & 255,
    e >>> 8 & 255,
    e >>> 16 & 255,
    e >>> 24,
    t & 255,
    t >>> 8 & 255,
    t >>> 16 & 255,
    t >>> 24
  ];
};
st.toBytesBE = function() {
  var t = this.high, e = this.low;
  return [
    t >>> 24,
    t >>> 16 & 255,
    t >>> 8 & 255,
    t & 255,
    e >>> 24,
    e >>> 16 & 255,
    e >>> 8 & 255,
    e & 255
  ];
};
Bt.fromBytes = function(t, e, s) {
  return s ? Bt.fromBytesLE(t, e) : Bt.fromBytesBE(t, e);
};
Bt.fromBytesLE = function(t, e) {
  return new Bt(
    t[0] | t[1] << 8 | t[2] << 16 | t[3] << 24,
    t[4] | t[5] << 8 | t[6] << 16 | t[7] << 24,
    e
  );
};
Bt.fromBytesBE = function(t, e) {
  return new Bt(
    t[4] << 24 | t[5] << 16 | t[6] << 8 | t[7],
    t[0] << 24 | t[1] << 16 | t[2] << 8 | t[3],
    e
  );
};
var $b = e2(Sb);
var o2 = DC({
  __proto__: null,
  default: $b
}, [Sb]);
var uo = (
  // tslint:disable-next-line
  $b || o2
);
function xa(n) {
  return uo.fromString(n, true, 16);
}
var Gb = xa("c3a5c85c97cb3127");
var co = xa("b492b66fbe98f273");
var De = xa("9ae16a3b2f90404f");
function hd(n) {
  return n.xor(n.shru(47));
}
function Eb(n, t, e) {
  const s = n.slice(t, t + e);
  return uo.fromBytes(Array.from(s), true, true);
}
function Xt(n, t) {
  return Eb(n, t, 8);
}
function bm(n, t) {
  return Eb(n, t, 4);
}
function ge(n, t) {
  return t === 0 ? n : n.shru(t).or(n.shl(64 - t));
}
function zs(n, t, e = xa("9ddfea08eb382d69")) {
  let s = n.xor(t).mul(e);
  s = s.xor(s.shru(47));
  let o = t.xor(s).mul(e);
  return o = o.xor(o.shru(47)), o = o.mul(e), o;
}
function r2(n, t, e, s, o, r) {
  o = o.add(n), r = ge(r.add(o).add(s), 21);
  const i6 = o;
  return o = o.add(t), o = o.add(e), r = r.add(ge(o, 44)), [o.add(s), r.add(i6)];
}
function Za(n, t, e, s) {
  return r2(Xt(n, t), Xt(n, t + 8), Xt(n, t + 16), Xt(n, t + 24), e, s);
}
function i2(n, t = n.length) {
  if (t >= 8) {
    const e = De.add(t * 2), s = Xt(n, 0).add(De), o = Xt(n, t - 8), r = ge(o, 37).mul(e).add(s), i6 = ge(s, 25).add(o).mul(e);
    return zs(r, i6, e);
  }
  if (t >= 4) {
    const e = De.add(t * 2), s = bm(n, 0);
    return zs(s.shl(3).add(t), bm(n, t - 4), e);
  }
  if (t > 0) {
    const e = n[0], s = n[t >> 1], o = n[t - 1], r = e + (s << 8), i6 = t + (o << 2);
    return hd(De.mul(r).xor(Gb.mul(i6))).mul(De);
  }
  return De;
}
function a2(n, t = n.length) {
  const e = De.add(t * 2), s = Xt(n, 0).mul(co), o = Xt(n, 8), r = Xt(n, t - 8).mul(e), i6 = Xt(n, t - 16).mul(De);
  return zs(ge(s.add(o), 43).add(ge(r, 30)).add(i6), s.add(ge(o.add(De), 18)).add(r), e);
}
function l2(n, t = n.length) {
  const e = De.add(t * 2), s = Xt(n, 0).mul(De), o = Xt(n, 8), r = Xt(n, t - 8).mul(e), i6 = Xt(n, t - 16).mul(De), a = ge(s.add(o), 43).add(ge(r, 30)).add(i6), l = zs(a, s.add(ge(o.add(De), 18)).add(r), e), c = Xt(n, 16).mul(e), u = Xt(n, 24), d = a.add(Xt(n, t - 32)).mul(e), h = l.add(Xt(n, t - 24)).mul(e);
  return zs(ge(c.add(u), 43).add(ge(d, 30)).add(h), c.add(ge(u.add(s), 18)).add(d), e);
}
function Lb(n, t = n.length) {
  const e = uo.fromNumber(81, true);
  if (t <= 32)
    return t <= 16 ? i2(n, t) : a2(n, t);
  if (t <= 64)
    return l2(n, t);
  let s = e, o = e.mul(co).add(113), r = hd(o.mul(De).add(113)).mul(De), i6 = [uo.UZERO, uo.UZERO], a = [uo.UZERO, uo.UZERO];
  s = s.mul(De).add(Xt(n, 0));
  let l = 0;
  const c = (t - 1 >> 6) * 64, u = c + (t - 1 & 63) - 63;
  do
    s = ge(s.add(o).add(i6[0]).add(Xt(n, l + 8)), 37).mul(co), o = ge(o.add(i6[1]).add(Xt(n, l + 48)), 42).mul(co), s = s.xor(a[1]), o = o.add(i6[0]).add(Xt(n, l + 40)), r = ge(r.add(a[0]), 33).mul(co), i6 = Za(n, l, i6[1].mul(co), s.add(a[0])), a = Za(n, l + 32, r.add(a[1]), o.add(Xt(n, l + 16))), [r, s] = [s, r], l += 64;
  while (l !== c);
  const d = co.add(r.and(255).shl(1));
  return l = u, a[0] = a[0].add(t - 1 & 63), i6[0] = i6[0].add(a[0]), a[0] = a[0].add(i6[0]), s = ge(s.add(o).add(i6[0]).add(Xt(n, l + 8)), 37).mul(d), o = ge(o.add(i6[1]).add(Xt(n, l + 48)), 42).mul(d), s = s.xor(a[1].mul(9)), o = o.add(i6[0].mul(9).add(Xt(n, l + 40))), r = ge(r.add(a[0]), 33).mul(d), i6 = Za(n, l, i6[1].mul(d), s.add(a[0])), a = Za(n, l + 32, r.add(a[1]), o.add(Xt(n, l + 16))), [r, s] = [s, r], zs(zs(i6[0], a[0], d).add(hd(o).mul(Gb)).add(r), zs(i6[1], a[1], d).add(s), d);
}
function Is(n, t) {
  return t === "string" ? ms(n) : Qs([n], t);
}
function c2(n, t) {
  return n instanceof Float32Array && t === "float32" || n instanceof Int32Array && t === "int32" || n instanceof Uint8Array && t === "bool";
}
function Qs(n, t) {
  if (t === "string")
    throw new Error("Cannot convert a string[] to a TypedArray");
  if (Array.isArray(n) && (n = Ks(n)), F().getBool("DEBUG") && eb(n, t), c2(n, t))
    return n;
  if (t == null || t === "float32" || t === "complex64")
    return new Float32Array(n);
  if (t === "int32")
    return new Int32Array(n);
  if (t === "bool") {
    const e = new Uint8Array(n.length);
    for (let s = 0; s < e.length; ++s)
      Math.round(n[s]) !== 0 && (e[s] = 1);
    return e;
  } else
    throw new Error(`Unknown data type ${t}`);
}
function Ie() {
  return F().platform.now();
}
function u2(n, t) {
  return F().platform.fetch(n, t);
}
function ms(n, t = "utf-8") {
  return t = t || "utf-8", F().platform.encode(n, t);
}
function gs(n, t = "utf-8") {
  return t = t || "utf-8", F().platform.decode(n, t);
}
function qe(n) {
  return F().platform.isTypedArray != null ? F().platform.isTypedArray(n) : vb(n);
}
function Ks(n, t = [], e = false) {
  if (t == null && (t = []), typeof n == "boolean" || typeof n == "number" || typeof n == "string" || Ci(n) || n == null || qe(n) && e)
    t.push(n);
  else if (Array.isArray(n) || qe(n))
    for (let s = 0; s < n.length; ++s)
      Ks(n[s], t, e);
  else {
    let s = -1;
    for (const o of Object.keys(n))
      /^([1-9]+[0-9]*|0)$/.test(o) && (s = Math.max(s, Number(o)));
    for (let o = 0; o <= s; o++)
      Ks(n[o], t, e);
  }
  return t;
}
var QY = Object.freeze(Object.defineProperty({
  __proto__: null,
  arraysEqual: $t,
  arraysEqualWithNull: XC,
  assert: C,
  assertNonNegativeIntegerDimensions: is,
  assertNonNull: Hl,
  assertShapesMatch: Pe,
  bytesFromStringArray: sb,
  bytesPerElement: ri,
  checkConversionForErrors: eb,
  clamp: Os,
  computeStrides: dt,
  convertBackendValuesAndArrayBuffer: ib,
  createScalarValue: Is,
  createShuffledIndices: ZC,
  decodeString: gs,
  distSquared: AC,
  encodeString: ms,
  fetch: u2,
  fingerPrint64: Lb,
  flatten: Ks,
  getArrayFromDType: ne,
  getTypedArrayFromDType: Se,
  hasEncodingLoss: Qd,
  hexToLong: xa,
  indexToLoc: Xo,
  inferDtype: Oo,
  inferFromImplicitShape: Yd,
  isBoolean: ob,
  isFunction: Xs,
  isInt: Co,
  isNumber: pl,
  isPromise: Ci,
  isScalarShape: OC,
  isString: vr,
  isTypedArray: qe,
  isValidDtype: nb,
  locToIndex: zn,
  makeOnesTypedArray: _l,
  makeZerosNestedTypedArray: Jd,
  makeZerosTypedArray: ke,
  nearestDivisor: fl,
  nearestLargerEven: Bl,
  now: Ie,
  parseAxisParam: Ct,
  randUniform: PC,
  repeatedTry: id,
  rightPad: xo,
  shuffle: Ud,
  shuffleCombo: zC,
  sizeFromShape: X,
  sizeToSquarishShape: hl,
  squeezeShape: ws,
  sum: tb,
  swap: ds,
  tanh: KC,
  toNestedArray: kn,
  toTypedArray: Qs
}, Symbol.toStringTag, { value: "Module" }));
var d2 = class {
  constructor(t, e) {
    this.backendTimer = t, this.logger = e, e == null && (this.logger = new p2());
  }
  profileKernel(t, e, s) {
    let o;
    const r = () => {
      o = s();
    };
    let i6;
    const a = Ie();
    if (this.backendTimer.timerAvailable())
      i6 = this.backendTimer.time(r);
    else {
      r();
      for (const c of o)
        c.dataSync();
      i6 = Promise.resolve({ kernelMs: Ie() - a });
    }
    if (F().getBool("CHECK_COMPUTATION_FOR_ERRORS"))
      for (let c = 0; c < o.length; c++) {
        const u = o[c];
        u.data().then((d) => {
          h2(d, u.dtype, t);
        });
      }
    return {
      kernelName: t,
      outputs: o,
      inputs: e,
      timeMs: i6.then((c) => c.kernelMs),
      extraInfo: i6.then((c) => c.getExtraProfileInfo != null ? c.getExtraProfileInfo() : "")
    };
  }
  logKernelProfile(t) {
    const { kernelName: e, outputs: s, timeMs: o, inputs: r, extraInfo: i6 } = t;
    s.forEach((a) => {
      Promise.all([a.data(), o, i6]).then((l) => {
        this.logger.logKernelProfile(e, a, l[0], l[1], r, l[2]);
      });
    });
  }
};
function h2(n, t, e) {
  if (t !== "float32")
    return false;
  for (let s = 0; s < n.length; s++) {
    const o = n[s];
    if (isNaN(o) || !isFinite(o))
      return console.warn(`Found ${o} in the result of '${e}'`), true;
  }
  return false;
}
var p2 = class {
  logKernelProfile(t, e, s, o, r, i6) {
    const a = typeof o == "number" ? xo(`${o}ms`, 9) : o.error, l = xo(t, 25), c = e.rank, u = e.size, d = xo(e.shape.toString(), 14);
    let h = "";
    for (const p in r) {
      const f = r[p];
      if (f != null) {
        const m = f.shape || e.shape, g = m.length;
        h += `${p}: ${g}D ${g > 0 ? m : ""} `;
      }
    }
    console.log(`%c${l}	%c${a}	%c${c}D ${d}	%c${u}	%c${h}	%c${i6}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
  }
};
function f2(n, t, e) {
  const s = {}, o = {};
  for (let l = 0; l < t.length; l++)
    s[t[l].id] = true;
  for (let l = 0; l < n.length; l++) {
    const c = n[l], u = c.inputs;
    for (const d in u) {
      const h = u[d];
      let p = false;
      for (let f = 0; f < t.length; f++)
        if (s[h.id]) {
          c.outputs.forEach((m) => s[m.id] = true), p = true, o[c.id] = true;
          break;
        }
      if (p)
        break;
    }
  }
  const r = {};
  r[e.id] = true;
  const i6 = {};
  for (let l = n.length - 1; l >= 0; l--) {
    const c = n[l], u = c.inputs;
    for (let d = 0; d < c.outputs.length; d++)
      if (r[c.outputs[d].id]) {
        for (const h in u)
          r[u[h].id] = true, i6[c.id] = true;
        break;
      }
  }
  const a = [];
  for (let l = 0; l < n.length; l++) {
    const c = n[l];
    if (o[c.id] && i6[c.id]) {
      const u = {};
      for (const h in c.inputs) {
        const p = c.inputs[h];
        s[p.id] && (u[h] = p);
      }
      const d = Object.assign({}, c);
      d.inputs = u, d.outputs = c.outputs, a.push(d);
    }
  }
  return a;
}
function m2(n, t, e, s) {
  for (let o = t.length - 1; o >= 0; o--) {
    const r = t[o], i6 = [];
    if (r.outputs.forEach((l) => {
      const c = n[l.id];
      c != null ? i6.push(c) : i6.push(null);
    }), r.gradient == null)
      throw new Error(`Cannot compute gradient: gradient function not found for ${r.kernelName}.`);
    const a = r.gradient(i6);
    for (const l in r.inputs) {
      if (!(l in a))
        throw new Error(`Cannot backprop through input ${l}. Available gradients found: ${Object.keys(a)}.`);
      const c = e(() => a[l]());
      if (c.dtype !== "float32")
        throw new Error(`Error in gradient for op ${r.kernelName}. The gradient of input ${l} must have 'float32' dtype, but has '${c.dtype}'`);
      const u = r.inputs[l];
      if (!$t(c.shape, u.shape))
        throw new Error(`Error in gradient for op ${r.kernelName}. The gradient of input '${l}' has shape '${c.shape}', which does not match the shape of the input '${u.shape}'`);
      if (n[u.id] == null)
        n[u.id] = c;
      else {
        const d = n[u.id];
        n[u.id] = s(d, c), d.dispose();
      }
    }
  }
}
var xm = 20;
var Ar = 3;
var Gu = 7;
function g2(n, t, e, s) {
  const o = dt(t), r = b2(n, t, e, o), i6 = t.length, a = ol(n, t, e, o, r), l = ["Tensor"];
  return s && (l.push(`  dtype: ${e}`), l.push(`  rank: ${i6}`), l.push(`  shape: [${t}]`), l.push("  values:")), l.push(a.map((c) => "    " + c).join(`
`)), l.join(`
`);
}
function b2(n, t, e, s) {
  const o = X(t), r = s[s.length - 1], i6 = new Array(r).fill(0), a = t.length, l = e === "complex64" ? Ur(n) : n;
  if (a > 1)
    for (let c = 0; c < o / r; c++) {
      const u = c * r;
      for (let d = 0; d < r; d++)
        i6[d] = Math.max(i6[d], _r(l[u + d], 0, e).length);
    }
  return i6;
}
function _r(n, t, e) {
  let s;
  return Array.isArray(n) ? s = `${parseFloat(n[0].toFixed(Gu))} + ${parseFloat(n[1].toFixed(Gu))}j` : vr(n) ? s = `'${n}'` : e === "bool" ? s = Mb(n) : s = parseFloat(n.toFixed(Gu)).toString(), xo(s, t);
}
function Mb(n) {
  return n === 0 ? "false" : "true";
}
function ol(n, t, e, s, o, r = true) {
  const i6 = e === "complex64" ? 2 : 1, a = t[0], l = t.length;
  if (l === 0) {
    if (e === "complex64") {
      const m = Ur(n);
      return [_r(m[0], 0, e)];
    }
    return e === "bool" ? [Mb(n[0])] : [n[0].toString()];
  }
  if (l === 1) {
    if (a > xm) {
      const g = Ar * i6;
      let b = Array.from(n.slice(0, g)), x6 = Array.from(n.slice((a - Ar) * i6, a * i6));
      return e === "complex64" && (b = Ur(b), x6 = Ur(x6)), [
        "[" + b.map((w, y6) => _r(w, o[y6], e)).join(", ") + ", ..., " + x6.map((w, y6) => _r(w, o[a - Ar + y6], e)).join(", ") + "]"
      ];
    }
    return [
      "[" + (e === "complex64" ? Ur(n) : Array.from(n)).map((g, b) => _r(g, o[b], e)).join(", ") + "]"
    ];
  }
  const c = t.slice(1), u = s.slice(1), d = s[0] * i6, h = [];
  if (a > xm) {
    for (let m = 0; m < Ar; m++) {
      const g = m * d, b = g + d;
      h.push(...ol(
        n.slice(g, b),
        c,
        e,
        u,
        o,
        false
        /* isLast */
      ));
    }
    h.push("...");
    for (let m = a - Ar; m < a; m++) {
      const g = m * d, b = g + d;
      h.push(...ol(
        n.slice(g, b),
        c,
        e,
        u,
        o,
        m === a - 1
        /* isLast */
      ));
    }
  } else
    for (let m = 0; m < a; m++) {
      const g = m * d, b = g + d;
      h.push(...ol(
        n.slice(g, b),
        c,
        e,
        u,
        o,
        m === a - 1
        /* isLast */
      ));
    }
  const p = l === 2 ? "," : "";
  h[0] = "[" + (a > 0 ? h[0] + p : "");
  for (let m = 1; m < h.length - 1; m++)
    h[m] = " " + h[m] + p;
  let f = `,
`;
  for (let m = 2; m < l; m++)
    f += `
`;
  return h[h.length - 1] = " " + h[h.length - 1] + "]" + (r ? "" : f), h;
}
function Ur(n) {
  const t = [];
  for (let e = 0; e < n.length; e += 2)
    t.push([n[e], n[e + 1]]);
  return t;
}
var ve = class {
  constructor(t, e, s) {
    if (this.dtype = e, this.shape = t.slice(), this.size = X(t), s != null) {
      const o = s.length;
      C(o === this.size, () => `Length of values '${o}' does not match the size inferred by the shape '${this.size}'.`);
    }
    if (e === "complex64")
      throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
    this.values = s || ne(e, this.size), this.strides = dt(t);
  }
  /**
   * Sets a value in the buffer at a given location.
   *
   * @param value The value to set.
   * @param locs  The location indices.
   *
   * @doc {heading: 'Tensors', subheading: 'Creation'}
   */
  set(t, ...e) {
    e.length === 0 && (e = [0]), C(e.length === this.rank, () => `The number of provided coordinates (${e.length}) must match the rank (${this.rank})`);
    const s = this.locToIndex(e);
    this.values[s] = t;
  }
  /**
   * Returns the value in the buffer at the provided location.
   *
   * @param locs The location indices.
   *
   * @doc {heading: 'Tensors', subheading: 'Creation'}
   */
  get(...t) {
    t.length === 0 && (t = [0]);
    let e = 0;
    for (const o of t) {
      if (o < 0 || o >= this.shape[e]) {
        const r = `Requested out of range element at ${t}.   Buffer shape=${this.shape}`;
        throw new Error(r);
      }
      e++;
    }
    let s = t[t.length - 1];
    for (let o = 0; o < t.length - 1; ++o)
      s += this.strides[o] * t[o];
    return this.values[s];
  }
  locToIndex(t) {
    if (this.rank === 0)
      return 0;
    if (this.rank === 1)
      return t[0];
    let e = t[t.length - 1];
    for (let s = 0; s < t.length - 1; ++s)
      e += this.strides[s] * t[s];
    return e;
  }
  indexToLoc(t) {
    if (this.rank === 0)
      return [];
    if (this.rank === 1)
      return [t];
    const e = new Array(this.shape.length);
    for (let s = 0; s < e.length - 1; ++s)
      e[s] = Math.floor(t / this.strides[s]), t -= e[s] * this.strides[s];
    return e[e.length - 1] = t, e;
  }
  get rank() {
    return this.shape.length;
  }
  /**
   * Creates an immutable `tf.Tensor` object from the buffer.
   *
   * @doc {heading: 'Tensors', subheading: 'Creation'}
   */
  toTensor() {
    return Dn().makeTensor(this.values, this.shape, this.dtype);
  }
};
var Dn = null;
var or = null;
function x2(n) {
  Dn = n;
}
function y2(n) {
  or = n;
}
var Mt = class {
  constructor(t, e, s, o) {
    this.kept = false, this.isDisposedInternal = false, this.shape = t.slice(), this.dtype = e || "float32", this.size = X(t), this.strides = dt(t), this.dataId = s, this.id = o, this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
  }
  get rank() {
    return this.shape.length;
  }
  /**
   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  async buffer() {
    const t = await this.data();
    return or.buffer(this.shape, this.dtype, t);
  }
  /**
   * Returns a `tf.TensorBuffer` that holds the underlying data.
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  bufferSync() {
    return or.buffer(this.shape, this.dtype, this.dataSync());
  }
  /**
   * Returns the tensor data as a nested array. The transfer of data is done
   * asynchronously.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  async array() {
    const t = await this.data();
    return kn(this.shape, t, this.dtype === "complex64");
  }
  /**
   * Returns the tensor data as a nested array. The transfer of data is done
   * synchronously.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  arraySync() {
    return kn(this.shape, this.dataSync(), this.dtype === "complex64");
  }
  /**
   * Asynchronously downloads the values from the `tf.Tensor`. Returns a
   * promise of `TypedArray` that resolves when the computation has finished.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  async data() {
    this.throwIfDisposed();
    const t = Dn().read(this.dataId);
    if (this.dtype === "string") {
      const e = await t;
      try {
        return e.map((s) => gs(s));
      } catch {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    }
    return t;
  }
  /**
   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`
   * and `data()`, this method prevents data from being downloaded to CPU.
   *
   * For WebGL backend, the data will be stored on a densely packed texture.
   * This means that the texture will use the RGBA channels to store value.
   *
   * For WebGPU backend, the data will be stored on a buffer. There is no
   * parameter, so can not use a user-defined size to create the buffer.
   *
   * @param options:
   *     For WebGL,
   *         - customTexShape: Optional. If set, will use the user defined
   *     texture shape to create the texture.
   *
   * @returns For WebGL backend, a GPUData contains the new texture and
   *     its information.
   *     {
   *        tensorRef: The tensor that is associated with this texture,
   *        texture: WebGLTexture,
   *        texShape: [number, number] // [height, width]
   *     }
   *
   *     For WebGPU backend, a GPUData contains the new buffer.
   *     {
   *        tensorRef: The tensor that is associated with this buffer,
   *        buffer: GPUBuffer,
   *     }
   *
   *     Remember to dispose the GPUData after it is used by
   *     `res.tensorRef.dispose()`.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  dataToGPU(t) {
    return this.throwIfDisposed(), Dn().readToGPU(this.dataId, t);
  }
  /**
   * Synchronously downloads the values from the `tf.Tensor`. This blocks the
   * UI thread until the values are ready, which can cause performance issues.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  dataSync() {
    this.throwIfDisposed();
    const t = Dn().readSync(this.dataId);
    if (this.dtype === "string")
      try {
        return t.map((e) => gs(e));
      } catch {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    return t;
  }
  /** Returns the underlying bytes of the tensor's data. */
  async bytes() {
    this.throwIfDisposed();
    const t = await Dn().read(this.dataId);
    return this.dtype === "string" ? t : new Uint8Array(t.buffer);
  }
  /**
   * Disposes `tf.Tensor` from memory.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  dispose() {
    this.isDisposed || (this.kerasMask && this.kerasMask.dispose(), Dn().disposeTensor(this), this.isDisposedInternal = true);
  }
  get isDisposed() {
    return this.isDisposedInternal;
  }
  throwIfDisposed() {
    if (this.isDisposed)
      throw new Error("Tensor is disposed.");
  }
  /**
   * Prints the `tf.Tensor`. See `tf.print` for details.
   *
   * @param verbose Whether to print verbose information about the tensor,
   *    including dtype and size.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  print(t = false) {
    return or.print(this, t);
  }
  /**
   * Returns a copy of the tensor. See `tf.clone` for details.
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  clone() {
    return this.throwIfDisposed(), or.clone(this);
  }
  /**
   * Returns a human-readable description of the tensor. Useful for logging.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  toString(t = false) {
    const e = this.dataSync();
    return g2(e, this.shape, this.dtype, t);
  }
  cast(t) {
    return this.throwIfDisposed(), or.cast(this, t);
  }
  variable(t = true, e, s) {
    return this.throwIfDisposed(), Dn().makeVariable(this, t, e, s);
  }
};
Object.defineProperty(Mt, Symbol.hasInstance, {
  value: (n) => !!n && n.data != null && n.dataSync != null && n.throwIfDisposed != null
});
function K() {
  return jd("Tensor", () => Mt);
}
K();
var yl = class extends Mt {
  constructor(t, e, s, o) {
    super(t.shape, t.dtype, t.dataId, o), this.trainable = e, this.name = s;
  }
  /**
   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have
   * the same shape and dtype as the old `tf.Tensor`.
   *
   * @param newValue New tensor to be assigned to this variable.
   *
   * @doc {heading: 'Tensors', subheading: 'Classes'}
   */
  assign(t) {
    if (t.dtype !== this.dtype)
      throw new Error(`dtype of the new value (${t.dtype}) and previous value (${this.dtype}) must match`);
    if (!$t(t.shape, this.shape))
      throw new Error(`shape of the new value (${t.shape}) and previous value (${this.shape}) must match`);
    Dn().disposeTensor(this), this.dataId = t.dataId, Dn().incRef(
      this,
      null
      /* backend */
    );
  }
  dispose() {
    Dn().disposeVariable(this), this.isDisposedInternal = true;
  }
};
Object.defineProperty(yl, Symbol.hasInstance, {
  value: (n) => n instanceof Mt && n.assign != null && n.assign instanceof Function
});
var ym;
(function(n) {
  n.R0 = "R0", n.R1 = "R1", n.R2 = "R2", n.R3 = "R3", n.R4 = "R4", n.R5 = "R5", n.R6 = "R6";
})(ym || (ym = {}));
var pd;
(function(n) {
  n.float32 = "float32", n.int32 = "int32", n.bool = "int32", n.complex64 = "complex64";
})(pd || (pd = {}));
var fd;
(function(n) {
  n.float32 = "float32", n.int32 = "int32", n.bool = "bool", n.complex64 = "complex64";
})(fd || (fd = {}));
var md;
(function(n) {
  n.float32 = "float32", n.int32 = "float32", n.bool = "float32", n.complex64 = "complex64";
})(md || (md = {}));
var gd;
(function(n) {
  n.float32 = "complex64", n.int32 = "complex64", n.bool = "complex64", n.complex64 = "complex64";
})(gd || (gd = {}));
var w2 = {
  float32: md,
  int32: pd,
  bool: fd,
  complex64: gd
};
function tn(n, t) {
  if (n === "string" || t === "string") {
    if (n === "string" && t === "string")
      return "string";
    throw new Error(`Can not upcast ${n} with ${t}`);
  }
  return w2[n][t];
}
function Yh(n) {
  return tn(n, "int32");
}
function Wb(n) {
  return n != null && typeof n == "object" && "texture" in n && n.texture instanceof WebGLTexture;
}
function Db(n) {
  return typeof GPUBuffer < "u" && n != null && typeof n == "object" && "buffer" in n && n.buffer instanceof GPUBuffer;
}
function se(n, t) {
  if (n.dtype === t.dtype)
    return [n, t];
  const e = tn(n.dtype, t.dtype);
  return [n.cast(e), t.cast(e)];
}
function I2(n, t) {
  C(n.dtype === t.dtype, () => `The dtypes of the first(${n.dtype}) and second(${t.dtype}) input must match`);
}
function Yc(n, t) {
  return t.some((e) => e.id === n.id);
}
function bs(n) {
  const t = [];
  return Fb(n, t, /* @__PURE__ */ new Set()), t;
}
function Fb(n, t, e) {
  if (n == null)
    return;
  if (n instanceof Mt) {
    t.push(n);
    return;
  }
  if (!C2(n))
    return;
  const s = n;
  for (const o in s) {
    const r = s[o];
    e.has(r) || (e.add(r), Fb(r, t, e));
  }
}
function C2(n) {
  return Array.isArray(n) || typeof n == "object";
}
var JY = Object.freeze(Object.defineProperty({
  __proto__: null,
  assertTypesMatch: I2,
  getTensorsInContainer: bs,
  isTensorInList: Yc,
  makeTypesMatch: se
}, Symbol.toStringTag, { value: "Module" }));
function Eu(n) {
  return n.kernelName != null;
}
var wm = class {
  constructor() {
    this.registeredVariables = {}, this.nextTapeNodeId = 0, this.numBytes = 0, this.numTensors = 0, this.numStringTensors = 0, this.numDataBuffers = 0, this.gradientDepth = 0, this.kernelDepth = 0, this.scopeStack = [], this.numDataMovesStack = [], this.nextScopeId = 0, this.tensorInfo = /* @__PURE__ */ new WeakMap(), this.profiling = false, this.activeProfile = {
      newBytes: 0,
      newTensors: 0,
      peakBytes: 0,
      kernels: [],
      result: null,
      get kernelNames() {
        return Array.from(new Set(this.kernels.map((t) => t.name)));
      }
    };
  }
  dispose() {
    for (const t in this.registeredVariables)
      this.registeredVariables[t].dispose();
  }
};
var mr = class _mr {
  constructor(t) {
    this.ENV = t, this.registry = {}, this.registryFactory = {}, this.pendingBackendInitId = 0, this.state = new wm();
  }
  async ready() {
    if (this.pendingBackendInit != null)
      return this.pendingBackendInit.then(() => {
      });
    if (this.backendInstance != null)
      return;
    const t = this.getSortedBackends();
    for (let e = 0; e < t.length; e++) {
      const s = t[e];
      if (await this.initializeBackend(s).success) {
        await this.setBackend(s);
        return;
      }
    }
    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }
  get backend() {
    if (this.pendingBackendInit != null)
      throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
    if (this.backendInstance == null) {
      const { name: t, asyncInit: e } = this.initializeBackendsAndReturnBest();
      if (e)
        throw new Error(`The highest priority backend '${t}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
      this.setBackend(t);
    }
    return this.backendInstance;
  }
  backendNames() {
    return Object.keys(this.registryFactory);
  }
  findBackend(t) {
    if (!(t in this.registry))
      if (t in this.registryFactory) {
        const { asyncInit: e } = this.initializeBackend(t);
        if (e)
          return null;
      } else
        return null;
    return this.registry[t];
  }
  findBackendFactory(t) {
    return t in this.registryFactory ? this.registryFactory[t].factory : null;
  }
  registerBackend(t, e, s = 1) {
    return t in this.registryFactory ? (ln(`${t} backend was already registered. Reusing existing backend factory.`), false) : (this.registryFactory[t] = { factory: e, priority: s }, true);
  }
  async setBackend(t) {
    if (this.registryFactory[t] == null)
      throw new Error(`Backend name '${t}' not found in registry`);
    if (this.backendName = t, this.registry[t] == null) {
      this.backendInstance = null;
      const { success: e, asyncInit: s } = this.initializeBackend(t);
      if (!(s ? await e : e))
        return false;
    }
    return this.backendInstance = this.registry[t], this.setupRegisteredKernels(), this.profiler = new d2(this.backendInstance), true;
  }
  setupRegisteredKernels() {
    ud(this.backendName).forEach((e) => {
      e.setupFunc != null && e.setupFunc(this.backendInstance);
    });
  }
  disposeRegisteredKernels(t) {
    ud(t).forEach((s) => {
      s.disposeFunc != null && s.disposeFunc(this.registry[t]);
    });
  }
  /**
   * Initializes a backend by looking up the backend name in the factory
   * registry and calling the factory method. Returns a boolean representing
   * whether the initialization of the backend suceeded. Throws an error if
   * there is no backend in the factory registry.
   */
  initializeBackend(t) {
    const e = this.registryFactory[t];
    if (e == null)
      throw new Error(`Cannot initialize backend ${t}, no registration found.`);
    try {
      const s = e.factory();
      if (s && !(s instanceof _d) && typeof s.then == "function") {
        const o = ++this.pendingBackendInitId, r = s.then((i6) => o < this.pendingBackendInitId ? false : (this.registry[t] = i6, this.pendingBackendInit = null, true)).catch((i6) => (o < this.pendingBackendInitId || (this.pendingBackendInit = null, ln(`Initialization of backend ${t} failed`), ln(i6.stack || i6.message)), false));
        return this.pendingBackendInit = r, { success: r, asyncInit: true };
      } else
        return this.registry[t] = s, { success: true, asyncInit: false };
    } catch (s) {
      return ln(`Initialization of backend ${t} failed`), ln(s.stack || s.message), { success: false, asyncInit: false };
    }
  }
  removeBackend(t) {
    if (!(t in this.registryFactory))
      throw new Error(`${t} backend not found in registry`);
    this.backendName === t && this.pendingBackendInit != null && this.pendingBackendInitId++, t in this.registry && (this.disposeRegisteredKernels(t), this.registry[t].dispose(), delete this.registry[t]), delete this.registryFactory[t], this.backendName === t && (this.pendingBackendInit = null, this.backendName = null, this.backendInstance = null);
  }
  getSortedBackends() {
    if (Object.keys(this.registryFactory).length === 0)
      throw new Error("No backend found in registry.");
    return Object.keys(this.registryFactory).sort((t, e) => this.registryFactory[e].priority - this.registryFactory[t].priority);
  }
  initializeBackendsAndReturnBest() {
    const t = this.getSortedBackends();
    for (let e = 0; e < t.length; e++) {
      const s = t[e], { success: o, asyncInit: r } = this.initializeBackend(s);
      if (r || o)
        return { name: s, asyncInit: r };
    }
    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }
  moveData(t, e) {
    const s = this.state.tensorInfo.get(e), o = s.backend, r = this.readSync(e), i6 = o.refCount(e);
    o.disposeData(e, true), s.backend = t, t.move(e, r, s.shape, s.dtype, i6), this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
  }
  tidy(t, e) {
    let s = null;
    if (e == null) {
      if (typeof t != "function")
        throw new Error("Please provide a function to tidy()");
      e = t;
    } else {
      if (typeof t != "string" && !(t instanceof String))
        throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
      if (typeof e != "function")
        throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
      s = t;
    }
    let o;
    return this.scopedRun(() => this.startScope(s), () => this.endScope(o), () => (o = e(), o instanceof Promise && console.error("Cannot return a Promise inside of tidy."), o));
  }
  scopedRun(t, e, s) {
    t();
    try {
      const o = s();
      return e(), o;
    } catch (o) {
      throw e(), o;
    }
  }
  nextTensorId() {
    return _mr.nextTensorId++;
  }
  nextVariableId() {
    return _mr.nextVariableId++;
  }
  /**
   * This method is called instead of the public-facing tensor.clone() when
   * saving a tensor for backwards pass. It makes sure to add the clone
   * operation to the tape regardless of being called inside a kernel
   * execution.
   */
  clone(t) {
    const e = $.runKernel(Ki, { x: t }), s = { x: t }, o = (i6) => ({
      x: () => {
        const a = "float32", l = { x: i6 }, c = { dtype: a };
        return $.runKernel(
          Gi,
          l,
          // tslint:disable-next-line: no-unnecessary-type-assertion
          c
        );
      }
    }), r = [];
    return this.addTapeNode(this.state.activeScope.name, s, [e], o, r, {}), e;
  }
  /**
   * Execute a kernel with the given name and return the output tensor.
   *
   * @param kernelName The name of the kernel to execute.
   * @param inputs A map of input names to tensors.
   * @param attrs A map of attribute names to their values. An attribute is a
   *     primitive (non-tensor) input to the kernel.
   * @param inputsToSave A list of tensors, inputs to save for the backprop
   *     computation.
   * @param outputsToSave A list of booleans, specifying which output to save
   *     for the backprop computation. These are booleans since the output
   * tensors are not visible to the user.
   */
  runKernel(t, e, s) {
    if (this.backendName == null && this.backend, !(bl(t, this.backendName) != null))
      throw new Error(`Kernel '${t}' not registered for backend '${this.backendName}'`);
    return this.runKernelFunc({ kernelName: t, inputs: e, attrs: s });
  }
  shouldCheckForMemLeaks() {
    return this.ENV.getBool("IS_TEST");
  }
  checkKernelForMemLeak(t, e, s) {
    const o = this.backend.numDataIds();
    let r = 0;
    s.forEach((l) => {
      r += l.dtype === "complex64" ? 3 : 1;
    });
    const i6 = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1], a = o - e - r - i6;
    if (a > 0)
      throw new Error(`Backend '${this.backendName}' has an internal memory leak (${a} data ids) after running '${t}'`);
  }
  /**
   * Internal helper method to execute a kernel Func
   *
   * Use `runKernel` to execute kernels from outside of engine.
   */
  runKernelFunc(t) {
    let e, s = [];
    const o = this.isTapeOn(), r = this.state.numBytes, i6 = this.state.numTensors;
    this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0);
    let a;
    this.backendName == null && this.backend;
    let l;
    const c = Eu(t) ? t.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
    if (Eu(t)) {
      const { kernelName: f, inputs: m, attrs: g } = t;
      this.backendName == null && this.backend;
      const b = bl(f, this.backendName);
      C(b != null, () => `Cannot find registered kernel '${f}' for backend '${this.backendName}'`), a = () => {
        const x6 = this.backend.numDataIds();
        l = b.kernelFunc({ inputs: m, attrs: g, backend: this.backend });
        const w = Array.isArray(l) ? l : [l];
        this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(f, x6, w);
        const y6 = w.map((I) => I.rank != null ? I : this.makeTensorFromTensorInfo(I));
        if (o) {
          const I = this.getTensorsForGradient(f, m, y6);
          s = this.saveTensorsForBackwardMode(I);
        }
        return y6;
      };
    } else {
      const { forwardFunc: f } = t, m = (g) => {
        o && (s = g.map((b) => this.keep(this.clone(b))));
      };
      a = () => {
        const g = this.backend.numDataIds();
        l = this.tidy(() => f(this.backend, m));
        const b = Array.isArray(l) ? l : [l];
        return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(c, g, b), b;
      };
    }
    const { inputs: u, attrs: d } = t, h = Eu(t) ? null : t.backwardsFunc;
    let p;
    return this.scopedRun(
      // Stop recording to a tape when running a kernel.
      () => this.state.kernelDepth++,
      () => this.state.kernelDepth--,
      () => {
        !this.ENV.getBool("DEBUG") && !this.state.profiling ? e = a() : (p = this.profiler.profileKernel(c, u, () => a()), this.ENV.getBool("DEBUG") && this.profiler.logKernelProfile(p), e = p.outputs);
      }
    ), o && this.addTapeNode(c, u, e, h, s, d), this.state.profiling && this.state.activeProfile.kernels.push({
      name: c,
      bytesAdded: this.state.numBytes - r,
      totalBytesSnapshot: this.state.numBytes,
      tensorsAdded: this.state.numTensors - i6,
      totalTensorsSnapshot: this.state.numTensors,
      inputShapes: Object.keys(u).map((f) => u[f] != null ? u[f].shape : null),
      outputShapes: e.map((f) => f.shape),
      kernelTimeMs: p.timeMs,
      extraInfo: p.extraInfo
    }), Array.isArray(l) ? e : e[0];
  }
  /**
   * Saves tensors used in forward mode for use in backward mode.
   *
   * @param tensors the list of tensors to save.
   */
  saveTensorsForBackwardMode(t) {
    return t.map((s) => this.keep(this.clone(s)));
  }
  /**
   * Returns a list of tensors to save for a given gradient calculation.
   *
   * @param kernelName name of kernel to look up gradient for.
   * @param inputs a map of input tensors.
   * @param outputs an array of output tensors from forward mode of kernel.
   */
  getTensorsForGradient(t, e, s) {
    const o = dm(t);
    if (o != null) {
      const r = o.inputsToSave || [], i6 = o.outputsToSave || [];
      let a;
      o.saveAllInputs ? (C(Array.isArray(e), () => "saveAllInputs is true, expected inputs to be an array."), a = Object.keys(e).map((c) => e[c])) : a = r.map((c) => e[c]);
      const l = s.filter((c, u) => i6[u]);
      return a.concat(l);
    }
    return [];
  }
  /**
   * Internal method used by public APIs for tensor creation. Makes a new
   * tensor with the provided shape, dtype and values. It always
   * creates a new data id and writes the values to the underlying backend.
   */
  makeTensor(t, e, s, o) {
    if (t == null)
      throw new Error("Values passed to engine.makeTensor() are null");
    s = s || "float32", o = o || this.backend;
    let r = t;
    s === "string" && vr(t[0]) && (r = t.map((l) => ms(l)));
    const i6 = o.write(r, e, s), a = new Mt(e, s, i6, this.nextTensorId());
    if (this.trackTensor(a, o), s === "string") {
      const l = this.state.tensorInfo.get(i6), c = sb(r);
      this.state.numBytes += c - l.bytes, l.bytes = c;
    }
    return a;
  }
  /**
   * Internal method used by backends. Makes a new tensor
   * that is a wrapper around an existing data id. It doesn't create
   * a new data id, only increments the ref count used in memory tracking.
   * @deprecated
   */
  makeTensorFromDataId(t, e, s, o) {
    s = s || "float32";
    const r = { dataId: t, shape: e, dtype: s };
    return this.makeTensorFromTensorInfo(r, o);
  }
  /**
   * Internal method used by backends. Makes a new tensor that is a wrapper
   * around an existing data id in TensorInfo. It doesn't create a new data id,
   * only increments the ref count used in memory tracking.
   */
  makeTensorFromTensorInfo(t, e) {
    const { dataId: s, shape: o, dtype: r } = t, i6 = new Mt(o, r, s, this.nextTensorId());
    return this.trackTensor(i6, e), i6;
  }
  makeVariable(t, e = true, s, o) {
    s = s || this.nextVariableId().toString(), o != null && o !== t.dtype && (t = t.cast(o));
    const r = new yl(t, e, s, this.nextTensorId());
    if (this.state.registeredVariables[r.name] != null)
      throw new Error(`Variable with name ${r.name} was already registered`);
    return this.state.registeredVariables[r.name] = r, this.incRef(r, this.backend), r;
  }
  trackTensor(t, e) {
    this.state.numTensors++, t.dtype === "string" && this.state.numStringTensors++;
    let s = 0;
    t.dtype !== "complex64" && t.dtype !== "string" && (s = t.size * ri(t.dtype)), this.state.numBytes += s, this.state.tensorInfo.has(t.dataId) || (this.state.numDataBuffers++, this.state.tensorInfo.set(t.dataId, {
      backend: e || this.backend,
      dtype: t.dtype,
      shape: t.shape,
      bytes: s
    })), t instanceof yl || this.track(t);
  }
  // Track the tensor by dataId and increase the refCount for the dataId in the
  // backend.
  // TODO(pyu10055): This is currently used by makeVariable method, to increase
  // refCount on the backend for the dataId. It can potentially be replaced with
  // Identity op indead of calling backend directly.
  incRef(t, e) {
    this.trackTensor(t, e), this.backend.incRef(t.dataId);
  }
  removeDataId(t, e) {
    this.state.tensorInfo.has(t) && this.state.tensorInfo.get(t).backend === e && (this.state.tensorInfo.delete(t), this.state.numDataBuffers--);
  }
  disposeTensor(t) {
    if (!this.state.tensorInfo.has(t.dataId))
      return;
    const e = this.state.tensorInfo.get(t.dataId);
    if (this.state.numTensors--, t.dtype === "string" && (this.state.numStringTensors--, this.state.numBytes -= e.bytes), t.dtype !== "complex64" && t.dtype !== "string") {
      const s = t.size * ri(t.dtype);
      this.state.numBytes -= s;
    }
    e.backend.disposeData(t.dataId) && this.removeDataId(t.dataId, e.backend);
  }
  disposeVariables() {
    for (const t in this.state.registeredVariables) {
      const e = this.state.registeredVariables[t];
      this.disposeVariable(e);
    }
  }
  disposeVariable(t) {
    this.disposeTensor(t), this.state.registeredVariables[t.name] != null && delete this.state.registeredVariables[t.name];
  }
  memory() {
    const t = this.backend.memory();
    return t.numTensors = this.state.numTensors, t.numDataBuffers = this.state.numDataBuffers, t.numBytes = this.state.numBytes, this.state.numStringTensors > 0 && (t.unreliable = true, t.reasons == null && (t.reasons = []), t.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")), t;
  }
  async profile(t) {
    this.state.profiling = true;
    const e = this.state.numBytes, s = this.state.numTensors;
    this.state.activeProfile.kernels = [], this.state.activeProfile.result = await t(), this.state.profiling = false, this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((o) => o.totalBytesSnapshot)), this.state.activeProfile.newBytes = this.state.numBytes - e, this.state.activeProfile.newTensors = this.state.numTensors - s;
    for (const o of this.state.activeProfile.kernels)
      o.kernelTimeMs = await o.kernelTimeMs, o.extraInfo = await o.extraInfo;
    return this.state.activeProfile;
  }
  isTapeOn() {
    return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
  }
  addTapeNode(t, e, s, o, r, i6) {
    const a = { id: this.state.nextTapeNodeId++, kernelName: t, inputs: e, outputs: s, saved: r }, l = dm(t);
    l != null && (o = l.gradFunc), o != null && (a.gradient = (c) => (c = c.map((u, d) => {
      if (u == null) {
        const h = s[d], p = ke(h.size, h.dtype);
        return this.makeTensor(p, h.shape, h.dtype);
      }
      return u;
    }), o(c.length > 1 ? c : c[0], r, i6))), this.state.activeTape.push(a);
  }
  keep(t) {
    return t.kept = true, t;
  }
  startTape() {
    this.state.gradientDepth === 0 && (this.state.activeTape = []), this.state.gradientDepth++;
  }
  endTape() {
    this.state.gradientDepth--;
  }
  /**
   * Start a scope. Use this with endScope() to achieve the same functionality
   * as scope() without the need for a function closure.
   */
  startScope(t) {
    const e = {
      track: [],
      name: "unnamed scope",
      id: this.state.nextScopeId++
    };
    t && (e.name = t), this.state.scopeStack.push(e), this.state.activeScope = e;
  }
  /**
   * End a scope. Use this with startScope() to achieve the same functionality
   * as scope() without the need for a function closure.
   */
  endScope(t) {
    const e = bs(t), s = new Set(e.map((r) => r.id));
    for (let r = 0; r < this.state.activeScope.track.length; r++) {
      const i6 = this.state.activeScope.track[r];
      !i6.kept && !s.has(i6.id) && i6.dispose();
    }
    const o = this.state.scopeStack.pop();
    this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1], e.forEach((r) => {
      !r.kept && r.scopeId === o.id && this.track(r);
    });
  }
  /**
   * Returns gradients of `f` with respect to each of the `xs`. The gradients
   * returned are of the same length as `xs`, but some might be null if `f`
   * was not a function of that `x`. It also takes optional dy to multiply the
   * gradient, which defaults to `1`.
   */
  gradients(t, e, s, o = false) {
    if (C(e.length > 0, () => "gradients() received an empty list of xs."), s != null && s.dtype !== "float32")
      throw new Error(`dy must have 'float32' dtype, but has '${s.dtype}'`);
    const r = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", t));
    C(r instanceof Mt, () => "The result y returned by f() must be a tensor.");
    const i6 = f2(this.state.activeTape, e, r);
    if (!o && i6.length === 0 && e.length > 0)
      throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
    return this.tidy("backward", () => {
      const a = {};
      a[r.id] = s ?? v2(r.shape), m2(
        a,
        i6,
        // Pass the tidy function to avoid circular dep with `tape.ts`.
        (c) => this.tidy(c),
        // Pass an add function to avoide a circular dep with `tape.ts`.
        S2
      );
      const l = e.map((c) => a[c.id]);
      return this.state.gradientDepth === 0 && (this.state.activeTape.forEach((c) => {
        for (const u of c.saved)
          u.dispose();
      }), this.state.activeTape = null), { value: r, grads: l };
    });
  }
  customGrad(t) {
    return C(Xs(t), () => "The f passed in customGrad(f) must be a function."), (...e) => {
      C(e.every((a) => a instanceof Mt), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
      let s;
      const o = {};
      e.forEach((a, l) => {
        o[l] = a;
      });
      const r = (a, l) => (s = t(...e, l), C(s.value instanceof Mt, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"), C(Xs(s.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."), s.value), i6 = (a, l) => {
        const c = s.gradFunc(a, l), u = Array.isArray(c) ? c : [c];
        C(u.length === e.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."), C(u.every((h) => h instanceof Mt), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
        const d = {};
        return u.forEach((h, p) => {
          d[p] = () => h;
        }), d;
      };
      return this.runKernelFunc({
        forwardFunc: r,
        backwardsFunc: i6,
        inputs: o
      });
    };
  }
  readSync(t) {
    return this.state.tensorInfo.get(t).backend.readSync(t);
  }
  read(t) {
    return this.state.tensorInfo.get(t).backend.read(t);
  }
  readToGPU(t, e) {
    return this.state.tensorInfo.get(t).backend.readToGPU(t, e);
  }
  async time(t) {
    const e = Ie(), s = await this.backend.time(t);
    return s.wallMs = Ie() - e, s;
  }
  /**
   * Tracks a Tensor in the current scope to be automatically cleaned up
   * when the current scope ends, and returns the value.
   *
   * @param result The Tensor to track in the current scope.
   */
  track(t) {
    return this.state.activeScope != null && (t.scopeId = this.state.activeScope.id, this.state.activeScope.track.push(t)), t;
  }
  get registeredVariables() {
    return this.state.registeredVariables;
  }
  /**
   * Resets the engine state. Removes all backends but does not remove
   * registered backend factories.
   */
  reset() {
    this.pendingBackendInitId++, this.state.dispose(), this.ENV.reset(), this.state = new wm();
    for (const t in this.registry)
      this.disposeRegisteredKernels(t), this.registry[t].dispose(), delete this.registry[t];
    this.backendName = null, this.backendInstance = null, this.pendingBackendInit = null;
  }
};
mr.nextTensorId = 0;
mr.nextVariableId = 0;
function v2(n) {
  const t = _l(X(n), "float32");
  return $.makeTensor(t, n, "float32");
}
function Vb() {
  const n = lb();
  if (n._tfengine == null) {
    const t = new BC(n);
    n._tfengine = new mr(t);
  }
  return YC(n._tfengine.ENV), x2(() => n._tfengine), n._tfengine;
}
var $ = Vb();
function S2(n, t) {
  const e = { a: n, b: t };
  return $.runKernel(Sr, e);
}
function k2() {
  return typeof navigator < "u" && navigator != null;
}
var bd;
function T2(n) {
  bd = n;
}
function Qh(n) {
  if (bd !== void 0)
    return bd;
  if (n || k2()) {
    if (n || (n = navigator), n.product === "ReactNative")
      return true;
    const t = n.userAgent || n.vendor || // tslint:disable-next-line:no-any
    (typeof window < "u" ? window.opera : "");
    if (!t) {
      const e = n;
      return e.userAgentData && e.userAgentData.mobile;
    }
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t) || // tslint:disable-next-line:max-line-length
    /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0, 4));
  }
  return false;
}
function Jh() {
  return typeof window < "u" && window.document != null || //@ts-ignore
  typeof WorkerGlobalScope < "u";
}
var jY = Object.freeze(Object.defineProperty({
  __proto__: null,
  isBrowser: Jh,
  isMobile: Qh,
  mockIsMobile: T2
}, Symbol.toStringTag, { value: "Module" }));
var Be = F();
Be.registerFlag("DEBUG", () => false, (n) => {
  n && console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
});
Be.registerFlag("IS_BROWSER", () => Jh());
Be.registerFlag("IS_NODE", () => typeof process < "u" && typeof process.versions < "u" && typeof process.versions.node < "u");
Be.registerFlag("IS_CHROME", () => typeof navigator < "u" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
Be.registerFlag("IS_SAFARI", () => typeof navigator < "u" && navigator != null && navigator.userAgent != null && /Safari/.test(navigator.userAgent) && /Apple/.test(navigator.vendor));
Be.registerFlag("PROD", () => false);
Be.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => Be.getBool("DEBUG"));
Be.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
Be.registerFlag("IS_TEST", () => false);
Be.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => Be.getBool("DEBUG"));
Be.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);
Be.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", () => false);
Be.registerFlag("USE_SETTIMEOUTCUSTOM", () => false);
function ya(n, t) {
  let e = n;
  if (qe(n))
    return t === "string" ? [] : [n.length];
  if (Wb(n)) {
    const o = n.channels || "RGBA";
    return [n.height, n.width * o.length];
  } else if (Db(n))
    return [n.buffer.size / (t == null ? 4 : ri(t))];
  if (!Array.isArray(n))
    return [];
  const s = [];
  for (; Array.isArray(e) || qe(e) && t !== "string"; )
    s.push(e.length), e = e[0];
  return Array.isArray(n) && F().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY") && zb(n, s, []), s;
}
function zb(n, t, e) {
  if (e = e || [], !Array.isArray(n) && !qe(n)) {
    C(t.length === 0, () => `Element arr[${e.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`);
    return;
  }
  C(t.length > 0, () => `Element arr[${e.join("][")}] should be a primitive, but is an array of ${n.length} elements`), C(n.length === t[0], () => `Element arr[${e.join("][")}] should have ${t[0]} elements, but has ${n.length} elements`);
  const s = t.slice(1);
  for (let o = 0; o < n.length; ++o)
    zb(n[o], s, e.concat(o));
}
function Im(n, t, e, s) {
  if (n !== "string_or_numeric") {
    if (n == null)
      throw new Error("Expected dtype cannot be null.");
    if (n !== "numeric" && n !== t || n === "numeric" && t === "string")
      throw new Error(`Argument '${e}' passed to '${s}' must be ${n} tensor, but got ${t} tensor`);
  }
}
function T(n, t, e, s = "numeric") {
  if (n instanceof K())
    return Im(s, n.dtype, t, e), n;
  let o = Oo(n);
  if (o !== "string" && ["bool", "int32", "float32"].indexOf(s) >= 0 && (o = s), Im(s, o, t, e), n == null || !qe(n) && !Array.isArray(n) && typeof n != "number" && typeof n != "boolean" && typeof n != "string") {
    const l = n == null ? "null" : n.constructor.name;
    throw new Error(`Argument '${t}' passed to '${e}' must be a Tensor or TensorLike, but got '${l}'`);
  }
  const r = ya(n, o);
  !qe(n) && !Array.isArray(n) && (n = [n]);
  const a = o !== "string" ? Qs(n, o) : Ks(n, [], true);
  return $.makeTensor(a, r, o);
}
function jh(n, t, e, s = "numeric") {
  if (!Array.isArray(n))
    throw new Error(`Argument ${t} passed to ${e} must be a \`Tensor[]\` or \`TensorLike[]\``);
  return n.map((r, i6) => T(r, `${t}[${i6}]`, e, s));
}
var N2 = "__op";
function L(n) {
  const t = Object.keys(n);
  if (t.length !== 1)
    throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);
  let e = t[0];
  const s = n[e];
  e.endsWith("_") && (e = e.substring(0, e.length - 1)), e = e + N2;
  const o = (...r) => {
    $.startScope(e);
    try {
      const i6 = s(...r);
      return Ci(i6) && console.error("Cannot return a Promise inside of tidy."), $.endScope(i6), i6;
    } catch (i6) {
      throw $.endScope(null), i6;
    }
  };
  return Object.defineProperty(o, "name", { value: e, configurable: true }), o;
}
function R2(n, t) {
  const e = T(n, "real", "complex"), s = T(t, "imag", "complex");
  Pe(e.shape, s.shape, `real and imag shapes, ${e.shape} and ${s.shape}, must match in call to tf.complex().`);
  const o = { real: e, imag: s };
  return $.runKernel(ih, o);
}
var vo = L({ complex_: R2 });
function wa(n, t, e, s) {
  if (s == null)
    s = Oo(n);
  else if (s === "complex64")
    throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
  if (Db(n) || Wb(n)) {
    if (s !== "float32" && s !== "int32")
      throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${s}.`);
    return $.backend.createTensorFromGPUData(n, t || e, s);
  }
  if (!qe(n) && !Array.isArray(n) && typeof n != "number" && typeof n != "boolean" && typeof n != "string")
    throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
  if (t != null) {
    is(t);
    const o = X(t), r = X(e);
    C(o === r, () => `Based on the provided shape, [${t}], the tensor should have ${o} values but has ${r}`);
    for (let i6 = 0; i6 < e.length; ++i6) {
      const a = e[i6], l = i6 === e.length - 1 ? a !== X(t.slice(i6)) : true;
      C(e[i6] === t[i6] || !l, () => `Error creating a new Tensor. Inferred shape (${e}) does not match the provided shape (${t}). `);
    }
  }
  return !qe(n) && !Array.isArray(n) && (n = [n]), t = t || e, n = s !== "string" ? Qs(n, s) : Ks(n, [], true), $.makeTensor(n, t, s);
}
function $e(n, t, e) {
  const s = ya(n, e);
  return wa(n, t, s, e);
}
var So = {
  float32: 4,
  float16: 2,
  int32: 4,
  uint16: 2,
  uint8: 1,
  bool: 1,
  complex64: 8
};
var Cs = class _Cs {
  /**
   * Concatenate a number of ArrayBuffers into one.
   *
   * @param buffers An array of ArrayBuffers to concatenate, or a single
   *     ArrayBuffer.
   * @returns Result of concatenating `buffers` in order.
   */
  static join(t) {
    return new _Cs(t).slice();
  }
  constructor(t) {
    if (this.shards = [], this.previousShardIndex = 0, t == null || (t instanceof Array || (t = [t]), t = t.map((s) => qe(s) ? s.buffer : s), t.length === 0))
      return;
    this.bufferUniformSize = t[0].byteLength;
    let e = 0;
    for (let s = 0; s < t.length; s++) {
      const o = t[s];
      s !== t.length - 1 && o.byteLength !== this.bufferUniformSize && (this.bufferUniformSize = void 0);
      const r = e + o.byteLength;
      this.shards.push({ buffer: o, start: e, end: r }), e = r;
    }
    this.shards.length === 0 && (this.byteLength = 0), this.byteLength = this.shards[this.shards.length - 1].end;
  }
  slice(t = 0, e = this.byteLength) {
    if (this.shards.length === 0)
      return new ArrayBuffer(0);
    if (t = isNaN(Number(t)) ? 0 : t, e = isNaN(Number(e)) ? 0 : e, t = Math.max(0, t), e = Math.min(this.byteLength, e), e <= t)
      return new ArrayBuffer(0);
    const s = this.findShardForByte(t);
    if (s === -1)
      throw new Error(`Could not find start shard for byte ${t}`);
    const o = e - t, r = new ArrayBuffer(o), i6 = new Uint8Array(r);
    let a = 0;
    for (let l = s; l < this.shards.length; l++) {
      const c = this.shards[l], d = t + a - c.start, h = a, f = Math.min(e, c.end) - c.start, m = new Uint8Array(c.buffer, d, f - d);
      if (i6.set(m, h), a += m.length, e < c.end)
        break;
    }
    return r;
  }
  /**
   * Get the index of the shard that contains the byte at `byteIndex`.
   */
  findShardForByte(t) {
    if (this.shards.length === 0 || t < 0 || t >= this.byteLength)
      return -1;
    if (this.bufferUniformSize != null)
      return this.previousShardIndex = Math.floor(t / this.bufferUniformSize), this.previousShardIndex;
    function e(o) {
      return t < o.start ? -1 : t >= o.end ? 1 : 0;
    }
    if (e(this.shards[this.previousShardIndex]) === 0)
      return this.previousShardIndex;
    const s = $2(this.shards, e);
    return s === -1 ? -1 : (this.previousShardIndex = s, this.previousShardIndex);
  }
};
function $2(n, t) {
  let e = 0, s = n.length;
  for (; e <= s; ) {
    const o = Math.floor((s - e) / 2) + e, r = t(n[o]);
    if (r === 0)
      return o;
    r < 0 ? s = o : e = o + 1;
  }
  return -1;
}
function qY() {
  F().set("PROD", true);
}
function tQ() {
  F().set("DEBUG", true);
}
function eQ() {
  F().set("DEPRECATION_WARNINGS_ENABLED", false), console.warn("TensorFlow.js deprecation warnings have been disabled.");
}
function nQ(n) {
  F().getBool("DEPRECATION_WARNINGS_ENABLED") && console.warn(n + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
}
function sQ() {
  $.disposeVariables();
}
function Ot() {
  return $;
}
function wl() {
  return $.memory();
}
function oQ(n) {
  return $.profile(n);
}
function D(n, t) {
  return $.tidy(n, t);
}
function xt(n) {
  bs(n).forEach((e) => e.dispose());
}
function hn(n) {
  return $.keep(n);
}
function rQ(n) {
  return $.time(n);
}
function iQ(n) {
  return $.setBackend(n);
}
function aQ() {
  return $.ready();
}
function G2() {
  return $.backendName;
}
function lQ(n) {
  $.removeBackend(n);
}
function cQ(n) {
  return $.findBackend(n);
}
function uQ(n) {
  return $.findBackendFactory(n);
}
function Pb(n, t, e = 1) {
  return $.registerBackend(n, t, e);
}
function ps() {
  return $.backend;
}
function dQ(n, t) {
  F().setPlatform(n, t);
}
var Zs = 4;
async function Cm(n, t) {
  const e = [], s = [], o = Array.isArray(n) ? n.map((i6) => i6.name) : Object.keys(n);
  for (let i6 = 0; i6 < o.length; ++i6) {
    const a = o[i6], l = Array.isArray(n) ? n[i6].tensor : n[a];
    if (l.dtype !== "float32" && l.dtype !== "int32" && l.dtype !== "bool" && l.dtype !== "string" && l.dtype !== "complex64")
      throw new Error(`Unsupported dtype in weight '${a}': ${l.dtype}`);
    const c = { name: a, shape: l.shape, dtype: l.dtype };
    if (l.dtype === "string") {
      const u = new Promise(async (d) => {
        const h = await l.bytes(), p = h.reduce((g, b) => g + b.length, 0) + Zs * h.length, f = new Uint8Array(p);
        let m = 0;
        for (let g = 0; g < h.length; g++) {
          const b = h[g], x6 = new Uint8Array(new Uint32Array([b.length]).buffer);
          f.set(x6, m), m += Zs, f.set(b, m), m += b.length;
        }
        d(f);
      });
      s.push(u);
    } else
      s.push(l.data());
    t != null && (c.group = t), e.push(c);
  }
  const r = await Promise.all(s);
  return { data: M2(r), specs: e };
}
function Ab(n, t) {
  const e = new Cs(n), s = {};
  let o = 0;
  for (const r of t) {
    const i6 = E2(r, (a, l) => e.slice(o + a, o + l));
    s[r.name] = Ob(r, e.slice(o, o + i6)), o += i6;
  }
  return s;
}
function E2(n, t) {
  const e = X(n.shape);
  let s;
  if ("quantization" in n) {
    const o = n.quantization;
    s = So[o.dtype];
  } else if (n.dtype === "string") {
    let o = 0;
    for (let r = 0; r < e; r++)
      o += Zs + new Uint32Array(t(o, o + Zs))[0];
    return o;
  } else
    s = So[n.dtype];
  return e * s;
}
async function L2(n, t) {
  const e = X(n.shape);
  let s;
  if ("quantization" in n) {
    const o = n.quantization;
    s = So[o.dtype];
  } else if (n.dtype === "string") {
    let o = 0;
    for (let r = 0; r < e; r++)
      o += Zs + new Uint32Array(await t(o, o + Zs))[0];
    return o;
  } else
    s = So[n.dtype];
  return e * s;
}
function Ob(n, t) {
  const e = n.name, s = n.dtype, o = n.shape, r = X(o);
  let i6, a = 0;
  if ("quantization" in n) {
    const l = n.quantization;
    if (l.dtype === "uint8" || l.dtype === "uint16") {
      if (!("min" in l && "scale" in l))
        throw new Error(`Weight ${n.name} with quantization ${l.dtype} doesn't have corresponding metadata min and scale.`);
    } else if (l.dtype === "float16") {
      if (s !== "float32")
        throw new Error(`Weight ${n.name} is quantized with ${l.dtype} which only supports weights of type float32 not ${s}.`);
    } else
      throw new Error(`Weight ${n.name} has unknown quantization dtype ${l.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
    const c = So[l.dtype], u = l.dtype === "uint8" ? new Uint8Array(t) : new Uint16Array(t);
    if (s === "float32")
      if (l.dtype === "uint8" || l.dtype === "uint16") {
        i6 = new Float32Array(u.length);
        for (let d = 0; d < u.length; d++) {
          const h = u[d];
          i6[d] = h * l.scale + l.min;
        }
      } else if (l.dtype === "float16")
        i6 = K2()(u);
      else
        throw new Error(`Unsupported quantization type ${l.dtype} for weight type float32.`);
    else if (s === "int32") {
      if (l.dtype !== "uint8" && l.dtype !== "uint16")
        throw new Error(`Unsupported quantization type ${l.dtype} for weight type int32.`);
      i6 = new Int32Array(u.length);
      for (let d = 0; d < u.length; d++) {
        const h = u[d];
        i6[d] = Math.round(h * l.scale + l.min);
      }
    } else
      throw new Error(`Unsupported dtype in weight '${e}': ${s}`);
    a += r * c;
  } else if (s === "string") {
    const l = X(n.shape);
    i6 = [];
    for (let c = 0; c < l; c++) {
      const u = new Uint32Array(t.slice(a, a + Zs))[0];
      a += Zs;
      const d = new Uint8Array(t.slice(a, a + u));
      i6.push(d), a += u;
    }
  } else {
    const l = So[s];
    if (s === "float32")
      i6 = new Float32Array(t);
    else if (s === "int32")
      i6 = new Int32Array(t);
    else if (s === "bool")
      i6 = new Uint8Array(t);
    else if (s === "complex64") {
      i6 = new Float32Array(t);
      const c = new Float32Array(i6.length / 2), u = new Float32Array(i6.length / 2);
      for (let f = 0; f < c.length; f++)
        c[f] = i6[f * 2], u[f] = i6[f * 2 + 1];
      const d = $e(c, o, "float32"), h = $e(u, o, "float32"), p = vo(d, h);
      return d.dispose(), h.dispose(), p;
    } else
      throw new Error(`Unsupported dtype in weight '${e}': ${s}`);
    a += r * l;
  }
  return $e(i6, o, s);
}
async function vm(n, t, e) {
  let s = new Uint8Array(t);
  for (; s.byteLength < e; ) {
    const { done: o, value: r } = await n.read();
    if (o && r == null) {
      const a = e - s.byteLength;
      throw new Error(`Reader is done but ${a} bytes are still expected`);
    }
    const i6 = new Uint8Array(s.length + r.byteLength);
    i6.set(s, 0), i6.set(new Uint8Array(r), s.length), s = i6;
  }
  return s.buffer;
}
async function hQ(n, t) {
  const e = {}, s = n.getReader();
  let o = new ArrayBuffer(0);
  for (const r of t) {
    const i6 = await L2(r, async (c, u) => (o = await vm(s, o, u), o.slice(c, u)));
    o = await vm(s, o, i6);
    const a = o.slice(0, i6);
    o = o.slice(i6);
    const l = Ob(r, a);
    if (e[r.name] = l, G2() === "webgpu") {
      const c = ps();
      "uploadToGPU" in c && X(l.shape) >= F().get("WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD") && c.uploadToGPU(l.dataId);
    }
  }
  return e;
}
function M2(n) {
  if (n === null)
    throw new Error(`Invalid input value: ${JSON.stringify(n)}`);
  let t = 0;
  const e = [];
  n.forEach((r) => {
    if (t += r.byteLength, e.push(r.byteLength === r.buffer.byteLength ? r : new r.constructor(r)), !(r instanceof Float32Array || r instanceof Int32Array || r instanceof Uint8Array))
      throw new Error(`Unsupported TypedArray subtype: ${r.constructor.name}`);
  });
  const s = new Uint8Array(t);
  let o = 0;
  return e.forEach((r) => {
    s.set(new Uint8Array(r.buffer), o), o += r.byteLength;
  }), s.buffer;
}
var qh = typeof Buffer < "u" && (typeof Blob > "u" || typeof atob > "u" || typeof btoa > "u");
function Sm(n) {
  return qh ? Buffer.byteLength(n, "utf8") : new Blob([n]).size;
}
function W2(n) {
  if (qh)
    return Buffer.from(n).toString("base64");
  const t = new Uint8Array(n);
  let e = "";
  for (let s = 0, o = t.length; s < o; s++)
    e += String.fromCharCode(t[s]);
  return btoa(e);
}
function D2(n) {
  if (qh) {
    const s = Buffer.from(n, "base64");
    return s.buffer.slice(s.byteOffset, s.byteOffset + s.byteLength);
  }
  const t = atob(n), e = new Uint8Array(t.length);
  for (let s = 0; s < t.length; ++s)
    e.set([t.charCodeAt(s)], s);
  return e.buffer;
}
function F2(n) {
  return Cs.join(n);
}
function pQ(n) {
  const t = "/";
  for (n = n.trim(); n.endsWith(t); )
    n = n.slice(0, n.length - 1);
  const e = n.split(t);
  return e[e.length - 1];
}
function V2(n, t) {
  const e = {
    modelTopology: n.modelTopology,
    format: n.format,
    generatedBy: n.generatedBy,
    convertedBy: n.convertedBy,
    weightsManifest: t
  };
  return n.signature != null && (e.signature = n.signature), n.userDefinedMetadata != null && (e.userDefinedMetadata = n.userDefinedMetadata), n.modelInitializer != null && (e.modelInitializer = n.modelInitializer), n.initializerSignature != null && (e.initializerSignature = n.initializerSignature), n.trainingConfig != null && (e.trainingConfig = n.trainingConfig), e;
}
function z2(n, t, e) {
  const s = {
    modelTopology: n.modelTopology,
    format: n.format,
    generatedBy: n.generatedBy,
    convertedBy: n.convertedBy
  };
  if (n.trainingConfig != null && (s.trainingConfig = n.trainingConfig), n.weightsManifest != null) {
    if (!t)
      throw new Error("modelJSON has weightsManifest but weightSpecs is null");
    if (!e)
      throw new Error("modelJSON has weightsManifest but weightData is null");
    s.weightSpecs = t, s.weightData = e;
  }
  return n.signature != null && (s.signature = n.signature), n.userDefinedMetadata != null && (s.userDefinedMetadata = n.userDefinedMetadata), n.modelInitializer != null && (s.modelInitializer = n.modelInitializer), n.initializerSignature != null && (s.initializerSignature = n.initializerSignature), s;
}
async function P2(n, t) {
  let e, s;
  return n.weightsManifest != null && ([e, s] = await t(n.weightsManifest)), z2(n, e, s);
}
function tp(n) {
  if (n.modelTopology instanceof ArrayBuffer)
    throw new Error("Expected JSON model topology, received ArrayBuffer.");
  return {
    dateSaved: /* @__PURE__ */ new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: n.modelTopology == null ? 0 : Sm(JSON.stringify(n.modelTopology)),
    weightSpecsBytes: n.weightSpecs == null ? 0 : Sm(JSON.stringify(n.weightSpecs)),
    weightDataBytes: n.weightData == null ? 0 : new Cs(n.weightData).byteLength
  };
}
function km(n) {
  const t = [];
  for (const e of n)
    t.push(...e.weights);
  return t;
}
function A2() {
  const n = (e) => {
    let s = e << 13, o = 0;
    for (; !(s & 8388608); )
      o -= 8388608, s <<= 1;
    return s &= -8388609, o += 947912704, s | o;
  }, t = new Uint32Array(2048);
  t[0] = 0;
  for (let e = 1; e < 1024; e++)
    t[e] = n(e);
  for (let e = 1024; e < 2048; e++)
    t[e] = 939524096 + (e - 1024 << 13);
  return t;
}
function O2() {
  const n = new Uint32Array(64);
  n[0] = 0, n[31] = 1199570944, n[32] = 2147483648, n[63] = 3347054592;
  for (let t = 1; t < 31; t++)
    n[t] = t << 23;
  for (let t = 33; t < 63; t++)
    n[t] = 2147483648 + (t - 32 << 23);
  return n;
}
function X2() {
  const n = new Uint32Array(64);
  for (let t = 0; t < 64; t++)
    n[t] = 1024;
  return n[0] = n[32] = 0, n;
}
function K2() {
  const n = A2(), t = O2(), e = X2();
  return (s) => {
    const o = new ArrayBuffer(4 * s.length), r = new Uint32Array(o);
    for (let i6 = 0; i6 < s.length; i6++) {
      const a = s[i6], l = n[e[a >> 10] + (a & 1023)] + t[a >> 10];
      r[i6] = l;
    }
    return new Float32Array(o);
  };
}
var ee = class _ee {
  constructor() {
    this.saveRouters = [], this.loadRouters = [];
  }
  static getInstance() {
    return _ee.instance == null && (_ee.instance = new _ee()), _ee.instance;
  }
  /**
   * Register a save-handler router.
   *
   * @param saveRouter A function that maps a URL-like string onto an instance
   * of `IOHandler` with the `save` method defined or `null`.
   */
  static registerSaveRouter(t) {
    _ee.getInstance().saveRouters.push(t);
  }
  /**
   * Register a load-handler router.
   *
   * @param loadRouter A function that maps a URL-like string onto an instance
   * of `IOHandler` with the `load` method defined or `null`.
   */
  static registerLoadRouter(t) {
    _ee.getInstance().loadRouters.push(t);
  }
  /**
   * Look up IOHandler for saving, given a URL-like string.
   *
   * @param url
   * @returns If only one match is found, an instance of IOHandler with the
   * `save` method defined. If no match is found, `null`.
   * @throws Error, if more than one match is found.
   */
  static getSaveHandlers(t) {
    return _ee.getHandlers(t, "save");
  }
  /**
   * Look up IOHandler for loading, given a URL-like string.
   *
   * @param url
   * @param loadOptions Optional, custom load options.
   * @returns All valid handlers for `url`, given the currently registered
   *   handler routers.
   */
  static getLoadHandlers(t, e) {
    return _ee.getHandlers(t, "load", e);
  }
  static getHandlers(t, e, s) {
    const o = [];
    return (e === "load" ? _ee.getInstance().loadRouters : _ee.getInstance().saveRouters).forEach((i6) => {
      const a = i6(t, s);
      a !== null && o.push(a);
    }), o;
  }
};
var fQ = (n) => ee.registerSaveRouter(n);
var mQ = (n) => ee.registerLoadRouter(n);
var Z2 = (n) => ee.getSaveHandlers(n);
var B2 = (n, t) => ee.getLoadHandlers(n, t);
var xd = "tensorflowjs";
var yd = 1;
var go = "models_store";
var Ws = "model_info_store";
function Xb() {
  if (!F().getBool("IS_BROWSER"))
    throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  const n = typeof window > "u" ? self : window, t = n.indexedDB || n.mozIndexedDB || n.webkitIndexedDB || n.msIndexedDB || n.shimIndexedDB;
  if (t == null)
    throw new Error("The current browser does not appear to support IndexedDB.");
  return t;
}
function wd(n) {
  const t = n.result;
  t.createObjectStore(go, { keyPath: "modelPath" }), t.createObjectStore(Ws, { keyPath: "modelPath" });
}
var ko = class {
  constructor(t) {
    if (this.indexedDB = Xb(), t == null || !t)
      throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
    this.modelPath = t;
  }
  async save(t) {
    if (t.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    return this.databaseAction(this.modelPath, t);
  }
  async load() {
    return this.databaseAction(this.modelPath);
  }
  /**
   * Perform database action to put model artifacts into or read model artifacts
   * from IndexedDB object store.
   *
   * Whether the action is put or get depends on whether `modelArtifacts` is
   * specified. If it is specified, the action will be put; otherwise the action
   * will be get.
   *
   * @param modelPath A unique string path for the model.
   * @param modelArtifacts If specified, it will be the model artifacts to be
   *   stored in IndexedDB.
   * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`
   *   of `ModelArtifacts`, if the action is get.
   */
  databaseAction(t, e) {
    return new Promise((s, o) => {
      const r = this.indexedDB.open(xd, yd);
      r.onupgradeneeded = () => wd(r), r.onsuccess = () => {
        const i6 = r.result;
        if (e == null) {
          const a = i6.transaction(go, "readonly"), c = a.objectStore(go).get(this.modelPath);
          c.onsuccess = () => {
            if (c.result == null)
              return i6.close(), o(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
            s(c.result.modelArtifacts);
          }, c.onerror = (u) => (i6.close(), o(c.error)), a.oncomplete = () => i6.close();
        } else {
          e.weightData = Cs.join(e.weightData);
          const a = tp(e), l = i6.transaction(Ws, "readwrite");
          let c = l.objectStore(Ws), u;
          try {
            u = c.put({ modelPath: this.modelPath, modelArtifactsInfo: a });
          } catch (h) {
            return o(h);
          }
          let d;
          u.onsuccess = () => {
            d = i6.transaction(go, "readwrite");
            const h = d.objectStore(go);
            let p;
            try {
              p = h.put({
                modelPath: this.modelPath,
                modelArtifacts: e,
                modelArtifactsInfo: a
              });
            } catch (f) {
              return o(f);
            }
            p.onsuccess = () => s({ modelArtifactsInfo: a }), p.onerror = (f) => {
              c = l.objectStore(Ws);
              const m = c.delete(this.modelPath);
              m.onsuccess = () => (i6.close(), o(p.error)), m.onerror = (g) => (i6.close(), o(p.error));
            };
          }, u.onerror = (h) => (i6.close(), o(u.error)), l.oncomplete = () => {
            d == null ? i6.close() : d.oncomplete = () => i6.close();
          };
        }
      }, r.onerror = (i6) => o(r.error);
    });
  }
};
ko.URL_SCHEME = "indexeddb://";
var Kb = (n) => F().getBool("IS_BROWSER") && !Array.isArray(n) && n.startsWith(ko.URL_SCHEME) ? H2(n.slice(ko.URL_SCHEME.length)) : null;
ee.registerSaveRouter(Kb);
ee.registerLoadRouter(Kb);
function H2(n) {
  return new ko(n);
}
function _2(n) {
  return n.startsWith(ko.URL_SCHEME) ? n.slice(ko.URL_SCHEME.length) : n;
}
var U2 = class {
  constructor() {
    this.indexedDB = Xb();
  }
  async listModels() {
    return new Promise((t, e) => {
      const s = this.indexedDB.open(xd, yd);
      s.onupgradeneeded = () => wd(s), s.onsuccess = () => {
        const o = s.result, r = o.transaction(Ws, "readonly"), a = r.objectStore(Ws).getAll();
        a.onsuccess = () => {
          const l = {};
          for (const c of a.result)
            l[c.modelPath] = c.modelArtifactsInfo;
          t(l);
        }, a.onerror = (l) => (o.close(), e(a.error)), r.oncomplete = () => o.close();
      }, s.onerror = (o) => e(s.error);
    });
  }
  async removeModel(t) {
    return t = _2(t), new Promise((e, s) => {
      const o = this.indexedDB.open(xd, yd);
      o.onupgradeneeded = () => wd(o), o.onsuccess = () => {
        const r = o.result, i6 = r.transaction(Ws, "readwrite"), a = i6.objectStore(Ws), l = a.get(t);
        let c;
        l.onsuccess = () => {
          if (l.result == null)
            return r.close(), s(new Error(`Cannot find model with path '${t}' in IndexedDB.`));
          {
            const u = a.delete(t), d = () => {
              c = r.transaction(go, "readwrite");
              const p = c.objectStore(go).delete(t);
              p.onsuccess = () => e(l.result.modelArtifactsInfo), p.onerror = (f) => s(l.error);
            };
            u.onsuccess = d, u.onerror = (h) => (d(), r.close(), s(l.error));
          }
        }, l.onerror = (u) => (r.close(), s(l.error)), i6.oncomplete = () => {
          c == null ? r.close() : c.oncomplete = () => r.close();
        };
      }, o.onerror = (r) => s(o.error);
    });
  }
};
var hs = "/";
var rr = "tensorflowjs_models";
var Zb = "info";
var Y2 = "model_topology";
var Q2 = "weight_specs";
var J2 = "weight_data";
var j2 = "model_metadata";
function Bb(n) {
  return {
    info: [rr, n, Zb].join(hs),
    topology: [rr, n, Y2].join(hs),
    weightSpecs: [rr, n, Q2].join(hs),
    weightData: [rr, n, J2].join(hs),
    modelMetadata: [rr, n, j2].join(hs)
  };
}
function Hb(n) {
  for (const t of Object.values(n))
    window.localStorage.removeItem(t);
}
function q2(n) {
  const t = n.split(hs);
  if (t.length < 3)
    throw new Error(`Invalid key format: ${n}`);
  return t.slice(1, t.length - 1).join(hs);
}
function tv(n) {
  return n.startsWith(To.URL_SCHEME) ? n.slice(To.URL_SCHEME.length) : n;
}
var To = class {
  constructor(t) {
    if (!F().getBool("IS_BROWSER") || typeof window > "u" || typeof window.localStorage > "u")
      throw new Error("The current environment does not support local storage.");
    if (this.LS = window.localStorage, t == null || !t)
      throw new Error("For local storage, modelPath must not be null, undefined or empty.");
    this.modelPath = t, this.keys = Bb(this.modelPath);
  }
  /**
   * Save model artifacts to browser local storage.
   *
   * See the documentation to `browserLocalStorage` for details on the saved
   * artifacts.
   *
   * @param modelArtifacts The model artifacts to be stored.
   * @returns An instance of SaveResult.
   */
  async save(t) {
    if (t.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    {
      const e = JSON.stringify(t.modelTopology), s = JSON.stringify(t.weightSpecs), o = tp(t), r = Cs.join(t.weightData);
      try {
        this.LS.setItem(this.keys.info, JSON.stringify(o)), this.LS.setItem(this.keys.topology, e), this.LS.setItem(this.keys.weightSpecs, s), this.LS.setItem(this.keys.weightData, W2(r));
        const i6 = {
          format: t.format,
          generatedBy: t.generatedBy,
          convertedBy: t.convertedBy,
          signature: t.signature != null ? t.signature : void 0,
          userDefinedMetadata: t.userDefinedMetadata != null ? t.userDefinedMetadata : void 0,
          modelInitializer: t.modelInitializer != null ? t.modelInitializer : void 0,
          initializerSignature: t.initializerSignature != null ? t.initializerSignature : void 0,
          trainingConfig: t.trainingConfig != null ? t.trainingConfig : void 0
        };
        return this.LS.setItem(this.keys.modelMetadata, JSON.stringify(i6)), { modelArtifactsInfo: o };
      } catch {
        throw Hb(this.keys), new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${o.modelTopologyBytes}, weightSpecsBytes=${o.weightSpecsBytes}, weightDataBytes=${o.weightDataBytes}.`);
      }
    }
  }
  /**
   * Load a model from local storage.
   *
   * See the documentation to `browserLocalStorage` for details on the saved
   * artifacts.
   *
   * @returns The loaded model (if loading succeeds).
   */
  async load() {
    const t = JSON.parse(this.LS.getItem(this.keys.info));
    if (t == null)
      throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
    if (t.modelTopologyType !== "JSON")
      throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
    const e = {}, s = JSON.parse(this.LS.getItem(this.keys.topology));
    if (s == null)
      throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
    e.modelTopology = s;
    const o = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
    if (o == null)
      throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
    e.weightSpecs = o;
    const r = this.LS.getItem(this.keys.modelMetadata);
    if (r != null) {
      const a = JSON.parse(r);
      e.format = a.format, e.generatedBy = a.generatedBy, e.convertedBy = a.convertedBy, a.signature != null && (e.signature = a.signature), a.userDefinedMetadata != null && (e.userDefinedMetadata = a.userDefinedMetadata), a.modelInitializer != null && (e.modelInitializer = a.modelInitializer), a.initializerSignature != null && (e.initializerSignature = a.initializerSignature), a.trainingConfig != null && (e.trainingConfig = a.trainingConfig);
    }
    const i6 = this.LS.getItem(this.keys.weightData);
    if (i6 == null)
      throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
    return e.weightData = D2(i6), e;
  }
};
To.URL_SCHEME = "localstorage://";
var _b = (n) => F().getBool("IS_BROWSER") && !Array.isArray(n) && n.startsWith(To.URL_SCHEME) ? ev(n.slice(To.URL_SCHEME.length)) : null;
ee.registerSaveRouter(_b);
ee.registerLoadRouter(_b);
function ev(n) {
  return new To(n);
}
var nv = class {
  constructor() {
    C(F().getBool("IS_BROWSER"), () => "Current environment is not a web browser"), C(typeof window > "u" || typeof window.localStorage < "u", () => "Current browser does not appear to support localStorage"), this.LS = window.localStorage;
  }
  async listModels() {
    const t = {}, e = rr + hs, s = hs + Zb;
    for (let o = 0; o < this.LS.length; ++o) {
      const r = this.LS.key(o);
      if (r.startsWith(e) && r.endsWith(s)) {
        const i6 = q2(r);
        t[i6] = JSON.parse(this.LS.getItem(r));
      }
    }
    return t;
  }
  async removeModel(t) {
    t = tv(t);
    const e = Bb(t);
    if (this.LS.getItem(e.info) == null)
      throw new Error(`Cannot find model at path '${t}'`);
    const s = JSON.parse(this.LS.getItem(e.info));
    return Hb(e), s;
  }
};
var lr = "://";
var We = class _We {
  constructor() {
    this.managers = {};
  }
  static getInstance() {
    return _We.instance == null && (_We.instance = new _We()), _We.instance;
  }
  /**
   * Register a save-handler router.
   *
   * @param saveRouter A function that maps a URL-like string onto an instance
   * of `IOHandler` with the `save` method defined or `null`.
   */
  static registerManager(t, e) {
    C(t != null, () => "scheme must not be undefined or null."), t.endsWith(lr) && (t = t.slice(0, t.indexOf(lr))), C(t.length > 0, () => "scheme must not be an empty string.");
    const s = _We.getInstance();
    C(s.managers[t] == null, () => `A model store manager is already registered for scheme '${t}'.`), s.managers[t] = e;
  }
  static getManager(t) {
    const e = _We.getInstance().managers[t];
    if (e == null)
      throw new Error(`Cannot find model manager for scheme '${t}'`);
    return e;
  }
  static getSchemes() {
    return Object.keys(_We.getInstance().managers);
  }
};
function rl(n) {
  if (n.indexOf(lr) === -1)
    throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${We.getSchemes().join(",")}`);
  return {
    scheme: n.split(lr)[0],
    path: n.split(lr)[1]
  };
}
async function Ub(n, t, e = false) {
  C(n !== t, () => `Old path and new path are the same: '${n}'`);
  const s = ee.getLoadHandlers(n);
  C(s.length > 0, () => `Copying failed because no load handler is found for source URL ${n}.`), C(s.length < 2, () => `Copying failed because more than one (${s.length}) load handlers for source URL ${n}.`);
  const o = s[0], r = ee.getSaveHandlers(t);
  C(r.length > 0, () => `Copying failed because no save handler is found for destination URL ${t}.`), C(r.length < 2, () => `Copying failed because more than one (${s.length}) save handlers for destination URL ${t}.`);
  const i6 = r[0], a = rl(n).scheme, l = rl(n).path, c = a === rl(n).scheme, u = await o.load();
  e && c && await We.getManager(a).removeModel(l);
  const d = await i6.save(u);
  return e && !c && await We.getManager(a).removeModel(l), d.modelArtifactsInfo;
}
async function gQ() {
  const n = We.getSchemes(), t = {};
  for (const e of n) {
    const s = await We.getManager(e).listModels();
    for (const o in s) {
      const r = e + lr + o;
      t[r] = s[o];
    }
  }
  return t;
}
async function bQ(n) {
  const t = rl(n);
  return We.getManager(t.scheme).removeModel(t.path);
}
async function xQ(n, t) {
  return Ub(n, t, false);
}
async function yQ(n, t) {
  return Ub(n, t, true);
}
var sv = class {
  constructor() {
    this.messageName = "setTimeoutCustom", this.functionRefs = [], this.handledMessageCount = 0, this.hasEventListener = false;
  }
  fetch(t, e) {
    return fetch(t, e);
  }
  now() {
    return performance.now();
  }
  encode(t, e) {
    if (e !== "utf-8" && e !== "utf8")
      throw new Error(`Browser's encoder only supports utf-8, but got ${e}`);
    return this.textEncoder == null && (this.textEncoder = new TextEncoder()), this.textEncoder.encode(t);
  }
  decode(t, e) {
    return new TextDecoder(e).decode(t);
  }
  // If the setTimeout nesting level is greater than 5 and timeout is less
  // than 4ms, timeout will be clamped to 4ms, which hurts the perf.
  // Interleaving window.postMessage and setTimeout will trick the browser and
  // avoid the clamp.
  setTimeoutCustom(t, e) {
    if (typeof window > "u" || !F().getBool("USE_SETTIMEOUTCUSTOM")) {
      setTimeout(t, e);
      return;
    }
    this.functionRefs.push(t), setTimeout(() => {
      window.postMessage({ name: this.messageName, index: this.functionRefs.length - 1 }, "*");
    }, e), this.hasEventListener || (this.hasEventListener = true, window.addEventListener("message", (s) => {
      if (s.source === window && s.data.name === this.messageName) {
        s.stopPropagation();
        const o = this.functionRefs[s.data.index];
        o(), this.handledMessageCount++, this.handledMessageCount === this.functionRefs.length && (this.functionRefs = [], this.handledMessageCount = 0);
      }
    }, true));
  }
  isTypedArray(t) {
    return vb(t);
  }
};
if (F().get("IS_BROWSER")) {
  F().setPlatform("browser", new sv());
  try {
    We.registerManager(To.URL_SCHEME, new nv());
  } catch {
  }
  try {
    We.registerManager(ko.URL_SCHEME, new U2());
  } catch {
  }
}
var ov = {
  // tslint:disable-next-line:no-require-imports
  importFetch: () => require_browser()
};
var Lu;
var rv = class {
  constructor() {
    this.util = require_util(), this.textEncoder = new this.util.TextEncoder();
  }
  fetch(t, e) {
    return F().global.fetch != null ? F().global.fetch(t, e) : (Lu == null && (Lu = ov.importFetch()), Lu(t, e));
  }
  now() {
    const t = process.hrtime();
    return t[0] * 1e3 + t[1] / 1e6;
  }
  encode(t, e) {
    if (e !== "utf-8" && e !== "utf8")
      throw new Error(`Node built-in encoder only supports utf-8, but got ${e}`);
    return this.textEncoder.encode(t);
  }
  decode(t, e) {
    return t.length === 0 ? "" : new this.util.TextDecoder(e).decode(t);
  }
  isTypedArray(t) {
    return this.util.types.isFloat32Array(t) || this.util.types.isInt32Array(t) || this.util.types.isUint8Array(t) || this.util.types.isUint8ClampedArray(t);
  }
};
F().get("IS_NODE") && !F().get("IS_BROWSER") && F().setPlatform("node", new rv());
function vt(n, t = "float32", e) {
  return t = t || "float32", is(n), new ve(n, t, e);
}
function iv(n, t) {
  const e = T(n, "x", "cast");
  if (!nb(t))
    throw new Error(`Failed to cast to unknown dtype ${t}`);
  if (t === "string" && e.dtype !== "string" || t !== "string" && e.dtype === "string")
    throw new Error("Only strings can be casted to strings");
  const s = { x: e }, o = { dtype: t };
  return $.runKernel(Gi, s, o);
}
var tt = L({ cast_: iv });
function av(n) {
  const e = { x: T(n, "x", "clone", "string_or_numeric") };
  return $.runKernel(Ki, e);
}
var yo = L({ clone_: av });
function lv(n, t = false) {
  console.log(n.toString(t));
}
Vb();
var cv = {
  buffer: vt,
  cast: tt,
  clone: yo,
  print: lv
};
y2(cv);
function uv(n, t) {
  let e = T(n, "a", "add"), s = T(t, "b", "add");
  [e, s] = se(e, s);
  const o = { a: e, b: s };
  return $.runKernel(Sr, o);
}
var U = L({ add_: uv });
function dv(n, t) {
  let e = T(n, "a", "floorDiv"), s = T(t, "b", "floorDiv");
  [e, s] = se(e, s);
  const o = { a: e, b: s };
  return $.runKernel(Oi, o);
}
var Yb = L({ floorDiv_: dv });
function hv(n, t) {
  let e = T(n, "a", "div"), s = T(t, "b", "div");
  if ([e, s] = se(e, s), e.dtype === "int32" && s.dtype === "int32")
    return Yb(e, s);
  const o = { a: e, b: s }, r = {};
  return $.runKernel(Di, o, r);
}
var ut = L({ div_: hv });
function pv(n, t) {
  let e = T(n, "a", "mul"), s = T(t, "b", "mul");
  [e, s] = se(e, s);
  const o = { a: e, b: s };
  return $.runKernel(ji, o);
}
var G = L({ mul_: pv });
function fv(n) {
  const t = T(n, "x", "abs");
  if (t.dtype === "complex64") {
    const e = { x: t };
    return $.runKernel(ec, e);
  } else {
    const e = { x: t };
    return $.runKernel(Ul, e);
  }
}
var me = L({ abs_: fv });
function mv(n) {
  const e = { x: T(n, "x", "acos") };
  return $.runKernel(vi, e);
}
var gv = L({ acos_: mv });
function bv(n) {
  const e = { x: T(n, "x", "acosh") };
  return $.runKernel(Si, e);
}
var xv = L({ acosh_: bv });
function yv(n, t = null, e = false) {
  const o = { x: T(n, "x", "all", "bool") }, r = { axis: t, keepDims: e };
  return $.runKernel(th, o, r);
}
var Qb = L({ all_: yv });
function wv(n, t = null, e = false) {
  const o = { x: T(n, "x", "any", "bool") }, r = { axis: t, keepDims: e };
  return $.runKernel(eh, o, r);
}
var Id = L({ any_: wv });
function Iv(n, t = 0) {
  const s = { x: T(n, "x", "argMax") }, o = { axis: t };
  return $.runKernel(Yl, s, o);
}
var ai = L({ argMax_: Iv });
function Cv(n, t = 0) {
  const s = { x: T(n, "x", "argMin") }, o = { axis: t };
  return $.runKernel(Ql, s, o);
}
var vv = L({ argMin_: Cv });
function Sv(n) {
  const e = { x: T(n, "x", "asin") };
  return $.runKernel(ki, e);
}
var kv = L({ asin_: Sv });
function Tv(n) {
  const e = { x: T(n, "x", "asinh") };
  return $.runKernel(Ti, e);
}
var Nv = L({ asinh_: Tv });
function Rv(n) {
  const e = { x: T(n, "x", "atan") };
  return $.runKernel(Ni, e);
}
var $v = L({ atan_: Rv });
function Gv(n, t) {
  let e = T(n, "a", "atan2"), s = T(t, "b", "atan2");
  [e, s] = se(e, s);
  const o = { a: e, b: s };
  return $.runKernel($i, o);
}
var Ev = L({ atan2_: Gv });
function Lv(n) {
  const e = { x: T(n, "x", "atanh") };
  return $.runKernel(Ri, e);
}
var Mv = L({ atanh_: Lv });
function Ia(n, t, e, s, o = "NHWC", r) {
  const i6 = n[3], a = [...t, i6], l = Ss(o);
  return Te(n, a, e, r, s, null, null, l);
}
function $n(n, t, e, s, o, r, i6 = "channelsLast") {
  const [a, l] = li(t);
  let c;
  if (i6 === "channelsLast")
    c = [a, l, n[3], n[3]];
  else if (i6 === "channelsFirst")
    c = [a, l, n[1], n[1]];
  else
    throw new Error(`Unknown dataFormat ${i6}`);
  return Te(n, c, e, s, o, r, false, i6);
}
function vs(n, t, e, s, o, r, i6 = "NDHWC") {
  const [a, l, c] = Cd(t);
  let u, d;
  if (i6 === "NDHWC")
    d = "channelsLast", u = [a, l, c, n[4], n[4]];
  else if (i6 === "NCDHW")
    d = "channelsFirst", u = [a, l, c, n[1], n[1]];
  else
    throw new Error(`Unknown dataFormat ${i6}`);
  return Js(n, u, e, s, o, false, d, r);
}
function Te(n, t, e, s, o, r, i6 = false, a = "channelsLast") {
  let [l, c, u, d] = [-1, -1, -1, -1];
  if (a === "channelsLast")
    [l, c, u, d] = n;
  else if (a === "channelsFirst")
    [l, d, c, u] = n;
  else
    throw new Error(`Unknown dataFormat ${a}`);
  const [h, p, , f] = t, [m, g] = li(e), [b, x6] = li(s), w = cr(h, b), y6 = cr(p, x6), { padInfo: I, outHeight: v, outWidth: k6 } = Fv(o, c, u, m, g, w, y6, r, a), S = i6 ? f * d : f;
  let N;
  return a === "channelsFirst" ? N = [l, S, v, k6] : a === "channelsLast" && (N = [l, v, k6, S]), {
    batchSize: l,
    dataFormat: a,
    inHeight: c,
    inWidth: u,
    inChannels: d,
    outHeight: v,
    outWidth: k6,
    outChannels: S,
    padInfo: I,
    strideHeight: m,
    strideWidth: g,
    filterHeight: h,
    filterWidth: p,
    effectiveFilterHeight: w,
    effectiveFilterWidth: y6,
    dilationHeight: b,
    dilationWidth: x6,
    inShape: n,
    outShape: N,
    filterShape: t
  };
}
function Js(n, t, e, s, o, r = false, i6 = "channelsLast", a) {
  let [l, c, u, d, h] = [-1, -1, -1, -1, -1];
  if (i6 === "channelsLast")
    [l, c, u, d, h] = n;
  else if (i6 === "channelsFirst")
    [l, h, c, u, d] = n;
  else
    throw new Error(`Unknown dataFormat ${i6}`);
  const [p, f, m, , g] = t, [b, x6, w] = Cd(e), [y6, I, v] = Cd(s), k6 = cr(p, y6), S = cr(f, I), N = cr(m, v), { padInfo: R, outDepth: M6, outHeight: V, outWidth: z } = Vv(o, c, u, d, b, x6, w, k6, S, N, a), P = r ? g * h : g;
  let A;
  return i6 === "channelsFirst" ? A = [l, P, M6, V, z] : i6 === "channelsLast" && (A = [l, M6, V, z, P]), {
    batchSize: l,
    dataFormat: i6,
    inDepth: c,
    inHeight: u,
    inWidth: d,
    inChannels: h,
    outDepth: M6,
    outHeight: V,
    outWidth: z,
    outChannels: P,
    padInfo: R,
    strideDepth: b,
    strideHeight: x6,
    strideWidth: w,
    filterDepth: p,
    filterHeight: f,
    filterWidth: m,
    effectiveFilterDepth: k6,
    effectiveFilterHeight: S,
    effectiveFilterWidth: N,
    dilationDepth: y6,
    dilationHeight: I,
    dilationWidth: v,
    inShape: n,
    outShape: A,
    filterShape: t
  };
}
function Wv(n, t, e, s, o) {
  s == null && (s = ep(n, t, e));
  const r = n[0], i6 = n[1], a = ci((r - t + 2 * s) / e + 1, o), l = ci((i6 - t + 2 * s) / e + 1, o);
  return [a, l];
}
function Dv(n, t, e, s, o, r) {
  o == null && (o = ep(n, t[0], s[0]));
  const i6 = [0, 0, 0, e];
  for (let a = 0; a < 3; a++)
    n[a] + 2 * o >= t[a] && (i6[a] = ci((n[a] - t[a] + 2 * o) / s[a] + 1, r));
  return i6;
}
function ep(n, t, e, s = 1) {
  const o = cr(t, s);
  return Math.floor((n[0] * (e - 1) - e + o) / 2);
}
function li(n) {
  return typeof n == "number" ? [n, n, n] : n.length === 2 ? [n[0], n[1], 1] : n;
}
function Cd(n) {
  return typeof n == "number" ? [n, n, n] : n;
}
function cr(n, t) {
  return t <= 1 ? n : n + (n - 1) * (t - 1);
}
function Fv(n, t, e, s, o, r, i6, a, l) {
  let c, u, d;
  if (typeof n == "number") {
    c = { top: n, bottom: n, left: n, right: n, type: n === 0 ? "VALID" : "NUMBER" };
    const p = Wv([t, e], r, s, n, a);
    u = p[0], d = p[1];
  } else if (n === "same") {
    u = Math.ceil(t / s), d = Math.ceil(e / o);
    const h = Math.max(0, (u - 1) * s + r - t), p = Math.max(0, (d - 1) * o + i6 - e), f = Math.floor(h / 2), m = h - f, g = Math.floor(p / 2), b = p - g;
    c = { top: f, bottom: m, left: g, right: b, type: "SAME" };
  } else if (n === "valid")
    c = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" }, u = Math.ceil((t - r + 1) / s), d = Math.ceil((e - i6 + 1) / o);
  else if (typeof n == "object") {
    const h = l === "channelsLast" ? n[1][0] : n[2][0], p = l === "channelsLast" ? n[1][1] : n[2][1], f = l === "channelsLast" ? n[2][0] : n[3][0], m = l === "channelsLast" ? n[2][1] : n[3][1];
    c = { top: h, bottom: p, left: f, right: m, type: h === 0 && p === 0 && f === 0 && m === 0 ? "VALID" : "EXPLICIT" }, u = ci((t - r + h + p) / s + 1, a), d = ci((e - i6 + f + m) / o + 1, a);
  } else
    throw Error(`Unknown padding parameter: ${n}`);
  return { padInfo: c, outHeight: u, outWidth: d };
}
function Vv(n, t, e, s, o, r, i6, a, l, c, u) {
  let d, h, p, f;
  if (n === "valid" && (n = 0), typeof n == "number") {
    d = {
      top: n,
      bottom: n,
      left: n,
      right: n,
      front: n,
      back: n,
      type: n === 0 ? "VALID" : "NUMBER"
    };
    const g = Dv([t, e, s, 1], [a, l, c], 1, [o, r, i6], n, u);
    h = g[0], p = g[1], f = g[2];
  } else if (n === "same") {
    h = Math.ceil(t / o), p = Math.ceil(e / r), f = Math.ceil(s / i6);
    const m = (h - 1) * o + a - t, g = (p - 1) * r + l - e, b = (f - 1) * i6 + c - s, x6 = Math.floor(m / 2), w = m - x6, y6 = Math.floor(g / 2), I = g - y6, v = Math.floor(b / 2), k6 = b - v;
    d = { top: y6, bottom: I, left: v, right: k6, front: x6, back: w, type: "SAME" };
  } else
    throw Error(`Unknown padding parameter: ${n}`);
  return { padInfo: d, outDepth: h, outHeight: p, outWidth: f };
}
function ci(n, t) {
  if (!t)
    return Math.trunc(n);
  switch (t) {
    case "round":
      return Math.round(n);
    case "ceil":
      return Math.ceil(n);
    case "floor":
      return Math.floor(n);
    default:
      throw new Error(`Unknown roundingMode ${t}`);
  }
}
function No(n) {
  const [t, e, s] = li(n);
  return t === 1 && e === 1 && s === 1;
}
function Le(n, t) {
  return No(n) || No(t);
}
function Ro(n) {
  return li(n).every((t) => t > 0);
}
function Ss(n) {
  if (n === "NHWC")
    return "channelsLast";
  if (n === "NCHW")
    return "channelsFirst";
  throw new Error(`Unknown dataFormat ${n}`);
}
function Ue(n, t, e) {
  if (e != null) {
    if (typeof t == "string")
      throw Error(`Error in ${n}: pad must be an integer when using dimRoundingMode ${e} but got pad ${t}.`);
    if (typeof t == "number")
      C(Co(t), () => `Error in ${n}: pad must be an integer when using dimRoundingMode ${e} but got pad ${t}.`);
    else if (typeof t == "object")
      t.forEach((s) => {
        s.forEach((o) => {
          C(Co(o), () => `Error in ${n}: pad must be an integer when using dimRoundingMode ${e} but got pad ${o}.`);
        });
      });
    else
      throw Error(`Error in ${n}: Unknown padding parameter: ${t}`);
  }
}
function zv(n, t) {
  const s = { x: T(n, "x", "reshape", "string_or_numeric") }, o = { shape: t };
  return $.runKernel(Dc, s, o);
}
var W = L({ reshape_: zv });
function Pv(n, t, e, s, o) {
  const r = T(n, "x", "avgPool", "float32"), i6 = 1;
  C(Le(e, i6), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${e} and dilations '${i6}'`);
  let a = r, l = false;
  r.rank === 3 && (l = true, a = W(r, [1, r.shape[0], r.shape[1], r.shape[2]])), C(a.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${a.rank}.`), Ue("avgPool", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o };
  let d = $.runKernel(Jl, c, u);
  return d = tt(d, r.dtype), l ? W(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}
var np = L({ avgPool_: Pv });
function Av(n, t, e, s, o, r = "NDHWC") {
  const i6 = T(n, "x", "avgPool3d", "float32");
  let a = i6, l = false;
  i6.rank === 4 && (l = true, a = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]])), C(a.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${a.rank}.`), C(r === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${r}`), C(typeof e == "number" && e > 0 || Array.isArray(e) && e[0] > 0 && e[1] > 0 && e[2] > 0, () => `Error in avgPool3d: Stride must be > 0, but got '${e}'`), Ue("avgPool3d", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o, dataFormat: r };
  let d = $.runKernel(jl, c, u);
  return d = tt(d, a.dtype), l ? W(d, [d.shape[1], d.shape[2], d.shape[3], d.shape[4]]) : d;
}
var Ov = L({ avgPool3d_: Av });
function Xv(n, t = 0) {
  C(n.length >= 1, () => "Pass at least one tensor to concat");
  const e = jh(n, "tensors", "concat", "string_or_numeric");
  if (e[0].dtype === "complex64" && e.forEach((r) => {
    if (r.dtype !== "complex64")
      throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${r.dtype}. `);
  }), e.length === 1)
    return yo(e[0]);
  const s = e, o = { axis: t };
  return $.runKernel(nc, s, o);
}
var Ge = L({ concat_: Xv });
function Kv(n, t, e = false, s = false) {
  let o = T(n, "a", "matMul"), r = T(t, "b", "matMul");
  [o, r] = se(o, r);
  const i6 = { a: o, b: r }, a = { transposeA: e, transposeB: s };
  return $.runKernel(ql, i6, a);
}
var Gt = L({ matMul_: Kv });
function Zv(n) {
  const e = { x: T(n, "x", "sigmoid", "float32") };
  return $.runKernel(ca, e);
}
var kr = L({ sigmoid_: Zv });
function Bv(n, t, e) {
  const s = T(n, "x", "slice", "string_or_numeric");
  if (s.rank === 0)
    throw new Error("Slicing scalar is not possible");
  const o = { x: s }, r = { begin: t, size: e };
  return $.runKernel(Ac, o, r);
}
var Ft = L({ slice_: Bv });
function Hv(n) {
  const e = { x: T(n, "x", "tanh", "float32") };
  return $.runKernel(ma, e);
}
var sp = L({ tanh_: Hv });
function _v(n, t, e) {
  const s = T(n, "x", "batchToSpaceND"), o = t.reduce((a, l) => a * l);
  C(s.rank >= 1 + t.length, () => `input rank is ${s.rank} but should be > than blockShape.length ${t.length}`), C(e.length === t.length, () => `crops.length is ${e.length} but should be equal to blockShape.length  ${t.length}`), C(s.shape[0] % o === 0, () => `input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${o}`);
  const r = { x: s }, i6 = { blockShape: t, crops: e };
  return $.runKernel(tc, r, i6);
}
var op = L({ batchToSpaceND_: _v });
function Uv(n) {
  let t;
  return n.rank === 0 || n.rank === 1 ? t = W(n, [1, 1, 1, n.size]) : n.rank === 2 ? t = W(n, [1, 1, n.shape[0], n.shape[1]]) : n.rank === 3 ? t = W(n, [1, n.shape[0], n.shape[1], n.shape[2]]) : t = n, t;
}
function Yv(n, t, e, s, o, r) {
  r == null && (r = 1e-3);
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  s != null && (u = T(s, "offset", "batchNorm")), C(a.rank === l.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks."), C(u == null || a.rank === u.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks."), C(c == null || a.rank === c.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  const h = {
    x: Uv(i6),
    scale: c,
    offset: u,
    mean: a,
    variance: l
  }, p = { varianceEpsilon: r }, f = $.runKernel(dc, h, p);
  return W(f, i6.shape);
}
var Qc = L({ batchNorm_: Yv });
function Qv(n, t, e, s, o, r) {
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  return s != null && (u = T(s, "offset", "batchNorm")), C(i6.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${i6.rank}.`), C(a.rank === 2 || a.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${a.rank}.`), C(l.rank === 2 || l.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`), c != null && C(c.rank === 2 || c.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${c.rank}.`), u != null && C(u.rank === 2 || u.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${u.rank}.`), Qc(i6, a, l, u, c, r);
}
var Jv = L({ batchNorm2d_: Qv });
function jv(n, t, e, s, o, r) {
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  return s != null && (u = T(s, "offset", "batchNorm")), C(i6.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${i6.rank}.`), C(a.rank === 3 || a.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${a.rank}.`), C(l.rank === 3 || l.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`), c != null && C(c.rank === 3 || c.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${c.rank}.`), u != null && C(u.rank === 3 || u.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${u.rank}.`), Qc(i6, a, l, u, c, r);
}
var qv = L({ batchNorm3d_: jv });
function tS(n, t, e, s, o, r) {
  const i6 = T(n, "x", "batchNorm"), a = T(t, "mean", "batchNorm"), l = T(e, "variance", "batchNorm");
  let c;
  o != null && (c = T(o, "scale", "batchNorm"));
  let u;
  return s != null && (u = T(s, "offset", "batchNorm")), C(i6.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${i6.rank}.`), C(a.rank === 4 || a.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${a.rank}.`), C(l.rank === 4 || l.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`), c != null && C(c.rank === 4 || c.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${c.rank}.`), u != null && C(u.rank === 4 || u.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${u.rank}.`), Qc(i6, a, l, u, c, r);
}
var eS = L({ batchNorm4d_: tS });
function nS(n, t, e) {
  const s = T(n, "x", "bincount"), o = T(t, "weights", "bincount");
  C(s.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${s.dtype}`), C(e >= 0, () => `size must be non-negative, but got ${e}.`), C(o.size === s.size || o.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${s.shape}, weights shape: ${o.shape}.`);
  const r = { x: s, weights: o }, i6 = { size: e };
  return $.runKernel(oh, r, i6);
}
var sS = L({ bincount_: nS });
function oS(n, t) {
  let e = T(n, "broadcastTo", "x");
  const s = e.shape;
  if (is(t), t.length < e.rank)
    throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${e.rank}.`);
  if (t.length > e.rank) {
    const c = e.shape.slice();
    for (; c.length < t.length; )
      c.unshift(1);
    e = W(e, c);
  }
  const o = e.shape, r = Array.from(t);
  for (let c = t.length - 1; c >= 0; c--)
    if (o[c] === t[c])
      r[c] = 1;
    else if (e.shape[c] !== 1)
      throw new Error(`broadcastTo(): [${s}] cannot be broadcast to [${t}].`);
  if (r.map((c, u) => c > 1 ? u : -1).filter((c) => c >= 0).length === 0)
    return yo(e);
  const a = { x: e }, l = { reps: r };
  return $.runKernel(ga, a, l);
}
var ni = L({ broadcastTo_: oS });
function rS(n) {
  const e = { x: T(n, "x", "ceil", "float32") };
  return $.runKernel(Ei, e);
}
var iS = L({ ceil_: rS });
function Ca(n, t, e) {
  is(n), e = e || Oo(t);
  const s = { shape: n, value: t, dtype: e };
  return $.runKernel(wh, {}, s);
}
function aS(n, t, e) {
  const s = T(n, "x", "clipByValue");
  if (C(t <= e, () => `Error in clip: min (${t}) must be less than or equal to max (${e}).`), t === e)
    return Ca(s.shape, t, s.dtype);
  const o = { x: s }, r = { clipValueMin: t, clipValueMax: e };
  return $.runKernel(Li, o, r);
}
var fn = L({ clipByValue_: aS });
function lS(n) {
  return Ge(
    n,
    0
    /* axis */
  );
}
var cS = L({ concat1d_: lS });
function uS(n, t) {
  return Ge(n, t);
}
var dS = L({ concat2d_: uS });
function hS(n, t) {
  return Ge(n, t);
}
var pS = L({ concat3d_: hS });
function fS(n, t) {
  return Ge(n, t);
}
var mS = L({ concat4d_: fS });
function gS(n, t, e, s, o = "NHWC", r = [1, 1], i6) {
  const a = T(n, "x", "conv2d", "float32"), l = T(t, "filter", "conv2d", "float32");
  let c = a, u = false;
  a.rank === 3 && (u = true, c = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), C(c.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${c.rank}.`), C(l.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`), Ue("conv2d", s, i6);
  const d = o === "NHWC" ? c.shape[3] : c.shape[1];
  C(d === l.shape[2], () => `Error in conv2d: depth of input (${d}) must match input depth for filter ${l.shape[2]}.`), C(Le(e, r), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${e} and dilations '${r}'`), C(Ro(r), () => "Error in conv2D: Dilated rates should be larger than 0."), C(Ro(e), () => "Error in conv2D: Strides should be larger than 0.");
  const h = { x: c, filter: l }, p = { strides: e, pad: s, dataFormat: o, dilations: r, dimRoundingMode: i6 }, f = $.runKernel(sc, h, p);
  return u ? W(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}
var $o = L({ conv2d_: gS });
function bS(n, t, e, s, o = "NWC", r = 1, i6) {
  const a = T(n, "x", "conv1d"), l = T(t, "filter", "conv1d");
  let c = a, u = false;
  a.rank === 2 && (u = true, c = W(a, [1, a.shape[0], a.shape[1]])), C(c.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${c.rank}.`), C(l.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`), Ue("conv1d", s, i6), C(c.shape[2] === l.shape[1], () => `Error in conv1d: depth of input (${c.shape[2]}) must match input depth for filter ${l.shape[1]}.`), C(Le(e, r), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${e} and dilation '${r}'`), C(Ro(r), () => "Error in conv1D: Dilated rates should be larger than 0."), C(Ro(e), () => "Error in conv1D: Stride should be larger than 0."), C(o === "NWC", () => `Error in conv1d: got dataFormat of ${o} but only NWC is currently supported.`);
  const d = W(l, [1, l.shape[0], l.shape[1], l.shape[2]]), h = W(c, [c.shape[0], 1, c.shape[1], c.shape[2]]), g = $o(h, d, [1, e], s, "NHWC", [1, r], i6);
  return u ? W(g, [g.shape[2], g.shape[3]]) : W(g, [g.shape[0], g.shape[2], g.shape[3]]);
}
var Jb = L({ conv1d_: bS });
function xS(n, t, e, s, o, r = "NHWC", i6) {
  C(n.length === t.rank, () => `Length of inShape (${n.length}) and rank of dy (${t.rank}) must match`);
  let a = n, l = t, c = false;
  t.rank === 3 && (c = true, l = W(t, [1, t.shape[0], t.shape[1], t.shape[2]]), a = [1, n[0], n[1], n[2]]), C(a.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${a.length}.`), C(l.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`), C(e.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${e.rank}`);
  const u = r === "NHWC" ? a[3] : a[1], d = r === "NHWC" ? l.shape[3] : l.shape[1];
  C(u === e.shape[2], () => `Error in conv2dDerInput: depth of input (${u}) must match input depth for filter ${e.shape[2]}.`), C(d === e.shape[3], () => `Error in conv2dDerInput: depth of output (${d}) must match output depth for filter ${e.shape[3]}.`), Ue("conv2dDerInput", o, i6);
  const h = { dy: l, filter: e }, p = { strides: s, pad: o, dataFormat: r, dimRoundingMode: i6, inputShape: a }, f = $.runKernel(oc, h, p);
  return c ? W(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}
var rp = L({ conv2DBackpropInput_: xS });
function yS(n, t, e, s, o, r) {
  const i6 = T(n, "x", "conv2dTranspose"), a = T(t, "filter", "conv2dTranspose");
  return rp(e, i6, a, s, o, "NHWC", r);
}
var jb = L({ conv2dTranspose_: yS });
function wS(n, t, e, s, o = "NDHWC", r = [1, 1, 1]) {
  const i6 = T(n, "x", "conv3d"), a = T(t, "filter", "conv3d");
  let l = i6, c = false;
  i6.rank === 4 && (c = true, l = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]])), C(l.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${l.rank}.`), C(a.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${a.rank}.`), C(l.shape[4] === a.shape[3], () => `Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${a.shape[3]}.`), C(Le(e, r), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${e} and dilations '${r}'`), C(o === "NDHWC", () => `Error in conv3d: got dataFormat of ${o} but only NDHWC is currently supported.`), C(Ro(r), () => "Error in conv3D: Dilated rates should be larger than 0."), C(Ro(e), () => "Error in conv3D: Strides should be larger than 0.");
  const u = { x: l, filter: a }, d = { strides: e, pad: s, dataFormat: o, dilations: r }, h = $.runKernel(rc, u, d);
  return c ? W(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h;
}
var IS = L({ conv3d_: wS });
function CS(n, t, e, s, o) {
  C(n.length === t.rank, () => `Length of inShape (${n.length}) and rank of dy (${t.rank}) must match`);
  let r = n, i6 = t, a = false;
  t.rank === 4 && (a = true, i6 = W(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]]), r = [1, n[0], n[1], n[2], n[3]]);
  const l = r[4], c = i6.shape[4];
  C(r.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${r.length}.`), C(i6.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${i6.rank}`), C(e.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${e.rank}`), C(l === e.shape[3], () => `Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${e.shape[3]}.`), C(c === e.shape[4], () => `Error in conv3dDerInput: depth of output (${c}) must match output depth for filter ${e.shape[4]}.`);
  const u = { dy: i6, filter: e }, d = { pad: o, strides: s, inputShape: r }, h = $.runKernel(ch, u, d);
  return a ? W(h, [h.shape[1], h.shape[2], h.shape[3], h.shape[4]]) : h;
}
var qb = L({ conv3DBackpropInput_: CS });
function vS(n, t, e, s, o) {
  const r = T(n, "x", "conv3dTranspose"), i6 = T(t, "filter", "conv3dTranspose");
  return qb(e, r, i6, s, o);
}
var SS = L({ conv3dTranspose_: vS });
function kS(n) {
  const e = { x: T(n, "x", "cos", "float32") };
  return $.runKernel(Mi, e);
}
var ip = L({ cos_: kS });
function TS(n) {
  const e = { x: T(n, "x", "cosh", "float32") };
  return $.runKernel(Wi, e);
}
var t0 = L({ cosh_: TS });
function NS(n, t = 0, e = false, s = false) {
  const r = { x: T(n, "x", "cumprod") }, i6 = { axis: t, exclusive: e, reverse: s };
  return $.runKernel(uh, r, i6);
}
var vd = L({ cumprod_: NS });
function RS(n, t = 0, e = false, s = false) {
  const r = { x: T(n, "x", "cumsum") }, i6 = { axis: t, exclusive: e, reverse: s };
  return $.runKernel(ic, r, i6);
}
var e0 = L({ cumsum_: RS });
function $S(n, t, e, s = false) {
  const o = T(n, "x", "denseBincount"), r = T(t, "weights", "denseBincount");
  C(o.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${o.dtype}`), C(o.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${o.rank}.`), C(e >= 0, () => `size must be non-negative, but got ${e}.`), C(r.size === o.size || r.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${o.shape}, weights shape: ${r.shape}.`);
  const i6 = { x: o, weights: r }, a = { size: e, binaryOutput: s };
  return $.runKernel(hh, i6, a);
}
var Tm = L({ denseBincount_: $S });
function GS(n, t, e = "NHWC") {
  const s = T(n, "x", "depthToSpace", "float32"), o = e === "NHWC" ? s.shape[1] : s.shape[2], r = e === "NHWC" ? s.shape[2] : s.shape[3], i6 = e === "NHWC" ? s.shape[3] : s.shape[1];
  C(t > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${t}`), C(o * t >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${o} and ${t}  for depthToSpace with input shape
    ${s.shape}`), C(r * t >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${r} and ${t} for depthToSpace with input shape
        ${s.shape}`), C(i6 % (t * t) === 0, () => `Dimension size must be evenly divisible by ${t * t} but is ${i6} for depthToSpace with input shape ${s.shape}`);
  const a = { x: s }, l = { blockSize: t, dataFormat: e };
  return $.runKernel(ph, a, l);
}
var ES = L({ depthToSpace_: GS });
function LS(n, t, e, s, o = "NHWC", r = [1, 1], i6) {
  const a = T(n, "x", "depthwiseConv2d", "float32"), l = T(t, "filter", "depthwiseConv2d", "float32");
  let c = a, u = false;
  a.rank === 3 && (u = true, c = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), C(c.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${c.rank}.`), C(l.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`);
  const d = o === "NHWC" ? c.shape[3] : c.shape[1];
  C(d === l.shape[2], () => `Error in depthwiseConv2d: number of input channels (${d}) must match the inChannels dimension in filter ${l.shape[2]}.`), Ue("depthwiseConv2d", s, i6);
  const h = { x: c, filter: l }, p = { strides: e, pad: s, dataFormat: o, dilations: r, dimRoundingMode: i6 }, f = $.runKernel(ac, h, p);
  return u ? W(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}
var ap = L({ depthwiseConv2d_: LS });
function MS(n, t, e, s, o = [1, 1], r = "NHWC") {
  const i6 = T(n, "x", "dilation2d"), a = T(t, "filter", "dilation2d");
  C(i6.rank === 3 || i6.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${i6.rank}.`), C(a.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${a.rank}.`), C(r === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${r}`);
  let l = i6, c = false;
  i6.rank === 3 && (l = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2]]), c = true), C(l.shape[3] === a.shape[2], () => `Error in dilation2d:  input and filter must have the same depth: ${l.shape[3]} vs ${a.shape[2]}`);
  const u = { x: l, filter: a }, d = { strides: e, pad: s, dilations: o }, h = $.runKernel(lc, u, d);
  return c ? W(h, [h.shape[1], h.shape[2], h.shape[3]]) : h;
}
var WS = L({ dilation2d_: MS });
function Go(n, t) {
  const e = n.length, s = [];
  for (let o = 0; o < e; o++) {
    const r = e - 1 - o, i6 = n[r] || 1;
    (t[t.length - 1 - o] || 1) > 1 && i6 === 1 && s.unshift(r);
  }
  return s;
}
function ce(n, t) {
  const e = [];
  for (let s = 0; s < t.length; s++) {
    const o = n[n.length - s - 1], r = t.length - s - 1, i6 = t[r];
    (o == null || o === 1 && i6 > 1) && e.unshift(r);
  }
  return e;
}
function bt(n, t) {
  const e = Math.max(n.length, t.length), s = new Array(e);
  for (let o = 0; o < e; o++) {
    let r = n[n.length - o - 1];
    r == null && (r = 1);
    let i6 = t[t.length - o - 1];
    if (i6 == null && (i6 = 1), r === 1)
      s[e - o - 1] = i6;
    else if (i6 === 1)
      s[e - o - 1] = r;
    else if (r !== i6) {
      const a = `Operands could not be broadcast together with shapes ${n} and ${t}.`;
      throw Error(a);
    } else
      s[e - o - 1] = r;
  }
  return s;
}
var wQ = Object.freeze(Object.defineProperty({
  __proto__: null,
  assertAndGetBroadcastShape: bt,
  getBroadcastDims: Go,
  getReductionAxes: ce
}, Symbol.toStringTag, { value: "Module" }));
function DS(n, t) {
  let e = T(n, "a", "equal", "string_or_numeric"), s = T(t, "b", "equal", "string_or_numeric");
  [e, s] = se(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(cc, o);
}
var Tn = L({ equal_: DS });
function FS(n, t, e) {
  const s = T(t, "a", "where"), o = T(e, "b", "where"), r = T(n, "condition", "where", "bool"), i6 = bt(bt(r.shape, s.shape), o.shape), a = ni(r, i6), l = ni(s, i6), c = ni(o, i6), u = {
    condition: a,
    t: l,
    e: c
  };
  return $.runKernel(Pc, u);
}
var Ee = L({ where_: FS });
function VS(n) {
  const e = { x: T(n, "x", "zerosLike") };
  return $.runKernel(Uc, e);
}
var Tt = L({ zerosLike_: VS });
function zS(n, t) {
  let e = T(n, "a", "div"), s = T(t, "b", "div");
  [e, s] = se(e, s);
  const o = ut(e, s), r = Tt(o), i6 = Tn(s, r);
  return Ee(i6, r, o);
}
var PS = L({ divNoNan_: zS });
function AS(n, t) {
  const e = T(n, "t1", "dot"), s = T(t, "t2", "dot");
  C((e.rank === 1 || e.rank === 2) && (s.rank === 1 || s.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${e.rank} and ${s.rank}.`);
  const o = e.rank === 1 ? e.size : e.shape[1], r = s.rank === 1 ? s.size : s.shape[0];
  if (C(o === r, () => `Error in dot: inner dimensions of inputs must match, but got ${o} and ${r}.`), e.rank === 1 && s.rank === 1) {
    const i6 = W(e, [1, -1]), a = W(s, [-1, 1]), l = Gt(i6, a);
    return W(l, []);
  } else if (e.rank === 1 && s.rank === 2) {
    const i6 = W(e, [1, -1]), a = W(s, [s.shape[0], s.shape[1]]), l = Gt(i6, a);
    return W(l, [l.size]);
  } else if (e.rank === 2 && s.rank === 1) {
    const i6 = W(s, [-1, 1]), a = Gt(e, i6);
    return W(a, [a.size]);
  } else {
    const i6 = W(s, [s.shape[0], s.shape[1]]);
    return Gt(e, i6);
  }
}
var OS = L({ dot_: AS });
function XS(n, ...t) {
  const e = t.map((o, r) => T(o, `tensors${r}`, "einsum")), s = { equation: n };
  return $.runKernel(bh, e, s);
}
var Or = L({ einsum_: XS });
function KS(n) {
  const e = { x: T(n, "x", "elu", "float32") };
  return $.runKernel(Fi, e);
}
var Jc = L({ elu_: KS });
function ZS(n) {
  let t = T(n, "x", "erf");
  C(t.dtype === "int32" || t.dtype === "float32", () => "Input dtype must be `int32` or `float32`."), t.dtype === "int32" && (t = tt(t, "float32"));
  const e = { x: t };
  return $.runKernel(Vi, e);
}
var BS = L({ erf_: ZS });
function lp(n, t) {
  for (let e = 0; e < n.length; ++e)
    if (n[n.length - e - 1] !== t - 1 - e)
      return false;
  return true;
}
function n0(n, t, e) {
  const s = n.length + t.length, o = [];
  let r = 0, i6 = 0;
  for (let a = 0; a < s; a++)
    e.indexOf(a) === -1 ? o.push(n[r++]) : o.push(t[i6++]);
  return o;
}
function ye(n, t) {
  const e = [], s = n.length;
  for (let r = 0; r < s; r++)
    t.indexOf(r) === -1 && e.push(n[r]);
  const o = t.map((r) => n[r]);
  return [e, o];
}
function re(n, t) {
  const e = t.map((s) => 1);
  return n0(n, e, t);
}
function Ne(n, t, e) {
  C(lp(t, e), () => `${n} supports only inner-most axes for now. Got axes ${t} and rank-${e} input.`);
}
function qt(n, t) {
  if (lp(n, t))
    return null;
  const e = [];
  for (let s = 0; s < t; ++s)
    n.indexOf(s) === -1 && e.push(s);
  return n.forEach((s) => e.push(s)), e;
}
function js(n) {
  return n.map((t, e) => [e, t]).sort((t, e) => t[1] - e[1]).map((t) => t[0]);
}
function ie(n, t) {
  const e = [];
  for (let s = t - n; s < t; ++s)
    e.push(s);
  return e;
}
function HS(n, t = null, e = false) {
  const o = { x: T(n, "x", "max") }, r = { reductionIndices: t, keepDims: e };
  return $.runKernel(Ic, o, r);
}
var Pn = L({ max_: HS });
function _S(n, t = null, e = false) {
  const o = { x: T(n, "x", "min") }, r = { axis: t, keepDims: e };
  return $.runKernel(kc, o, r);
}
var Il = L({ min_: _S });
function US(n, t) {
  let e = T(n, "base", "pow"), s = T(t, "exp", "pow");
  [e, s] = se(e, s);
  const o = { a: e, b: s };
  return $.runKernel(qi, o);
}
var gr = L({ pow_: US });
function gt(n, t) {
  if ((qe(n) && t !== "string" || Array.isArray(n)) && t !== "complex64")
    throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  if (t === "string" && qe(n) && !(n instanceof Uint8Array))
    throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  return wa(n, [], [], t);
}
function YS(n) {
  const e = { x: T(n, "x", "sqrt", "float32") };
  return $.runKernel(da, e);
}
var Ve = L({ sqrt_: YS });
function QS(n) {
  const t = T(n, "x", "square"), e = {};
  return $.runKernel("Square", { x: t }, e);
}
var Kt = L({ square_: QS });
function JS(n, t = null, e = false) {
  let s = T(n, "x", "sum");
  s.dtype === "bool" && (s = tt(s, "int32"));
  const o = { x: s }, r = { axis: t, keepDims: e };
  return $.runKernel(Oc, o, r);
}
var at = L({ sum_: JS });
function jS(n, t = "euclidean", e = null, s = false) {
  n = T(n, "x", "norm");
  const o = s0(n, t, e);
  let r = o.shape;
  if (s) {
    const i6 = Ct(e, n.shape);
    r = re(o.shape, i6);
  }
  return W(o, r);
}
function s0(n, t, e = null) {
  if (n.rank === 0)
    return me(n);
  if (n.rank !== 1 && e === null)
    return s0(W(n, [-1]), t, e);
  if (n.rank === 1 || typeof e == "number" || Array.isArray(e) && e.length === 1) {
    if (t === 1)
      return at(me(n), e);
    if (t === 1 / 0)
      return Pn(me(n), e);
    if (t === -1 / 0)
      return Il(me(n), e);
    if (t === "euclidean" || t === 2)
      return Ve(at(gr(me(n), gt(2, "int32")), e));
    throw new Error(`Error in norm: invalid ord value: ${t}`);
  }
  if (Array.isArray(e) && e.length === 2) {
    if (t === 1)
      return Pn(at(me(n), e[0]), e[1] - 1);
    if (t === 1 / 0)
      return Pn(at(me(n), e[1]), e[0]);
    if (t === -1 / 0)
      return Il(at(me(n), e[1]), e[0]);
    if (t === "fro" || t === "euclidean")
      return Ve(at(Kt(n), e));
    throw new Error(`Error in norm: invalid ord value: ${t}`);
  }
  throw new Error(`Error in norm: invalid axis: ${e}`);
}
var jc = L({ norm_: jS });
function qS(n, t = null, e = false) {
  return jc(n, "euclidean", t, e);
}
var tk = L({ euclideanNorm_: qS });
function ek(n) {
  const e = { x: T(n, "x", "exp") };
  return $.runKernel(zi, e);
}
var mn = L({ exp_: ek });
function nk(n, t = 0) {
  const e = T(n, "x", "expandDims", "string_or_numeric");
  C(t <= e.rank, () => "Axis must be <= rank of the tensor");
  const s = { input: e }, o = { dim: t };
  return $.runKernel(uc, s, o);
}
var Oe = L({ expandDims_: nk });
function sk(n) {
  const e = { x: T(n, "x", "expm1") };
  return $.runKernel(Pi, e);
}
var ok = L({ expm1_: sk });
function rk(n, t) {
  const e = T(n, "x", "tile", "string_or_numeric");
  C(e.rank === t.length, () => `Error in transpose: rank of input ${e.rank} must match length of reps ${t}.`);
  const s = { x: e }, o = { reps: t };
  return $.runKernel(ga, s, o);
}
var Vn = L({ tile_: rk });
function ik(n, t, e, s = "float32") {
  t == null && (t = n);
  const o = vt([n, t], s), r = n <= t ? n : t;
  for (let a = 0; a < r; ++a)
    o.set(1, a, a);
  const i6 = W(o.toTensor(), [n, t]);
  if (e == null)
    return i6;
  if (e.length === 1)
    return Vn(Oe(i6, 0), [e[0], 1, 1]);
  if (e.length === 2)
    return Vn(Oe(Oe(i6, 0), 0), [e[0], e[1], 1, 1]);
  if (e.length === 3)
    return Vn(Oe(Oe(Oe(i6, 0), 0), 0), [
      e[0],
      e[1],
      e[2],
      1,
      1
    ]);
  throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${e.length}D.`);
}
var o0 = L({ eye_: ik });
function ak(n) {
  const e = { x: T(n, "x", "floor", "float32") };
  return $.runKernel(Ai, e);
}
var qc = L({ floor_: ak });
function lk(n, t, e = 0, s = 0) {
  const o = T(n, "x", "gather"), r = T(t, "indices", "gather", "int32"), i6 = { x: o, indices: r }, a = { axis: e, batchDims: s };
  return $.runKernel(hc, i6, a);
}
var cp = L({ gather_: lk });
function ck(n, t) {
  let e = T(n, "a", "greater", "string_or_numeric"), s = T(t, "b", "greater", "string_or_numeric");
  [e, s] = se(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(pc, o);
}
var rn = L({ greater_: ck });
function uk(n, t) {
  let e = T(n, "a", "greaterEqual", "string_or_numeric"), s = T(t, "b", "greaterEqual", "string_or_numeric");
  [e, s] = se(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(Xi, o);
}
var Bo = L({ greaterEqual_: uk });
function dk(n) {
  const e = { input: T(n, "input", "imag") };
  return $.runKernel(vh, e);
}
var up = L({ imag_: dk });
function hk(n) {
  const e = { x: T(n, "x", "isFinite") };
  return $.runKernel(Zi, e);
}
var pk = L({ isFinite_: hk });
function fk(n) {
  const e = { x: T(n, "x", "isInf") };
  return $.runKernel(Bi, e);
}
var mk = L({ isInf_: fk });
function gk(n) {
  const e = { x: T(n, "x", "isNaN") };
  return $.runKernel(Hi, e);
}
var bk = L({ isNaN_: gk });
function xk(n, t = 0.2) {
  const s = { x: T(n, "x", "leakyRelu") }, o = { alpha: t };
  return $.runKernel(fc, s, o);
}
var dp = L({ leakyRelu_: xk });
function yk(n, t) {
  let e = T(n, "a", "less", "string_or_numeric"), s = T(t, "b", "less", "string_or_numeric");
  [e, s] = se(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(mc, o);
}
var Cl = L({ less_: yk });
function wk(n, t) {
  let e = T(n, "a", "lessEqual", "string_or_numeric"), s = T(t, "b", "lessEqual", "string_or_numeric");
  [e, s] = se(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(gc, o);
}
var Tr = L({ lessEqual_: wk });
function Ik(n, t = 5, e = 1, s = 1, o = 0.5) {
  const r = T(n, "x", "localResponseNormalization");
  C(r.rank === 4 || r.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${r.rank}.`), C(Co(t), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`);
  let i6 = r, a = false;
  r.rank === 3 && (a = true, i6 = W(r, [1, r.shape[0], r.shape[1], r.shape[2]]));
  const l = { x: i6 }, c = { depthRadius: t, bias: e, alpha: s, beta: o }, u = $.runKernel(wc, l, c);
  return a ? W(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;
}
var Ck = L({ localResponseNormalization_: Ik });
function vk(n) {
  const e = { x: T(n, "x", "log", "float32") };
  return $.runKernel(_i, e);
}
var Nn = L({ log_: vk });
function Sk(n) {
  const e = { x: T(n, "x", "log1p") };
  return $.runKernel(Ui, e);
}
var hp = L({ log1p_: Sk });
function IQ(n) {
  return C(Xs(n), () => "The f passed in grad(f) must be a function"), (t, e) => {
    const s = T(t, "x", "tf.grad", "string_or_numeric"), o = e != null ? T(e, "dy", "tf.grad") : null;
    return $.tidy(() => {
      const { value: r, grads: i6 } = $.gradients(() => n(s), [s], o);
      return o != null && Pe(r.shape, o.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)"), tu(i6), i6[0];
    });
  };
}
function CQ(n) {
  return C(Xs(n), () => "The f passed in grads(f) must be a function"), (t, e) => {
    C(Array.isArray(t), () => "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s");
    const s = jh(t, "args", "tf.grads", "string_or_numeric"), o = e != null ? T(e, "dy", "tf.grads") : null;
    return $.tidy(() => {
      const { value: r, grads: i6 } = $.gradients(() => n(...s), s, o);
      return o != null && Pe(r.shape, o.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), tu(i6), i6;
    });
  };
}
function vQ(n) {
  return C(Xs(n), () => "The f passed in valueAndGrad(f) must be a function"), (t, e) => {
    C(t instanceof Mt, () => "The x passed in valueAndGrad(f)(x) must be a tensor"), C(e == null || e instanceof Mt, () => "The dy passed in valueAndGrad(f)(x, dy) must be a tensor");
    const { grads: s, value: o } = $.gradients(() => n(t), [t], e);
    return tu(s), { grad: s[0], value: o };
  };
}
function SQ(n) {
  return C(Xs(n), () => "The f passed in valueAndGrads(f) must be a function"), (t, e) => {
    C(Array.isArray(t) && t.every((o) => o instanceof Mt), () => "The args passed in valueAndGrads(f)(args) must be array of tensors"), C(e == null || e instanceof Mt, () => "The dy passed in valueAndGrads(f)(args, dy) must be a tensor");
    const s = $.gradients(() => n(...t), t, e);
    return e != null && Pe(s.value.shape, e.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), tu(s.grads), s;
  };
}
function kk(n, t) {
  C(Xs(n), () => "The f passed in variableGrads(f) must be a function"), C(t == null || Array.isArray(t) && t.every((c) => c instanceof yl), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  const e = t != null;
  if (!e) {
    t = [];
    for (const c in $.registeredVariables)
      t.push($.registeredVariables[c]);
  }
  const s = e ? t.filter((c) => !c.trainable) : null, o = t.length;
  t = t.filter((c) => c.trainable), C(t.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${o} variables is trainable.`);
  const r = true, { value: i6, grads: a } = $.gradients(n, t, null, r);
  C(a.some((c) => c != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."), C(i6.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${i6.rank} tensor`);
  const l = {};
  return t.forEach((c, u) => {
    a[u] != null && (l[c.name] = a[u]);
  }), s != null && s.forEach((c) => l[c.name] = null), { value: i6, grads: l };
}
function Eo(n) {
  return $.customGrad(n);
}
function tu(n) {
  if (n.filter((e) => e == null).length > 0)
    throw new Error(`Cannot compute gradient of y=f(x) with respect to x. Make sure that
    the f you passed encloses all operations that lead from x to y.`);
}
function Tk(n) {
  const e = { x: T(n, "x", "neg") };
  return $.runKernel(Nc, e);
}
var Yt = L({ neg_: Tk });
function Nk(n) {
  const e = { x: T(n, "x", "softplus") };
  return $.runKernel(ua, e);
}
var va = L({ softplus_: Nk });
function Rk(n) {
  const t = T(n, "x", "logSigmoid");
  return Eo((s) => ({ value: Yt(va(Yt(s))), gradFunc: (i6) => G(i6, kr(Yt(s))) }))(t);
}
var $k = L({ logSigmoid_: Rk });
function Gk(n, t) {
  let e = T(n, "a", "sub"), s = T(t, "b", "sub");
  [e, s] = se(e, s);
  const o = { a: e, b: s };
  return $.runKernel(pa, o);
}
var it = L({ sub_: Gk });
function Ek(n, t = -1) {
  const e = T(n, "logits", "logSoftmax");
  if (t === -1 && (t = e.rank - 1), t !== e.rank - 1)
    throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${e.rank} and axis was ${t}`);
  return Eo((o, r) => {
    const a = Pn(o, t, true), l = it(o, a), c = it(tt(l, "float32"), Nn(at(mn(l), t, true)));
    return r([c]), { value: c, gradFunc: (d, h) => {
      const [p] = h, f = true, m = mn(p);
      return it(d, G(at(d, t, f), m));
    } };
  })(e);
}
var r0 = L({ logSoftmax_: Ek });
function Lk(n, t = null, e = false) {
  const s = T(n, "x", "logSumExp"), o = Ct(t, s.shape), r = Pn(
    s,
    o,
    true
    /* keepDims */
  ), i6 = it(s, r), a = mn(i6), l = at(a, o), c = Nn(l), u = U(W(r, c.shape), c);
  if (e) {
    const d = re(u.shape, o);
    return W(u, d);
  }
  return u;
}
var pp = L({ logSumExp_: Lk });
function Mk(n, t) {
  const e = T(n, "a", "logicalAnd", "bool"), s = T(t, "b", "logicalAnd", "bool");
  bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(bc, o);
}
var ss = L({ logicalAnd_: Mk });
function Wk(n) {
  const e = { x: T(n, "x", "logicalNot", "bool") };
  return $.runKernel(xc, e);
}
var fp = L({ logicalNot_: Wk });
function Dk(n, t) {
  const e = T(n, "a", "logicalOr", "bool"), s = T(t, "b", "logicalOr", "bool");
  bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(yc, o);
}
var i0 = L({ logicalOr_: Dk });
function Fk(n, t) {
  const e = T(n, "a", "logicalXor", "bool"), s = T(t, "b", "logicalXor", "bool");
  return bt(e.shape, s.shape), ss(i0(n, t), fp(ss(n, t)));
}
var Vk = L({ logicalXor_: Fk });
function zk(n, t, e, s, o) {
  const r = T(n, "x", "maxPool"), i6 = 1;
  let a = r, l = false;
  r.rank === 3 && (l = true, a = W(r, [1, r.shape[0], r.shape[1], r.shape[2]])), C(a.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${a.rank}.`), C(Le(e, i6), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${e} and dilations '${i6}'`), Ue("maxPool", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o }, d = $.runKernel(Cc, c, u);
  return l ? W(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}
var mp = L({ maxPool_: zk });
function Pk(n, t = [1, 1, 1], e, s, o, r = "NDHWC") {
  const i6 = T(n, "x", "maxPool3d");
  let a = i6, l = false;
  i6.rank === 4 && (l = true, a = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]])), C(a.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${a.rank}.`), C(r === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${r}`), Ue("maxPool3d", s, o);
  const c = { x: a }, u = { filterSize: t, strides: e, pad: s, dimRoundingMode: o, dataFormat: r }, d = $.runKernel(vc, c, u);
  return l ? W(d, [d.shape[1], d.shape[2], d.shape[3], d.shape[4]]) : d;
}
var Ak = L({ maxPool3d_: Pk });
function Ok(n, t) {
  let e = T(n, "a", "maximum"), s = T(t, "b", "maximum");
  [e, s] = se(e, s), e.dtype === "bool" && (e = tt(e, "int32"), s = tt(s, "int32")), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(Yi, o);
}
var qs = L({ maximum_: Ok });
function Xk(n, t = null, e = false) {
  const o = { x: T(n, "x", "mean") }, r = { axis: t, keepDims: e };
  return $.runKernel(Sc, o, r);
}
var oe = L({ mean_: Xk });
function be(n, t = "float32") {
  if (is(n), t === "complex64") {
    const s = be(n, "float32"), o = be(n, "float32");
    return vo(s, o);
  }
  const e = ke(X(n), t);
  return $.makeTensor(e, n, t);
}
function ks(n, t = "float32") {
  if (is(n), t === "complex64") {
    const s = ks(n, "float32"), o = be(n, "float32");
    return vo(s, o);
  }
  const e = _l(X(n), t);
  return $.makeTensor(e, n, t);
}
function Kk(n, t) {
  let e = T(n, "a", "minimum"), s = T(t, "b", "minimum");
  [e, s] = se(e, s), e.dtype === "bool" && (e = tt(e, "int32"), s = tt(s, "int32")), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(Qi, o);
}
var br = L({ minimum_: Kk });
function Zk(n, t, e) {
  C(e === "reflect" || e === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${e}.`);
  const s = T(n, "x", "mirrorPad");
  if (s.rank === 0)
    throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  C(t.length === s.rank, () => `Padding doesn't match input. Must be ${s.rank}. Got ${t.length}.`);
  const o = e === "reflect" ? 1 : 0;
  for (let a = 0; a < s.rank; a++)
    C(t[a].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), C(t[a][0] >= 0 && t[a][0] <= s.shape[a] - o && t[a][1] >= 0 && t[a][1] <= s.shape[a] - o, () => `Padding in dimension ${a} cannot be greater than or equal to ${s.shape[a] - o} or less than 0 for input of shape ${s.shape}`);
  const r = { paddings: t, mode: e }, i6 = { x: s };
  return $.runKernel(Tc, i6, r);
}
var Bk = L({ mirrorPad_: Zk });
function Hk(n, t) {
  let e = T(n, "a", "mod"), s = T(t, "b", "mod");
  [e, s] = se(e, s);
  const o = { a: e, b: s };
  return $.runKernel(Ji, o);
}
var _k = L({ mod_: Hk });
function Uk(n, t = null, e = false) {
  n = T(n, "x", "moments");
  const s = Ct(t, n.shape), o = oe(n, s, e);
  let r = o.shape;
  e || (r = re(o.shape, s));
  const i6 = Kt(it(tt(n, "float32"), W(o, r))), a = oe(i6, s, e);
  return { mean: o, variance: a };
}
var gp = L({ moments_: Uk });
function Yk(n, t) {
  let e = T(n, "a", "notEqual", "string_or_numeric"), s = T(t, "b", "notEqual", "string_or_numeric");
  [e, s] = se(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s };
  return $.runKernel(Rc, o);
}
var ui = L({ notEqual_: Yk });
function Qk(n, t, e = 1, s = 0, o = "int32") {
  if (t < 2)
    throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);
  const i6 = { indices: T(n, "indices", "oneHot", "int32") }, a = { dtype: o, depth: t, onValue: e, offValue: s };
  return $.runKernel(Gc, i6, a);
}
var a0 = L({ oneHot_: Qk });
function Jk(n) {
  const e = { x: T(n, "x", "onesLike") };
  return $.runKernel($c, e);
}
var Rn = L({ onesLike_: Jk });
function jk(n, t, e = 0) {
  const s = T(n, "x", "pad");
  if (s.rank === 0)
    throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  const o = { paddings: t, constantValue: e }, r = { x: s };
  return $.runKernel(Lc, r, o);
}
var bp = L({ pad_: jk });
function qk(n, t, e) {
  const s = T(n, "x", "spaceToBatchND");
  C(s.rank >= 1 + t.length, () => `input rank ${s.rank} should be > than [blockShape] ${t.length}`), C(e.length === t.length, () => `paddings.shape[0] ${e.length} must be equal to [blockShape] ${t.length}`), C(s.shape.reduce((i6, a, l) => l > 0 && l <= t.length ? i6 && (a + e[l - 1][0] + e[l - 1][1]) % t[l - 1] === 0 : i6, true), () => `input spatial dimensions ${s.shape.slice(1)} with paddings ${e.toString()} must be divisible by blockShapes ${t.toString()}`);
  const o = { x: s }, r = { blockShape: t, paddings: e };
  return $.runKernel(Xc, o, r);
}
var xp = L({ spaceToBatchND_: qk });
function tT(n, t, e, s, o, r, i6) {
  o == null && (o = [1, 1]), r == null && (r = 1), s === 0 && (s = "valid");
  const a = T(n, "x", "maxPool");
  let l = a, c = false;
  a.rank === 3 && (c = true, l = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), C(Le(r, o), () => `Error in pool: Either strides or dilations must be 1. Got strides ${r} and dilations '${o}'`);
  const u = $n(l.shape, t, r, o, s), d = [u.dilationHeight, u.dilationWidth];
  let h;
  s === "same" ? h = nT([u.filterHeight, u.filterWidth], d) : h = [[0, 0], [0, 0]];
  const p = d[0] === 1 && d[1] === 1, [f, m] = eT([u.inHeight, u.inWidth], d, h), g = p ? s : "valid", b = p ? l : xp(l, d, f), w = (e === "avg" ? () => np(b, t, r, g, i6) : () => mp(b, t, r, g, i6))(), y6 = p ? w : op(w, d, m);
  return c ? W(y6, [y6.shape[1], y6.shape[2], y6.shape[3]]) : y6;
}
function eT(n, t, e) {
  const s = e.map((u) => u[0]), o = e.map((u) => u[1]), r = n.concat(s, o), i6 = t.map((u, d) => (u - r[d] % u) % u), a = o.map((u, d) => u + i6[d]), l = t.map((u, d) => [s[d], a[d]]), c = t.map((u, d) => [0, i6[d]]);
  return [l, c];
}
function nT(n, t) {
  const s = n.map((i6, a) => i6 + (i6 - 1) * (t[a] - 1)).map((i6) => i6 - 1), o = s.map((i6) => Math.floor(i6 / 2)), r = s.map((i6, a) => i6 - o[a]);
  return s.map((i6, a) => [o[a], r[a]]);
}
var sT = L({ pool_: tT });
function oT(n, t) {
  const e = T(n, "x", "prelu"), s = T(t, "alpha", "prelu"), o = { x: e, alpha: s };
  return $.runKernel(Mc, o);
}
var yp = L({ prelu_: oT });
function rT(n, t = null, e = false) {
  let s = T(n, "x", "prod");
  s.dtype === "bool" && (s = tt(s, "int32"));
  const o = { x: s }, r = { axis: t, keepDims: e };
  return $.runKernel(Wc, o, r);
}
var iT = L({ prod_: rT });
var wp = { exports: {} };
wp.exports;
(function(n) {
  (function(t, e, s) {
    function o(l) {
      var c = this, u = a();
      c.next = function() {
        var d = 2091639 * c.s0 + c.c * 23283064365386963e-26;
        return c.s0 = c.s1, c.s1 = c.s2, c.s2 = d - (c.c = d | 0);
      }, c.c = 1, c.s0 = u(" "), c.s1 = u(" "), c.s2 = u(" "), c.s0 -= u(l), c.s0 < 0 && (c.s0 += 1), c.s1 -= u(l), c.s1 < 0 && (c.s1 += 1), c.s2 -= u(l), c.s2 < 0 && (c.s2 += 1), u = null;
    }
    function r(l, c) {
      return c.c = l.c, c.s0 = l.s0, c.s1 = l.s1, c.s2 = l.s2, c;
    }
    function i6(l, c) {
      var u = new o(l), d = c && c.state, h = u.next;
      return h.int32 = function() {
        return u.next() * 4294967296 | 0;
      }, h.double = function() {
        return h() + (h() * 2097152 | 0) * 11102230246251565e-32;
      }, h.quick = h, d && (typeof d == "object" && r(d, u), h.state = function() {
        return r(u, {});
      }), h;
    }
    function a() {
      var l = 4022871197, c = function(u) {
        u = String(u);
        for (var d = 0; d < u.length; d++) {
          l += u.charCodeAt(d);
          var h = 0.02519603282416938 * l;
          l = h >>> 0, h -= l, h *= l, l = h >>> 0, h -= l, l += h * 4294967296;
        }
        return (l >>> 0) * 23283064365386963e-26;
      };
      return c;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.alea = i6;
  })(
    Ko,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(wp);
var aT = wp.exports;
var Ip = { exports: {} };
Ip.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this, c = "";
      l.x = 0, l.y = 0, l.z = 0, l.w = 0, l.next = function() {
        var d = l.x ^ l.x << 11;
        return l.x = l.y, l.y = l.z, l.z = l.w, l.w ^= l.w >>> 19 ^ d ^ d >>> 8;
      }, a === (a | 0) ? l.x = a : c += a;
      for (var u = 0; u < c.length + 64; u++)
        l.x ^= c.charCodeAt(u) | 0, l.next();
    }
    function r(a, l) {
      return l.x = a.x, l.y = a.y, l.z = a.z, l.w = a.w, l;
    }
    function i6(a, l) {
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h = c.next() >>> 11, p = (c.next() >>> 0) / 4294967296, f = (h + p) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (typeof u == "object" && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xor128 = i6;
  })(
    Ko,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(Ip);
var lT = Ip.exports;
var Cp = { exports: {} };
Cp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this, c = "";
      l.next = function() {
        var d = l.x ^ l.x >>> 2;
        return l.x = l.y, l.y = l.z, l.z = l.w, l.w = l.v, (l.d = l.d + 362437 | 0) + (l.v = l.v ^ l.v << 4 ^ (d ^ d << 1)) | 0;
      }, l.x = 0, l.y = 0, l.z = 0, l.w = 0, l.v = 0, a === (a | 0) ? l.x = a : c += a;
      for (var u = 0; u < c.length + 64; u++)
        l.x ^= c.charCodeAt(u) | 0, u == c.length && (l.d = l.x << 10 ^ l.x >>> 4), l.next();
    }
    function r(a, l) {
      return l.x = a.x, l.y = a.y, l.z = a.z, l.w = a.w, l.v = a.v, l.d = a.d, l;
    }
    function i6(a, l) {
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h = c.next() >>> 11, p = (c.next() >>> 0) / 4294967296, f = (h + p) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (typeof u == "object" && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xorwow = i6;
  })(
    Ko,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(Cp);
var cT = Cp.exports;
var vp = { exports: {} };
vp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this;
      l.next = function() {
        var u = l.x, d = l.i, h, p;
        return h = u[d], h ^= h >>> 7, p = h ^ h << 24, h = u[d + 1 & 7], p ^= h ^ h >>> 10, h = u[d + 3 & 7], p ^= h ^ h >>> 3, h = u[d + 4 & 7], p ^= h ^ h << 7, h = u[d + 7 & 7], h = h ^ h << 13, p ^= h ^ h << 9, u[d] = p, l.i = d + 1 & 7, p;
      };
      function c(u, d) {
        var h, p = [];
        if (d === (d | 0))
          p[0] = d;
        else
          for (d = "" + d, h = 0; h < d.length; ++h)
            p[h & 7] = p[h & 7] << 15 ^ d.charCodeAt(h) + p[h + 1 & 7] << 13;
        for (; p.length < 8; )
          p.push(0);
        for (h = 0; h < 8 && p[h] === 0; ++h)
          ;
        for (h == 8 ? p[7] = -1 : p[h], u.x = p, u.i = 0, h = 256; h > 0; --h)
          u.next();
      }
      c(l, a);
    }
    function r(a, l) {
      return l.x = a.x.slice(), l.i = a.i, l;
    }
    function i6(a, l) {
      a == null && (a = +/* @__PURE__ */ new Date());
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h = c.next() >>> 11, p = (c.next() >>> 0) / 4294967296, f = (h + p) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (u.x && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xorshift7 = i6;
  })(
    Ko,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(vp);
var uT = vp.exports;
var Sp = { exports: {} };
Sp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this;
      l.next = function() {
        var u = l.w, d = l.X, h = l.i, p, f;
        return l.w = u = u + 1640531527 | 0, f = d[h + 34 & 127], p = d[h = h + 1 & 127], f ^= f << 13, p ^= p << 17, f ^= f >>> 15, p ^= p >>> 12, f = d[h] = f ^ p, l.i = h, f + (u ^ u >>> 16) | 0;
      };
      function c(u, d) {
        var h, p, f, m, g, b = [], x6 = 128;
        for (d === (d | 0) ? (p = d, d = null) : (d = d + "\0", p = 0, x6 = Math.max(x6, d.length)), f = 0, m = -32; m < x6; ++m)
          d && (p ^= d.charCodeAt((m + 32) % d.length)), m === 0 && (g = p), p ^= p << 10, p ^= p >>> 15, p ^= p << 4, p ^= p >>> 13, m >= 0 && (g = g + 1640531527 | 0, h = b[m & 127] ^= p + g, f = h == 0 ? f + 1 : 0);
        for (f >= 128 && (b[(d && d.length || 0) & 127] = -1), f = 127, m = 4 * 128; m > 0; --m)
          p = b[f + 34 & 127], h = b[f = f + 1 & 127], p ^= p << 13, h ^= h << 17, p ^= p >>> 15, h ^= h >>> 12, b[f] = p ^ h;
        u.w = g, u.X = b, u.i = f;
      }
      c(l, a);
    }
    function r(a, l) {
      return l.i = a.i, l.w = a.w, l.X = a.X.slice(), l;
    }
    function i6(a, l) {
      a == null && (a = +/* @__PURE__ */ new Date());
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h = c.next() >>> 11, p = (c.next() >>> 0) / 4294967296, f = (h + p) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (u.X && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.xor4096 = i6;
  })(
    Ko,
    // window object or global
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(Sp);
var dT = Sp.exports;
var kp = { exports: {} };
kp.exports;
(function(n) {
  (function(t, e, s) {
    function o(a) {
      var l = this, c = "";
      l.next = function() {
        var d = l.b, h = l.c, p = l.d, f = l.a;
        return d = d << 25 ^ d >>> 7 ^ h, h = h - p | 0, p = p << 24 ^ p >>> 8 ^ f, f = f - d | 0, l.b = d = d << 20 ^ d >>> 12 ^ h, l.c = h = h - p | 0, l.d = p << 16 ^ h >>> 16 ^ f, l.a = f - d | 0;
      }, l.a = 0, l.b = 0, l.c = -1640531527, l.d = 1367130551, a === Math.floor(a) ? (l.a = a / 4294967296 | 0, l.b = a | 0) : c += a;
      for (var u = 0; u < c.length + 20; u++)
        l.b ^= c.charCodeAt(u) | 0, l.next();
    }
    function r(a, l) {
      return l.a = a.a, l.b = a.b, l.c = a.c, l.d = a.d, l;
    }
    function i6(a, l) {
      var c = new o(a), u = l && l.state, d = function() {
        return (c.next() >>> 0) / 4294967296;
      };
      return d.double = function() {
        do
          var h = c.next() >>> 11, p = (c.next() >>> 0) / 4294967296, f = (h + p) / (1 << 21);
        while (f === 0);
        return f;
      }, d.int32 = c.next, d.quick = d, u && (typeof u == "object" && r(u, c), d.state = function() {
        return r(c, {});
      }), d;
    }
    e && e.exports ? e.exports = i6 : s && s.amd ? s(function() {
      return i6;
    }) : this.tychei = i6;
  })(
    Ko,
    n,
    // present in node.js
    false
    // present with an AMD loader
  );
})(kp);
var hT = kp.exports;
var l0 = { exports: {} };
var pT = {};
var fT = Object.freeze(Object.defineProperty({
  __proto__: null,
  default: pT
}, Symbol.toStringTag, { value: "Module" }));
var mT = n2(fT);
(function(n) {
  (function(t, e, s) {
    var o = 256, r = 6, i6 = 52, a = "random", l = s.pow(o, r), c = s.pow(2, i6), u = c * 2, d = o - 1, h;
    function p(y6, I, v) {
      var k6 = [];
      I = I == true ? { entropy: true } : I || {};
      var S = b(g(
        I.entropy ? [y6, w(e)] : y6 ?? x6(),
        3
      ), k6), N = new f(k6), R = function() {
        for (var M6 = N.g(r), V = l, z = 0; M6 < c; )
          M6 = (M6 + z) * o, V *= o, z = N.g(1);
        for (; M6 >= u; )
          M6 /= 2, V /= 2, z >>>= 1;
        return (M6 + z) / V;
      };
      return R.int32 = function() {
        return N.g(4) | 0;
      }, R.quick = function() {
        return N.g(4) / 4294967296;
      }, R.double = R, b(w(N.S), e), (I.pass || v || function(M6, V, z, P) {
        return P && (P.S && m(P, N), M6.state = function() {
          return m(N, {});
        }), z ? (s[a] = M6, V) : M6;
      })(
        R,
        S,
        "global" in I ? I.global : this == s,
        I.state
      );
    }
    function f(y6) {
      var I, v = y6.length, k6 = this, S = 0, N = k6.i = k6.j = 0, R = k6.S = [];
      for (v || (y6 = [v++]); S < o; )
        R[S] = S++;
      for (S = 0; S < o; S++)
        R[S] = R[N = d & N + y6[S % v] + (I = R[S])], R[N] = I;
      (k6.g = function(M6) {
        for (var V, z = 0, P = k6.i, A = k6.j, O = k6.S; M6--; )
          V = O[P = d & P + 1], z = z * o + O[d & (O[P] = O[A = d & A + V]) + (O[A] = V)];
        return k6.i = P, k6.j = A, z;
      })(o);
    }
    function m(y6, I) {
      return I.i = y6.i, I.j = y6.j, I.S = y6.S.slice(), I;
    }
    function g(y6, I) {
      var v = [], k6 = typeof y6, S;
      if (I && k6 == "object")
        for (S in y6)
          try {
            v.push(g(y6[S], I - 1));
          } catch {
          }
      return v.length ? v : k6 == "string" ? y6 : y6 + "\0";
    }
    function b(y6, I) {
      for (var v = y6 + "", k6, S = 0; S < v.length; )
        I[d & S] = d & (k6 ^= I[d & S] * 19) + v.charCodeAt(S++);
      return w(I);
    }
    function x6() {
      try {
        var y6;
        return h && (y6 = h.randomBytes) ? y6 = y6(o) : (y6 = new Uint8Array(o), (t.crypto || t.msCrypto).getRandomValues(y6)), w(y6);
      } catch {
        var I = t.navigator, v = I && I.plugins;
        return [+/* @__PURE__ */ new Date(), t, v, t.screen, w(e)];
      }
    }
    function w(y6) {
      return String.fromCharCode.apply(0, y6);
    }
    if (b(s.random(), e), n.exports) {
      n.exports = p;
      try {
        h = mT;
      } catch {
      }
    } else
      s["seed" + a] = p;
  })(
    // global: `self` in browsers (including strict mode and web workers),
    // otherwise `this` in Node and other environments
    typeof self < "u" ? self : Ko,
    [],
    // pool: entropy pool starts empty
    Math
    // math: package containing random, pow, and seedrandom
  );
})(l0);
var gT = l0.exports;
var bT = aT;
var xT = lT;
var yT = cT;
var wT = uT;
var IT = dT;
var CT = hT;
var Ho = gT;
Ho.alea = bT;
Ho.xor128 = xT;
Ho.xorwow = yT;
Ho.xorshift7 = wT;
Ho.xor4096 = IT;
Ho.tychei = CT;
var Nr = Ho;
var Tp = class {
  constructor(t, e, s, o, r) {
    this.mean = t, this.stdDev = e, this.dtype = s, this.nextVal = NaN, this.truncated = o, this.truncated && (this.upper = this.mean + this.stdDev * 2, this.lower = this.mean - this.stdDev * 2);
    const i6 = r || Math.random();
    this.random = Nr.alea(i6.toString());
  }
  /** Returns next sample from a Gaussian distribution. */
  nextValue() {
    if (!isNaN(this.nextVal)) {
      const o = this.nextVal;
      return this.nextVal = NaN, o;
    }
    let t, e, s = false;
    for (; !s; ) {
      let o, r, i6;
      do
        o = 2 * this.random() - 1, r = 2 * this.random() - 1, i6 = o * o + r * r;
      while (i6 >= 1 || i6 === 0);
      const a = Math.sqrt(-2 * Math.log(i6) / i6);
      t = this.mean + this.stdDev * o * a, e = this.mean + this.stdDev * r * a, (!this.truncated || this.isValidTruncated(t)) && (s = true);
    }
    return (!this.truncated || this.isValidTruncated(e)) && (this.nextVal = this.convertValue(e)), this.convertValue(t);
  }
  /** Handles proper rounding for non-floating-point numbers. */
  convertValue(t) {
    return this.dtype == null || this.dtype === "float32" ? t : Math.round(t);
  }
  /** Returns true if less than 2-standard-deviations from the mean. */
  isValidTruncated(t) {
    return t <= this.upper && t >= this.lower;
  }
};
var kQ = class {
  constructor(t, e, s, o) {
    this.alpha = t, this.beta = 1 / e, this.dtype = s;
    const r = o || Math.random();
    this.randu = Nr.alea(r.toString()), this.randn = new Tp(0, 1, s, false, this.randu()), t < 1 ? this.d = t + 2 / 3 : this.d = t - 1 / 3, this.c = 1 / Math.sqrt(9 * this.d);
  }
  /** Returns next sample from a gamma distribution. */
  nextValue() {
    let t, e, s, o, r, i6;
    for (; ; ) {
      do
        o = this.randn.nextValue(), i6 = 1 + this.c * o;
      while (i6 <= 0);
      if (i6 *= i6 * i6, t = o * o, e = 1 - 0.331 * t * t, s = 0.5 * t + this.d * (1 - i6 + Math.log(i6)), r = this.randu(), r < e || Math.log(r) < s)
        break;
    }
    return i6 = 1 / this.beta * this.d * i6, this.alpha < 1 && (i6 *= Math.pow(this.randu(), 1 / this.alpha)), this.convertValue(i6);
  }
  /** Handles proper rounding for non-floating-point numbers. */
  convertValue(t) {
    return this.dtype === "float32" ? t : Math.round(t);
  }
};
var vT = class {
  constructor(t = 0, e = 1, s, o) {
    if (this.canReturnFloat = () => this.dtype == null || this.dtype === "float32", this.min = t, this.range = e - t, this.dtype = s, o == null && (o = Math.random()), typeof o == "number" && (o = o.toString()), !this.canReturnFloat() && this.range <= 1)
      throw new Error(`The difference between ${t} - ${e} <= 1 and dtype is not float`);
    this.random = Nr.alea(o);
  }
  convertValue(t) {
    return this.canReturnFloat() ? t : Math.round(t);
  }
  nextValue() {
    return this.convertValue(this.min + this.range * this.random());
  }
};
function ST(n, t = 0, e = 1, s, o) {
  if (is(n), s != null && s === "bool")
    throw new Error(`Unsupported data type ${s}`);
  const r = new Tp(t, e, s, false, o), i6 = vt(n, s);
  for (let a = 0; a < i6.values.length; a++)
    i6.values[a] = r.nextValue();
  return i6.toTensor();
}
var kT = L({ randomNormal_: ST });
function TT(n, t = 0, e = 1, s = "float32", o) {
  is(n);
  const r = vt(n, s), i6 = new vT(t, e, null, o);
  for (let a = 0; a < r.values.length; a++)
    r.values[a] = i6.nextValue();
  return r.toTensor();
}
var Sa = L({ randomUniform_: TT });
function di(n, t, e = 1, s = "float32") {
  if (e === 0)
    throw new Error("Cannot have a step of zero");
  const o = { start: n, stop: t, step: e, dtype: s };
  return $.runKernel(Gh, {}, o);
}
function NT(n) {
  const e = { input: T(n, "input", "real") };
  return $.runKernel(Eh, e);
}
var vl = L({ real_: NT });
function RT(n) {
  const e = { x: T(n, "x", "reciprocal") };
  return $.runKernel(ta, e);
}
var $T = L({ reciprocal_: RT });
function GT(n) {
  const e = { x: T(n, "x", "relu") };
  return $.runKernel(ea, e);
}
var Ts = L({ relu_: GT });
function ET(n) {
  const e = { x: T(n, "x", "relu6") };
  return $.runKernel(na, e);
}
var c0 = L({ relu6_: ET });
function LT(n, t) {
  const s = { x: T(n, "x", "reverse") }, o = { dims: t };
  return $.runKernel(zc, s, o);
}
var Lo = L({ reverse_: LT });
function MT(n) {
  const e = { x: T(n, "x", "round") };
  return $.runKernel(sa, e);
}
var u0 = L({ round_: MT });
function WT(n) {
  const e = { x: T(n, "x", "rsqrt", "float32") };
  return $.runKernel(oa, e);
}
var d0 = L({ rsqrt_: WT });
function DT(n) {
  const e = { x: T(n, "x", "selu") };
  return $.runKernel(ra, e);
}
var h0 = L({ selu_: DT });
function FT(n, t, e, s, o, r = [1, 1], i6 = "NHWC") {
  const a = T(n, "x", "separableConv2d"), l = T(t, "depthwiseFilter", "separableConv2d"), c = T(e, "pointwiseFilter", "separableConv2d");
  let u = a, d = false;
  if (a.rank === 3 && (d = true, u = W(a, [1, a.shape[0], a.shape[1], a.shape[2]])), i6 === "NCHW")
    throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  C(u.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${u.rank}.`), C(l.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`), C(c.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`), C(c.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${c.shape[0]}.`), C(c.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${c.shape[1]}.`);
  const h = l.shape[2], p = l.shape[3];
  C(c.shape[2] === h * p, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${h * p}, but got ${c.shape[2]}.`);
  const f = ap(u, l, s, o, i6, r), g = $o(f, c, 1, "valid", i6);
  return d ? W(g, [g.shape[1], g.shape[2], g.shape[3]]) : g;
}
var p0 = L({ separableConv2d_: FT });
function VT(n) {
  const e = { x: T(n, "x", "sign") };
  return $.runKernel(la, e);
}
var zT = L({ sign_: VT });
function PT(n) {
  const e = { x: T(n, "x", "sin", "float32") };
  return $.runKernel(ia, e);
}
var f0 = L({ sin_: PT });
function AT(n) {
  const e = { x: T(n, "x", "sinh") };
  return $.runKernel(aa, e);
}
var m0 = L({ sinh_: AT });
function OT(n, t, e) {
  const s = T(n, "x", "slice1d");
  return C(s.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`), Ft(s, [t], [e]);
}
var Np = L({ slice1d_: OT });
function XT(n, t, e) {
  const s = T(n, "x", "slice2d");
  return C(s.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`), Ft(s, t, e);
}
var g0 = L({ slice2d_: XT });
function KT(n, t, e) {
  const s = T(n, "x", "slice3d");
  return C(s.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`), Ft(s, t, e);
}
var Rp = L({ slice3d_: KT });
function ZT(n, t, e) {
  const s = T(n, "x", "slice4d");
  return C(s.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`), Ft(s, t, e);
}
var Sl = L({ slice4d_: ZT });
function BT(n, t = -1) {
  const e = T(n, "logits", "softmax", "float32");
  if (t === -1 && (t = e.rank - 1), t !== e.rank - 1)
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${e.rank} and dim was ${t}`);
  const s = { logits: e }, o = { dim: t };
  return $.runKernel(Zc, s, o);
}
var $p = L({ softmax_: BT });
function HT(n) {
  C(n.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${n.dtype}.`);
  const t = { input: n };
  return $.runKernel(yh, t);
}
var Gp = L({ fft_: HT });
function _T(n) {
  C(n.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${n.dtype}.`);
  const t = { input: n };
  return $.runKernel(Ch, t);
}
var kl = L({ ifft_: _T });
function UT(n) {
  const t = n.shape[n.shape.length - 1], e = n.size / t;
  let s;
  if (t <= 2) {
    const o = W(n, [e, t]);
    s = kl(o);
  } else {
    const o = [e, 2 * (t - 1)], r = W(vl(n), [e, t]), i6 = W(up(n), [e, t]), a = Lo(Ft(r, [0, 1], [e, t - 2]), 1), l = G(Lo(Ft(i6, [0, 1], [e, t - 2]), 1), gt(-1)), c = Ge([r, a], 1), u = Ge([i6, l], 1), d = W(vo(c, u), [o[0], o[1]]);
    s = kl(d);
  }
  if (s = vl(s), n.rank === 3 && n.shape[0] !== 0) {
    const o = s, r = n.shape[0];
    s = W(s, [r, s.shape[0] / r, s.shape[1]]), o.dispose();
  }
  return s;
}
var b0 = L({ irfft_: UT });
function YT(n, t, e = 0) {
  const o = { x: T(n, "x", "split") }, r = { numOrSizeSplits: t, axis: e };
  return $.runKernel(Kc, o, r);
}
var pn = L({ split_: YT });
function QT(n, t) {
  C(n.dtype === "float32", () => `The dtype for rfft() must be real value but got ${n.dtype}`);
  let e = n.shape[n.shape.length - 1];
  const s = n.size / e;
  let o;
  if (t != null && t < e) {
    const f = n.shape.map((g) => 0), m = n.shape.map((g) => g);
    m[n.shape.length - 1] = t, o = Ft(n, f, m), e = t;
  } else if (t != null && t > e) {
    const f = n.shape.map((m) => m);
    f[n.shape.length - 1] = t - e, o = Ge([n, be(f)], n.shape.length - 1), e = t;
  } else
    o = n;
  const r = Tt(o), i6 = W(vo(o, r), [s, e]), a = Gp(i6), l = Math.floor(e / 2) + 1, c = vl(a), u = up(a), d = pn(c, [l, e - l], c.shape.length - 1), h = pn(u, [l, e - l], u.shape.length - 1), p = o.shape.slice();
  return p[o.shape.length - 1] = l, W(vo(d[0], h[0]), p);
}
var Ep = L({ rfft_: QT });
function JT(n, t) {
  let e = T(n, "a", "squaredDifference"), s = T(t, "b", "squaredDifference");
  [e, s] = se(e, s), bt(e.shape, s.shape);
  const o = { a: e, b: s }, r = {};
  return $.runKernel(ha, o, r);
}
var x0 = L({ squaredDifference_: JT });
function jT(n, t) {
  const e = T(n, "x", "squeeze", "string_or_numeric");
  return W(e, ws(e.shape, t).newShape);
}
var ka = L({ squeeze_: jT });
function qT(n, t = 0) {
  const e = jh(n, "tensors", "stack", "string_or_numeric");
  C(e.length >= 1, () => "Pass at least one tensor to tf.stack"), e.length > 0 && C(t <= e[0].rank, () => "Axis must be <= rank of the tensor");
  const s = e, o = { axis: t };
  return $.runKernel(Ec, s, o);
}
var Xn = L({ stack_: qT });
function tN(n, t = 0) {
  const s = { x: T(n, "x", "step") }, o = { alpha: t };
  return $.runKernel(ba, s, o);
}
var Ta = L({ step_: tN });
function eN(n, t, e, s, o = 0, r = 0, i6 = 0, a = 0, l = 0) {
  const u = { x: T(n, "x", "stridedSlice", "string_or_numeric") }, d = {
    begin: t,
    end: e,
    strides: s,
    beginMask: o,
    endMask: r,
    ellipsisMask: i6,
    newAxisMask: a,
    shrinkAxisMask: l
  };
  return $.runKernel(Ph, u, d);
}
var nN = L({ stridedSlice_: eN });
function sN(n) {
  const e = { x: T(n, "x", "tan", "float32") };
  return $.runKernel(fa, e);
}
var oN = L({ tan_: sN });
function Ze(n, t) {
  Hl(n);
  const e = ya(n, t);
  if (e.length !== 1)
    throw new Error("tensor1d() requires values to be a flat/TypedArray");
  return wa(n, null, e, t);
}
function il(n, t, e) {
  if (Hl(n), t != null && t.length !== 2)
    throw new Error("tensor2d() requires shape to have two numbers");
  const s = ya(n, e);
  if (s.length !== 2 && s.length !== 1)
    throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  if (s.length === 1 && t == null)
    throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  return wa(n, t, s, e);
}
function rN(n, t, e) {
  if (Hl(n), t != null && t.length !== 3)
    throw new Error("tensor3d() requires shape to have three numbers");
  const s = ya(n, e);
  if (s.length !== 3 && s.length !== 1)
    throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  if (s.length === 1 && t == null)
    throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  return wa(n, t, s, e);
}
function Lp(n, t, e) {
  const s = t.rank > 1 ? t.shape[t.rank - 1] : 1, o = t.rank > 1 ? t.rank - 1 : 1, r = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${e.shape}, indices.shape: ${t.shape}, shape: ${n}, sliceDim: ${s}, and batchDim: ${o}.`;
  if (e.rank < o)
    throw new Error(r + ` update.rank < ${o}. `);
  if (n.length < s + (e.rank - o))
    throw new Error(r + ` Output shape length < ${s + (e.rank - o)}`);
  if (e.rank !== o + n.length - s)
    throw new Error(r + ` update.rank != ${o + n.length - s}`);
  for (let i6 = 0; i6 < o; ++i6)
    if (e.shape[i6] !== t.shape[i6])
      throw new Error(r + ` updates.shape[${i6}] (${e.shape[i6]}) != indices.shape[${i6}] (${t.shape[i6]}).`);
  for (let i6 = 0; i6 < e.rank - o; ++i6)
    if (e.shape[i6 + o] !== n[i6 + s])
      throw new Error(r + ` updates.shape[${i6 + o}] (${e.shape[i6 + o]}) != shape[${i6 + o}] (${n[i6 + o]})`);
}
function y0(n, t, e) {
  if (t.rank < 1)
    throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);
  if (n.rank < 1)
    throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${n.rank}.`);
  if (t.dtype !== "int32")
    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);
  if (e.length < 1)
    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${e}`);
  if (e.length === 0) {
    if (t.size === 0)
      throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);
    if (n.size === 0)
      throw new Error(`Updates specified for empty output. updates shape: ${n.shape}`);
  }
  Lp(e, t, n);
}
function to(n, t, e) {
  const s = t.shape.length, o = s > 1 ? t.shape[s - 1] : 1, r = e.length;
  let i6 = 1;
  for (let d = o; d < r; ++d)
    i6 *= e[d];
  const a = o < 1 ? 1 : o, l = X(t.shape) / a, c = [...dt(e.slice(0, o)), 1], u = X(e);
  return { sliceRank: o, numUpdates: l, sliceSize: i6, strides: c, outputSize: u };
}
var TQ = Object.freeze(Object.defineProperty({
  __proto__: null,
  calculateShapes: to,
  validateInput: y0,
  validateUpdateShape: Lp
}, Symbol.toStringTag, { value: "Module" }));
function iN(n, t = 1, e = true) {
  const s = T(n, "x", "topk");
  if (s.rank === 0)
    throw new Error("topk() expects the input to be of rank 1 or higher");
  const o = s.shape[s.shape.length - 1];
  if (t < 0)
    throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);
  if (t > o)
    throw new Error(`'k' passed to topk() must be <= the last dimension (${o}) but got ${t}`);
  const r = { x: s }, i6 = { k: t, sorted: e }, [a, l] = $.runKernel(Kh, r, i6);
  return { values: a, indices: l };
}
var aN = L({ topk_: iN });
function lN(n, t = 0, e = 1, s, o) {
  if (is(n), s != null && s === "bool")
    throw new Error("Unsupported data type $ { dtype }");
  const r = new Tp(t, e, s, true, o), i6 = vt(n, s);
  for (let a = 0; a < i6.values.length; a++)
    i6.values[a] = r.nextValue();
  return i6.toTensor();
}
var w0 = L({ truncatedNormal_: lN });
function cN(n, t = 0) {
  const e = T(n, "x", "unique", "string_or_numeric");
  C(e.rank > 0, () => "The input tensor must be at least 1D");
  const s = { x: e }, o = { axis: t }, [r, i6] = $.runKernel(Bh, s, o);
  return { values: r, indices: i6 };
}
var uN = L({ unique_: cN });
function dN(n, t, e) {
  const s = T(n, "x", "unsortedSegmentSum"), o = T(t, "segmentIds", "unsortedSegmentSum", "int32");
  C(Co(e), () => "numSegments must be of dtype int");
  const r = { x: s, segmentIds: o }, i6 = { numSegments: e };
  return $.runKernel(_c, r, i6);
}
var I0 = L({ unsortedSegmentSum_: dN });
function hN(n, t = 0) {
  const e = T(n, "x", "unstack", "string_or_numeric");
  C(t >= -e.shape.length && t < e.shape.length, () => `Axis = ${t} is not in [-${e.shape.length}, ${e.shape.length})`);
  const s = { value: e }, o = { axis: t };
  return $.runKernel(Hc, s, o);
}
var Mo = L({ unstack_: hN });
function pN(n, t = true, e, s) {
  return $.makeVariable(n, t, e, s);
}
function C0(n, t) {
  const e = [];
  for (let r = 0; r < t.length; r++)
    t[r] && e.push(r);
  const s = vt(n, "int32"), o = vt([e.length, n.length], "int32");
  for (let r = 0; r < e.length; r++) {
    const i6 = s.indexToLoc(e[r]), a = r * n.length;
    o.values.set(i6, a);
  }
  return o.toTensor();
}
function fN(n, t, e) {
  const s = T(n, "x", "transpose");
  if (t == null && (t = s.shape.map((i6, a) => a).reverse()), C(s.rank === t.length, () => `Error in transpose: rank of input ${s.rank} must match length of perm ${t}.`), t.forEach((i6) => {
    C(i6 >= 0 && i6 < s.rank, () => `All entries in 'perm' must be between 0 and ${s.rank - 1} but got ${t}`);
  }), s.rank <= 1)
    return s.clone();
  const o = { x: s }, r = { perm: t };
  return s.dtype === "complex64" ? D(() => {
    let i6 = vl(s), a = up(s);
    return i6 = $.runKernel(ar, { x: i6 }, r), a = $.runKernel(ar, { x: a }, r), e && (a = Yt(a)), vo(i6, a);
  }) : $.runKernel(ar, o, r);
}
var kt = L({ transpose_: fN });
function mN(n, t) {
  if (t == null)
    return n.shape.slice();
  if ($t(n.shape, t))
    return t;
  if (n.shape.length === t.length) {
    const e = [];
    for (let s = 0; s < n.shape.length; s++)
      t[s] == null && n.shape[s] != null ? e.push(n.shape[s]) : e.push(t[s]);
    return e;
  }
  return t;
}
function gN(n, t, e, s) {
  const o = T(n, "x", "dropout");
  if (C(o.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${o.dtype} tensor instead.`), C(t >= 0 && t < 1, () => `rate must be a float in the range [0, 1), but got ${t}.`), t === 0)
    return n instanceof Mt ? o.clone() : o;
  const r = mN(o, e), i6 = 1 - t, a = ut(qc(U(Sa(r, 0, 1, "float32", s), i6)), i6);
  return G(o, a);
}
var bN = L({ dropout_: gN });
function xN(n) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(n) / Math.log(2))));
}
function v0(n, t, e) {
  const s = 1 - n % 2, o = new Float32Array(n);
  for (let r = 0; r < n; ++r) {
    const i6 = 2 * Math.PI * r / (n + s - 1);
    o[r] = t - e * Math.cos(i6);
  }
  return Ze(o, "float32");
}
function yN(n, t, e, s, o, r = "NHWC", i6) {
  let a = n;
  n.rank === 3 && (a = W(n, [1, n.shape[0], n.shape[1], n.shape[2]]));
  let l = t;
  l.rank === 3 && (l = W(t, [1, t.shape[0], t.shape[1], t.shape[2]])), C(a.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${a.shape}.`), C(l.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`), C(e.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${e}.`);
  const c = r === "NHWC" ? a.shape[3] : a.shape[1], u = r === "NHWC" ? l.shape[3] : l.shape[1];
  C(c === e[2], () => `Error in conv2dDerFilter: depth of input ${c}) must match input depth in filter (${e[2]}.`), C(u === e[3], () => `Error in conv2dDerFilter: depth of dy (${u}) must match output depth for filter (${e[3]}).`), Ue("conv2dDerFilter", o, i6);
  const d = { x: a, dy: l }, h = { strides: s, pad: o, dataFormat: r, dimRoundingMode: i6, filterShape: e };
  return $.runKernel(ah, d, h);
}
var Mp = L({ conv2DBackpropFilter_: yN });
function Wp(n, t, e) {
  if (e == null || e === "linear")
    return n;
  if (e === "relu")
    return G(n, Ta(t));
  throw new Error(`Cannot compute gradient for fused activation ${e}.`);
}
function Dp(n, t) {
  let e = t;
  const s = ce(n.shape, t.shape);
  return s.length > 0 && (e = at(e, s)), W(e, n.shape);
}
function Fp(n, t, e, s) {
  if (t === "linear")
    return n;
  if (t === "relu")
    return Ts(n);
  if (t === "elu")
    return Jc(n);
  if (t === "relu6")
    return c0(n);
  if (t === "prelu")
    return yp(n, e);
  if (t === "leakyrelu")
    return dp(n, s);
  if (t === "sigmoid")
    return kr(n);
  throw new Error(`Unknown fused activation ${t}.`);
}
var Vp = (n, t) => !(n > 0) || t === "linear";
function wN({ x: n, filter: t, strides: e, pad: s, dataFormat: o = "NHWC", dilations: r = [1, 1], dimRoundingMode: i6, bias: a, activation: l = "linear", preluActivationWeights: c, leakyreluAlpha: u }) {
  if (l = l || "linear", Vp($.state.gradientDepth, l) === false) {
    C(o === "NHWC", () => `Error in fused conv2d: got dataFormat of ${o} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`);
    let v = $o(n, t, e, s, o, r, i6);
    return a != null && (v = U(v, a)), Fp(v, l, c, u);
  }
  const d = T(n, "x", "conv2d", "float32"), h = T(t, "filter", "conv2d", "float32");
  let p = d, f = false;
  d.rank === 3 && (f = true, p = W(d, [1, d.shape[0], d.shape[1], d.shape[2]])), C(p.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${p.rank}.`), C(h.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${h.rank}.`), Ue("fused conv2d", s, i6);
  const m = o === "NHWC" ? p.shape[3] : p.shape[1];
  C(h.shape[2] === m, () => `Error in conv2d: depth of input (${m}) must match input depth for filter ${h.shape[2]}.`), C(Le(e, r), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${e} and dilations '${r}'`);
  const g = Te(p.shape, h.shape, e, r, s, i6);
  let b;
  a != null && (b = T(a, "bias", "fused conv2d"), [b] = se(b, d), o === "NHWC" ? bt(g.outShape, b.shape) : (C(b.shape.length <= 1, () => `Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${b.shape.length}.`), C(b.shape.length === 0 || b.shape[0] === g.outChannels || b.shape[0] === 1, () => `Error in fused conv2d: bias shape (${b.shape}) is not compatible with the number of output channels (${g.outChannels})`)));
  let x6;
  if (c != null) {
    const v = c.shape;
    if (C(v.length <= 1 || v.length === 3, () => `Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${v.length}.`), v.length === 1)
      C(v[0] === 1 || v[0] === g.outChannels, () => `Error in fused conv2d: PReLU activation weights (${v}) is not compatible with the number of output channels (${g.outChannels}).`);
    else if (v.length === 3)
      try {
        bt(v, g.outShape);
      } catch {
        const S = `Error in fused conv2d: PReLU activation weights (${v}) is not compatible with the output shape of the conv2d (${g.outShape}).`;
        throw Error(S);
      }
    x6 = T(c, "prelu weights", "fused conv2d");
  }
  const w = (v, k6) => {
    C(o === "NHWC", () => `Error in gradient of fused conv2D: got dataFormat of ${o} but only NHWC is currently supported.`);
    const [S, N, R, M6] = k6, V = Wp(v, R, l);
    C(No(r), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`);
    const z = rp(N.shape, V, S, e, s), P = Mp(N, V, S.shape, e, s), A = [z, P];
    if (M6 != null) {
      const O = Dp(M6, V);
      A.push(O);
    }
    return A;
  }, y6 = {
    x: p,
    filter: h,
    bias: b,
    preluActivationWeights: x6
  }, I = {
    strides: e,
    pad: s,
    dataFormat: o,
    dilations: r,
    dimRoundingMode: i6,
    activation: l,
    leakyreluAlpha: u
  };
  return a == null ? Eo((k6, S, N) => {
    let R = (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(gl, y6, I)
    );
    return N([S, k6, R]), f && (R = W(R, [R.shape[1], R.shape[2], R.shape[3]])), { value: R, gradFunc: w };
  })(p, h) : Eo((k6, S, N, R) => {
    let M6 = $.runKernel(gl, y6, I);
    return R([S, k6, M6, N]), f && (M6 = W(M6, [M6.shape[1], M6.shape[2], M6.shape[3]])), { value: M6, gradFunc: w };
  })(p, h, b);
}
var IN = L({ fusedConv2d_: wN });
function CN(n, t, e, s, o, r = [1, 1], i6) {
  let a = n;
  n.rank === 3 && (a = W(n, [1, n.shape[0], n.shape[1], n.shape[2]]));
  let l = t;
  l.rank === 3 && (l = W(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
  const c = { x: a, dy: l }, u = { strides: s, pad: o, dimRoundingMode: i6, dilations: r, filterShape: e };
  return $.runKernel(fh, c, u);
}
var vN = L({ depthwiseConv2dNativeBackpropFilter_: CN });
function SN(n, t, e, s, o, r = [1, 1], i6) {
  let a = t, l = false;
  t.rank === 3 && (l = true, a = W(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
  const c = { dy: a, filter: e }, u = { strides: s, pad: o, dimRoundingMode: i6, dilations: r, inputShape: n }, d = (
    // tslint:disable-next-line: no-unnecessary-type-assertion
    $.runKernel(mh, c, u)
  );
  return l ? W(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}
var kN = L({ depthwiseConv2dNativeBackpropInput_: SN });
function TN({ a: n, b: t, transposeA: e = false, transposeB: s = false, bias: o, activation: r = "linear", preluActivationWeights: i6, leakyreluAlpha: a = 0.2 }) {
  if (Vp($.state.gradientDepth, r) === false) {
    let M6 = Gt(n, t, e, s);
    return o != null && (M6 = U(M6, o)), Fp(M6, r, i6, a);
  }
  let l = T(n, "a", "fused matMul"), c = T(t, "b", "fused matMul");
  [l, c] = se(l, c);
  const u = e ? l.shape[l.rank - 2] : l.shape[l.rank - 1], d = s ? c.shape[c.rank - 1] : c.shape[c.rank - 2], h = e ? l.shape[l.rank - 1] : l.shape[l.rank - 2], p = s ? c.shape[c.rank - 2] : c.shape[c.rank - 1], f = l.shape.slice(0, -2), m = c.shape.slice(0, -2), g = X(f), b = X(m);
  C(u === d, () => `Error in fused matMul: inner shapes (${u}) and (${d}) of Tensors with shapes ${l.shape} and ${c.shape} and transposeA=${e} and transposeB=${s} must match.`);
  const w = bt(l.shape.slice(0, -2), c.shape.slice(0, -2)).concat([h, p]), y6 = e ? W(l, [g, u, h]) : W(l, [g, h, u]), I = s ? W(c, [b, p, d]) : W(c, [b, d, p]);
  let v;
  o != null && (v = T(o, "bias", "fused matMul"), [v] = se(v, l), bt(w, v.shape));
  let k6;
  i6 != null && (k6 = T(i6, "prelu weights", "fused matMul"));
  const S = (M6, V) => {
    const [z, P, A, O] = V, B6 = Wp(W(M6, A.shape), A, r);
    let Z, H6;
    if (!e && !s ? (Z = Gt(B6, P, false, true), H6 = Gt(z, B6, true, false)) : !e && s ? (Z = Gt(B6, P, false, false), H6 = Gt(B6, z, true, false)) : e && !s ? (Z = Gt(P, B6, false, true), H6 = Gt(z, B6, false, false)) : (Z = Gt(P, B6, true, true), H6 = Gt(B6, z, true, true)), o != null) {
      const Y = Dp(O, B6);
      return [Z, H6, Y];
    } else
      return [Z, H6];
  }, N = {
    a: y6,
    b: I,
    bias: v,
    preluActivationWeights: k6
  }, R = { transposeA: e, transposeB: s, activation: r, leakyreluAlpha: a };
  return o == null ? Eo((V, z, P) => {
    const A = (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(ml, N, R)
    );
    return P([V, z, A]), { value: W(A, w), gradFunc: S };
  })(y6, I) : Eo((V, z, P, A) => {
    const O = (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(ml, N, R)
    );
    return A([V, z, O, P]), { value: W(O, w), gradFunc: S };
  })(y6, I, v);
}
var Nm = L({ fusedMatMul_: TN });
function NN(n) {
  return v0(n, 0.54, 0.46);
}
var RN = L({ hammingWindow_: NN });
function $N(n) {
  return v0(n, 0.5, 0.5);
}
var S0 = L({ hannWindow_: $N });
function GN(n, t, e, s = false, o = 0) {
  let r = 0;
  const i6 = [];
  for (; r + t <= n.size; )
    i6.push(Ft(n, r, t)), r += e;
  if (s)
    for (; r < n.size; ) {
      const a = r + t - n.size, l = Ge([
        Ft(n, r, t - a),
        Ca([a], o)
      ]);
      i6.push(l), r += e;
    }
  return i6.length === 0 ? il([], [0, t]) : W(Ge(i6), [i6.length, t]);
}
var k0 = L({ frame_: GN });
function EN(n, t, e, s, o = S0) {
  s == null && (s = xN(t));
  const r = k0(n, t, e), i6 = G(r, o(t));
  return Ep(i6, s);
}
var LN = L({ stft_: EN });
function MN(n, t, e, s, o = "bilinear", r = 0) {
  const i6 = T(n, "image", "cropAndResize"), a = T(t, "boxes", "cropAndResize", "float32"), l = T(e, "boxInd", "cropAndResize", "int32"), c = a.shape[0];
  C(i6.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${i6.rank}.`), C(a.rank === 2 && a.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${c},4] but had shape ${a.shape}.`), C(l.rank === 1 && l.shape[0] === c, () => `Error in cropAndResize: boxInd must be have size [${c}] but had shape ${a.shape}.`), C(s.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`), C(s[0] >= 1 && s[1] >= 1, () => `cropSize must be atleast [1,1], but was ${s}`), C(o === "bilinear" || o === "nearest", () => `method must be bilinear or nearest, but was ${o}`);
  const u = { image: i6, boxes: a, boxInd: l }, d = { method: o, extrapolationValue: r, cropSize: s };
  return $.runKernel(dh, u, d);
}
var WN = L({ cropAndResize_: MN });
function DN(n) {
  const t = T(n, "image", "flipLeftRight", "float32");
  C(t.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`);
  const e = { image: t };
  return $.runKernel(Ih, e, {});
}
var FN = L({ flipLeftRight_: DN });
function VN(n) {
  const t = T(n, "image", "grayscaleToRGB"), e = t.rank - 1, s = t.shape[e];
  C(t.rank >= 2, () => `Error in grayscaleToRGB: images must be at least rank 2, but got rank ${t.rank}.`), C(s === 1, () => `Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${s}.`);
  const o = new Array(t.rank);
  return o.fill(1, 0, e), o[e] = 3, Vn(t, o);
}
var zN = L({ grayscaleToRGB_: VN });
function PN(n) {
  const t = T(n, "image", "RGBToGrayscale"), e = t.rank - 1, s = t.shape[e];
  C(t.rank >= 2, () => `Error in RGBToGrayscale: images must be at least rank 2, but got rank ${t.rank}.`), C(s === 3, () => `Error in RGBToGrayscale: last dimension of an RGB image should be size 3, but got size ${s}.`);
  const o = t.dtype, r = tt(t, "float32"), i6 = Ze([0.2989, 0.587, 0.114]);
  let a;
  switch (t.rank) {
    case 2:
      a = Or("ij,j->i", r, i6);
      break;
    case 3:
      a = Or("ijk,k->ij", r, i6);
      break;
    case 4:
      a = Or("ijkl,l->ijk", r, i6);
      break;
    case 5:
      a = Or("ijklm,m->ijkl", r, i6);
      break;
    case 6:
      a = Or("ijklmn,n->ijklm", r, i6);
      break;
    default:
      throw new Error("Not a valid tensor rank.");
  }
  return a = Oe(a, -1), tt(a, o);
}
var AN = L({ rgbToGrayscale_: PN });
function ON(n, t, e = 0, s = 0.5) {
  const o = T(n, "image", "rotateWithOffset", "float32");
  C(o.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${o.rank}.`);
  const r = { image: o }, i6 = { radians: t, fillValue: e, center: s };
  return $.runKernel(Hh, r, i6);
}
var XN = L({ rotateWithOffset_: ON });
function Rr(n, t, e, s, o, r) {
  s == null && (s = 0.5), o == null && (o = Number.NEGATIVE_INFINITY), r == null && (r = 0);
  const i6 = n.shape[0];
  return e = Math.min(e, i6), C(0 <= s && s <= 1, () => `iouThreshold must be in [0, 1], but was '${s}'`), C(n.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${n.rank}'`), C(n.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${n.shape[1]}`), C(t.rank === 1, () => "scores must be a 1D tensor"), C(t.shape[0] === i6, () => `scores has incompatible shape with boxes. Expected ${i6}, but was ${t.shape[0]}`), C(0 <= r && r <= 1, () => `softNmsSigma must be in [0, 1], but was '${r}'`), { maxOutputSize: e, iouThreshold: s, scoreThreshold: o, softNmsSigma: r };
}
function KN(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY) {
  const r = T(n, "boxes", "nonMaxSuppression", "float32"), i6 = T(t, "scores", "nonMaxSuppression", "float32"), a = Rr(r, i6, e, s, o);
  e = a.maxOutputSize, s = a.iouThreshold, o = a.scoreThreshold;
  const l = { maxOutputSize: e, iouThreshold: s, scoreThreshold: o };
  return $.runKernel(Nh, { boxes: r, scores: i6 }, l);
}
var ZN = L({ nonMaxSuppression_: KN });
function BN(n, t, e) {
  const s = HN(n, t, e), o = s < 0 ? -(s + 1) : s;
  n.splice(o, 0, t);
}
function HN(n, t, e) {
  return UN(n, t, e || _N);
}
function _N(n, t) {
  return n > t ? 1 : n < t ? -1 : 0;
}
function UN(n, t, e) {
  let s = 0, o = n.length, r = 0, i6 = false;
  for (; s < o; ) {
    r = s + (o - s >>> 1);
    const a = e(t, n[r]);
    a > 0 ? s = r + 1 : (o = r, i6 = !a);
  }
  return i6 ? s : -s - 1;
}
function zp(n, t, e, s, o) {
  return Op(
    n,
    t,
    e,
    s,
    o,
    0
    /* softNmsSigma */
  );
}
function Pp(n, t, e, s, o, r) {
  return Op(
    n,
    t,
    e,
    s,
    o,
    0,
    false,
    r,
    true
    /* returnValidOutputs */
  );
}
function Ap(n, t, e, s, o, r) {
  return Op(
    n,
    t,
    e,
    s,
    o,
    r,
    true
    /* returnScoresTensor */
  );
}
function Op(n, t, e, s, o, r, i6 = false, a = false, l = false) {
  const c = [];
  for (let g = 0; g < t.length; g++)
    t[g] > o && c.push({ score: t[g], boxIndex: g, suppressBeginIndex: 0 });
  c.sort(Rm);
  const u = r > 0 ? -0.5 / r : 0, d = [], h = [];
  for (; d.length < e && c.length > 0; ) {
    const g = c.pop(), { score: b, boxIndex: x6, suppressBeginIndex: w } = g;
    if (b < o)
      break;
    let y6 = false;
    for (let I = d.length - 1; I >= w; --I) {
      const v = YN(n, x6, d[I]);
      if (v >= s) {
        y6 = true;
        break;
      }
      if (g.score = g.score * QN(s, u, v), g.score <= o)
        break;
    }
    g.suppressBeginIndex = d.length, y6 || (g.score === b ? (d.push(x6), h.push(g.score)) : g.score > o && BN(c, g, Rm));
  }
  const p = d.length, f = e - p;
  a && f > 0 && (d.push(...new Array(f).fill(0)), h.push(...new Array(f).fill(0)));
  const m = { selectedIndices: d };
  return i6 && (m.selectedScores = h), l && (m.validOutputs = p), m;
}
function YN(n, t, e) {
  const s = n.subarray(t * 4, t * 4 + 4), o = n.subarray(e * 4, e * 4 + 4), r = Math.min(s[0], s[2]), i6 = Math.min(s[1], s[3]), a = Math.max(s[0], s[2]), l = Math.max(s[1], s[3]), c = Math.min(o[0], o[2]), u = Math.min(o[1], o[3]), d = Math.max(o[0], o[2]), h = Math.max(o[1], o[3]), p = (a - r) * (l - i6), f = (d - c) * (h - u);
  if (p <= 0 || f <= 0)
    return 0;
  const m = Math.max(r, c), g = Math.max(i6, u), b = Math.min(a, d), x6 = Math.min(l, h), w = Math.max(b - m, 0) * Math.max(x6 - g, 0);
  return w / (p + f - w);
}
function QN(n, t, e) {
  const s = Math.exp(t * e * e);
  return e <= n ? s : 0;
}
function Rm(n, t) {
  return n.score - t.score || n.score === t.score && t.boxIndex - n.boxIndex;
}
async function JN(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY) {
  const r = T(n, "boxes", "nonMaxSuppressionAsync"), i6 = T(t, "scores", "nonMaxSuppressionAsync"), a = Rr(r, i6, e, s, o);
  e = a.maxOutputSize, s = a.iouThreshold, o = a.scoreThreshold;
  const l = await Promise.all([r.data(), i6.data()]), c = l[0], u = l[1], { selectedIndices: d } = zp(c, u, e, s, o);
  return r !== n && r.dispose(), i6 !== t && i6.dispose(), Ze(d, "int32");
}
var jN = JN;
function qN(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = 0) {
  const i6 = T(n, "boxes", "nonMaxSuppression"), a = T(t, "scores", "nonMaxSuppression"), l = Rr(i6, a, e, s, o, r);
  e = l.maxOutputSize, s = l.iouThreshold, o = l.scoreThreshold, r = l.softNmsSigma;
  const c = { boxes: i6, scores: a }, u = { maxOutputSize: e, iouThreshold: s, scoreThreshold: o, softNmsSigma: r }, d = $.runKernel($h, c, u);
  return { selectedIndices: d[0], selectedScores: d[1] };
}
var tR = L({ nonMaxSuppressionWithScore_: qN });
async function eR(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = 0) {
  const i6 = T(n, "boxes", "nonMaxSuppressionAsync"), a = T(t, "scores", "nonMaxSuppressionAsync"), l = Rr(i6, a, e, s, o, r);
  e = l.maxOutputSize, s = l.iouThreshold, o = l.scoreThreshold, r = l.softNmsSigma;
  const c = await Promise.all([i6.data(), a.data()]), u = c[0], d = c[1], { selectedIndices: h, selectedScores: p } = Ap(u, d, e, s, o, r);
  return i6 !== n && i6.dispose(), a !== t && a.dispose(), {
    selectedIndices: Ze(h, "int32"),
    selectedScores: Ze(p)
  };
}
var nR = eR;
function sR(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = false) {
  const i6 = T(n, "boxes", "nonMaxSuppression"), a = T(t, "scores", "nonMaxSuppression"), l = Rr(
    i6,
    a,
    e,
    s,
    o,
    null
    /* softNmsSigma */
  ), c = l.maxOutputSize, u = l.iouThreshold, d = l.scoreThreshold, h = { boxes: i6, scores: a }, p = {
    maxOutputSize: c,
    iouThreshold: u,
    scoreThreshold: d,
    padToMaxOutputSize: r
  }, f = $.runKernel(Rh, h, p);
  return { selectedIndices: f[0], validOutputs: f[1] };
}
var oR = L({ nonMaxSuppressionPadded_: sR });
async function rR(n, t, e, s = 0.5, o = Number.NEGATIVE_INFINITY, r = false) {
  const i6 = T(n, "boxes", "nonMaxSuppressionAsync"), a = T(t, "scores", "nonMaxSuppressionAsync"), l = Rr(
    i6,
    a,
    e,
    s,
    o,
    null
    /* softNmsSigma */
  ), c = l.maxOutputSize, u = l.iouThreshold, d = l.scoreThreshold, [h, p] = await Promise.all([i6.data(), a.data()]), { selectedIndices: f, validOutputs: m } = Pp(h, p, c, u, d, r);
  return i6 !== n && i6.dispose(), a !== t && a.dispose(), {
    selectedIndices: Ze(f, "int32"),
    validOutputs: gt(m, "int32")
  };
}
var iR = rR;
function aR(n, t, e = false, s = false) {
  const o = T(n, "images", "resizeBilinear");
  C(o.rank === 3 || o.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${o.rank}.`), C(t.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${t}.`), C(s === false || e === false, () => "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.");
  let r = o, i6 = false;
  o.rank === 3 && (i6 = true, r = W(o, [1, o.shape[0], o.shape[1], o.shape[2]]));
  const a = { images: r }, l = { alignCorners: e, halfPixelCenters: s, size: t }, c = $.runKernel(Vc, a, l);
  return i6 ? W(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}
var T0 = L({ resizeBilinear_: aR });
function lR(n, t, e = false, s = false) {
  const o = T(n, "images", "resizeNearestNeighbor");
  C(o.rank === 3 || o.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${o.rank}.`), C(t.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`), C(o.dtype === "float32" || o.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype"), C(s === false || e === false, () => "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.");
  let r = o, i6 = false;
  o.rank === 3 && (i6 = true, r = W(o, [1, o.shape[0], o.shape[1], o.shape[2]]));
  const a = { images: r }, l = { alignCorners: e, halfPixelCenters: s, size: t }, c = $.runKernel(Fc, a, l);
  return i6 ? W(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}
var N0 = L({ resizeNearestNeighbor_: lR });
function cR(n, t = "binary", e = false, s = 0.5) {
  const o = T(n, "image", "threshold"), r = 0.2989, i6 = 0.587, a = 0.114, l = o.shape[0] * o.shape[1];
  let c = G(Ze([s]), 255), u, d, h, p;
  if (C(o.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${o.rank}.`), C(o.shape[2] === 3 || o.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${o.shape[2]}.`), C(o.dtype === "int32" || o.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${o.dtype}.`), C(t === "otsu" || t === "binary", () => `Method must be binary or otsu, but was ${t}`), o.shape[2] === 3) {
    [u, d, h] = pn(o, [1, 1, 1], -1);
    const g = G(u, r), b = G(d, i6), x6 = G(h, a);
    p = U(U(g, b), x6);
  } else
    p = n;
  if (t === "otsu") {
    const g = sS(tt(u0(p), "int32"), $e([]), 256);
    c = uR(g, l);
  }
  const f = e ? Tr(p, c) : rn(p, c);
  return tt(G(f, 255), "int32");
}
function uR(n, t) {
  let e = Ze([-1]), s = Ze([0]), o = Ze([0]), r, i6, a, l, c, u;
  for (let d = 0; d < n.size - 1; d++) {
    r = Ft(n, 0, d + 1), i6 = Ft(n, d + 1), c = ut(at(r), t), u = ut(at(i6), t);
    const h = at(G(r, di(0, r.size)));
    a = ut(h, at(r));
    const p = Ca(i6.shape, r.size), f = U(di(0, i6.size), p), m = G(i6, f);
    l = ut(at(m), at(i6));
    const g = it(a, l), b = it(a, l), x6 = G(c, u);
    o = G(G(x6, g), b);
    const w = rn(o, s);
    s = Ee(w, o, s), e = Ee(w, Ze([d]), e);
  }
  return e;
}
var dR = L({ threshold_: cR });
function hR(n, t, e = "nearest", s = "constant", o = 0, r) {
  const i6 = T(n, "image", "transform", "float32"), a = T(t, "transforms", "transform", "float32");
  C(i6.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${i6.rank}.`), C(a.rank === 2 && (a.shape[0] === i6.shape[0] || a.shape[0] === 1) && a.shape[1] === 8, () => "Error in transform: Input transform should be batch x 8 or 1 x 8"), C(r == null || r.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${r}.`);
  const l = { image: i6, transforms: a }, c = { interpolation: e, fillMode: s, fillValue: o, outputShape: r };
  return $.runKernel(Zh, l, c);
}
var pR = L({ transform_: hR });
function fR(n, t, e) {
  const s = T(n, "a", "bandPart");
  C(s.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${s.rank}.`);
  const o = s.shape, [r, i6] = s.shape.slice(-2);
  let a, l;
  typeof t == "number" ? (C(t % 1 === 0, () => `bandPart(): numLower must be an integer, got ${t}.`), C(t <= r, () => `bandPart(): numLower (${t}) must not be greater than the number of rows (${r}).`), a = T(t < 0 ? r : t, "numLower", "bandPart")) : (C(t.dtype === "int32", () => "bandPart(): numLower's dtype must be an int32."), a = Ee(Cl(t, 0), r, br(t, r))), typeof e == "number" ? (C(e % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${e}.`), C(e <= i6, () => `bandPart(): numUpper (${e}) must not be greater than the number of columns (${i6}).`), l = T(e < 0 ? i6 : e, "numUpper", "bandPart")) : (C(e.dtype === "int32", () => "bandPart(): numUpper's dtype must be an int32."), l = Ee(Cl(e, 0), i6, br(e, i6)));
  const c = W(di(0, r, 1, "int32"), [-1, 1]), u = di(0, i6, 1, "int32"), d = it(c, u), h = ss(Tr(d, a), Bo(d, Yt(l))), p = be([r, i6], s.dtype);
  return W(Xn(Mo(W(s, [-1, r, i6])).map((f) => Ee(h, f, p))), o);
}
var mR = L({ bandPart_: fR });
function gR(n) {
  let t;
  if (Array.isArray(n)) {
    t = false, C(n != null && n.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
    const o = n[0].shape[0];
    for (let r = 1; r < n.length; ++r)
      C(n[r].shape[0] === o, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${n[r].shape[0]} vs. ${o})`);
  } else
    t = true, n = pn(n, n.shape[0], 0).map((o) => ka(o, [0]));
  C(n.length <= n[0].shape[0], () => `Gram-Schmidt: Number of vectors (${n.length}) exceeds number of dimensions (${n[0].shape[0]}).`);
  const e = [], s = n;
  for (let o = 0; o < n.length; ++o)
    e.push($.tidy(() => {
      let r = s[o];
      if (o > 0)
        for (let i6 = 0; i6 < o; ++i6) {
          const a = G(at(G(e[i6], r)), e[i6]);
          r = it(r, a);
        }
      return ut(r, jc(r, "euclidean"));
    }));
  return t ? Xn(e, 0) : e;
}
var bR = L({ gramSchmidt_: gR });
function xR(n, t = false) {
  if (C(n.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${n.rank}`), n.rank === 2)
    return $m(n, t);
  {
    const e = n.shape.slice(0, n.shape.length - 2).reduce((l, c) => l * c), s = Mo(W(n, [
      e,
      n.shape[n.shape.length - 2],
      n.shape[n.shape.length - 1]
    ]), 0), o = [], r = [];
    s.forEach((l) => {
      const [c, u] = $m(l, t);
      o.push(c), r.push(u);
    });
    const i6 = W(Xn(o, 0), n.shape), a = W(Xn(r, 0), n.shape);
    return [i6, a];
  }
}
function $m(n, t = false) {
  return $.tidy(() => {
    C(n.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${n.shape.length}D Tensor.`);
    const e = n.shape[0], s = n.shape[1];
    let o = o0(e), r = yo(n);
    const i6 = il([[1]], [1, 1]);
    let a = yo(i6);
    const l = e >= s ? s : e;
    for (let c = 0; c < l; ++c) {
      const u = r, d = a, h = o;
      [a, r, o] = $.tidy(() => {
        const p = Ft(r, [c, c], [e - c, 1]), f = jc(p), m = Ft(r, [c, c], [1, 1]), g = Ee(rn(m, 0), il([[-1]]), il([[1]])), b = it(m, G(g, f)), x6 = ut(p, b);
        x6.shape[0] === 1 ? a = yo(i6) : a = Ge([
          i6,
          Ft(x6, [1, 0], [x6.shape[0] - 1, x6.shape[1]])
        ], 0);
        const w = Yt(ut(Gt(g, b), f)), y6 = Ft(r, [c, 0], [e - c, s]), I = G(w, a), v = kt(a);
        if (c === 0)
          r = it(y6, Gt(I, Gt(v, y6)));
        else {
          const N = it(y6, Gt(I, Gt(v, y6)));
          r = Ge([Ft(r, [0, 0], [c, s]), N], 0);
        }
        const k6 = kt(I), S = Ft(o, [0, c], [e, o.shape[1] - c]);
        if (c === 0)
          o = it(S, Gt(Gt(S, a), k6));
        else {
          const N = it(S, Gt(Gt(S, a), k6));
          o = Ge([Ft(o, [0, 0], [e, c]), N], 1);
        }
        return [a, r, o];
      }), xt([u, d, h]);
    }
    return !t && e > s && (o = Ft(o, [0, 0], [e, s]), r = Ft(r, [0, 0], [s, s])), [o, r];
  });
}
var yR = L({ qr_: xR });
var Ke;
(function(n) {
  n[n.NONE = 0] = "NONE", n[n.MEAN = 1] = "MEAN", n[n.SUM = 2] = "SUM", n[n.SUM_BY_NONZERO_WEIGHTS = 3] = "SUM_BY_NONZERO_WEIGHTS";
})(Ke || (Ke = {}));
function wR(n, t, e = Ke.SUM_BY_NONZERO_WEIGHTS) {
  const s = T(n, "losses", "computeWeightedLoss");
  let o = null;
  t != null && (o = T(t, "weights", "computeWeightedLoss"));
  const r = o == null ? s : G(s, o);
  if (e === Ke.NONE)
    return r;
  if (e === Ke.SUM)
    return at(r);
  if (e === Ke.MEAN) {
    if (o == null)
      return oe(r);
    {
      const i6 = s.size / o.size, a = ut(at(r), at(o));
      return i6 > 1 ? ut(a, gt(i6)) : a;
    }
  }
  if (e === Ke.SUM_BY_NONZERO_WEIGHTS) {
    if (o == null)
      return ut(at(r), gt(s.size));
    {
      const i6 = G(o, ks(s.shape)), a = tt(at(ui(i6, gt(0))), "float32");
      return ut(at(r), a);
    }
  }
  throw Error(`Unknown reduction: ${e}`);
}
var Ns = L({ computeWeightedLoss_: wR });
function IR(n, t, e, s = Ke.SUM_BY_NONZERO_WEIGHTS) {
  const o = T(n, "labels", "absoluteDifference"), r = T(t, "predictions", "absoluteDifference");
  let i6 = null;
  e != null && (i6 = T(e, "weights", "absoluteDifference")), Pe(o.shape, r.shape, "Error in absoluteDifference: ");
  const a = me(it(o, r));
  return Ns(a, i6, s);
}
var CR = L({ absoluteDifference_: IR });
function vR(n, t, e, s, o = Ke.SUM_BY_NONZERO_WEIGHTS) {
  const r = T(n, "labels", "cosineDistance"), i6 = T(t, "predictions", "cosineDistance");
  let a = null;
  s != null && (a = T(s, "weights", "cosineDistance")), Pe(r.shape, i6.shape, "Error in cosineDistance: ");
  const l = gt(1), c = it(l, at(G(r, i6), e, true));
  return Ns(c, a, o);
}
var SR = L({ cosineDistance_: vR });
function kR(n, t, e, s = Ke.SUM_BY_NONZERO_WEIGHTS) {
  let o = T(n, "labels", "hingeLoss");
  const r = T(t, "predictions", "hingeLoss");
  let i6 = null;
  e != null && (i6 = T(e, "weights", "hingeLoss")), Pe(o.shape, r.shape, "Error in hingeLoss: ");
  const a = gt(1);
  o = it(G(gt(2), o), a);
  const l = Ts(it(a, G(o, r)));
  return Ns(l, i6, s);
}
var TR = L({ hingeLoss_: kR });
function NR(n, t, e, s = 1, o = Ke.SUM_BY_NONZERO_WEIGHTS) {
  const r = T(n, "labels", "huberLoss"), i6 = T(t, "predictions", "huberLoss");
  let a = null;
  e != null && (a = T(e, "weights", "huberLoss")), Pe(r.shape, i6.shape, "Error in huberLoss: ");
  const l = gt(s), c = me(it(i6, r)), u = br(c, l), d = it(c, u), h = U(G(gt(0.5), Kt(u)), G(l, d));
  return Ns(h, a, o);
}
var RR = L({ huberLoss_: NR });
function $R(n, t, e, s = 1e-7, o = Ke.SUM_BY_NONZERO_WEIGHTS) {
  const r = T(n, "labels", "logLoss"), i6 = T(t, "predictions", "logLoss");
  let a = null;
  e != null && (a = T(e, "weights", "logLoss")), Pe(r.shape, i6.shape, "Error in logLoss: ");
  const l = gt(1), c = gt(s), u = Yt(G(r, Nn(U(i6, c)))), d = G(it(l, r), Nn(U(it(l, i6), c))), h = it(u, d);
  return Ns(h, a, o);
}
var GR = L({ logLoss_: $R });
function ER(n, t, e, s = Ke.SUM_BY_NONZERO_WEIGHTS) {
  const o = T(n, "labels", "meanSquaredError"), r = T(t, "predictions", "meanSquaredError");
  let i6 = null;
  e != null && (i6 = T(e, "weights", "meanSquaredError")), Pe(o.shape, r.shape, "Error in meanSquaredError: ");
  const a = x0(o, r);
  return Ns(a, i6, s);
}
var LR = L({ meanSquaredError_: ER });
function MR(n, t) {
  const e = T(n, "labels", "sigmoidCrossEntropyWithLogits"), s = T(t, "logits", "sigmoidCrossEntropyWithLogits");
  Pe(e.shape, s.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  const o = Ts(s), r = G(s, e), i6 = hp(mn(Yt(me(s))));
  return U(it(o, r), i6);
}
function WR(n, t, e, s = 0, o = Ke.SUM_BY_NONZERO_WEIGHTS) {
  let r = T(n, "multiClassLabels", "sigmoidCrossEntropy");
  const i6 = T(t, "logits", "sigmoidCrossEntropy");
  let a = null;
  if (e != null && (a = T(e, "weights", "sigmoidCrossEntropy")), Pe(r.shape, i6.shape, "Error in sigmoidCrossEntropy: "), s > 0) {
    const c = gt(s), u = gt(1), d = gt(0.5);
    r = U(G(r, it(u, c)), G(d, c));
  }
  const l = MR(r, i6);
  return Ns(l, a, o);
}
var DR = L({ sigmoidCrossEntropy_: WR });
function FR(n, t, e = -1) {
  if (e === -1 && (e = t.rank - 1), e !== t.rank - 1)
    throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${e}`);
  return Eo((o, r, i6) => {
    const l = pp(r, [e], true), c = it(tt(r, "float32"), l);
    i6([o, c]);
    const u = Yt(G(c, o));
    return { value: at(u, [e]), gradFunc: (p, f) => {
      const [m, g] = f, b = re(p.shape, [e]);
      return [
        G(W(p, b), it(tt(m, "float32"), mn(g))),
        G(W(p, b), it(mn(g), tt(m, "float32")))
      ];
    } };
  })(n, t);
}
function VR(n, t, e, s = 0, o = Ke.SUM_BY_NONZERO_WEIGHTS) {
  let r = T(n, "onehotLabels", "softmaxCrossEntropy");
  const i6 = T(t, "logits", "softmaxCrossEntropy");
  let a = null;
  if (e != null && (a = T(e, "weights", "softmaxCrossEntropy")), Pe(r.shape, i6.shape, "Error in softmaxCrossEntropy: "), s > 0) {
    const c = gt(s), u = gt(1), d = gt(r.shape[1]);
    r = U(G(r, it(u, c)), ut(c, d));
  }
  const l = FR(r, i6);
  return Ns(l, a, o);
}
var zR = L({ softmaxCrossEntropy_: VR });
function PR(n, t, e, s) {
  const o = T(n, "indices", "sparseFillEmptyRows", "int32"), r = T(t, "values", "sparseFillEmptyRows"), i6 = T(e, "denseShape", "sparseFillEmptyRows", "int32"), a = T(s, "defaultValue", "sparseFillEmptyRows", r.dtype);
  if (o.rank !== 2)
    throw new Error(`Indices should be Tensor2D but received shape
        ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`Values should be Tensor1D but received shape ${r.shape}`);
  if (i6.rank !== 1)
    throw new Error(`Dense shape should be Tensor1D but received shape ${i6.shape}`);
  if (a.rank !== 0)
    throw new Error(`Default value should be a scalar but received shape ${a.shape}`);
  const l = {
    indices: o,
    values: r,
    denseShape: i6,
    defaultValue: a
  }, c = $.runKernel(Wh, l);
  return {
    outputIndices: c[0],
    outputValues: c[1],
    emptyRowIndicator: c[2],
    reverseIndexMap: c[3]
  };
}
var AR = L({ sparseFillEmptyRows_: PR });
function OR(n, t, e) {
  const s = T(n, "inputIndices", "sparseReshape", "int32"), o = T(t, "inputShape", "sparseReshape", "int32"), r = T(e, "newShape", "sparseReshape", "int32");
  if (s.rank !== 2)
    throw new Error(`Input indices should be Tensor2D but received shape
        ${s.shape}`);
  if (o.rank !== 1)
    throw new Error(`Input shape should be Tensor1D but received shape ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`New shape should be Tensor1D but received shape ${r.shape}`);
  const i6 = {
    inputIndices: s,
    inputShape: o,
    newShape: r
  }, a = $.runKernel(Dh, i6);
  return { outputIndices: a[0], outputShape: a[1] };
}
var XR = L({ sparseReshape_: OR });
function KR(n, t, e) {
  const s = T(n, "data", "sparseSegmentMean"), o = T(t, "indices", "sparseSegmentMean", "int32"), r = T(e, "segmentIds", "sparseSegmentMean", "int32");
  if (s.rank < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.rank !== 1)
    throw new Error(`Indices should be Tensor1D but received shape
          ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`Segment ids should be Tensor1D but received shape
          ${r.shape}`);
  const i6 = {
    data: s,
    indices: o,
    segmentIds: r
  };
  return $.runKernel(Fh, i6);
}
var ZR = L({ sparseSegmentMean_: KR });
function BR(n, t, e) {
  const s = T(n, "data", "sparseSegmentSum"), o = T(t, "indices", "sparseSegmentSum", "int32"), r = T(e, "segmentIds", "sparseSegmentSum", "int32");
  if (s.rank < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.rank !== 1)
    throw new Error(`Indices should be Tensor1D but received shape
         ${o.shape}`);
  if (r.rank !== 1)
    throw new Error(`Segment ids should be Tensor1D but received shape
         ${r.shape}`);
  const i6 = {
    data: s,
    indices: o,
    segmentIds: r
  };
  return $.runKernel(Vh, i6);
}
var HR = L({ sparseSegmentSum_: BR });
function _R(n, t, e, s, o, r, i6, a) {
  const l = T(n, "data", "stringNGrams", "string");
  if (l.dtype !== "string")
    throw new Error("Data must be of datatype string");
  if (l.shape.length !== 1)
    throw new Error(`Data must be a vector, saw: ${l.shape}`);
  const c = T(t, "dataSplits", "stringNGrams");
  if (c.dtype !== "int32")
    throw new Error("Data splits must be of datatype int32");
  const u = {
    separator: e,
    nGramWidths: s,
    leftPad: o,
    rightPad: r,
    padWidth: i6,
    preserveShortSequences: a
  }, d = { data: l, dataSplits: c }, h = $.runKernel(Ah, d, u);
  return { nGrams: h[0], nGramsSplits: h[1] };
}
var UR = L({ stringNGrams_: _R });
function YR(n, t, e = true) {
  const s = T(n, "input", "stringSplit", "string"), o = T(t, "delimiter", "stringSplit", "string");
  if (s.rank !== 1)
    throw new Error(`Input should be Tensor1D but received shape ${s.shape}`);
  if (o.rank !== 0)
    throw new Error(`Delimiter should be a scalar but received shape ${o.shape}`);
  const r = { skipEmpty: e }, i6 = { input: s, delimiter: o }, a = $.runKernel(Oh, i6, r);
  return { indices: a[0], values: a[1], shape: a[2] };
}
var QR = L({ stringSplit_: YR });
function JR(n, t) {
  const e = T(n, "input", "stringToHashBucketFast", "string"), s = { numBuckets: t };
  if (t <= 0)
    throw new Error("Number of buckets must be at least 1");
  const o = { input: e };
  return $.runKernel(Xh, o, s);
}
var jR = L({ stringToHashBucketFast_: JR });
function qR(n, t, e, s = true) {
  const o = T(n, "input", "staticRegexReplace", "string"), r = { pattern: t, rewrite: e, replaceGlobal: s };
  return $.runKernel(Bc, { x: o }, r);
}
var t$ = L({ staticRegexReplace_: qR });
var NQ = {
  fft: Gp,
  ifft: kl,
  rfft: Ep,
  irfft: b0
};
var RQ = {
  hammingWindow: RN,
  hannWindow: S0,
  frame: k0,
  stft: LN
};
var fs = {
  flipLeftRight: FN,
  grayscaleToRGB: zN,
  resizeNearestNeighbor: N0,
  resizeBilinear: T0,
  rgbToGrayscale: AN,
  rotateWithOffset: XN,
  cropAndResize: WN,
  nonMaxSuppression: ZN,
  nonMaxSuppressionAsync: jN,
  nonMaxSuppressionWithScore: tR,
  nonMaxSuppressionWithScoreAsync: nR,
  nonMaxSuppressionPadded: oR,
  nonMaxSuppressionPaddedAsync: iR,
  threshold: dR,
  transform: pR
};
var e$ = {
  bandPart: mR,
  gramSchmidt: bR,
  qr: yR
};
var $Q = {
  absoluteDifference: CR,
  computeWeightedLoss: Ns,
  cosineDistance: SR,
  hingeLoss: TR,
  huberLoss: RR,
  logLoss: GR,
  meanSquaredError: LR,
  sigmoidCrossEntropy: DR,
  softmaxCrossEntropy: zR
};
var GQ = {
  sparseFillEmptyRows: AR,
  sparseReshape: XR,
  sparseSegmentMean: ZR,
  sparseSegmentSum: HR
};
var EQ = {
  stringNGrams: UR,
  stringSplit: QR,
  stringToHashBucketFast: jR,
  staticRegexReplace: t$
};
var n$ = /* @__PURE__ */ new Map();
var Sd = /* @__PURE__ */ new Map();
var _o = class {
  /**
   * Return the class name for this class to use in serialization contexts.
   *
   * Generally speaking this will be the same thing that constructor.name
   * would have returned.  However, the class name needs to be robust
   * against minification for serialization/deserialization to work properly.
   *
   * There's also places such as initializers.VarianceScaling, where
   * implementation details between different languages led to different
   * class hierarchies and a non-leaf node is used for serialization purposes.
   */
  getClassName() {
    return this.constructor.className;
  }
  /**
   * Creates an instance of T from a ConfigDict.
   *
   * This works for most descendants of serializable.  A few need to
   * provide special handling.
   * @param cls A Constructor for the class to instantiate.
   * @param config The Configuration for the object.
   */
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e);
  }
};
var cn = class _cn {
  constructor() {
    this.classNameMap = {};
  }
  /**
   * Returns the singleton instance of the map.
   */
  static getMap() {
    return _cn.instance == null && (_cn.instance = new _cn()), _cn.instance;
  }
  /**
   * Registers the class as serializable.
   */
  static register(t) {
    _cn.getMap().classNameMap[t.className] = [t, t.fromConfig];
  }
};
function _(n, t, e) {
  C(n.className != null, () => "Class being registered does not have the static className property defined."), C(typeof n.className == "string", () => "className is required to be a string, but got type " + typeof n.className), C(n.className.length > 0, () => "Class being registered has an empty-string as its className, which is disallowed."), typeof t > "u" && (t = "Custom"), typeof e > "u" && (e = n.className);
  const s = e, o = t + ">" + s;
  return cn.register(n), n$.set(o, n), Sd.set(n, o), n;
}
function s$(n) {
  return Sd.has(n) ? Sd.get(n) : n.className;
}
var LQ = Object.freeze(Object.defineProperty({
  __proto__: null,
  Serializable: _o,
  SerializationMap: cn,
  getRegisteredName: s$,
  registerClass: _
}, Symbol.toStringTag, { value: "Module" }));
var eo = class extends _o {
  /**
   * Executes `f()` and minimizes the scalar output of `f()` by computing
   * gradients of y with respect to the list of trainable variables provided by
   * `varList`. If no list is provided, it defaults to all trainable variables.
   *
   * @param f The function to execute and whose output to minimize.
   * @param returnCost Whether to return the scalar cost value produced by
   * executing `f()`.
   * @param varList An optional list of variables to update. If specified, only
   * the trainable variables in varList will be updated by minimize. Defaults to
   * all trainable variables.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers'}
   */
  minimize(t, e = false, s) {
    const { value: o, grads: r } = this.computeGradients(t, s);
    if (s != null) {
      const i6 = s.map((a) => ({ name: a.name, tensor: r[a.name] }));
      this.applyGradients(i6);
    } else
      this.applyGradients(r);
    return xt(r), e ? o : (o.dispose(), null);
  }
  /**
   * The number of iterations that this optimizer instance has been invoked for.
   */
  get iterations() {
    return this.iterations_ == null && (this.iterations_ = 0), this.iterations_;
  }
  incrementIterations() {
    this.iterations_ = this.iterations + 1;
  }
  /**
   * Executes f() and computes the gradient of the scalar output of f() with
   * respect to the list of trainable variables provided by `varList`. If no
   * list is provided, it defaults to all trainable variables.
   *
   * @param f The function to execute and whose output to use for computing
   * gradients with respect to variables.
   * @param varList An optional list of variables to compute gradients with
   * respect to. If specified, only the trainable variables in varList will have
   * gradients computed with respect to. Defaults to all trainable variables.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers'}
   */
  computeGradients(t, e) {
    return kk(t, e);
  }
  /**
   * Dispose the variables (if any) owned by this optimizer instance.
   */
  dispose() {
    this.iterations_ != null && xt(this.iterations_);
  }
  async saveIterations() {
    return this.iterations_ == null && (this.iterations_ = 0), {
      name: "iter",
      // TODO(cais): Use 'int64' type when available.
      tensor: gt(this.iterations_, "int32")
    };
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for this optimizer yet.");
  }
  async setWeights(t) {
    throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
  }
  /**
   * Extract the first element of the weight values and set it
   * as the iterations counter variable of this instance of optimizer.
   *
   * @param weightValues
   * @returns Weight values with the first element consumed and excluded.
   */
  async extractIterations(t) {
    return this.iterations_ = (await t[0].tensor.data())[0], t.slice(1);
  }
};
Object.defineProperty(eo, Symbol.hasInstance, {
  value: (n) => n.minimize != null && n.computeGradients != null && n.applyGradients != null
});
var R0 = class extends eo {
  /** @nocollapse */
  static get className() {
    return "Adadelta";
  }
  constructor(t, e, s = null) {
    super(), this.learningRate = t, this.rho = e, this.epsilon = s, this.accumulatedGrads = [], this.accumulatedUpdates = [], s == null && (this.epsilon = $.backend.epsilon());
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s], i6 = false;
      this.accumulatedGrads[o] == null && (this.accumulatedGrads[o] = {
        originalName: `${s}/accum_grad`,
        variable: D(() => Tt(r).variable(i6))
      }), this.accumulatedUpdates[o] == null && (this.accumulatedUpdates[o] = {
        originalName: `${s}/accum_var`,
        variable: D(() => Tt(r).variable(i6))
      });
      const a = Array.isArray(t) ? t[o].tensor : t[s];
      if (a == null)
        return;
      const l = this.accumulatedGrads[o].variable, c = this.accumulatedUpdates[o].variable;
      D(() => {
        const u = U(G(l, this.rho), G(Kt(a), 1 - this.rho)), d = G(ut(Ve(U(c, this.epsilon)), Ve(U(l, this.epsilon))), a), h = U(G(c, this.rho), G(Kt(d), 1 - this.rho));
        l.assign(u), c.assign(h);
        const p = U(G(d, -this.learningRate), r);
        r.assign(p);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedUpdates != null && (xt(this.accumulatedGrads.map((t) => t.variable)), xt(this.accumulatedUpdates.map((t) => t.variable)));
  }
  async getWeights() {
    const t = [...this.accumulatedGrads, ...this.accumulatedUpdates];
    return [await this.saveIterations()].concat(t.map((e) => ({ name: e.originalName, tensor: e.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = t.length / 2, s = false;
    this.accumulatedGrads = t.slice(0, e).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.accumulatedUpdates = t.slice(e, e * 2).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      rho: this.rho,
      epsilon: this.epsilon
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.rho, e.epsilon);
  }
};
var $0 = class extends eo {
  /** @nocollapse */
  static get className() {
    return "Adagrad";
  }
  constructor(t, e = 0.1) {
    super(), this.learningRate = t, this.initialAccumulatorValue = e, this.accumulatedGrads = [];
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s];
      this.accumulatedGrads[o] == null && (this.accumulatedGrads[o] = {
        originalName: `${s}/accumulator`,
        variable: D(() => Ca(r.shape, this.initialAccumulatorValue).variable(false))
      });
      const i6 = Array.isArray(t) ? t[o].tensor : t[s];
      if (i6 == null)
        return;
      const a = this.accumulatedGrads[o].variable;
      D(() => {
        const l = U(a, Kt(i6));
        a.assign(l);
        const c = U(G(ut(i6, Ve(U(l, $.backend.epsilon()))), -this.learningRate), r);
        r.assign(c);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedGrads != null && xt(this.accumulatedGrads.map((t) => t.variable));
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulatedGrads.map((t) => ({ name: t.originalName, tensor: t.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = false;
    this.accumulatedGrads = t.map((s) => ({ originalName: s.name, variable: s.tensor.variable(e) }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      initialAccumulatorValue: this.initialAccumulatorValue
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.initialAccumulatorValue);
  }
};
var G0 = class extends eo {
  /** @nocollapse */
  static get className() {
    return "Adam";
  }
  constructor(t, e, s, o = null) {
    super(), this.learningRate = t, this.beta1 = e, this.beta2 = s, this.epsilon = o, this.accumulatedFirstMoment = [], this.accumulatedSecondMoment = [], D(() => {
      this.accBeta1 = gt(e).variable(), this.accBeta2 = gt(s).variable();
    }), o == null && (this.epsilon = $.backend.epsilon());
  }
  applyGradients(t) {
    const e = Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t);
    D(() => {
      const s = it(1, this.accBeta1), o = it(1, this.accBeta2);
      e.forEach((r, i6) => {
        const a = $.registeredVariables[r], l = false;
        this.accumulatedFirstMoment[i6] == null && (this.accumulatedFirstMoment[i6] = {
          originalName: `${r}/m`,
          variable: D(() => Tt(a).variable(l))
        }), this.accumulatedSecondMoment[i6] == null && (this.accumulatedSecondMoment[i6] = {
          originalName: `${r}/v`,
          variable: D(() => Tt(a).variable(l))
        });
        const c = Array.isArray(t) ? t[i6].tensor : t[r];
        if (c == null)
          return;
        const u = this.accumulatedFirstMoment[i6].variable, d = this.accumulatedSecondMoment[i6].variable, h = U(G(u, this.beta1), G(c, 1 - this.beta1)), p = U(G(d, this.beta2), G(Kt(c), 1 - this.beta2)), f = ut(h, s), m = ut(p, o);
        u.assign(h), d.assign(p);
        const g = U(G(ut(f, U(Ve(m), this.epsilon)), -this.learningRate), a);
        a.assign(g);
      }), this.accBeta1.assign(G(this.accBeta1, this.beta1)), this.accBeta2.assign(G(this.accBeta2, this.beta2));
    }), this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose(), this.accBeta2.dispose(), this.accumulatedFirstMoment != null && xt(this.accumulatedFirstMoment.map((t) => t.variable)), this.accumulatedSecondMoment != null && xt(this.accumulatedSecondMoment.map((t) => t.variable));
  }
  async getWeights() {
    const t = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
    return [await this.saveIterations()].concat(t.map((e) => ({ name: e.originalName, tensor: e.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t), D(() => {
      this.accBeta1.assign(gr(this.beta1, this.iterations_ + 1)), this.accBeta2.assign(gr(this.beta2, this.iterations_ + 1));
    });
    const e = t.length / 2, s = false;
    this.accumulatedFirstMoment = t.slice(0, e).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.accumulatedSecondMoment = t.slice(e, e * 2).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.beta1, e.beta2, e.epsilon);
  }
};
var E0 = class extends eo {
  /** @nocollapse */
  static get className() {
    return "Adamax";
  }
  constructor(t, e, s, o = null, r = 0) {
    super(), this.learningRate = t, this.beta1 = e, this.beta2 = s, this.epsilon = o, this.decay = r, this.accumulatedFirstMoment = [], this.accumulatedWeightedInfNorm = [], D(() => {
      this.iteration = gt(0).variable(), this.accBeta1 = gt(e).variable();
    }), o == null && (this.epsilon = $.backend.epsilon());
  }
  applyGradients(t) {
    const e = Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t);
    D(() => {
      const s = it(1, this.accBeta1), o = ut(-this.learningRate, U(G(this.iteration, this.decay), 1));
      e.forEach((r, i6) => {
        const a = $.registeredVariables[r], l = false;
        this.accumulatedFirstMoment[i6] == null && (this.accumulatedFirstMoment[i6] = {
          originalName: `${r}/m`,
          variable: Tt(a).variable(l)
        }), this.accumulatedWeightedInfNorm[i6] == null && (this.accumulatedWeightedInfNorm[i6] = {
          originalName: `${r}/v`,
          variable: Tt(a).variable(l)
        });
        const c = Array.isArray(t) ? t[i6].tensor : t[r];
        if (c == null)
          return;
        const u = this.accumulatedFirstMoment[i6].variable, d = this.accumulatedWeightedInfNorm[i6].variable, h = U(G(u, this.beta1), G(c, 1 - this.beta1)), p = G(d, this.beta2), f = me(c), m = qs(p, f);
        u.assign(h), d.assign(m);
        const g = U(G(ut(o, s), ut(h, U(m, this.epsilon))), a);
        a.assign(g);
      }), this.iteration.assign(U(this.iteration, 1)), this.accBeta1.assign(G(this.accBeta1, this.beta1));
    }), this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose(), this.iteration.dispose(), this.accumulatedFirstMoment != null && xt(this.accumulatedFirstMoment.map((t) => t.variable)), this.accumulatedWeightedInfNorm != null && xt(this.accumulatedWeightedInfNorm.map((t) => t.variable));
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for Adamax yet.");
  }
  async setWeights(t) {
    throw new Error("setWeights() is not implemented for Adamax yet.");
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon,
      decay: this.decay
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.beta1, e.beta2, e.epsilon, e.decay);
  }
};
var Xp = class extends eo {
  /** @nocollapse */
  static get className() {
    return "SGD";
  }
  constructor(t) {
    super(), this.learningRate = t, this.setLearningRate(t);
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = Array.isArray(t) ? t[o].tensor : t[s];
      if (r == null)
        return;
      const i6 = $.registeredVariables[s];
      D(() => {
        const a = U(G(this.c, r), i6);
        i6.assign(a);
      });
    }), this.incrementIterations();
  }
  /**
   * Sets the learning rate of the optimizer.
   */
  setLearningRate(t) {
    this.learningRate = t, this.c != null && this.c.dispose(), this.c = hn(gt(-t));
  }
  dispose() {
    this.c.dispose();
  }
  async getWeights() {
    return [await this.saveIterations()];
  }
  async setWeights(t) {
    if (t = await this.extractIterations(t), t.length !== 0)
      throw new Error("SGD optimizer does not have settable weights.");
  }
  getConfig() {
    return { learningRate: this.learningRate };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate);
  }
};
var L0 = class extends Xp {
  /** @nocollapse */
  // Name matters for Python compatibility.
  static get className() {
    return "Momentum";
  }
  constructor(t, e, s = false) {
    super(t), this.learningRate = t, this.momentum = e, this.useNesterov = s, this.accumulations = [], this.m = gt(this.momentum);
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s];
      this.accumulations[o] == null && (this.accumulations[o] = {
        originalName: `${s}/momentum`,
        variable: D(() => Tt(r).variable(false))
      });
      const i6 = this.accumulations[o].variable, a = Array.isArray(t) ? t[o].tensor : t[s];
      a != null && D(() => {
        let l;
        const c = U(G(this.m, i6), a);
        this.useNesterov ? l = U(G(this.c, U(a, G(c, this.m))), r) : l = U(G(this.c, c), r), i6.assign(c), r.assign(l);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.m.dispose(), this.accumulations != null && xt(this.accumulations.map((t) => t.variable));
  }
  /**
   * Sets the momentum of the optimizer.
   *
   * @param momentum
   */
  setMomentum(t) {
    this.momentum = t;
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulations.map((t) => ({ name: t.originalName, tensor: t.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = false;
    this.accumulations = t.map((s) => ({ originalName: s.name, variable: s.tensor.variable(e) }));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      momentum: this.momentum,
      useNesterov: this.useNesterov
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.momentum, e.useNesterov);
  }
};
var M0 = class extends eo {
  /** @nocollapse */
  static get className() {
    return "RMSProp";
  }
  constructor(t, e = 0.9, s = 0, o = null, r = false) {
    if (super(), this.learningRate = t, this.decay = e, this.momentum = s, this.epsilon = o, this.accumulatedMeanSquares = [], this.accumulatedMoments = [], this.accumulatedMeanGrads = [], this.centered = r, o == null && (this.epsilon = $.backend.epsilon()), t == null)
      throw new Error("learningRate for RMSPropOptimizer must be defined.");
  }
  applyGradients(t) {
    (Array.isArray(t) ? t.map((s) => s.name) : Object.keys(t)).forEach((s, o) => {
      const r = $.registeredVariables[s], i6 = false;
      this.accumulatedMeanSquares[o] == null && (this.accumulatedMeanSquares[o] = {
        originalName: `${s}/rms`,
        variable: D(() => Tt(r).variable(i6))
      }), this.accumulatedMoments[o] == null && (this.accumulatedMoments[o] = {
        originalName: `${s}/momentum`,
        variable: D(() => Tt(r).variable(i6))
      }), this.accumulatedMeanGrads[o] == null && this.centered && (this.accumulatedMeanGrads[o] = {
        originalName: `${s}/mg`,
        variable: D(() => Tt(r).variable(i6))
      });
      const a = Array.isArray(t) ? t[o].tensor : t[s];
      if (a == null)
        return;
      const l = this.accumulatedMeanSquares[o].variable, c = this.accumulatedMoments[o].variable;
      D(() => {
        const u = U(G(l, this.decay), G(Kt(a), 1 - this.decay));
        if (this.centered) {
          const d = this.accumulatedMeanGrads[o].variable, h = U(G(d, this.decay), G(a, 1 - this.decay)), p = ut(G(a, this.learningRate), Ve(it(u, U(Kt(h), this.epsilon)))), f = U(G(c, this.momentum), p);
          l.assign(u), d.assign(h), c.assign(f);
          const m = it(r, f);
          r.assign(m);
        } else {
          const d = U(G(l, this.decay), G(Kt(a), 1 - this.decay)), h = U(G(c, this.momentum), ut(G(a, this.learningRate), Ve(U(d, this.epsilon))));
          l.assign(d), c.assign(h);
          const p = it(r, h);
          r.assign(p);
        }
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedMeanSquares != null && xt(this.accumulatedMeanSquares.map((t) => t.variable)), this.accumulatedMeanGrads != null && this.centered && xt(this.accumulatedMeanGrads.map((t) => t.variable)), this.accumulatedMoments != null && xt(this.accumulatedMoments.map((t) => t.variable));
  }
  async getWeights() {
    const t = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
    return this.centered && t.push(...this.accumulatedMeanGrads), [await this.saveIterations()].concat(t.map((e) => ({ name: e.originalName, tensor: e.variable })));
  }
  async setWeights(t) {
    t = await this.extractIterations(t);
    const e = this.centered ? t.length / 3 : t.length / 2, s = false;
    this.accumulatedMeanSquares = t.slice(0, e).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.accumulatedMoments = t.slice(e, e * 2).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })), this.centered && (this.accumulatedMeanGrads = t.slice(e * 2, e * 3).map((o) => ({
      originalName: o.name,
      variable: o.tensor.variable(s)
    })));
  }
  getConfig() {
    return {
      learningRate: this.learningRate,
      decay: this.decay,
      momentum: this.momentum,
      epsilon: this.epsilon,
      centered: this.centered
    };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e.learningRate, e.decay, e.momentum, e.epsilon, e.centered);
  }
};
var o$ = [
  R0,
  $0,
  G0,
  E0,
  L0,
  M0,
  Xp
];
function r$() {
  for (const n of o$)
    _(n);
}
function Gm(n, t, e, s) {
  i6(n), e = e ?? 0, s = s ?? 1, a(e, s);
  let o = 0;
  const r = (l) => (l.then((c) => {
    const u = e + ++o / n.length * (s - e);
    return t(u), c;
  }), l);
  function i6(l) {
    C(l != null && Array.isArray(l) && l.length > 0, () => "promises must be a none empty array");
  }
  function a(l, c) {
    C(l >= 0 && l <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${l}`), C(c >= 0 && c <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${c}`), C(c >= l, () => `startFraction must be no more than endFraction, but got startFraction ${l} and endFraction ${c}`);
  }
  return Promise.all(n.map(r));
}
async function W0(n, t) {
  t == null && (t = {});
  const e = t.fetchFunc == null ? F().platform.fetch : t.fetchFunc, s = n.map((d) => e(d, t.requestInit, { isBinary: true })), a = (t.onProgress == null ? await Promise.all(s) : await Gm(s, t.onProgress, 0, 0.5)).map((d) => d.arrayBuffer());
  return t.onProgress == null ? await Promise.all(a) : await Gm(a, t.onProgress, 0.5, 1);
}
function i$(n, t) {
  var e;
  const s = t.fetchFunc == null ? F().platform.fetch : t.fetchFunc;
  let o = 0, r;
  return (e = t.onProgress) === null || e === void 0 || e.call(t, 0), new ReadableStream({
    pull: async (i6) => {
      for (var a; o < n.length; ) {
        r || (r = (await s(n[o], t.requestInit, { isBinary: true })).body.getReader());
        const { done: l, value: c } = await r.read();
        if (l) {
          o++, r = void 0, (a = t.onProgress) === null || a === void 0 || a.call(t, o / n.length);
          continue;
        }
        i6.enqueue(c);
        return;
      }
      i6.close();
    }
  });
}
async function a$(n, t = "", e, s) {
  return l$((i6) => W0(i6, { requestInit: s }))(n, t, e);
}
function l$(n) {
  return async (t, e = "", s) => {
    const o = t.map(() => false), r = {}, i6 = s != null ? s.map(() => false) : [], a = [];
    if (t.forEach((p, f) => {
      let m = 0;
      p.weights.forEach((g) => {
        const b = "quantization" in g ? g.quantization.dtype : g.dtype, x6 = So[b] * X(g.shape), w = () => {
          o[f] = true, r[f] == null && (r[f] = []), r[f].push({
            manifestEntry: g,
            groupOffset: m,
            sizeBytes: x6
          });
        };
        s != null ? s.forEach((y6, I) => {
          y6 === g.name && (w(), i6[I] = true);
        }) : w(), a.push(g.name), m += x6;
      });
    }), !i6.every((p) => p)) {
      const p = s.filter((f, m) => !i6[m]);
      throw new Error(`Could not find weights in manifest with names: ${p.join(", ")}. 
Manifest JSON has weights with names: ${a.join(", ")}.`);
    }
    const l = o.reduce((p, f, m) => (f && p.push(m), p), []), c = [];
    l.forEach((p) => {
      t[p].paths.forEach((f) => {
        const m = e + (e.endsWith("/") ? "" : "/") + f;
        c.push(m);
      });
    });
    const u = await n(c), d = {};
    let h = 0;
    return l.forEach((p) => {
      const f = t[p].paths.length, m = new Cs(u.slice(h, h + f));
      r[p].forEach((b) => {
        const x6 = m.slice(b.groupOffset, b.groupOffset + b.sizeBytes), w = Ab(x6, [b.manifestEntry]);
        for (const y6 in w)
          d[y6] = w[y6];
      }), h += f;
    }), d;
  };
}
var c$ = "application/octet-stream";
var u$ = "application/json";
var Kp = class {
  constructor(t, e) {
    if (this.DEFAULT_METHOD = "POST", e == null && (e = {}), this.weightPathPrefix = e.weightPathPrefix, this.weightUrlConverter = e.weightUrlConverter, e.fetchFunc != null ? (C(typeof e.fetchFunc == "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"), this.fetch = e.fetchFunc) : this.fetch = F().platform.fetch, C(t != null && t.length > 0, () => "URL path for http must not be null, undefined or empty."), Array.isArray(t) && C(t.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${t.length}).`), this.path = t, e.requestInit != null && e.requestInit.body != null)
      throw new Error("requestInit is expected to have no pre-existing body, but has one.");
    this.requestInit = e.requestInit || {}, this.loadOptions = e;
  }
  async save(t) {
    if (t.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
    const e = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
    e.body = new FormData();
    const s = [{
      paths: ["./model.weights.bin"],
      weights: t.weightSpecs
    }], o = V2(t, s);
    if (e.body.append("model.json", new Blob([JSON.stringify(o)], { type: u$ }), "model.json"), t.weightData != null) {
      const i6 = Cs.join(t.weightData);
      e.body.append("model.weights.bin", new Blob([i6], { type: c$ }), "model.weights.bin");
    }
    const r = await this.fetch(this.path, e);
    if (r.ok)
      return {
        modelArtifactsInfo: tp(t),
        responses: [r]
      };
    throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${r.status}.`);
  }
  async loadModelJSON() {
    const t = await this.fetch(this.path, this.requestInit);
    if (!t.ok)
      throw new Error(`Request to ${this.path} failed with status code ${t.status}. Please verify this URL points to the model JSON of the model to load.`);
    let e;
    try {
      e = await t.json();
    } catch {
      let i6 = `Failed to parse model JSON of response from ${this.path}.`;
      throw this.path.endsWith(".pb") ? i6 += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository." : i6 += " Please make sure the server is serving valid JSON for this request.", new Error(i6);
    }
    const s = e.modelTopology, o = e.weightsManifest;
    if (s == null && o == null)
      throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
    return e;
  }
  /**
   * Load model artifacts via HTTP request(s).
   *
   * See the documentation to `tf.io.http` for details on the saved
   * artifacts.
   *
   * @returns The loaded model artifacts (if loading succeeds).
   */
  async load() {
    if (this.loadOptions.streamWeights)
      return this.loadStream();
    const t = await this.loadModelJSON();
    return P2(t, (e) => this.loadWeights(e));
  }
  async loadStream() {
    const t = await this.loadModelJSON(), e = await this.getWeightUrls(t.weightsManifest), s = km(t.weightsManifest), o = () => i$(e, this.loadOptions);
    return Object.assign(Object.assign({}, t), { weightSpecs: s, getWeightStream: o });
  }
  async getWeightUrls(t) {
    const e = Array.isArray(this.path) ? this.path[1] : this.path, [s, o] = d$(e), r = this.weightPathPrefix || s, i6 = [], a = [];
    for (const l of t)
      for (const c of l.paths)
        this.weightUrlConverter != null ? a.push(this.weightUrlConverter(c)) : i6.push(r + c + o);
    return this.weightUrlConverter && i6.push(...await Promise.all(a)), i6;
  }
  async loadWeights(t) {
    const e = await this.getWeightUrls(t), s = km(t), o = await W0(e, this.loadOptions);
    return [s, o];
  }
};
Kp.URL_SCHEME_REGEX = /^https?:\/\//;
function d$(n) {
  const t = n.lastIndexOf("/"), e = n.lastIndexOf("?"), s = n.substring(0, t), o = e > t ? n.substring(e) : "";
  return [s + "/", o];
}
function Em(n) {
  return n.match(Kp.URL_SCHEME_REGEX) != null;
}
var D0 = (n, t) => {
  if (typeof fetch > "u" && (t == null || t.fetchFunc == null))
    return null;
  {
    let e = true;
    if (Array.isArray(n) ? e = n.every((s) => Em(s)) : e = Em(n), e)
      return F0(n, t);
  }
  return null;
};
ee.registerSaveRouter(D0);
ee.registerLoadRouter(D0);
function F0(n, t) {
  return new Kp(n, t);
}
function h$(n, t) {
  return F0(n, t);
}
var io;
var Lm = false;
function V0(n, t = 3) {
  if (t > 4)
    throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  if (n == null)
    throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  let e = false, s = false, o = false, r = false, i6 = false, a = false;
  if (n.data instanceof Uint8Array)
    e = true;
  else if (typeof ImageData < "u" && n instanceof ImageData)
    s = true;
  else if (typeof HTMLVideoElement < "u" && n instanceof HTMLVideoElement)
    o = true;
  else if (typeof HTMLImageElement < "u" && n instanceof HTMLImageElement)
    r = true;
  else if (n.getContext != null)
    i6 = true;
  else if (typeof ImageBitmap < "u" && n instanceof ImageBitmap)
    a = true;
  else
    throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${n.constructor.name}`);
  if (bl(cd, $.backendName) != null) {
    const f = { pixels: n }, m = { numChannels: t };
    return $.runKernel(cd, f, m);
  }
  const [c, u] = o ? [
    n.videoWidth,
    n.videoHeight
  ] : [n.width, n.height];
  let d;
  if (i6)
    d = // tslint:disable-next-line:no-any
    n.getContext("2d").getImageData(0, 0, c, u).data;
  else if (s || e)
    d = n.data;
  else if (r || o || a) {
    if (io == null)
      if (typeof document > "u")
        if (typeof OffscreenCanvas < "u" && typeof OffscreenCanvasRenderingContext2D < "u")
          io = new OffscreenCanvas(1, 1).getContext("2d");
        else
          throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
      else
        io = document.createElement("canvas").getContext("2d", { willReadFrequently: true });
    io.canvas.width = c, io.canvas.height = u, io.drawImage(n, 0, 0, c, u), d = io.getImageData(0, 0, c, u).data;
  }
  let h;
  if (t === 4)
    h = new Int32Array(d);
  else {
    const f = c * u;
    h = new Int32Array(f * t);
    for (let m = 0; m < f; m++)
      for (let g = 0; g < t; ++g)
        h[m * t + g] = d[m * 4 + g];
  }
  return rN(h, [u, c, t], "int32");
}
function p$(n) {
  return n != null && n.data instanceof Uint8Array;
}
function f$() {
  return typeof window < "u" && typeof ImageBitmap < "u" && window.hasOwnProperty("createImageBitmap");
}
function m$(n) {
  return n != null && n.width !== 0 && n.height !== 0;
}
function g$(n) {
  return f$() && !(n instanceof ImageBitmap) && m$(n) && !p$(n);
}
async function b$(n, t = 3) {
  let e = null;
  if (F().getBool("WRAP_TO_IMAGEBITMAP") && g$(n)) {
    let s;
    try {
      s = await createImageBitmap(n, { premultiplyAlpha: "none" });
    } catch {
      s = null;
    }
    s != null && s.width === n.width && s.height === n.height ? e = s : e = n;
  } else
    e = n;
  return V0(e, t);
}
function z0(n) {
  if (n.rank !== 2 && n.rank !== 3)
    throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${n.rank}.`);
  const t = n.rank === 2 ? 1 : n.shape[2];
  if (t > 4 || t === 2)
    throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${t}`);
  if (n.dtype !== "float32" && n.dtype !== "int32")
    throw new Error(`Unsupported type for toPixels: ${n.dtype}. Please use float32 or int32 tensors.`);
}
function x$(n) {
  const t = (n == null ? void 0 : n.alpha) || 1;
  if (t > 1 || t < 0)
    throw new Error(`Alpha value ${t} is suppoed to be in range [0 - 1].`);
}
async function y$(n, t) {
  let e = T(n, "img", "toPixels");
  if (!(n instanceof Mt)) {
    const c = e;
    e = tt(c, "int32"), c.dispose();
  }
  z0(e);
  const [s, o] = e.shape.slice(0, 2), r = e.rank === 2 ? 1 : e.shape[2], i6 = await e.data(), a = e.dtype === "float32" ? 255 : 1, l = new Uint8ClampedArray(o * s * 4);
  for (let c = 0; c < s * o; ++c) {
    const u = [0, 0, 0, 255];
    for (let h = 0; h < r; h++) {
      const p = i6[c * r + h];
      if (e.dtype === "float32") {
        if (p < 0 || p > 1)
          throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${p}.`);
      } else if (e.dtype === "int32" && (p < 0 || p > 255))
        throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${p}.`);
      r === 1 ? (u[0] = p * a, u[1] = p * a, u[2] = p * a) : u[h] = p * a;
    }
    const d = c * 4;
    l[d + 0] = Math.round(u[0]), l[d + 1] = Math.round(u[1]), l[d + 2] = Math.round(u[2]), l[d + 3] = Math.round(u[3]);
  }
  if (t != null) {
    Lm || bl(gh, $.backendName) != null && (console.warn("tf.browser.toPixels is not efficient to draw tensor on canvas. Please try tf.browser.draw instead."), Lm = true), t.width = o, t.height = s;
    const c = t.getContext("2d"), u = new ImageData(l, o, s);
    c.putImageData(u, 0, 0);
  }
  return e !== n && e.dispose(), l;
}
function w$(n, t, e) {
  let s = T(n, "img", "draw");
  if (!(n instanceof Mt)) {
    const i6 = s;
    s = tt(i6, "int32"), i6.dispose();
  }
  z0(s), x$(e == null ? void 0 : e.imageOptions);
  const o = { image: s }, r = { canvas: t, options: e };
  $.runKernel(gh, o, r);
}
var P0 = L({ fromPixels_: V0 });
var MQ = Object.freeze(Object.defineProperty({
  __proto__: null,
  draw: w$,
  fromPixels: P0,
  fromPixelsAsync: b$,
  toPixels: y$
}, Symbol.toStringTag, { value: "Module" }));
function eu(n, t) {
  const e = n.shape.length, s = t.shape.length;
  if (e < 1)
    throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${e}.`);
  if (s < 1)
    throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${s}.`);
  if (t.dtype !== "int32")
    throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);
  if (t.shape[s - 1] > e)
    throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t.shape[s - 1]} vs. ${e}`);
  if (X(n.shape) === 0)
    throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${n.shape}.`);
  const o = t.shape, r = o[o.length - 1];
  let i6 = 1;
  for (let d = 0; d < o.length - 1; ++d)
    i6 *= o[d];
  const a = n.shape, l = o.slice();
  l.pop();
  let c = 1;
  for (let d = r; d < e; ++d)
    c *= a[d], l.push(a[d]);
  const u = [
    ...dt(n.shape).map((d) => d / c),
    1
  ].slice(0, r);
  return [l, i6, c, u];
}
var WQ = Object.freeze(Object.defineProperty({
  __proto__: null,
  prepareAndValidate: eu
}, Symbol.toStringTag, { value: "Module" }));
var kd = -2;
var I$ = -1;
function Zp(n, t, e) {
  const s = n.shape.length;
  C(s === t.length, () => `Error in slice${s}D: Length of begin ${t} must match the rank of the array (${s}).`), C(s === e.length, () => `Error in slice${s}D: Length of size ${e} must match the rank of the array (${s}).`);
  for (let o = 0; o < s; ++o)
    C(t[o] + e[o] <= n.shape[o], () => `Error in slice${s}D: begin[${o}] + size[${o}] (${t[o] + e[o]}) would overflow input.shape[${o}] (${n.shape[o]})`);
}
function C$(n) {
  const t = [];
  let e = 0;
  for (; n > 0; )
    n & 1 && t.push(e), n /= 2, e++;
  return t;
}
function Bp(n, t, e) {
  const s = [];
  for (let o = 0; o < n.length; o++)
    s[o] = Math.ceil((t[o] - n[o]) / e[o]);
  return s;
}
function A0(n, t, e, s) {
  const o = [...n];
  for (let r = o.length; r < s.length; r++)
    o.push(1);
  for (let r = 0; r < e; r++)
    r === 0 ? o[t] = 1 : (o.splice(
      t,
      0,
      1
      /* element to add */
    ), o.pop());
  return o;
}
function O0(n, t, e) {
  return e <= n ? e : e - (t - 1);
}
function X0(n, t) {
  const e = [];
  for (let s = 0; s < n; s++)
    e.push(t + s);
  return e;
}
function v$(n, t, e, s, o, r, i6, a, l) {
  const c = n.length;
  let u = new Array(c), d = new Array(c), h = new Array(c);
  if (t.length && e > 0) {
    const p = t[0], f = e + 1;
    u = K0(i6, p, f, s, n), d = Z0(a, p, f, o, n), h = A0(r, p, f, n);
  } else
    for (let p = 0; p < c; p++)
      u[p] = H0(i6, s, r, n, p, l), d[p] = _0(a, o, r, n, p, l), h[p] = B0(r, p, l);
  return {
    begin: u,
    end: d,
    strides: h
  };
}
function K0(n, t, e, s, o) {
  const r = [...o], i6 = X0(e, t);
  for (let a = 0; a < r.length; a++)
    if (i6.indexOf(a) > -1)
      r[a] = 0;
    else {
      const l = O0(t, e, a);
      let c = s[l];
      n & 1 << l && (c = 0), r[a] = c;
    }
  return r;
}
function Z0(n, t, e, s, o) {
  const r = [...o], i6 = X0(e, t);
  for (let a = 0; a < r.length; a++)
    if (i6.indexOf(a) > -1)
      r[a] = Number.MAX_SAFE_INTEGER;
    else {
      const l = O0(t, e, a);
      let c = s[l];
      n & 1 << l && (c = Number.MAX_SAFE_INTEGER), r[a] = c;
    }
  for (let a = 0; a < r.length; a++) {
    const l = o[a];
    r[a] < 0 && (r[a] += l), r[a] = Os(0, r[a], o[a]);
  }
  return r;
}
function B0(n, t, e) {
  let s = n[t];
  return (e & 1 << t || s == null) && (s = 1), s;
}
function H0(n, t, e, s, o, r) {
  let i6 = t[o];
  const a = e[o] || 1;
  (n & 1 << o || r & 1 << o || i6 == null) && (a > 0 ? i6 = Number.MIN_SAFE_INTEGER : i6 = Number.MAX_SAFE_INTEGER);
  const l = s[o];
  return i6 < 0 && (i6 += l), i6 = Os(0, i6, l - 1), i6;
}
function _0(n, t, e, s, o, r) {
  let i6 = t[o];
  const a = e[o] || 1;
  (n & 1 << o || r & 1 << o || i6 == null) && (a > 0 ? i6 = Number.MAX_SAFE_INTEGER : i6 = Number.MIN_SAFE_INTEGER);
  const l = s[o];
  return i6 < 0 && (i6 += l), a > 0 ? i6 = Os(0, i6, l) : i6 = Os(-1, i6, l - 1), i6;
}
function Hp(n, t, e) {
  let s = e.length;
  for (let o = 0; o < e.length; o++)
    if (e[o] > 1) {
      s = o;
      break;
    }
  for (let o = s + 1; o < e.length; o++)
    if (t[o] > 0 || e[o] !== n[o])
      return false;
  return true;
}
function _p(n, t) {
  let e = n.length > 0 ? n[n.length - 1] : 1;
  for (let s = 0; s < n.length - 1; s++)
    e += n[s] * t[s];
  return e;
}
function nu(n, t, e) {
  let s;
  const o = n.shape.length;
  typeof t == "number" ? s = [t, ...new Array(o - 1).fill(0)] : t.length < o ? s = t.concat(new Array(o - t.length).fill(0)) : s = t.slice(), s.forEach((i6) => {
    C(i6 !== -1, () => "slice() does not support negative begin indexing.");
  });
  let r;
  return e == null ? r = new Array(o).fill(-1) : typeof e == "number" ? r = [e, ...new Array(o - 1).fill(-1)] : e.length < o ? r = e.concat(new Array(o - e.length).fill(-1)) : r = e, r = r.map((i6, a) => i6 >= 0 ? i6 : (C(i6 === -1, () => `Negative size values should be exactly -1 but got ${i6} for the slice() size at index ${a}.`), n.shape[a] - s[a])), [s, r];
}
function Up(n, t, e, s, o, r, i6, a, l) {
  let c;
  if (s == null ? (c = new Array(t.length), c.fill(1)) : c = s, i6 != null && i6 & i6 - 1)
    throw new Error("Multiple ellipses in slice is not allowed.");
  let u = false;
  const d = {
    dims: c.length,
    numAddAxisAfterEllipsis: 0,
    begin: t.slice(),
    end: e.slice(),
    strides: c.slice(),
    beginMask: o,
    endMask: r,
    ellipsisMask: i6,
    newAxisMask: a,
    shrinkAxisMask: l
  };
  for (let w = 0; w < d.dims; w++)
    u && 1 << w & a && d.numAddAxisAfterEllipsis++, 1 << w & i6 && (u = true);
  u || (d.ellipsisMask |= 1 << d.dims, d.dims++);
  const h = {
    dims: n.length,
    beginMask: 0,
    endMask: 0,
    beginValid: false,
    endValid: false
  };
  S$(d, h);
  let p = true, f = true, m = true;
  const g = [], b = [];
  for (let w = 0; w < n.length; ++w) {
    if (h.strides[w] === 0)
      throw Error(`strides[${w}] must be non-zero`);
    const y6 = !!(h.shrinkAxisMask & 1 << w), I = n[w];
    if (I === -1) {
      g.push(y6 ? 1 : -1);
      continue;
    }
    const v = [h.beginMask & 1 << w, h.endMask & 1 << w], k6 = [
      h.strides[w] > 0 ? 0 : -1,
      h.strides[w] > 0 ? I : I - 1
    ];
    if (y6 && h.strides[w] <= 0)
      throw Error("only stride 1 allowed on non-range indexing.");
    m = m && h.strides[w] === 1;
    const S = !!(h.beginMask & 1 << w && h.endMask & 1 << w);
    if (h.beginValid && h.endValid) {
      if (y6) {
        const V = h.begin[w] < 0 ? I + h.begin[w] : h.begin[w];
        if (h.begin[w] = V, h.end[w] = h.begin[w] + 1, V < 0 || V >= I)
          throw Error(`slice index ${h.begin[w]} of dimension ${w} out of bounds.`);
      } else
        h.begin[w] = Mm(h.begin[w], 0, h.strides[w], I, v, k6), h.end[w] = Mm(h.end[w], 1, h.strides[w], I, v, k6);
      const M6 = h.strides[w] === 1 && h.begin[w] === 0 && h.end[w] === I;
      p = p && M6, f = f && (w === 0 && h.strides[w] === 1 || M6);
    } else
      p = p && h.strides[w] === 1 && S, f = f && (w === 0 && h.strides[w] === 1 || S);
    let N, R = false;
    if (h.beginValid && h.endValid ? (N = h.end[w] - h.begin[w], R = true) : y6 ? (N = 1, R = true) : S && I >= 0 && (h.strides[w] < 0 ? N = -I : N = I, R = true), R) {
      let M6;
      N === 0 || N < 0 != h.strides[w] < 0 ? M6 = 0 : M6 = Math.trunc(N / h.strides[w]) + (N % h.strides[w] !== 0 ? 1 : 0), g.push(M6);
    } else
      g.push(-1);
  }
  for (let w = 0; w < h.finalShapeGatherIndices.length; ++w) {
    const y6 = h.finalShapeGatherIndices[w];
    y6 >= 0 ? b.push(g[y6]) : y6 === kd && b.push(1);
  }
  return {
    finalShapeSparse: b.filter((w, y6) => h.finalShapeGatherIndices[y6] !== kd),
    finalShape: b,
    isIdentity: p,
    sliceDim0: f,
    isSimpleSlice: m,
    begin: h.begin,
    end: h.end,
    strides: h.strides
  };
}
function S$(n, t) {
  t.beginMask = 0, t.endMask = 0, t.shrinkAxisMask = 0;
  let e = 0;
  t.beginValid = n.begin != null, t.endValid = n.end != null, t.begin = new Array(t.dims), t.end = new Array(t.dims), t.strides = new Array(t.dims), t.finalShapeGatherIndices = [], t.finalShapeGatherIndicesSparse = [], t.inputShapeGatherIndicesSparse = new Array(t.dims);
  for (let s = 0; s < n.dims; s++)
    if (1 << s & n.ellipsisMask) {
      const o = Math.min(t.dims - (n.dims - s) + 1 + n.numAddAxisAfterEllipsis, t.dims);
      for (; e < o; e++)
        t.begin[e] = 0, t.end[e] = 0, t.strides[e] = 1, t.beginMask |= 1 << e, t.endMask |= 1 << e, t.finalShapeGatherIndices.push(e), t.finalShapeGatherIndicesSparse.push(-1), t.inputShapeGatherIndicesSparse[e] = s;
    } else if (1 << s & n.newAxisMask)
      t.finalShapeGatherIndices.push(kd), t.finalShapeGatherIndicesSparse.push(-1);
    else {
      if (e === t.begin.length)
        throw Error(`Index out of range using input dim ${e}; input has only ${t.dims} dims, ${t.begin.length}.`);
      n.begin != null && (t.begin[e] = n.begin[s]), n.end != null && (t.end[e] = n.end[s]), t.strides[e] = n.strides[s], n.beginMask & 1 << s && (t.beginMask |= 1 << e), n.endMask & 1 << s && (t.endMask |= 1 << e), n.shrinkAxisMask & 1 << s ? (t.finalShapeGatherIndices.push(I$), t.finalShapeGatherIndicesSparse.push(-1), t.shrinkAxisMask |= 1 << e) : (t.finalShapeGatherIndices.push(e), t.finalShapeGatherIndicesSparse.push(s)), t.inputShapeGatherIndicesSparse[e] = s, e++;
    }
}
function Mm(n, t, e, s, o, r) {
  if (o[t])
    return e > 0 ? r[t] : r[t + 1 & 1];
  {
    const i6 = n < 0 ? s + n : n;
    return i6 < r[0] ? r[0] : i6 > r[1] ? r[1] : i6;
  }
}
var k$ = Object.freeze(Object.defineProperty({
  __proto__: null,
  assertParamsValid: Zp,
  computeFlatOffset: _p,
  computeOutShape: Bp,
  getNormalizedAxes: v$,
  isSliceContinous: Hp,
  maskToAxes: C$,
  parseSliceParams: nu,
  sliceInfo: Up,
  startForAxis: H0,
  startIndicesWithElidedDims: K0,
  stopForAxis: _0,
  stopIndicesWithElidedDims: Z0,
  stridesForAxis: B0,
  stridesWithElidedDims: A0
}, Symbol.toStringTag, { value: "Module" }));
var T$ = class {
  /**
   * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.
   *
   * ```js
   * // Fit a quadratic function by learning the coefficients a, b, c.
   * const xs = tf.tensor1d([0, 1, 2, 3]);
   * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);
   *
   * const a = tf.scalar(Math.random()).variable();
   * const b = tf.scalar(Math.random()).variable();
   * const c = tf.scalar(Math.random()).variable();
   *
   * // y = a * x^2 + b * x + c.
   * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);
   * const loss = (pred, label) => pred.sub(label).square().mean();
   *
   * const learningRate = 0.01;
   * const optimizer = tf.train.sgd(learningRate);
   *
   * // Train the model.
   * for (let i = 0; i < 10; i++) {
   *   optimizer.minimize(() => loss(f(xs), ys));
   * }
   *
   * // Make predictions.
   * console.log(
   *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);
   * const preds = f(xs).dataSync();
   * preds.forEach((pred, i) => {
   *   console.log(`x: ${i}, pred: ${pred}`);
   * });
   * ```
   *
   * @param learningRate The learning rate to use for the SGD algorithm.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static sgd(t) {
    return new Xp(t);
  }
  /**
   * Constructs a `tf.MomentumOptimizer` that uses momentum gradient
   * descent.
   *
   * See
   * [http://proceedings.mlr.press/v28/sutskever13.pdf](
   * http://proceedings.mlr.press/v28/sutskever13.pdf)
   *
   * @param learningRate The learning rate to use for the Momentum gradient
   * descent algorithm.
   * @param momentum The momentum to use for the momentum gradient descent
   * algorithm.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static momentum(t, e, s = false) {
    return new L0(t, e, s);
  }
  /**
   * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient
   * descent. This implementation uses plain momentum and is not centered
   * version of RMSProp.
   *
   * See
   * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](
   * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
   *
   * @param learningRate The learning rate to use for the RMSProp gradient
   * descent algorithm.
   * @param decay The discounting factor for the history/coming gradient.
   * @param momentum The momentum to use for the RMSProp gradient descent
   * algorithm.
   * @param epsilon Small value to avoid zero denominator.
   * @param centered If true, gradients are normalized by the estimated
   * variance of the gradient.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static rmsprop(t, e = 0.9, s = 0, o = null, r = false) {
    return new M0(t, e, s, o, r);
  }
  /**
   * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.
   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
   *
   * @param learningRate The learning rate to use for the Adam gradient
   * descent algorithm.
   * @param beta1 The exponential decay rate for the 1st moment estimates.
   * @param beta2 The exponential decay rate for the 2nd moment estimates.
   * @param epsilon A small constant for numerical stability.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adam(t = 1e-3, e = 0.9, s = 0.999, o = null) {
    return new G0(t, e, s, o);
  }
  /**
   * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.
   * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)
   *
   * @param learningRate The learning rate to use for the Adadelta gradient
   * descent algorithm.
   * @param rho The learning rate decay over each update.
   * @param epsilon A constant epsilon used to better condition the grad
   * update.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adadelta(t = 1e-3, e = 0.95, s = null) {
    return new R0(t, e, s);
  }
  /**
   * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.
   * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
   *
   * @param learningRate The learning rate to use for the Adamax gradient
   * descent algorithm.
   * @param beta1 The exponential decay rate for the 1st moment estimates.
   * @param beta2 The exponential decay rate for the 2nd moment estimates.
   * @param epsilon A small constant for numerical stability.
   * @param decay The learning rate decay over each update.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adamax(t = 2e-3, e = 0.9, s = 0.999, o = null, r = 0) {
    return new E0(t, e, s, o, r);
  }
  /**
   * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.
   * See
   * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](
   * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)
   * or
   * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](
   * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)
   *
   * @param learningRate The learning rate to use for the Adagrad gradient
   * descent algorithm.
   * @param initialAccumulatorValue Starting value for the accumulators, must be
   * positive.
   *
   * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
   */
  static adagrad(t, e = 0.1) {
    return new $0(t, e);
  }
};
var tr = T$;
var N$ = typeof requestAnimationFrame < "u" ? requestAnimationFrame : typeof setImmediate < "u" ? setImmediate : (n) => n();
function su() {
  return new Promise((n) => N$(() => n()));
}
function Yp(n, t) {
  const e = n[0].length;
  n.forEach((o, r) => {
    C(o.length === e, () => `Error in concat${e}D: rank of tensors[${r}] must be the same as the rank of the rest (${e})`);
  }), C(t >= 0 && t < e, () => `Error in concat${e}D: axis must be between 0 and ${e - 1}.`);
  const s = n[0];
  n.forEach((o, r) => {
    for (let i6 = 0; i6 < e; i6++)
      C(i6 === t || o[i6] === s[i6], () => `Error in concat${e}D: Shape of tensors[${r}] (${o}) does not match the shape of the rest (${s}) along the non-concatenated axis ${r}.`);
  });
}
function ts(n, t) {
  const e = n[0].slice();
  for (let s = 1; s < n.length; s++)
    e[t] += n[s][t];
  return e;
}
var Fn;
(function(n) {
  n[n.FIRST_DIM_SIZE = 0] = "FIRST_DIM_SIZE", n[n.VALUE_ROWIDS = 1] = "VALUE_ROWIDS", n[n.ROW_LENGTHS = 2] = "ROW_LENGTHS", n[n.ROW_SPLITS = 3] = "ROW_SPLITS", n[n.ROW_LIMITS = 4] = "ROW_LIMITS", n[n.ROW_STARTS = 5] = "ROW_STARTS";
})(Fn || (Fn = {}));
function U0(n, t, e) {
  let s = new Array();
  if (e == null && t == null)
    return s;
  if (t == null)
    for (; s.length < n + e.length; )
      s.push(-1);
  else
    s = t.slice();
  if (e == null)
    return s;
  if (n + e.length !== s.length)
    throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.rank = ${n + e.length}, but shape.rank = ${s.length}`);
  for (let o = 1; o < e.length; ++o) {
    const r = e[o], i6 = s[s.length - e.length + o], a = s[i6];
    if (r >= 0)
      if (a >= 0) {
        if (a !== r)
          throw new Error(`rt input.shape and shape=${t} are incompatible: rt input.shape[${o + n}] = ${r} but shape[${o + n}] = ${a}`);
      } else
        s[i6] = r;
  }
  return s;
}
function Y0(n) {
  const t = {
    FIRST_DIM_SIZE: Fn.FIRST_DIM_SIZE,
    VALUE_ROWIDS: Fn.VALUE_ROWIDS,
    ROW_LENGTHS: Fn.ROW_LENGTHS,
    ROW_SPLITS: Fn.ROW_SPLITS,
    ROW_LIMITS: Fn.ROW_LIMITS,
    ROW_STARTS: Fn.ROW_STARTS
  }, e = [];
  for (const s of n)
    if (s in t)
      e.push(t[s]);
    else
      break;
  return e;
}
function Q0(n) {
  return n.length === 0 ? 0 : n[0] === Fn.FIRST_DIM_SIZE ? n.length - 1 : n.length;
}
function J0(n, t) {
  if (n == null || t == null)
    return;
  const e = n.length, s = t.length;
  if (e >= s)
    throw new Error(`defaultValue.shape=${n} and ragged tensor flatValues.shape=${t}, are incompatible: defaultValue.rank = ${e} must be less than ragged tensor input flatValues.rank = ${s})`);
  for (let o = 0; o < Math.min(e, s - 1); ++o) {
    const r = n[o], i6 = t[o + 1];
    if (r >= 0 && i6 >= 0 && r !== 1 && r !== i6)
      throw new Error(`defaultValue.shape=${n}, and ragged tensor input flatValues.shape=${t} are incompatible: defaultValue.shape[${o - n.length}] = ${r} but ragged tensor input.flatValues.shape[${o - n.length}] = ${i6}`);
  }
}
var Qp = 30;
function ou(n) {
  return n <= Qp ? n : fl(n, Math.floor(Math.sqrt(n)));
}
function Jp(n, t, e) {
  const s = e * (typeof n == "number" ? n : n[0]), o = t * (typeof n == "number" ? n : n[1]);
  return [s, o];
}
function Na(n, t, e, s = true) {
  let o = [];
  if (s)
    o = o.concat(t.slice(0)), o.push(n[0] / e), o = o.concat(n.slice(1));
  else {
    o = o.concat(n[0]);
    const r = t.length;
    for (let i6 = 0; i6 < r; ++i6)
      o = o.concat([n[i6 + 1] / t[i6], t[i6]]);
    o = o.concat(n.slice(r + 1));
  }
  return o;
}
function Ra(n, t, e = true) {
  const s = [];
  if (e) {
    s.push(t);
    for (let o = t + 1; o < n; ++o)
      o <= 2 * t ? (s.push(o), s.push(o - (t + 1))) : s.push(o);
  } else {
    const o = [], r = [];
    for (let i6 = 1; i6 < n; ++i6)
      i6 >= t * 2 + 1 || i6 % 2 === 1 ? r.push(i6) : o.push(i6);
    s.push(...o), s.push(0), s.push(...r);
  }
  return s;
}
function $a(n, t, e, s = true) {
  const o = [];
  s ? o.push(n[0] / e) : o.push(n[0] * e);
  for (let r = 1; r < n.length; ++r)
    r <= t.length ? s ? o.push(t[r - 1] * n[r]) : o.push(n[r] / t[r - 1]) : o.push(n[r]);
  return o;
}
function jp(n, t) {
  const e = [0];
  for (let s = 0; s < t; ++s)
    e.push(n[s][0]);
  return e;
}
function qp(n, t, e) {
  const s = n.slice(0, 1);
  for (let o = 0; o < e; ++o)
    s.push(n[o + 1] - t[o][0] - t[o][1]);
  return s;
}
var ru = 1.7580993408473768;
var iu = 1.0507009873554805;
var tf = 0.3275911;
var ef = 0.254829592;
var nf = -0.284496736;
var sf = 1.421413741;
var of = -1.453152027;
var rf = 1.061405429;
function xs(n, t) {
  if (n.length !== t.length)
    throw new Error(`Cannot merge real and imag arrays of different lengths. real:${n.length}, imag: ${t.length}.`);
  const e = new Float32Array(n.length * 2);
  for (let s = 0; s < e.length; s += 2)
    e[s] = n[s / 2], e[s + 1] = t[s / 2];
  return e;
}
function j0(n) {
  const t = new Float32Array(n.length / 2), e = new Float32Array(n.length / 2);
  for (let s = 0; s < n.length; s += 2)
    t[s / 2] = n[s], e[s / 2] = n[s + 1];
  return { real: t, imag: e };
}
function q0(n) {
  const t = Math.ceil(n.length / 4), e = new Float32Array(t), s = new Float32Array(t);
  for (let o = 0; o < n.length; o += 4)
    e[Math.floor(o / 4)] = n[o], s[Math.floor(o / 4)] = n[o + 1];
  return { real: e, imag: s };
}
function tx(n) {
  const t = Math.floor(n.length / 4), e = new Float32Array(t), s = new Float32Array(t);
  for (let o = 2; o < n.length; o += 4)
    e[Math.floor(o / 4)] = n[o], s[Math.floor(o / 4)] = n[o + 1];
  return { real: e, imag: s };
}
function af(n, t) {
  const e = n[t * 2], s = n[t * 2 + 1];
  return { real: e, imag: s };
}
function ex(n, t, e, s) {
  n[s * 2] = t, n[s * 2 + 1] = e;
}
function nx(n, t) {
  const e = new Float32Array(n / 2), s = new Float32Array(n / 2);
  for (let o = 0; o < Math.ceil(n / 2); o++) {
    const r = (t ? 2 : -2) * Math.PI * (o / n);
    e[o] = Math.cos(r), s[o] = Math.sin(r);
  }
  return { real: e, imag: s };
}
function sx(n, t, e) {
  const s = (e ? 2 : -2) * Math.PI * (n / t), o = Math.cos(s), r = Math.sin(s);
  return { real: o, imag: r };
}
var Mu = "->";
var R$ = /->/g;
var Wm = ",";
var Dm = "...";
function lf(n, t) {
  n = n.replace(/\s/g, "");
  const e = (n.length - n.replace(R$, "").length) / Mu.length;
  if (e < 1)
    throw new Error("Equations without an arrow are not supported.");
  if (e > 1)
    throw new Error(`Equation must contain exactly one arrow ("${Mu}").`);
  const [s, o] = n.split(Mu);
  C(s.indexOf(Dm) === -1, () => `The ellipsis notation ("${Dm}") is not supported yet.`);
  const r = s.split(Wm), i6 = r.length;
  if (t !== i6)
    throw new Error(`Expected ${i6} input tensors, received ${t}`);
  if (i6 > 2)
    throw new Error("Support for more than 2 input tensors is not implemented yet.");
  const a = [];
  for (let h = 0; h < o.length; ++h) {
    const p = o[h];
    if (!r.some((f) => f.indexOf(p) !== -1))
      throw new Error(`Output subscripts contain the label ${p} not present in the input subscripts.`);
    a.indexOf(p) === -1 && a.push(p);
  }
  for (let h = 0; h < s.length; ++h) {
    const p = s[h];
    a.indexOf(p) === -1 && p !== Wm && a.push(p);
  }
  const l = new Array(r.length);
  for (let h = 0; h < i6; ++h) {
    if (new Set(r[h].split("")).size !== r[h].length)
      throw new Error(`Found duplicate axes in input component ${r[h]}. Support for duplicate axes in input is not implemented yet.`);
    l[h] = [];
    for (let p = 0; p < r[h].length; ++p)
      l[h].push(a.indexOf(r[h][p]));
  }
  const c = a.length, u = o.length, d = [];
  for (let h = u; h < c; ++h)
    d.push(h);
  return { allDims: a, summedDims: d, idDims: l };
}
function cf(n, t) {
  let e = new Array(n);
  e.fill(-1);
  for (let o = 0; o < t.length; ++o)
    e[t[o]] = o;
  const s = [];
  for (let o = 0; o < n; ++o)
    e[o] === -1 && s.push(o);
  return e = e.filter((o) => o !== -1), { permutationIndices: e, expandDims: s };
}
function uf(n, t, e) {
  const s = new Array(n);
  for (let o = 0; o < e.length; ++o) {
    const r = e[o].shape;
    for (let i6 = 0; i6 < t[o].length; ++i6)
      s[t[o][i6]] === void 0 ? s[t[o][i6]] = r[i6] : C(s[t[o][i6]] === r[i6], () => `Expected dimension ${s[t[o][i6]]} at axis ${i6} of input shaped ${JSON.stringify(r)}, but got dimension ${r[i6]}`);
  }
}
function df(n, t) {
  const e = n, s = [];
  let o = 0;
  n.length === 0 && e.push(-1), o = n.length + 1;
  for (let i6 = 0; i6 < o; ++i6)
    s.push([]);
  const r = [];
  for (let i6 = 0; i6 < e.length; ++i6) {
    const a = e[i6], l = $$(t, a);
    for (const c of l)
      r.indexOf(c) === -1 && (s[i6].push(c), r.push(c));
  }
  return { path: e, steps: s };
}
function hf(n) {
  return n.every((t, e) => t === e);
}
function $$(n, t) {
  const e = [];
  for (let s = 0; s < n.length; ++s)
    (n[s].length === 0 || n[s].indexOf(t) !== -1 || t === -1) && e.push(s);
  return e;
}
function pf(n, t, e = 0) {
  let s = [];
  if (typeof t == "number")
    C(n.shape[e] % t === 0, () => "Number of splits must evenly divide the axis."), s = new Array(t).fill(n.shape[e] / t);
  else {
    const o = t.reduce((i6, a) => (a === -1 && (i6 += 1), i6), 0);
    C(o <= 1, () => "There should be only one negative value in split array.");
    const r = t.indexOf(-1);
    if (r !== -1) {
      const i6 = t.reduce((a, l) => l > 0 ? a + l : a);
      t[r] = n.shape[e] - i6;
    }
    C(n.shape[e] === t.reduce((i6, a) => i6 + a), () => "The sum of sizes must match the size of the axis dimension."), s = t;
  }
  return s;
}
function ox(n) {
  return `Received SparseTensor with denseShape[0] = 0 but
  indices.shape[0] = ${n}`;
}
function rx(n, t) {
  return `indices(${n}, 0) is invalid: ${t} < 0`;
}
function ix(n, t, e) {
  return `indices(${n}, 0) is invalid: ${t} >= ${e}`;
}
function ax(n, t) {
  return `only one output dimension may be -1, not both ${n} and ${t}`;
}
function lx(n, t) {
  return `size ${n} must be non-negative, not ${t}`;
}
function cx() {
  return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
}
function ux(n, t) {
  const e = X(n), s = X(t);
  return `Input to reshape is a SparseTensor with ${e}
  dense values, but the requested shape requires a multiple of ${s}. inputShape=${n} outputShape= ${t}`;
}
function dx(n, t) {
  const e = X(n), s = X(t);
  return `Input to reshape is a tensor with ${e} dense values, but the requested shape has ${s}. inputShape=${n} outputShape=${t}`;
}
function Td() {
  return "segment ids must be >= 0";
}
function hx() {
  return "segment ids are not increasing";
}
function px(n, t) {
  return `Segment id ${n} out of range [0, ${t}), possibly because segmentIds input is not sorted.`;
}
function fx(n, t, e) {
  return `Bad: indices[${n}] == ${t} out of range [0, ${e})`;
}
function mx(n, t) {
  let e = false, s;
  for (n <= Qp ? (s = n, e = true) : s = fl(n, Math.floor(Math.sqrt(n))); !e; )
    s > t || s === n ? e = true : s = fl(n, s + 1);
  return s;
}
function gx(n, t, e) {
  const s = [], o = n.length;
  for (let r = 0; r < o; r++)
    r !== t ? s.push(n[r]) : s.push(e);
  return s;
}
function ff(n, t, e, s) {
  const o = t.shape.length, r = n.shape.length;
  if (s !== 0 && (s < -o || s > o))
    throw new Error(`Expect batchDims in the range of [-${o}, ${o}], but got ${s}`);
  if (s < 0 && (s += o), s > r)
    throw new Error(`batchDims (${s}) must be less than rank(x) (
    ${r}).`);
  if (e < s)
    throw new Error(`batchDims (${s}) must be less than or equal to axis (${e}).`);
  for (let d = 0; d < s; ++d)
    if (n.shape[d] !== t.shape[d])
      throw new Error(`x.shape[${d}]: ${n.shape[d]} should be equal to indices.shape[${d}]: ${t.shape[d]}.`);
  const i6 = n.shape[e], a = [];
  let l = 1, c = 1, u = 1;
  for (let d = 0; d < s; ++d)
    a.push(n.shape[d]), l *= n.shape[d];
  for (let d = s; d < e; d++)
    a.push(n.shape[d]), c *= n.shape[d];
  for (let d = s; d < o; d++)
    a.push(t.shape[d]);
  for (let d = e + 1; d < r; d++)
    a.push(n.shape[d]), u *= n.shape[d];
  return { batchSize: l, sliceSize: u, outerSize: c, dimSize: i6, outputShape: a };
}
var G$ = Object.freeze(Object.defineProperty({
  __proto__: null,
  collectGatherOpShapeInfo: ff,
  computeOutShape: gx,
  segOpComputeOptimalWindowSize: mx
}, Symbol.toStringTag, { value: "Module" }));
function ys(n) {
  try {
    return n.map((t) => gs(t));
  } catch (t) {
    throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${t}`);
  }
}
function bx(n) {
  return n.map((t) => ms(t));
}
var E$ = Object.freeze(Object.defineProperty({
  __proto__: null,
  ERF_A1: ef,
  ERF_A2: nf,
  ERF_A3: sf,
  ERF_A4: of,
  ERF_A5: rf,
  ERF_P: tf,
  PARALLELIZE_THRESHOLD: Qp,
  get RowPartitionType() {
    return Fn;
  },
  SELU_SCALE: iu,
  SELU_SCALEALPHA: ru,
  applyActivation: Fp,
  assertAndGetBroadcastShape: bt,
  assertAxesAreInnerMostDims: Ne,
  assertParamsConsistent: Yp,
  assignToTypedArray: ex,
  axesAreInnerMostDims: lp,
  calculateShapes: to,
  checkEinsumDimSizes: uf,
  checkPadOnDimRoundingMode: Ue,
  combineLocations: n0,
  combineRaggedTensorToTensorShapes: U0,
  complexWithEvenIndex: q0,
  complexWithOddIndex: tx,
  computeConv2DInfo: Te,
  computeConv3DInfo: Js,
  computeDefaultPad: ep,
  computeDilation2DInfo: Ia,
  computeOptimalWindowSize: ou,
  computeOutAndReduceShapes: ye,
  computeOutShape: ts,
  computePool2DInfo: $n,
  computePool3DInfo: vs,
  convertConv2DDataFormat: Ss,
  decodeEinsumEquation: lf,
  eitherStridesOrDilationsAreOne: Le,
  expandShapeToKeepDim: re,
  exponent: sx,
  exponents: nx,
  fromStringArrayToUint8: bx,
  fromUint8ToStringArray: ys,
  getAxesPermutation: qt,
  getBroadcastDims: Go,
  getComplexWithIndex: af,
  getEinsumComputePath: df,
  getEinsumPermutation: cf,
  getFusedBiasGradient: Dp,
  getFusedDyActivation: Wp,
  getImageCenter: Jp,
  getInnerMostAxes: ie,
  getPermuted: Ra,
  getRaggedRank: Q0,
  getReductionAxes: ce,
  getReshaped: Na,
  getReshapedPermuted: $a,
  getRowPartitionTypesHelper: Y0,
  getSliceBeginCoords: jp,
  getSliceSize: qp,
  getSparseFillEmptyRowsIndicesDenseShapeMismatch: ox,
  getSparseFillEmptyRowsNegativeIndexErrorMessage: rx,
  getSparseFillEmptyRowsOutOfRangeIndexErrorMessage: ix,
  getSparseReshapeEmptyTensorZeroOutputDimErrorMessage: cx,
  getSparseReshapeInputOutputMismatchErrorMessage: dx,
  getSparseReshapeInputOutputMultipleErrorMessage: ux,
  getSparseReshapeMultipleNegativeOneOutputDimErrorMessage: ax,
  getSparseReshapeNegativeOutputDimErrorMessage: lx,
  getSparseSegmentReductionIndicesOutOfRangeErrorMessage: fx,
  getSparseSegmentReductionNegativeSegmentIdsErrorMessage: Td,
  getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage: hx,
  getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage: px,
  getUndoAxesPermutation: js,
  isIdentityPermutation: hf,
  log: qC,
  mergeRealAndImagArrays: xs,
  prepareAndValidate: eu,
  prepareSplitSize: pf,
  segment_util: G$,
  shouldFuse: Vp,
  slice_util: k$,
  splitRealAndImagArrays: j0,
  stridesOrDilationsArePositive: Ro,
  tupleValuesAreOne: No,
  upcastType: tn,
  validateDefaultValueShape: J0,
  validateInput: y0,
  validateUpdateShape: Lp,
  warn: ln
}, Symbol.toStringTag, { value: "Module" }));
r$();
var xx = {
  kernelName: Ul,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, Ta(tt(e, "float32"), -1)) };
  }
};
var L$ = {
  kernelName: vi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = Kt(tt(e, "float32")), o = Ve(it(gt(1), s));
        return Yt(ut(n, o));
      }
    };
  }
};
var M$ = {
  kernelName: Si,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = Ve(it(Kt(tt(e, "float32")), 1));
        return ut(n, s);
      }
    };
  }
};
var W$ = {
  kernelName: Sr,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      let a = n;
      const l = ce(e.shape, o);
      return l.length > 0 && (a = at(a, l)), W(a, e.shape);
    }, b: () => {
      let a = n;
      const l = ce(s.shape, o);
      return l.length > 0 && (a = at(a, l)), W(a, s.shape);
    } };
  }
};
var D$ = {
  kernelName: qd,
  saveAllInputs: true,
  gradFunc: (n, t) => {
    const e = {};
    return t.forEach((s, o) => {
      e[o] = () => n.clone();
    }), e;
  }
};
var F$ = {
  kernelName: Yl,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => Tt(e) };
  }
};
var V$ = {
  kernelName: Ql,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => Tt(e) };
  }
};
var z$ = {
  kernelName: ki,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, Ve(it(gt(1), Kt(tt(e, "float32"))))) };
  }
};
var P$ = {
  kernelName: Ti,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = Ve(U(gt(1), Kt(tt(e, "float32"))));
        return ut(n, s);
      }
    };
  }
};
var A$ = {
  kernelName: $i,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = U(Kt(e), Kt(s));
      let l = G(n, ut(s, a));
      const c = ce(e.shape, o);
      return c.length > 0 && (l = at(l, c)), W(l, e.shape);
    }, b: () => {
      const a = U(Kt(e), Kt(s));
      let l = Yt(G(n, ut(e, a)));
      const c = ce(s.shape, o);
      return c.length > 0 && (l = at(l, c)), W(l, s.shape);
    } };
  }
};
var O$ = {
  kernelName: Ni,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, U(Kt(tt(e, "float32")), 1)) };
  }
};
var X$ = {
  kernelName: Ri,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, it(gt(1), Kt(tt(e, "float32")))) };
  }
};
function K$(n, t, e, s, o, r) {
  const i6 = T(n, "dy", "avgPool3dGrad"), a = T(t, "input", "avgPool3dGrad");
  let l = i6, c = a, u = false;
  a.rank === 4 && (u = true, l = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2], i6.shape[3]]), c = W(a, [
    1,
    a.shape[0],
    a.shape[1],
    a.shape[2],
    a.shape[3]
  ])), C(l.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`), C(c.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ${c.rank}.`), Ue("avgPool3dGrad", o, r);
  const d = { dy: l, input: c }, h = { filterSize: e, strides: s, pad: o, dimRoundingMode: r }, p = $.runKernel(sh, d, h);
  return u ? W(p, [p.shape[1], p.shape[2], p.shape[3], p.shape[4]]) : p;
}
var Z$ = L({ avgPool3dGrad_: K$ });
var B$ = {
  kernelName: jl,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { filterSize: o, strides: r, pad: i6, dimRoundingMode: a } = e;
    return {
      x: () => Z$(n, s, o, r, i6, a)
    };
  }
};
function H$(n, t, e, s, o) {
  const r = T(n, "dy", "avgPoolGrad"), i6 = T(t, "input", "avgPoolGrad");
  C(i6.rank === r.rank, () => `Rank of input (${i6.rank}) does not match rank of dy (${r.rank})`);
  let a = i6, l = r, c = false;
  i6.rank === 3 && (c = true, a = W(i6, [1, i6.shape[0], i6.shape[1], i6.shape[2]]), l = W(r, [1, r.shape[0], r.shape[1], r.shape[2]])), C(l.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`), C(a.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ${a.rank}.`);
  const u = { dy: l, input: a }, d = { filterSize: e, strides: s, pad: o }, h = $.runKernel(nh, u, d);
  return c ? W(h, [h.shape[1], h.shape[2], h.shape[3]]) : h;
}
var _$ = L({ avgPoolGrad_: H$ });
var U$ = {
  kernelName: Jl,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { filterSize: o, strides: r, pad: i6 } = e;
    return { x: () => _$(n, s, o, r, i6) };
  }
};
var Y$ = {
  kernelName: ql,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { transposeA: r, transposeB: i6 } = e;
    return !r && !i6 ? {
      a: () => Gt(n, o, false, true),
      b: () => Gt(s, n, true, false)
    } : !r && i6 ? {
      a: () => Gt(n, o, false, false),
      b: () => Gt(n, s, true, false)
    } : r && !i6 ? {
      a: () => Gt(o, n, false, true),
      b: () => Gt(s, n, false, false)
    } : {
      a: () => Gt(o, n, true, true),
      b: () => Gt(n, s, true, true)
    };
  }
};
var Q$ = {
  kernelName: tc,
  gradFunc: (n, t, e) => {
    const { blockShape: s, crops: o } = e;
    return { x: () => xp(n, s, o) };
  }
};
var J$ = {
  kernelName: JC,
  gradFunc: (n, t, e) => {
    const s = e, o = s.inputShape, r = s.shape, i6 = Array.from(r);
    for (let l = o.length - 1; l >= 0; l--)
      if (o[l] === r[l])
        i6[l] = 1;
      else if (o[l] !== 1)
        throw new Error(`broadcastTo(): [${o}] cannot be broadcast to [${r}].`);
    const a = [];
    for (let l = 0; l < i6.length; l++)
      i6[l] > 1 && a.push(l);
    return { x: () => at(
      n,
      a,
      true
      /* keepDims */
    ) };
  }
};
var j$ = {
  kernelName: Gi,
  gradFunc: (n) => ({ x: () => n.clone() })
};
var q$ = {
  kernelName: Ei,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var tG = {
  kernelName: Li,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { clipValueMin: o, clipValueMax: r } = e;
    return {
      x: () => Ee(ss(Bo(s, o), Tr(s, r)), n, Tt(n))
    };
  }
};
var eG = {
  kernelName: ec,
  inputsToSave: ["x"],
  gradFunc: xx.gradFunc
};
var nG = {
  kernelName: nc,
  saveAllInputs: true,
  gradFunc: (n, t, e) => {
    const s = t.map((l) => l.shape), { axis: o } = e, r = Ct(o, t[0].shape)[0], i6 = s.map((l) => l[r]);
    return pn(n, i6, r).map((l) => () => l);
  }
};
var sG = {
  kernelName: sc,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { dilations: r, strides: i6, pad: a, dataFormat: l } = e;
    return C(No(r), () => `Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`), {
      x: () => rp(s.shape, n, o, i6, a, l),
      filter: () => Mp(s, n, o.shape, i6, a, l)
    };
  }
};
var oG = {
  kernelName: oc,
  inputsToSave: ["dy", "filter"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { strides: r, pad: i6, dataFormat: a, dimRoundingMode: l } = e;
    return {
      dy: () => $o(n, o, r, i6, a, 1, l),
      filter: () => Mp(n, s, o.shape, r, i6, a, l)
    };
  }
};
function rG(n, t, e, s, o) {
  let r = n;
  n.rank === 4 && (r = W(n, [1, n.shape[0], n.shape[1], n.shape[2], n.shape[3]]));
  let i6 = t;
  i6.rank === 4 && (i6 = W(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]])), C(r.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ${r.shape}.`), C(i6.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ${i6.shape}.`), C(e.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ${e}.`), C(r.shape[4] === e[3], () => `Error in conv3dDerFilter: depth of input ${r.shape[4]}) must match input depth in filter (${e[3]}.`), C(i6.shape[4] === e[4], () => `Error in conv3dDerFilter: depth of dy (${i6.shape[4]}) must match output depth for filter (${e[4]}).`);
  const a = { x: r, dy: i6 }, l = { strides: s, pad: o, filterShape: e };
  return $.runKernel(lh, a, l);
}
var iG = L({ conv3DBackpropFilter_: rG });
var aG = {
  kernelName: rc,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const { dilations: s, strides: o, pad: r } = e;
    C(No(s), () => `Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`);
    const [i6, a] = t;
    return {
      x: () => qb(i6.shape, n, a, o, r),
      filter: () => iG(i6, n, a.shape, o, r)
    };
  }
};
var lG = {
  kernelName: Mi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(Yt(f0(tt(e, "float32"))), n) };
  }
};
var cG = {
  kernelName: Wi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(m0(tt(e, "float32")), n) };
  }
};
var uG = {
  kernelName: ic,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o, exclusive: r, reverse: i6 } = e;
    return {
      x: () => {
        const a = qt([o], s.rank);
        let l = e0(n, o, r, !i6);
        return a != null && (l = kt(l, a)), l;
      }
    };
  }
};
var dG = {
  kernelName: ac,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const { dilations: s, strides: o, pad: r, dimRoundingMode: i6 } = e, a = s ?? [1, 1];
    C(No(a), () => `Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${a}'`);
    const [l, c] = t;
    return C(l.rank === 4, () => `Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`), C(c.rank === 4, () => `Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${c.rank}.`), C(l.shape[3] === c.shape[2], () => `Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${c.shape[2]}.`), C(Le(o, a), () => `Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${o} and dilations '${a}'.`), Ue("depthwiseConv2d", r, i6), {
      x: () => kN(l.shape, n, c, o, r, a, i6),
      filter: () => vN(l, n, c.shape, o, r, a, i6)
    };
  }
};
var hG = {
  kernelName: lc,
  inputsToSave: ["x", "filter"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, r = { x: s, filter: o, dy: n }, i6 = { x: s, filter: o, dy: n };
    return {
      x: () => $.runKernel(ad, r, e),
      filter: () => $.runKernel(ld, i6, e)
    };
  }
};
var pG = {
  kernelName: Fi,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t, s = { dy: n, y: e };
    return { x: () => $.runKernel(xh, s) };
  }
};
var fG = {
  kernelName: Vi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t, s = G(mn(Yt(Kt(e))), 2 / Math.sqrt(Math.PI));
    return { x: () => G(n, s) };
  }
};
var mG = {
  kernelName: zi,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, e) };
  }
};
var gG = {
  kernelName: uc,
  inputsToSave: ["input"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { input: () => W(n, e.shape) };
  }
};
var bG = {
  kernelName: Pi,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, mn(e)) };
  }
};
var xG = {
  kernelName: Ai,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var yG = {
  kernelName: Oi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = ut(n, tt(s, "float32")), l = ce(e.shape, o);
      return l.length > 0 ? W(at(a, l), e.shape) : a;
    }, b: () => {
      let a = G(n, tt(e, "float32"));
      const l = ce(s.shape, o);
      l.length > 0 && (a = W(at(a, l), s.shape));
      const c = Kt(s);
      return Yt(ut(a, tt(c, "float32")));
    } };
  }
};
var wG = {
  kernelName: dc,
  inputsToSave: ["x", "mean", "variance", "scale"],
  gradFunc: (n, t, e) => {
    const { varianceEpsilon: s } = e, [o, r, i6, a] = t, l = a ?? gt(1), c = ce(r.shape, o.shape), u = [];
    if (r.rank === 1) {
      for (let y6 = 0; y6 < o.shape.length - 1; ++y6)
        u.push(o.shape[y6]);
      u.push(1);
    }
    const d = it(o, r), h = G(n, l), p = d0(U(i6, gt(s))), f = G(G(G(p, p), p), gt(-0.5));
    return {
      x: () => r.rank === 1 ? W(G(G(n, Vn(W(p, [1, 1, 1, r.shape[0]]), u)), l), o.shape) : W(G(G(n, p), l), o.shape),
      mean: () => {
        let y6 = G(G(p, gt(-1)), h);
        return r.rank === 1 && (y6 = at(y6, c)), W(y6, r.shape);
      },
      variance: () => {
        let y6 = G(G(f, d), h);
        return r.rank === 1 && (y6 = at(y6, c)), W(y6, r.shape);
      },
      scale: () => {
        const y6 = G(d, p);
        let I = G(n, y6);
        return r.rank === 1 && (I = at(I, c)), W(I, r.shape);
      },
      offset: () => {
        let y6 = n;
        return r.rank === 1 && (y6 = at(y6, c)), W(y6, r.shape);
      }
    };
  }
};
var IG = {
  kernelName: hc,
  inputsToSave: ["x", "indices"],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { axis: r, batchDims: i6 } = e, a = Ct(r, s.shape)[0], l = (c, u, d) => () => {
      const h = c.shape, p = u.size, f = h.slice(0, a), m = f.length, g = h.slice(r, h.length).slice(1), b = g.length, x6 = Fm(0, m), w = Fm(m + 1, m + 1 + b), y6 = Vm([
        f,
        [p],
        g
      ]), I = W(d, y6), v = W(u, [p]), k6 = Vm([[m], x6, w]), S = kt(I, k6);
      let N = I0(S, v, c.shape[a]);
      const R = js(k6);
      return N = kt(N, R), N;
    };
    if (i6 === 1) {
      const c = s.shape[0], u = s.split(c, 0);
      return { x: () => Xn(u.map((p, f) => l(p, o.slice(f, 1), n.slice(f, 1))())).reshape(s.shape), indices: () => o };
    } else
      return { x: l(s, o, n), indices: () => o };
  }
};
function Fm(n, t) {
  const e = [];
  for (let s = n; s < t; ++s)
    e.push(s);
  return e;
}
function Vm(n) {
  const t = [];
  for (let e = 0; e < n.length; ++e)
    for (let s = 0; s < n[e].length; ++s)
      t.push(n[e][s]);
  return t;
}
var CG = {
  kernelName: Xi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t;
    return { a: () => Tt(e), b: () => Tt(s) };
  }
};
var vG = {
  kernelName: Ki,
  gradFunc: (n) => ({ x: () => tt(n, "float32") })
};
var SG = {
  kernelName: Zi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var kG = {
  kernelName: Bi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var TG = {
  kernelName: Hi,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var NG = {
  kernelName: fc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { alpha: o } = e, r = rn(s, 0);
    return { x: () => Ee(r, n, G(n, o)) };
  }
};
var RG = {
  kernelName: Ui,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, U(e, 1)) };
  }
};
var $G = {
  kernelName: _i,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, tt(e, "float32")) };
  }
};
var GG = {
  kernelName: jC,
  inputsToSave: [],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o } = e;
    return {
      logits: () => {
        const i6 = mn(s);
        return it(n, G(at(n, o, true), i6));
      }
    };
  }
};
function EG(n, t, e, s = 5, o = 1, r = 1, i6 = 0.5) {
  const a = { x: n, y: t, dy: e }, l = { depthRadius: s, bias: o, alpha: r, beta: i6 };
  return $.runKernel(Sh, a, l);
}
var LG = L({ localResponseNormalizationBackprop_: EG });
var MG = {
  kernelName: wc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { depthRadius: r, bias: i6, alpha: a, beta: l } = e;
    return {
      x: () => LG(s, o, n, r, i6, a, l)
    };
  }
};
function yx(n, t, e, s) {
  return t.rank < e.rank && (t = W(t, re(t.shape, s))), n.rank < e.rank && (n = W(n, re(n.shape, s))), {
    x: () => G(n, tt(Tn(e, t), n.dtype))
  };
}
var zm = {
  kernelName: Ic,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const s = e, { reductionIndices: o } = s, r = t[0], i6 = t[1], a = Ct(o, r.shape), l = yx(n, i6, r, a);
    return {
      x: () => l.x()
    };
  }
};
var WG = {
  kernelName: Yi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t;
    return { a: () => G(n, tt(Bo(e, s), "float32")), b: () => G(n, tt(Cl(e, s), "float32")) };
  }
};
function DG(n, t, e, s, o, r, i6) {
  const a = T(n, "dy", "maxPool3dGrad"), l = T(t, "input", "maxPool3dGrad"), c = T(e, "output", "maxPool3dGrad");
  let u = a, d = l, h = c, p = false;
  l.rank === 4 && (p = true, u = W(a, [1, a.shape[0], a.shape[1], a.shape[2], a.shape[3]]), d = W(l, [
    1,
    l.shape[0],
    l.shape[1],
    l.shape[2],
    l.shape[3]
  ]), h = W(c, [
    1,
    c.shape[0],
    c.shape[1],
    c.shape[2],
    c.shape[3]
  ])), C(u.rank === 5, () => `Error in maxPool3dGrad: dy must be rank 5 but got rank ${u.rank}.`), C(d.rank === 5, () => `Error in maxPool3dGrad: input must be rank 5 but got rank ${d.rank}.`), C(h.rank === 5, () => `Error in maxPool3dGrad: output must be rank 5 but got rank ${h.rank}.`), Ue("maxPool3dGrad", r, i6);
  const f = { dy: u, input: d, output: h }, m = { filterSize: s, strides: o, pad: r, dimRoundingMode: i6 }, g = $.runKernel(Th, f, m);
  return p ? W(g, [g.shape[1], g.shape[2], g.shape[3], g.shape[4]]) : g;
}
var FG = L({ maxPool3dGrad_: DG });
var VG = {
  kernelName: vc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = e;
    return {
      x: () => FG(n, s, o, r, i6, a, l)
    };
  }
};
function zG(n, t, e, s, o, r, i6) {
  const a = T(n, "dy", "maxPoolGrad"), l = T(t, "input", "maxPoolGrad"), c = T(e, "output", "maxPoolGrad");
  C(l.rank === a.rank, () => `Rank of input (${l.rank}) does not match rank of dy (${a.rank})`), C(a.rank === 4, () => `Error in maxPoolGrad: dy must be rank 4 but got rank ${a.rank}.`), C(l.rank === 4, () => `Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`), Ue("maxPoolGrad", r, i6);
  const u = { dy: a, input: l, output: c }, d = { filterSize: s, strides: o, pad: r, dimRoundingMode: i6 };
  return $.runKernel(kh, u, d);
}
var PG = L({ maxPoolGrad_: zG });
var AG = {
  kernelName: Cc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s, o] = t, { filterSize: r, strides: i6, pad: a } = e;
    return {
      x: () => PG(n, s, o, r, i6, a)
    };
  }
};
var OG = {
  kernelName: Sc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o } = e, r = Ct(o, s.shape), a = ye(s.shape, r)[1], l = X(a);
    return { x: () => {
      const u = s.shape.slice();
      r.forEach((p) => {
        u[p] = 1;
      });
      const d = W(n, u);
      return ut(G(d, ks(s.shape, "float32")), l);
    } };
  }
};
var XG = {
  kernelName: kc,
  inputsToSave: ["x"],
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const s = e, { axis: o } = s, [r, i6] = t, a = Ct(o, r.shape), l = yx(n, i6, r, a);
    return {
      x: () => l.x()
    };
  }
};
var KG = {
  kernelName: Qi,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t;
    return { a: () => G(n, tt(Tr(e, s), "float32")), b: () => G(n, tt(rn(e, s), "float32")) };
  }
};
var ZG = {
  kernelName: Tc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const s = t[0], { paddings: o } = e, r = o.map((i6) => i6[0]);
    return { x: () => Ft(n, r, s.shape) };
  }
};
var BG = {
  kernelName: Ji,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = ce(e.shape, o);
      return a.length > 0 ? W(at(n, a), e.shape) : n;
    }, b: () => {
      const a = G(n, Yt(qc(ut(e, s)))), l = ce(s.shape, o);
      return l.length > 0 ? W(at(a, l), s.shape) : a;
    } };
  }
};
var HG = {
  kernelName: ji,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = G(n, tt(s, "float32")), l = ce(e.shape, o);
      return l.length > 0 ? W(at(a, l), e.shape) : a;
    }, b: () => {
      const a = G(n, tt(e, "float32")), l = ce(s.shape, o);
      return l.length > 0 ? W(at(a, l), s.shape) : a;
    } };
  }
};
var _G = {
  kernelName: Nc,
  gradFunc: (n) => ({ x: () => Yt(n) })
};
var UG = {
  kernelName: Gc,
  inputsToSave: ["indices"],
  gradFunc: (n, t) => {
    const e = t[0];
    return { indices: () => be(e.shape, "float32") };
  }
};
var YG = {
  kernelName: $c,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var QG = {
  kernelName: Ec,
  saveAllInputs: true,
  gradFunc: (n, t, e) => {
    const { axis: s } = e;
    return Mo(n, s).map((r) => () => r);
  }
};
var Pm = {
  kernelName: Lc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const s = t[0], { paddings: o } = e, r = o.map((i6) => i6[0]);
    return { x: () => Ft(n, r, s.shape) };
  }
};
var JG = {
  kernelName: qi,
  inputsToSave: ["a", "b"],
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e, s, o] = t, r = e, i6 = s, a = bt(r.shape, i6.shape);
    return { a: () => {
      const u = tt(i6, "float32");
      let d = G(n, G(u, gr(r, it(u, gt(1)))));
      const h = ce(r.shape, a);
      return h.length > 0 && (d = at(d, h)), W(d, r.shape);
    }, b: () => {
      const u = rn(r, 0), d = Ee(u, Nn(r), Tt(r));
      let h = G(n, G(o, d));
      const p = ce(i6.shape, a);
      return p.length > 0 && (h = at(h, p)), W(h, i6.shape);
    } };
  }
};
var jG = {
  kernelName: Mc,
  inputsToSave: ["x", "alpha"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = rn(e, 0);
    return {
      x: () => Ee(o, n, G(n, s)),
      alpha: () => {
        let r = Ee(o, Tt(n), G(n, e));
        const i6 = ce(s.shape, n.shape);
        return i6.length > 0 && (r = at(r, i6)), W(r, s.shape);
      }
    };
  }
};
function qG(n, t, e) {
  const s = n.shape.slice();
  s[e] = 1;
  const o = W(t, s), r = vd(n, e, true, false), i6 = vd(n, e, true, true), a = G(r, i6);
  return G(o, a);
}
function tE(n, t, e) {
  const s = n.shape.length, o = s - e.length, r = qt(e, s);
  let i6 = n;
  r != null && (i6 = kt(n, r));
  const a = i6.shape.slice(), c = a.splice(s - e.length, e.length).reduce((h, p) => h * p, 1);
  a.push(c);
  const u = i6.reshape(a);
  let d = qG(u, t, o);
  if (d = d.reshape(i6.shape), r != null) {
    const h = js(r);
    d = kt(d, h);
  }
  return d;
}
var eE = {
  kernelName: Wc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { axis: o } = e;
    let r = [];
    return o == null ? r = s.shape.map((i6, a) => a) : typeof o == "number" ? r = [o] : r = o, { x: () => tE(s, n, r) };
  }
};
var nE = {
  kernelName: Di,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      const a = ut(n, tt(s, "float32")), l = ce(e.shape, o);
      return l.length > 0 ? W(at(a, l), e.shape) : a;
    }, b: () => {
      let a = G(n, tt(e, "float32"));
      const l = ce(s.shape, o);
      l.length > 0 && (a = W(at(a, l), s.shape));
      const c = Kt(s);
      return Yt(ut(a, tt(c, "float32")));
    } };
  }
};
var sE = {
  kernelName: ta,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, Yt(Kt(e))) };
  }
};
var oE = {
  kernelName: na,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t, s = G(Tr(e, 6), Ta(e));
    return { x: () => G(n, tt(s, "float32")) };
  }
};
var rE = {
  kernelName: ea,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, tt(Ta(e), "float32")) };
  }
};
var iE = {
  kernelName: Dc,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => W(n, e.shape) };
  }
};
var aE = {
  kernelName: Vc,
  inputsToSave: ["images"],
  gradFunc: (n, t, e) => {
    const [s] = t, o = { dy: n, images: s };
    return { images: () => (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(Mh, o, e)
    ) };
  }
};
var lE = {
  kernelName: Fc,
  inputsToSave: ["images"],
  gradFunc: (n, t, e) => {
    const [s] = t, o = { dy: n, images: s };
    return { images: () => (
      // tslint:disable-next-line: no-unnecessary-type-assertion
      $.runKernel(Lh, o, e)
    ) };
  }
};
var cE = {
  kernelName: zc,
  gradFunc: (n, t, e) => {
    const { dims: s } = e, o = Ct(s, n.shape);
    return { x: () => Lo(n, o) };
  }
};
var uE = {
  kernelName: sa,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var dE = {
  kernelName: oa,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => Yt(ut(n, G(gr(e, 1.5), 2))) };
  }
};
var hE = {
  kernelName: Pc,
  inputsToSave: ["condition"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      // TODO(julianoks): Return null for condition gradient
      // when backprop supports it.
      condition: () => tt(Tt(e), "float32"),
      t: () => G(n, tt(e, n.dtype)),
      e: () => G(n, tt(fp(e), n.dtype))
    };
  }
};
var pE = {
  kernelName: ra,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return {
      x: () => {
        const s = rn(e, gt(0)), o = gt(ru), r = gt(iu), i6 = G(n, r), a = G(G(n, o), mn(tt(e, "float32")));
        return Ee(s, i6, a);
      }
    };
  }
};
var fE = {
  kernelName: ca,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, G(e, it(gt(1), e))) };
  }
};
var mE = {
  kernelName: la,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var gE = {
  kernelName: ia,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(ip(tt(e, "float32")), n) };
  }
};
var bE = {
  kernelName: aa,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(t0(tt(e, "float32")), n) };
  }
};
var xE = {
  kernelName: Ac,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { begin: o, size: r } = e, i6 = s.shape, [a, l] = nu(s, o, r), c = [];
    for (let u = 0; u < n.rank; u++)
      c.push([a[u], i6[u] - a[u] - l[u]]);
    return { x: () => bp(n, c) };
  }
};
var yE = {
  kernelName: Zc,
  outputsToSave: [true],
  gradFunc: (n, t, e) => {
    const [s] = t, { dim: o } = e, r = true, i6 = G(n, s);
    return {
      logits: () => it(i6, G(at(i6, [o], r), s))
    };
  }
};
var wE = {
  kernelName: ua,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, kr(e)) };
  }
};
var Am = {
  kernelName: Xc,
  gradFunc: (n, t, e) => {
    const { blockShape: s, paddings: o } = e;
    return { x: () => op(n, s, o) };
  }
};
var Om = {
  kernelName: Kc,
  gradFunc: (n, t, e) => {
    const { axis: s } = e;
    return { x: () => Ge(n, s) };
  }
};
var IE = {
  kernelName: da,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, G(Ve(tt(e, "float32")), 2)) };
  }
};
var CE = {
  kernelName: zh,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(n, G(tt(e, "float32"), 2)) };
  }
};
var vE = {
  kernelName: ha,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = gt(2);
    return { a: () => G(n, G(o, it(e, s))), b: () => G(n, G(o, it(s, e))) };
  }
};
var SE = {
  kernelName: ba,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var kE = {
  kernelName: pa,
  inputsToSave: ["a", "b"],
  gradFunc: (n, t) => {
    const [e, s] = t, o = bt(e.shape, s.shape);
    return { a: () => {
      let a = n;
      const l = ce(e.shape, o);
      return l.length > 0 && (a = at(a, l)), W(a, e.shape);
    }, b: () => {
      let a = n;
      const l = ce(s.shape, o);
      return l.length > 0 && (a = at(a, l)), W(Yt(a), s.shape);
    } };
  }
};
var TE = {
  kernelName: Oc,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, o = s.shape.slice(), { axis: r } = e;
    Ct(r, s.shape).forEach((c) => {
      o[c] = 1;
    });
    const a = W(n, o), l = G(a, ks(s.shape, "float32"));
    return { x: () => l };
  }
};
var NE = {
  kernelName: fa,
  inputsToSave: ["x"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ut(n, Kt(ip(e))) };
  }
};
var RE = {
  kernelName: ma,
  outputsToSave: [true],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => G(it(gt(1), Kt(e)), n) };
  }
};
var $E = {
  kernelName: ga,
  inputsToSave: ["x"],
  gradFunc: (n, t, e) => {
    const [s] = t, { reps: o } = e;
    return { x: () => {
      let i6 = Tt(s);
      if (s.rank === 1)
        for (let a = 0; a < o[0]; ++a)
          i6 = U(i6, Ft(n, [a * s.shape[0]], [s.shape[0]]));
      else if (s.rank === 2)
        for (let a = 0; a < o[0]; ++a)
          for (let l = 0; l < o[1]; ++l)
            i6 = U(i6, Ft(n, [a * s.shape[0], l * s.shape[1]], [
              s.shape[0],
              s.shape[1]
            ]));
      else if (s.rank === 3)
        for (let a = 0; a < o[0]; ++a)
          for (let l = 0; l < o[1]; ++l)
            for (let c = 0; c < o[2]; ++c)
              i6 = U(i6, Ft(n, [a * s.shape[0], l * s.shape[1], c * s.shape[2]], [s.shape[0], s.shape[1], s.shape[2]]));
      else if (s.rank === 4)
        for (let a = 0; a < o[0]; ++a)
          for (let l = 0; l < o[1]; ++l)
            for (let c = 0; c < o[2]; ++c)
              for (let u = 0; u < o[3]; ++u)
                i6 = U(i6, Ft(n, [
                  a * s.shape[0],
                  l * s.shape[1],
                  c * s.shape[2],
                  u * s.shape[3]
                ], [s.shape[0], s.shape[1], s.shape[2], s.shape[3]]));
      else
        throw new Error(`Gradient for tile operation is not implemented for rank-${s.rank} tensors yet.`);
      return i6;
    } };
  }
};
var GE = {
  kernelName: ar,
  gradFunc: (n, t, e) => {
    const s = e, { perm: o } = s, r = js(o);
    return { x: () => kt(n, r) };
  }
};
var EE = {
  kernelName: Hc,
  gradFunc: (n, t, e) => {
    const s = e, { axis: o } = s;
    return { value: () => Xn(n, o) };
  }
};
var LE = {
  kernelName: _c,
  inputsToSave: ["segmentIds"],
  gradFunc: (n, t) => {
    const [e] = t;
    return { x: () => ME(n, e) };
  }
};
function ME(n, t) {
  const e = qs(t, Tt(t)), s = cp(n, e);
  let o = Bo(t, gt(0, "int32"));
  const r = s.rank - o.rank;
  for (let a = 0; a < r; ++a)
    o = Oe(o, a + 1);
  o = ss(o, ks(s.shape, "bool"));
  const i6 = Tt(s);
  return Ee(o, s, i6);
}
var WE = {
  kernelName: Uc,
  gradFunc: (n) => ({ x: () => Tt(n) })
};
var DE = [
  xx,
  L$,
  M$,
  W$,
  D$,
  F$,
  V$,
  z$,
  P$,
  A$,
  O$,
  X$,
  B$,
  U$,
  Y$,
  Q$,
  J$,
  j$,
  q$,
  tG,
  eG,
  nG,
  oG,
  sG,
  aG,
  lG,
  cG,
  uG,
  dG,
  hG,
  nE,
  pG,
  fG,
  mG,
  gG,
  bG,
  yG,
  xG,
  wG,
  IG,
  CG,
  vG,
  SG,
  kG,
  TG,
  NG,
  RG,
  $G,
  GG,
  MG,
  zm,
  zm,
  WG,
  VG,
  AG,
  OG,
  XG,
  KG,
  ZG,
  BG,
  HG,
  _G,
  UG,
  YG,
  QG,
  Pm,
  Pm,
  JG,
  jG,
  eE,
  sE,
  oE,
  rE,
  iE,
  aE,
  lE,
  cE,
  uE,
  dE,
  hE,
  pE,
  fE,
  mE,
  gE,
  bE,
  xE,
  yE,
  wE,
  Am,
  Am,
  Om,
  Om,
  IE,
  vE,
  CE,
  SE,
  kE,
  TE,
  NE,
  RE,
  $E,
  GE,
  EE,
  LE,
  WE
];
for (const n of DE)
  t2(n);
K().prototype.abs = function() {
  return this.throwIfDisposed(), me(this);
};
K().prototype.acos = function() {
  return this.throwIfDisposed(), gv(this);
};
K().prototype.acosh = function() {
  return this.throwIfDisposed(), xv(this);
};
K().prototype.add = function(n) {
  return this.throwIfDisposed(), U(this, n);
};
K().prototype.all = function(n, t) {
  return this.throwIfDisposed(), Qb(this, n, t);
};
K().prototype.any = function(n, t) {
  return this.throwIfDisposed(), Id(this, n, t);
};
K().prototype.argMax = function(n) {
  return this.throwIfDisposed(), ai(this, n);
};
K().prototype.argMin = function(n) {
  return this.throwIfDisposed(), vv(this, n);
};
K().prototype.asScalar = function() {
  return this.throwIfDisposed(), C(this.size === 1, () => "The array must have only 1 element."), W(this, []);
};
K().prototype.asType = function(n) {
  return this.throwIfDisposed(), tt(this, n);
};
K().prototype.as1D = function() {
  return this.throwIfDisposed(), W(this, [this.size]);
};
K().prototype.as2D = function(n, t) {
  return this.throwIfDisposed(), W(this, [n, t]);
};
K().prototype.as3D = function(n, t, e) {
  return this.throwIfDisposed(), W(this, [n, t, e]);
};
K().prototype.as4D = function(n, t, e, s) {
  return this.throwIfDisposed(), W(this, [n, t, e, s]);
};
K().prototype.as5D = function(n, t, e, s, o) {
  return this.throwIfDisposed(), W(this, [n, t, e, s, o]);
};
K().prototype.asin = function() {
  return this.throwIfDisposed(), kv(this);
};
K().prototype.asinh = function() {
  return this.throwIfDisposed(), Nv(this);
};
K().prototype.atan = function() {
  return this.throwIfDisposed(), $v(this);
};
K().prototype.atan2 = function(n) {
  return this.throwIfDisposed(), Ev(this, n);
};
K().prototype.atanh = function() {
  return this.throwIfDisposed(), Mv(this);
};
K().prototype.avgPool = function(n, t, e, s) {
  return this.throwIfDisposed(), np(this, n, t, e, s);
};
K().prototype.batchToSpaceND = function(n, t) {
  return this.throwIfDisposed(), op(this, n, t);
};
K().prototype.batchNorm = function(n, t, e, s, o) {
  return this.throwIfDisposed(), Qc(this, n, t, e, s, o);
};
K().prototype.broadcastTo = function(n) {
  return this.throwIfDisposed(), ni(this, n);
};
K().prototype.cast = function(n) {
  return this.throwIfDisposed(), tt(this, n);
};
K().prototype.ceil = function() {
  return this.throwIfDisposed(), iS(this);
};
K().prototype.clipByValue = function(n, t) {
  return this.throwIfDisposed(), fn(this, n, t);
};
K().prototype.concat = function(n, t) {
  return this.throwIfDisposed(), n instanceof Mt && (n = [n]), Ge([this, ...n], t);
};
K().prototype.conv1d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), Jb(this, n, t, e, s, o, r);
};
K().prototype.conv2dTranspose = function(n, t, e, s, o) {
  return this.throwIfDisposed(), jb(this, n, t, e, s, o);
};
K().prototype.conv2d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), $o(this, n, t, e, s, o, r);
};
K().prototype.cos = function() {
  return this.throwIfDisposed(), ip(this);
};
K().prototype.cosh = function() {
  return this.throwIfDisposed(), t0(this);
};
K().prototype.cumprod = function(n, t, e) {
  return this.throwIfDisposed(), vd(this, n, t, e);
};
K().prototype.cumsum = function(n, t, e) {
  return this.throwIfDisposed(), e0(this, n, t, e);
};
K().prototype.depthToSpace = function(n, t) {
  return this.throwIfDisposed(), ES(this, n, t);
};
K().prototype.depthwiseConv2d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), ap(this, n, t, e, s, o, r);
};
K().prototype.dilation2d = function(n, t, e, s, o) {
  return this.throwIfDisposed(), WS(this, n, t, e, s, o);
};
K().prototype.divNoNan = function(n) {
  return this.throwIfDisposed(), PS(this, n);
};
K().prototype.div = function(n) {
  return this.throwIfDisposed(), ut(this, n);
};
K().prototype.dot = function(n) {
  return this.throwIfDisposed(), OS(this, n);
};
K().prototype.elu = function() {
  return this.throwIfDisposed(), Jc(this);
};
K().prototype.equal = function(n) {
  return this.throwIfDisposed(), Tn(this, n);
};
K().prototype.erf = function() {
  return this.throwIfDisposed(), BS(this);
};
K().prototype.euclideanNorm = function(n, t) {
  return this.throwIfDisposed(), tk(this, n, t);
};
K().prototype.exp = function() {
  return this.throwIfDisposed(), mn(this);
};
K().prototype.expandDims = function(n) {
  return this.throwIfDisposed(), Oe(this, n);
};
K().prototype.expm1 = function() {
  return this.throwIfDisposed(), ok(this);
};
K().prototype.fft = function() {
  return this.throwIfDisposed(), Gp(this);
};
K().prototype.flatten = function() {
  return this.throwIfDisposed(), W(this, [this.size]);
};
K().prototype.floor = function() {
  return this.throwIfDisposed(), qc(this);
};
K().prototype.floorDiv = function(n) {
  return this.throwIfDisposed(), Yb(this, n);
};
K().prototype.gather = function(n, t, e) {
  return this.throwIfDisposed(), cp(this, n, t, e);
};
K().prototype.greaterEqual = function(n) {
  return this.throwIfDisposed(), Bo(this, n);
};
K().prototype.greater = function(n) {
  return this.throwIfDisposed(), rn(this, n);
};
K().prototype.ifft = function() {
  return this.throwIfDisposed(), kl(this);
};
K().prototype.irfft = function() {
  return this.throwIfDisposed(), b0(this);
};
K().prototype.isFinite = function() {
  return this.throwIfDisposed(), pk(this);
};
K().prototype.isInf = function() {
  return this.throwIfDisposed(), mk(this);
};
K().prototype.isNaN = function() {
  return this.throwIfDisposed(), bk(this);
};
K().prototype.leakyRelu = function(n) {
  return this.throwIfDisposed(), dp(this, n);
};
K().prototype.lessEqual = function(n) {
  return this.throwIfDisposed(), Tr(this, n);
};
K().prototype.less = function(n) {
  return this.throwIfDisposed(), Cl(this, n);
};
K().prototype.localResponseNormalization = function(n, t, e, s) {
  return this.throwIfDisposed(), Ck(this, n, t, e, s);
};
K().prototype.logSigmoid = function() {
  return this.throwIfDisposed(), $k(this);
};
K().prototype.logSoftmax = function(n) {
  return this.throwIfDisposed(), r0(this, n);
};
K().prototype.logSumExp = function(n, t) {
  return this.throwIfDisposed(), pp(this, n, t);
};
K().prototype.log = function() {
  return this.throwIfDisposed(), Nn(this);
};
K().prototype.log1p = function() {
  return this.throwIfDisposed(), hp(this);
};
K().prototype.logicalAnd = function(n) {
  return this.throwIfDisposed(), ss(this, n);
};
K().prototype.logicalNot = function() {
  return this.throwIfDisposed(), fp(this);
};
K().prototype.logicalOr = function(n) {
  return this.throwIfDisposed(), i0(this, n);
};
K().prototype.logicalXor = function(n) {
  return this.throwIfDisposed(), Vk(this, n);
};
K().prototype.matMul = function(n, t, e) {
  return this.throwIfDisposed(), Gt(this, n, t, e);
};
K().prototype.maxPool = function(n, t, e, s) {
  return this.throwIfDisposed(), mp(this, n, t, e, s);
};
K().prototype.max = function(n, t) {
  return this.throwIfDisposed(), Pn(this, n, t);
};
K().prototype.maximum = function(n) {
  return this.throwIfDisposed(), qs(this, n);
};
K().prototype.mean = function(n, t) {
  return this.throwIfDisposed(), oe(this, n, t);
};
K().prototype.min = function(n, t) {
  return this.throwIfDisposed(), Il(this, n, t);
};
K().prototype.minimum = function(n) {
  return this.throwIfDisposed(), br(this, n);
};
K().prototype.mirrorPad = function(n, t) {
  return this.throwIfDisposed(), Bk(this, n, t);
};
K().prototype.mod = function(n) {
  return this.throwIfDisposed(), _k(this, n);
};
K().prototype.mul = function(n) {
  return this.throwIfDisposed(), G(this, n);
};
K().prototype.neg = function() {
  return this.throwIfDisposed(), Yt(this);
};
K().prototype.norm = function(n, t, e) {
  return this.throwIfDisposed(), jc(this, n, t, e);
};
K().prototype.notEqual = function(n) {
  return this.throwIfDisposed(), ui(this, n);
};
K().prototype.oneHot = function(n, t = 1, e = 0) {
  return this.throwIfDisposed(), a0(this, n, t, e);
};
K().prototype.onesLike = function() {
  return this.throwIfDisposed(), Rn(this);
};
K().prototype.pad = function(n, t) {
  return this.throwIfDisposed(), bp(this, n, t);
};
K().prototype.pool = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), sT(this, n, t, e, s, o, r);
};
K().prototype.pow = function(n) {
  return this.throwIfDisposed(), gr(this, n);
};
K().prototype.prelu = function(n) {
  return this.throwIfDisposed(), yp(this, n);
};
K().prototype.prod = function(n, t) {
  return this.throwIfDisposed(), iT(this, n, t);
};
K().prototype.reciprocal = function() {
  return this.throwIfDisposed(), $T(this);
};
K().prototype.relu = function() {
  return this.throwIfDisposed(), Ts(this);
};
K().prototype.relu6 = function() {
  return this.throwIfDisposed(), c0(this);
};
K().prototype.reshapeAs = function(n) {
  return this.throwIfDisposed(), W(this, n.shape);
};
K().prototype.reshape = function(n) {
  return this.throwIfDisposed(), W(this, n);
};
K().prototype.resizeBilinear = function(n, t, e) {
  return this.throwIfDisposed(), T0(this, n, t, e);
};
K().prototype.resizeNearestNeighbor = function(n, t, e) {
  return this.throwIfDisposed(), N0(this, n, t, e);
};
K().prototype.reverse = function(n) {
  return this.throwIfDisposed(), Lo(this, n);
};
K().prototype.rfft = function() {
  return this.throwIfDisposed(), Ep(this);
};
K().prototype.round = function() {
  return this.throwIfDisposed(), u0(this);
};
K().prototype.rsqrt = function() {
  return this.throwIfDisposed(), d0(this);
};
K().prototype.selu = function() {
  return this.throwIfDisposed(), h0(this);
};
K().prototype.separableConv2d = function(n, t, e, s, o, r) {
  return this.throwIfDisposed(), p0(this, n, t, e, s, o, r);
};
K().prototype.sigmoid = function() {
  return this.throwIfDisposed(), kr(this);
};
K().prototype.sign = function() {
  return this.throwIfDisposed(), zT(this);
};
K().prototype.sin = function() {
  return this.throwIfDisposed(), f0(this);
};
K().prototype.sinh = function() {
  return this.throwIfDisposed(), m0(this);
};
K().prototype.slice = function(n, t) {
  return this.throwIfDisposed(), Ft(this, n, t);
};
K().prototype.softmax = function(n) {
  return this.throwIfDisposed(), $p(this, n);
};
K().prototype.softplus = function() {
  return this.throwIfDisposed(), va(this);
};
K().prototype.spaceToBatchND = function(n, t) {
  return this.throwIfDisposed(), xp(this, n, t);
};
K().prototype.split = function(n, t) {
  return this.throwIfDisposed(), pn(this, n, t);
};
K().prototype.sqrt = function() {
  return this.throwIfDisposed(), Ve(this);
};
K().prototype.square = function() {
  return this.throwIfDisposed(), Kt(this);
};
K().prototype.squaredDifference = function(n) {
  return this.throwIfDisposed(), x0(this, n);
};
K().prototype.squeeze = function(n) {
  return this.throwIfDisposed(), ka(this, n);
};
K().prototype.stack = function(n, t) {
  this.throwIfDisposed();
  const e = n instanceof Mt ? [this, n] : [this, ...n];
  return Xn(e, t);
};
K().prototype.step = function(n) {
  return this.throwIfDisposed(), Ta(this, n);
};
K().prototype.stridedSlice = function(n, t, e, s, o, r, i6, a) {
  return this.throwIfDisposed(), nN(this, n, t, e, s, o, r, i6, a);
};
K().prototype.sub = function(n) {
  return this.throwIfDisposed(), it(this, n);
};
K().prototype.sum = function(n, t) {
  return this.throwIfDisposed(), at(this, n, t);
};
K().prototype.tan = function() {
  return this.throwIfDisposed(), oN(this);
};
K().prototype.tanh = function() {
  return this.throwIfDisposed(), sp(this);
};
K().prototype.tile = function(n) {
  return this.throwIfDisposed(), Vn(this, n);
};
K().prototype.toBool = function() {
  return this.throwIfDisposed(), tt(this, "bool");
};
K().prototype.toFloat = function() {
  return this.throwIfDisposed(), tt(this, "float32");
};
K().prototype.toInt = function() {
  return this.throwIfDisposed(), tt(this, "int32");
};
K().prototype.topk = function(n, t) {
  return this.throwIfDisposed(), aN(this, n, t);
};
K().prototype.transpose = function(n) {
  return this.throwIfDisposed(), kt(this, n);
};
K().prototype.unique = function(n) {
  return this.throwIfDisposed(), uN(this, n);
};
K().prototype.unsortedSegmentSum = function(n, t) {
  return this.throwIfDisposed(), I0(this, n, t);
};
K().prototype.unstack = function(n) {
  return this.throwIfDisposed(), Mo(this, n);
};
K().prototype.where = function(n, t) {
  return this.throwIfDisposed(), Ee(n, this, t);
};
K().prototype.zerosLike = function() {
  return this.throwIfDisposed(), Tt(this);
};
var Qn = class _Qn extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, _Qn.prototype);
  }
};
var Sn = class _Sn extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, _Sn.prototype);
  }
};
var E = class _E2 extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, _E2.prototype);
  }
};
var yt = class _yt extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, _yt.prototype);
  }
};
var mf = class _mf extends Error {
  constructor(t) {
    super(t), Object.setPrototypeOf(this, _mf.prototype);
  }
};
var wx = class {
  constructor(t) {
    this.maxEntries = t || 100, this.cache = /* @__PURE__ */ new Map();
  }
  /**
   * Get the entry for the key and mark it as used recently.
   */
  get(t) {
    let e;
    return this.cache.has(t) && (e = this.cache.get(t), this.cache.delete(t), this.cache.set(t, e)), e;
  }
  /**
   * Put the entry into the cache. If the key already existed, mark the key as
   * used recently.
   */
  put(t, e) {
    if (this.cache.has(t))
      this.cache.delete(t);
    else if (this.cache.size >= this.maxEntries) {
      const s = this.cache.keys().next().value;
      this.cache.delete(s);
    }
    this.cache.set(t, e);
  }
  /**
   * Get the MaxEntries of the cache.
   */
  getMaxEntries() {
    return this.maxEntries;
  }
  /**
   * Set the MaxEntries of the cache. If the maxEntries is decreased, reduce
   * entries in the cache.
   */
  setMaxEntries(t) {
    if (t < 0)
      throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${t}.`);
    if (this.maxEntries > t)
      for (let e = 0; e < this.maxEntries - t; e++) {
        const s = this.cache.keys().next().value;
        this.cache.delete(s);
      }
    this.maxEntries = t;
  }
};
function Wo(n, t) {
  if (Array.isArray(n)) {
    let e = [];
    for (let s = 0; s < t; s++)
      e = e.concat(n);
    return e;
  } else {
    const e = new Array(t);
    return e.fill(n), e;
  }
}
function Jn(n, t) {
  if (!n)
    throw new mf(t);
}
function Xm(n, t) {
  let e = 0;
  for (const s of n)
    s === t && e++;
  return e;
}
function Xe(n) {
  return n.length === 1 ? n[0] : n;
}
function Lt(n) {
  return Array.isArray(n) ? n : [n];
}
function us(n) {
  const e = n.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2").replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
  return e[0] !== "_" ? e : "private" + e;
}
function ho(n) {
  return n.length <= 1 || n.indexOf("_") === -1 ? n : n.replace(/[_]+(\w|$)/g, (t, e) => e.toUpperCase());
}
var bn = {};
function gf(n) {
  if (n == null)
    return null;
  const t = {};
  return t.className = n.getClassName(), t.config = n.getConfig(), t;
}
function Nd(n) {
  if (!(n == null || typeof n != "object"))
    if (Array.isArray(n))
      n.forEach((t) => Nd(t));
    else {
      const t = Object.keys(n);
      for (const e of t) {
        const s = n[e];
        s != null && typeof s == "object" && (!Array.isArray(s) && s.type === "ndarray" && typeof s.value == "number" ? n[e] = s.value : Nd(s));
      }
    }
}
function Ga(n, t = {}, e = {}, s = "object", o = false) {
  if (typeof n == "string") {
    const r = n;
    let i6;
    if (r in e)
      i6 = e[r];
    else if (r in bn)
      i6 = bn[r];
    else if (i6 = t[r], i6 == null)
      throw new E(`Unknown ${s}: ${n}. This may be due to one of the following reasons:
1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    return i6;
  } else {
    const r = n;
    if (r.className == null || r.config == null)
      throw new E(`${s}: Improper config format: ${JSON.stringify(r)}.
'className' and 'config' must set.`);
    const i6 = r.className;
    let a, l;
    if (i6 in e ? [a, l] = e[i6] : i6 in bn ? [a, l] = bn.className : i6 in t && ([a, l] = t[i6]), a == null)
      throw new E(`Unknown ${s}: ${i6}. This may be due to one of the following reasons:
1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    if (l != null) {
      const c = {};
      for (const p of Object.keys(bn))
        c[p] = bn[p];
      for (const p of Object.keys(e))
        c[p] = e[p];
      const u = r.config;
      u.customObjects = c;
      const d = Object.assign({}, bn);
      for (const p of Object.keys(e))
        bn[p] = e[p];
      Nd(r.config);
      const h = l(a, r.config, e, o);
      return bn = Object.assign({}, d), h;
    } else {
      const c = Object.assign({}, bn);
      for (const d of Object.keys(e))
        bn[d] = e[d];
      const u = new a(r.config);
      return bn = Object.assign({}, c), u;
    }
  }
}
function FE(n, t) {
  return n < t ? -1 : n > t ? 1 : 0;
}
function Ba(n, t) {
  return -1 * FE(n, t);
}
function Ps(n) {
  if (n == null)
    return n;
  const t = [];
  for (const e of n)
    t.indexOf(e) === -1 && t.push(e);
  return t;
}
function VE(n) {
  if (n == null)
    throw new E(`Invalid value in obj: ${JSON.stringify(n)}`);
  for (const t in n)
    if (n.hasOwnProperty(t))
      return false;
  return true;
}
function Uo(n, t, e) {
  if (e != null && n.indexOf(e) < 0)
    throw new E(`${e} is not a valid ${t}.  Valid values are ${n} or null/undefined.`);
}
function bf(n, t, e = 0, s = 1 / 0) {
  return Jn(e >= 0), Jn(s >= e), Array.isArray(n) && n.length >= e && n.length <= s && n.every((o) => typeof o === t);
}
function xe(n, t) {
  Array.isArray(n) ? (C(n.length > 0, () => `${t} is unexpectedly an empty array.`), n.forEach((e, s) => xe(e, `element ${s + 1} of ${t}`))) : C(Number.isInteger(n) && n > 0, () => `Expected ${t} to be a positive integer, but got ${Ix(n)}.`);
}
function Ix(n) {
  return n === null ? "null" : Array.isArray(n) ? "[" + n.map((t) => Ix(t)).join(",") + "]" : typeof n == "string" ? `"${n}"` : `${n}`;
}
function zE(n, t, e) {
  let s = e != null ? e() : Ie(), o;
  return (...i6) => {
    const a = e != null ? e() : Ie();
    return a - s < t || (s = a, o = n(...i6)), o;
  };
}
function Cx(n) {
  return n === "relu" ? "relu" : n === "linear" ? "linear" : n === "elu" ? "elu" : null;
}
var PE = 0;
function vx() {
  return PE++;
}
var Ha = {};
function au(n = "") {
  return n in Ha || (Ha[n] = 0), Ha[n] += 1, n + Ha[n].toString();
}
var AE = ["channelsFirst", "channelsLast"];
var OE = ["nearest", "bilinear"];
var XE = ["valid", "same", "causal"];
var KE = ["max", "avg"];
var ZE = ["sum", "mul", "concat", "ave"];
var er = /* @__PURE__ */ new Map();
function ae(n) {
  Uo(AE, "DataFormat", n);
}
function BE(n) {
  Uo(OE, "InterpolationFormat", n);
}
function gn(n) {
  Uo(XE, "PaddingMode", n);
}
function Sx(n) {
  Uo(KE, "PoolMode", n);
}
var si = [];
var Km = "/";
function wo(n, t) {
  si.push(n);
  try {
    const e = t();
    return si.pop(), e;
  } catch (e) {
    throw si.pop(), e;
  }
}
function HE() {
  return si.length === 0 ? "" : si.join(Km) + Km;
}
function kx(n) {
  if (!Nx(n))
    throw new Error("Not a valid tensor name: '" + n + "'");
  return HE() + n;
}
function Tx(n) {
  if (!Nx(n))
    throw new Error("Not a valid tensor name: '" + n + "'");
  er.has(n) || er.set(n, 0);
  const t = er.get(n);
  if (er.set(n, er.get(n) + 1), t > 0) {
    const e = `${n}_${t}`;
    return er.set(e, 1), e;
  } else
    return n;
}
var _E = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);
function Nx(n) {
  return !!n.match(_E);
}
function UE(n) {
  return n === parseInt(n.toString(), 10);
}
function As(n, t, e) {
  t == null && (t = 0), e == null && (e = n.length);
  let s = 1;
  for (let o = t; o < e; ++o)
    s *= n[o];
  return s;
}
function xr(n) {
  if (n.length === 0)
    return Number.NaN;
  let t = Number.POSITIVE_INFINITY;
  for (let e = 0; e < n.length; e++) {
    const s = n[e];
    s < t && (t = s);
  }
  return t;
}
function Bs(n) {
  if (n.length === 0)
    return Number.NaN;
  let t = Number.NEGATIVE_INFINITY;
  for (let e = 0; e < n.length; e++) {
    const s = n[e];
    s > t && (t = s);
  }
  return t;
}
function Kn(n, t) {
  if (t < n)
    throw new E(`end (${t}) < begin (${n}) is forbidden.`);
  const e = [];
  for (let s = n; s < t; ++s)
    e.push(s);
  return e;
}
var Wu;
function ue() {
  return Wu == null && (Wu = ps().epsilon()), Wu;
}
function Zn() {
  return "channelsLast";
}
function es(n, t) {
  return tt(n, t);
}
function Ea(n, t = -1) {
  const e = n.shape.slice();
  return t < 0 && (t = e.length + t + 1), e.splice(t, 0, 1), W(n, e);
}
function YE(n, t) {
  return D(() => {
    if (n.shape.length !== 2)
      throw new E(`repeat() expects a rank-2 tensor, but received a rank-${n.shape.length} tensor.`);
    const e = Ea(n, 1);
    return Rd(e, [1, t, 1]);
  });
}
function QE(n) {
  const t = [As(n.shape)];
  return W(n, t);
}
function JE(n) {
  if (n.rank <= 1)
    throw new E(`batchFlatten requires a minimum rank of 2. Got rank: ${n.rank}.`);
  const t = [n.shape[0], As(n.shape, 1)];
  return W(n, t);
}
function Io(n, t, e) {
  return D(() => {
    switch (n.rank) {
      case 1:
        return Np(n, t, e);
      case 2:
        return g0(n, [t, 0], [e, n.shape[1]]);
      case 3:
        return Rp(n, [t, 0, 0], [e, n.shape[1], n.shape[2]]);
      case 4:
        return Sl(n, [t, 0, 0, 0], [e, n.shape[1], n.shape[2], n.shape[3]]);
      case 5:
        return Ft(n, [t, 0, 0, 0, 0], [
          e,
          n.shape[1],
          n.shape[2],
          n.shape[3],
          n.shape[4]
        ]);
      case 6:
        return Ft(n, [t, 0, 0, 0, 0, 0], [
          e,
          n.shape[1],
          n.shape[2],
          n.shape[3],
          n.shape[4],
          n.shape[5]
        ]);
      default:
        throw new E(`sliceAlongFirstAxis() received an unsupported tensor rank: ${n.rank}`);
    }
  });
}
function Du(n, t, e) {
  return D(() => {
    switch (n.rank) {
      case 1:
        return Np(n, t, e);
      case 2:
        return g0(n, [0, t], [n.shape[0], e]);
      case 3:
        return Rp(n, [0, 0, t], [n.shape[0], n.shape[1], e]);
      case 4:
        return Sl(n, [0, 0, 0, t], [n.shape[0], n.shape[1], n.shape[2], e]);
      default:
        throw new E(`sliceAlongLastAxis() received an unsupported tensor rank: ${n.rank}`);
    }
  });
}
function _a(n, t, e, s) {
  return D(() => {
    switch (n.rank) {
      case 1:
        return Np(n, t, e);
      case 2:
        switch (s) {
          case 1:
            return Io(n, t, e);
          case 2:
            return Du(n, t, e);
          default:
            throw new E(`The axis is not within the rank of the tensor ${s}`);
        }
      case 3:
        switch (s) {
          case 1:
            return Io(n, t, e);
          case 2:
            return Rp(n, [0, t, 0], [n.shape[0], e, n.shape[2]]);
          case 3:
            return Du(n, t, e);
          default:
            throw new E(`The axis is not within the rank of the tensor ${s}`);
        }
      case 4:
        switch (s) {
          case 1:
            return Io(n, t, e);
          case 2:
            return Sl(n, [0, t, 0, 0], [n.shape[0], e, n.shape[2], n.shape[3]]);
          case 3:
            return Sl(n, [0, 0, t, 0], [n.shape[0], n.shape[1], e, n.shape[3]]);
          case 4:
            return Du(n, t, e);
          default:
            throw new E(`The axis is not within the rank of the tensor ${s}`);
        }
      default:
        throw new E(`sliceAlongLastAxis() received an unsupported tensor rank: ${n.rank}`);
    }
  });
}
function xf(n, t = -1) {
  let e;
  return t < 0 && (e = n[0].rank, e !== 0 ? t = e : t = 0), t === n[0].rank && (t = -1), Ge(n, t);
}
function Zm(n, t) {
  switch (n.rank) {
    case 1:
      return cS([n, t]);
    case 2:
      return dS([n, t], 0);
    case 3:
      return pS([n, t], 0);
    case 4:
      return mS([n, t], 0);
    default:
      throw new E(`concatAlongFirstAxis() received an unsupported tensor rank: ${n.rank}`);
  }
}
function Rd(n, t) {
  if (Array.isArray(t) || (t = [t]), n.rank !== t.length)
    throw new E(`The length of input n (${t.length}) does not match the number of dimensions in input x (${n.rank})`);
  return Vn(n, t);
}
function lu(n, t = 0, e = 1, s, o) {
  return kT(n, t, e, s, o);
}
function ns(n, t, e, s) {
  if (n.rank < 2 || t.rank < 2)
    throw new yt(`dot requires both inputs to be rank >= 2 but got x shape = ${n.shape} and y shape = ${t.shape}`);
  if (t.rank >= 3) {
    const o = n.shape.slice(-1)[0], r = t.shape.slice(-2)[0];
    if (o !== r)
      throw new yt(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${n.shape} and  y shape = ${t.shape}`);
  }
  if (n.rank === 2 && t.rank === 2)
    return Nm({
      a: n,
      b: t,
      transposeA: false,
      transposeB: false,
      bias: s ? $d(n.rank, s, Zn()) : null,
      activation: e
    });
  {
    const o = n.shape.slice(), r = o.pop();
    n = W(n, [-1, r]);
    const i6 = t.shape.slice(), a = i6.pop(), l = i6.pop(), c = [...i6, a], u = Array.from({ length: t.rank }, (f, m) => m === 0 ? t.rank - 2 : m <= t.rank - 2 ? m - 1 : m);
    t = W(kt(t, u), [l, -1]);
    const d = [...o, ...c];
    return W(Nm({
      a: n,
      b: t,
      transposeA: false,
      transposeB: false,
      bias: s ? $d(n.rank, s, Zn()) : null,
      activation: e
    }), d);
  }
}
function Rx(n, t, e) {
  return D(() => (Array.isArray(t) ? t = Ze(t, "int32") : t = tt(t, "int32"), cp(n, t, e)));
}
function La(n) {
  return G(n, n);
}
function $d(n, t, e) {
  const s = t.shape;
  if (t.rank !== 1 && t.rank !== n)
    throw new E(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${n}`);
  if (n === 5) {
    if (e === "channelsFirst")
      return s.length === 1 ? W(t, [1, s[0], 1, 1, 1]) : W(t, [1, s[3], s[0], s[1], s[2]]);
    if (e === "channelsLast")
      return s.length === 1 ? W(t, [1, 1, 1, 1, s[0]]) : W(t, [1].concat(s));
  } else if (n === 4) {
    if (e === "channelsFirst")
      return s.length === 1 ? W(t, [1, s[0], 1, 1]) : W(t, [1, s[2], s[0], s[1]]);
    if (e === "channelsLast")
      return s.length === 1 ? W(t, [1, 1, 1, s[0]]) : W(t, [1].concat(s));
  } else if (n === 3) {
    if (e === "channelsFirst")
      return s.length === 1 ? W(t, [1, s[0], 1]) : W(t, [1, s[1], s[0]]);
    if (e === "channelsLast")
      return s.length === 1 ? W(t, [1, 1, s[0]]) : W(t, [1].concat(s));
  } else if (n < 3)
    return t;
  throw new E(`Unsupported input rank by biasAdd: ${t.rank}`);
}
function _n(n, t, e) {
  return D(() => (e == null && (e = Zn()), ae(e), U(n, $d(n.rank, t, e))));
}
function jE(n, t = 1) {
  if (t !== 1)
    throw new yt(`Support for alpha values other than 1 (${t}) is not implemented yet.`);
  return Jc(n);
}
function qE(n) {
  return D(() => ut(n, U(me(n), 1)));
}
function $x(n, t, e, s) {
  return D(() => bN(n, t, e, s));
}
function tL(n) {
  return D(() => {
    const t = U(0.5, G(0.2, n));
    return fn(t, 0, 1);
  });
}
function Ma(n, t, e = false) {
  return e ? n() : t();
}
var eL = ["fanIn", "fanOut", "fanAvg"];
var nL = ["normal", "uniform", "truncatedNormal"];
function sL(n) {
  Uo(eL, "FanMode", n);
}
function oL(n) {
  Uo(nL, "Distribution", n);
}
var Gn = class extends _o {
  fromConfigUsesCustomObjects() {
    return false;
  }
  getConfig() {
    return {};
  }
};
var Gx = class extends Gn {
  apply(t, e) {
    return be(t, e);
  }
};
Gx.className = "Zeros";
_(Gx);
var yf = class extends Gn {
  apply(t, e) {
    return ks(t, e);
  }
};
yf.className = "Ones";
_(yf);
var Ex = class extends Gn {
  constructor(t) {
    if (super(), typeof t != "object")
      throw new E(`Expected argument of type ConstantConfig but got ${t}`);
    if (t.value === void 0)
      throw new E(`config must have value set but got ${t}`);
    this.value = t.value;
  }
  apply(t, e) {
    return D(() => G(gt(this.value), ks(t, e)));
  }
  getConfig() {
    return {
      value: this.value
    };
  }
};
Ex.className = "Constant";
_(Ex);
var Lx = class extends Gn {
  constructor(t) {
    super(), this.DEFAULT_MINVAL = -0.05, this.DEFAULT_MAXVAL = 0.05, this.minval = t.minval || this.DEFAULT_MINVAL, this.maxval = t.maxval || this.DEFAULT_MAXVAL, this.seed = t.seed;
  }
  apply(t, e) {
    return Sa(t, this.minval, this.maxval, e, this.seed);
  }
  getConfig() {
    return { minval: this.minval, maxval: this.maxval, seed: this.seed };
  }
};
Lx.className = "RandomUniform";
_(Lx);
var Mx = class extends Gn {
  constructor(t) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = 0.05, this.mean = t.mean || this.DEFAULT_MEAN, this.stddev = t.stddev || this.DEFAULT_STDDEV, this.seed = t.seed;
  }
  apply(t, e) {
    if (e = e || "float32", e !== "float32" && e !== "int32")
      throw new yt(`randomNormal does not support dType ${e}.`);
    return lu(t, this.mean, this.stddev, e, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
Mx.className = "RandomNormal";
_(Mx);
var Wx = class extends Gn {
  constructor(t) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = 0.05, this.mean = t.mean || this.DEFAULT_MEAN, this.stddev = t.stddev || this.DEFAULT_STDDEV, this.seed = t.seed;
  }
  apply(t, e) {
    if (e = e || "float32", e !== "float32" && e !== "int32")
      throw new yt(`truncatedNormal does not support dType ${e}.`);
    return w0(t, this.mean, this.stddev, e, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
Wx.className = "TruncatedNormal";
_(Wx);
var Dx = class extends Gn {
  constructor(t) {
    super(), this.gain = t.gain != null ? t.gain : 1;
  }
  apply(t, e) {
    return D(() => {
      if (t.length !== 2 || t[0] !== t[1])
        throw new E("Identity matrix initializer can only be used for 2D square matrices.");
      return G(this.gain, o0(t[0]));
    });
  }
  getConfig() {
    return { gain: this.gain };
  }
};
Dx.className = "Identity";
_(Dx);
function rL(n, t = "channelsLast") {
  let e, s;
  if (ae(t), n.length === 2)
    e = n[0], s = n[1];
  else if ([3, 4, 5].indexOf(n.length) !== -1) {
    if (t === "channelsFirst") {
      const o = As(n, 2);
      e = n[1] * o, s = n[0] * o;
    } else if (t === "channelsLast") {
      const o = As(n, 0, n.length - 2);
      e = n[n.length - 2] * o, s = n[n.length - 1] * o;
    }
  } else {
    const o = As(n);
    e = Math.sqrt(o), s = Math.sqrt(o);
  }
  return [e, s];
}
var en = class extends Gn {
  /**
   * Constructor of VarianceScaling.
   * @throws ValueError for invalid value in scale.
   */
  constructor(t) {
    if (super(), t.scale < 0)
      throw new E(`scale must be a positive float. Got: ${t.scale}`);
    this.scale = t.scale == null ? 1 : t.scale, this.mode = t.mode == null ? "fanIn" : t.mode, sL(this.mode), this.distribution = t.distribution == null ? "normal" : t.distribution, oL(this.distribution), this.seed = t.seed;
  }
  apply(t, e) {
    const s = rL(t), o = s[0], r = s[1];
    let i6 = this.scale;
    if (this.mode === "fanIn" ? i6 /= Math.max(1, o) : this.mode === "fanOut" ? i6 /= Math.max(1, r) : i6 /= Math.max(1, (o + r) / 2), this.distribution === "normal") {
      const a = Math.sqrt(i6);
      if (e = e || "float32", e !== "float32" && e !== "int32")
        throw new yt(`${this.getClassName()} does not support dType ${e}.`);
      return w0(t, 0, a, e, this.seed);
    } else {
      const a = Math.sqrt(3 * i6);
      return Sa(t, -a, a, e, this.seed);
    }
  }
  getConfig() {
    return {
      scale: this.scale,
      mode: this.mode,
      distribution: this.distribution,
      seed: this.seed
    };
  }
};
en.className = "VarianceScaling";
_(en);
var wf = class extends en {
  /**
   * Constructor of GlorotUniform
   * @param scale
   * @param mode
   * @param distribution
   * @param seed
   */
  constructor(t) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "uniform",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return en.className;
  }
};
wf.className = "GlorotUniform";
_(wf);
var If = class extends en {
  /**
   * Constructor of GlorotNormal.
   * @param scale
   * @param mode
   * @param distribution
   * @param seed
   */
  constructor(t) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "normal",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return en.className;
  }
};
If.className = "GlorotNormal";
_(If);
var Cf = class extends en {
  constructor(t) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "normal",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return en.className;
  }
};
Cf.className = "HeNormal";
_(Cf);
var vf = class extends en {
  constructor(t) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "uniform",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return en.className;
  }
};
vf.className = "HeUniform";
_(vf);
var Sf = class extends en {
  constructor(t) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "normal",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return en.className;
  }
};
Sf.className = "LeCunNormal";
_(Sf);
var kf = class extends en {
  constructor(t) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "uniform",
      seed: t == null ? null : t.seed
    });
  }
  getClassName() {
    return en.className;
  }
};
kf.className = "LeCunUniform";
_(kf);
var Fx = class extends Gn {
  constructor(t) {
    super(), this.DEFAULT_GAIN = 1, this.ELEMENTS_WARN_SLOW = 2e3, this.gain = t.gain == null ? this.DEFAULT_GAIN : t.gain, this.seed = t.seed;
  }
  apply(t, e) {
    return D(() => {
      if (t.length < 2)
        throw new yt("Shape must be at least 2D.");
      if (e !== "int32" && e !== "float32" && e !== void 0)
        throw new TypeError(`Unsupported data type ${e}.`);
      e = e;
      const s = X(t.slice(0, -1)), o = t[t.length - 1], r = s * o;
      r > this.ELEMENTS_WARN_SLOW && console.warn(`Orthogonal initializer is being called on a matrix with more than ${this.ELEMENTS_WARN_SLOW} (${r}) elements: Slowness may result.`);
      const i6 = [Math.max(o, s), Math.min(o, s)], a = lu(i6, 0, 1, e, this.seed), l = e$.qr(a, false);
      let c = l[0];
      const d = l[1].flatten().stridedSlice([0], [Math.min(o, s) * Math.min(o, s)], [Math.min(o, s) + 1]);
      return c = G(c, d.sign()), s < o && (c = c.transpose()), G(gt(this.gain), c.reshape(t));
    });
  }
  getConfig() {
    return {
      gain: this.gain,
      seed: this.seed
    };
  }
};
Fx.className = "Orthogonal";
_(Fx);
var Bm = {
  constant: "Constant",
  glorotNormal: "GlorotNormal",
  glorotUniform: "GlorotUniform",
  heNormal: "HeNormal",
  heUniform: "HeUniform",
  identity: "Identity",
  leCunNormal: "LeCunNormal",
  leCunUniform: "LeCunUniform",
  ones: "Ones",
  orthogonal: "Orthogonal",
  randomNormal: "RandomNormal",
  randomUniform: "RandomUniform",
  truncatedNormal: "TruncatedNormal",
  varianceScaling: "VarianceScaling",
  zeros: "Zeros"
};
function Hm(n, t = {}) {
  return Ga(n, cn.getMap().classNameMap, t, "initializer");
}
function jt(n) {
  return gf(n);
}
function Ut(n) {
  if (typeof n == "string") {
    const t = n in Bm ? Bm[n] : n;
    if (t === "GlorotNormal")
      return new If();
    if (t === "GlorotUniform")
      return new wf();
    if (t === "HeNormal")
      return new Cf();
    if (t === "HeUniform")
      return new vf();
    if (t === "LeCunNormal")
      return new Sf();
    if (t === "LeCunUniform")
      return new kf();
    {
      const e = {};
      return e.className = t, e.config = {}, Hm(e);
    }
  } else
    return n instanceof Gn ? n : Hm(n);
}
function Gd(n) {
  return Array.isArray(n) && Array.isArray(n[0]);
}
function Tl(n) {
  return n.length === 0 ? [] : Array.isArray(n[0]) ? n : [n];
}
function mt(n) {
  let t;
  if (Array.isArray(n)) {
    if (n.length !== 1)
      throw new E(`Expected Tensor length to be 1; got ${n.length}`);
    t = n[0];
  } else
    t = n;
  return t;
}
function Rt(n) {
  if (Array.isArray(n) && Array.isArray(n[0])) {
    if (n.length === 1)
      return n = n, n[0];
    throw new E(`Expected exactly 1 Shape; got ${n.length}`);
  } else
    return n;
}
function Nl(n) {
  let t = 0;
  for (const e of n)
    e.shape.length === 0 ? t += 1 : t += e.shape.reduce((s, o) => s * o);
  return t;
}
var _m = "Variable";
var iL = class {
  /**
   * Construct Variable from a `tf.Tensor`.
   *
   * If not explicitly named, the Variable will be given a name with the
   * prefix 'Variable'. Variable names are unique. In the case of name
   * collision, suffixies '_<num>' will be added to the name.
   *
   * @param val Initial value of the Variable.
   * @param name Name of the variable. If `null` or `undefined` is provided, it
   *   will default a name with the prefix 'Variable'.
   * @param constraint Optional, projection function to be applied to the
   * variable after optimize updates
   * @throws ValueError if `name` is `null` or `undefined`.
   */
  constructor(t, e = "float32", s = _m, o = true, r = null) {
    this.dtype = e ?? "float32", this.shape = t.shape, this.id = vx(), s = s ?? _m, this.originalName = kx(s), this.name = Tx(this.originalName), this.trainable_ = o, this.constraint = r, this.val = pN(t, this.trainable_, this.name, this.dtype);
  }
  /**
   * Get a snapshot of the Variable's value.
   *
   * The returned value is a snapshot of the Variable's value at the time of
   * the invocation. Future mutations in the value of the tensor will only
   * be reflected by future calls to this method.
   */
  read() {
    return this.assertNotDisposed(), this.val;
  }
  /**
   * Update the value of the Variable.
   *
   * @param newVal: The new value to update to. Must be consistent with the
   *   dtype and shape of the Variable.
   * @return This Variable.
   */
  write(t) {
    return this.assertNotDisposed(), aL(this.val, t), this.val.id !== t.id && (this.val.assign(t), this.constraint != null && this.val.assign(this.constraint.apply(this.val))), this;
  }
  /**
   * Dispose this LayersVariable instance from memory.
   */
  dispose() {
    this.assertNotDisposed(), this.val.dispose();
  }
  assertNotDisposed() {
    if (this.val.isDisposed)
      throw new Error(`LayersVariable ${this.name} is already disposed.`);
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t) {
    this.trainable_ = t, this.val.trainable = t;
  }
};
function aL(n, t) {
  if (n.shape.toString() !== t.shape.toString())
    throw new Error("Shape mismatch: " + JSON.stringify(n.shape) + " vs. " + JSON.stringify(t.shape));
}
function Ed(n) {
  return n.map((t) => t.read());
}
function Tf(n) {
  n.forEach((t) => {
    t[0].write(t[1]);
  });
}
var de = class {
  constructor(t) {
    this.dtype = t.dtype, this.shape = t.shape, t.shape != null ? this.ndim = t.shape.length : this.ndim = t.ndim, this.maxNDim = t.maxNDim, this.minNDim = t.minNDim, this.axes = t.axes || {};
  }
};
var os = class {
  /**
   *
   * @param dtype
   * @param shape
   * @param sourceLayer The Layer that produced this symbolic tensor.
   * @param inputs The inputs passed to sourceLayer's __call__() method.
   * @param nodeIndex
   * @param tensorIndex
   * @param callArgs The keyword arguments passed to the __call__() method.
   * @param name
   * @param outputTensorIndex The index of this tensor in the list of outputs
   *   returned by apply().
   */
  constructor(t, e, s, o, r, i6, a) {
    this.dtype = t, this.shape = e, this.sourceLayer = s, this.inputs = o, this.callArgs = r, this.outputTensorIndex = a, this.id = vx(), i6 != null && (this.originalName = kx(i6), this.name = Tx(this.originalName)), this.rank = e.length;
  }
};
var lL = 0;
var cu = class {
  constructor(t, e) {
    this.callArgs = e, this.id = lL++, this.outboundLayer = t.outboundLayer, this.inboundLayers = t.inboundLayers, this.nodeIndices = t.nodeIndices, this.tensorIndices = t.tensorIndices, this.inputTensors = t.inputTensors, this.outputTensors = t.outputTensors, this.inputMasks = t.inputMasks, this.outputMasks = t.outputMasks, this.inputShapes = t.inputShapes, this.outputShapes = t.outputShapes;
    for (const s of t.inboundLayers)
      s != null && s.outboundNodes.push(this);
    t.outboundLayer.inboundNodes.push(this);
  }
  getConfig() {
    const t = [];
    for (const e of this.inboundLayers)
      e != null ? t.push(e.name) : t.push(null);
    return {
      outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
      inboundLayers: t,
      nodeIndices: this.nodeIndices,
      tensorIndices: this.tensorIndices
    };
  }
};
var cL = 0;
var St = class extends _o {
  constructor(t = {}) {
    super(), this._callHook = null, this._addedWeightNames = [], this._stateful = false, this.id = cL++, this.activityRegularizer = null, this.inputSpec = null, this.supportsMasking = false, this._trainableWeights = [], this._nonTrainableWeights = [], this._losses = [], this._updates = [], this._built = false, this.inboundNodes = [], this.outboundNodes = [];
    let e = t.name;
    if (!e) {
      const s = this.getClassName();
      e = us(s) + "_" + au(s);
    }
    if (this.name = e, this.trainable_ = t.trainable == null ? true : t.trainable, t.inputShape != null || t.batchInputShape != null) {
      let s;
      if (t.batchInputShape != null)
        s = t.batchInputShape;
      else if (t.inputShape != null) {
        let r = null;
        t.batchSize != null && (r = t.batchSize), s = [r].concat(t.inputShape);
      }
      this.batchInputShape = s;
      let o = t.dtype;
      o == null && (o = t.inputDType), o == null && (o = "float32"), this.dtype = o;
    }
    t.weights != null ? this.initialWeights = t.weights : this.initialWeights = null, this._refCount = null, this.fastWeightInitDuringBuild = false;
  }
  /**
   * Converts a layer and its index to a unique (immutable type) name.
   * This function is used internally with `this.containerNodes`.
   * @param layer The layer.
   * @param nodeIndex The layer's position (e.g. via enumerate) in a list of
   *   nodes.
   *
   * @returns The unique name.
   */
  static nodeKey(t, e) {
    return t.name + "_ib-" + e.toString();
  }
  /**
   * Returns this.inboundNode at index nodeIndex.
   *
   * Porting note: This is a replacement for _get_node_attribute_at_index()
   * @param nodeIndex
   * @param attrName The name of the attribute related to request for this node.
   */
  getNodeAtIndex(t, e) {
    if (this.inboundNodes.length === 0)
      throw new Sn(`The layer has never been called and thus has no defined ${e}.`);
    if (this.inboundNodes.length <= t)
      throw new E(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);
    return this.inboundNodes[t];
  }
  /**
   * Retrieves the input tensor(s) of a layer at a given node.
   *
   * @param nodeIndex Integer, index of the node from which to retrieve the
   *   attribute. E.g. `nodeIndex=0` will correspond to the first time the layer
   *   was called.
   *
   * @return A tensor (or list of tensors if the layer has multiple inputs).
   */
  getInputAt(t) {
    return Xe(this.getNodeAtIndex(t, "input").inputTensors);
  }
  /**
   * Retrieves the output tensor(s) of a layer at a given node.
   *
   * @param nodeIndex Integer, index of the node from which to retrieve the
   *   attribute. E.g. `nodeIndex=0` will correspond to the first time the layer
   *   was called.
   *
   * @return A tensor (or list of tensors if the layer has multiple outputs).
   */
  getOutputAt(t) {
    return Xe(this.getNodeAtIndex(t, "output").outputTensors);
  }
  // Properties
  /**
   * Retrieves the input tensor(s) of a layer.
   *
   * Only applicable if the layer has exactly one inbound node,
   * i.e. if it is connected to one incoming layer.
   *
   * @return Input tensor or list of input tensors.
   *
   * @exception AttributeError if the layer is connected to more than one
   *   incoming layers.
   */
  get input() {
    if (this.inboundNodes.length > 1)
      throw new Qn(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);
    if (this.inboundNodes.length === 0)
      throw new Qn(`Layer ${this.name} is not connected, no input to return.`);
    return Xe(this.getNodeAtIndex(0, "input").inputTensors);
  }
  /**
   * Retrieves the output tensor(s) of a layer.
   *
   * Only applicable if the layer has exactly one inbound node,
   * i.e. if it is connected to one incoming layer.
   *
   * @return Output tensor or list of output tensors.
   *
   * @exception AttributeError if the layer is connected to more than one
   *   incoming layers.
   */
  get output() {
    if (this.inboundNodes.length === 0)
      throw new Qn(`Layer ${this.name} has no inbound nodes.`);
    if (this.inboundNodes.length > 1)
      throw new Qn(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);
    return Xe(this.getNodeAtIndex(0, "output").outputTensors);
  }
  get losses() {
    return this._losses;
  }
  /**
   * Retrieves the Layer's current loss values.
   *
   * Used for regularizers during training.
   */
  calculateLosses() {
    return this.losses.map((t) => t());
  }
  get updates() {
    return this._updates;
  }
  get built() {
    return this._built;
  }
  set built(t) {
    this._built = t;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t) {
    this._trainableWeights.forEach((e) => e.trainable = t), this.trainable_ = t;
  }
  get trainableWeights() {
    return this.trainable_ ? this._trainableWeights.filter((t) => t.trainable) : [];
  }
  set trainableWeights(t) {
    this._trainableWeights = t;
  }
  get nonTrainableWeights() {
    return this.trainable ? this._trainableWeights.filter((t) => !t.trainable).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights);
  }
  set nonTrainableWeights(t) {
    this._nonTrainableWeights = t;
  }
  /**
   * The concatenation of the lists trainableWeights and nonTrainableWeights
   * (in this order).
   */
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  get stateful() {
    return this._stateful;
  }
  /**
   * Reset the states of the layer.
   *
   * This method of the base Layer class is essentially a no-op.
   * Subclasses that are stateful (e.g., stateful RNNs) should override this
   * method.
   */
  resetStates() {
    if (!this.stateful)
      throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
  }
  /**
   * Checks compatibility between the layer and provided inputs.
   *
   * This checks that the tensor(s) `input`
   * verify the input assumptions of the layer
   * (if any). If not, exceptions are raised.
   *
   * @param inputs Input tensor or list of input tensors.
   *
   * @exception ValueError in case of mismatch between
   *   the provided inputs and the expectations of the layer.
   */
  assertInputCompatibility(t) {
    const e = Lt(t);
    if (this.inputSpec == null || this.inputSpec.length === 0)
      return;
    const s = Lt(this.inputSpec);
    if (e.length !== s.length)
      throw new E(`Layer ${this.name} expects ${s.length} inputs, but it received ${e.length} input tensors. Input received: ${t}`);
    for (let o = 0; o < e.length; o++) {
      const r = e[o], i6 = s[o];
      if (i6 == null)
        continue;
      const a = r.rank;
      if (i6.ndim != null && a !== i6.ndim)
        throw new E(`Input ${o} is incompatible with layer ${this.name}: expected ndim=${i6.ndim}, found ndim=${a}`);
      if (i6.maxNDim != null && a > i6.maxNDim)
        throw new E(`Input ${o} is incompatible with layer ${this.name}: expected max_ndim=${i6.maxNDim}, found ndim=${a}`);
      if (i6.minNDim != null && a < i6.minNDim)
        throw new E(`Input ${o} is incompatible with layer ${this.name}: expected min_ndim=${i6.minNDim}, found ndim=${a}.`);
      if (i6.dtype != null && r.dtype !== i6.dtype)
        throw new E(`Input ${o} is incompatible with layer ${this.name} : expected dtype=${i6.dtype}, found dtype=${r.dtype}.`);
      if (i6.axes) {
        const l = r.shape;
        for (const c in i6.axes) {
          const u = Number(c), d = i6.axes[c], h = u >= 0 ? l[u] : l[l.length + u];
          if (d != null && [d, null].indexOf(h) === -1)
            throw new E(`Input ${o} is incompatible with layer ${this.name}: expected axis ${u} of input shape to have value ${d} but got shape ${l}.`);
        }
      }
      if (i6.shape != null)
        for (let l = 0; l < i6.shape.length; ++l) {
          const c = i6.shape[l], u = r.shape[l];
          if (c != null && u != null && c !== u)
            throw new E(`Input ${o} is incompatible with layer ${this.name}: expected shape=${i6.shape}, found shape=${r.shape}.`);
        }
    }
  }
  /**
   * This is where the layer's logic lives.
   *
   * @param inputs Input tensor, or list/tuple of input tensors.
   * @param kwargs Additional keyword arguments.
   *
   * @return A tensor or list/tuple of tensors.
   */
  call(t, e) {
    return t;
  }
  invokeCallHook(t, e) {
    this._callHook != null && this._callHook(t, e);
  }
  /**
   * Set call hook.
   * This is currently used for testing only.
   * @param callHook
   */
  setCallHook(t) {
    this._callHook = t;
  }
  /**
   * Clear call hook.
   * This is currently used for testing only.
   */
  clearCallHook() {
    this._callHook = null;
  }
  /**
   * Builds or executes a `Layer`'s logic.
   *
   * When called with `tf.Tensor`(s), execute the `Layer`'s computation and
   * return Tensor(s). For example:
   *
   * ```js
   * const denseLayer = tf.layers.dense({
   *   units: 1,
   *   kernelInitializer: 'zeros',
   *   useBias: false
   * });
   *
   * // Invoke the layer's apply() method with a `tf.Tensor` (with concrete
   * // numeric values).
   * const input = tf.ones([2, 2]);
   * const output = denseLayer.apply(input);
   *
   * // The output's value is expected to be [[0], [0]], due to the fact that
   * // the dense layer has a kernel initialized to all-zeros and does not have
   * // a bias.
   * output.print();
   * ```
   *
   * When called with `tf.SymbolicTensor`(s), this will prepare the layer for
   * future execution.  This entails internal book-keeping on shapes of
   * expected Tensors, wiring layers together, and initializing weights.
   *
   * Calling `apply` with `tf.SymbolicTensor`s are typically used during the
   * building of non-`tf.Sequential` models. For example:
   *
   * ```js
   * const flattenLayer = tf.layers.flatten();
   * const denseLayer = tf.layers.dense({units: 1});
   *
   * // Use tf.layers.input() to obtain a SymbolicTensor as input to apply().
   * const input = tf.input({shape: [2, 2]});
   * const output1 = flattenLayer.apply(input);
   *
   * // output1.shape is [null, 4]. The first dimension is the undetermined
   * // batch size. The second dimension comes from flattening the [2, 2]
   * // shape.
   * console.log(JSON.stringify(output1.shape));
   *
   * // The output SymbolicTensor of the flatten layer can be used to call
   * // the apply() of the dense layer:
   * const output2 = denseLayer.apply(output1);
   *
   * // output2.shape is [null, 1]. The first dimension is the undetermined
   * // batch size. The second dimension matches the number of units of the
   * // dense layer.
   * console.log(JSON.stringify(output2.shape));
   *
   * // The input and output can be used to construct a model that consists
   * // of the flatten and dense layers.
   * const model = tf.model({inputs: input, outputs: output2});
   * ```
   *
   * @param inputs a `tf.Tensor` or `tf.SymbolicTensor` or an Array of them.
   * @param kwargs Additional keyword arguments to be passed to `call()`.
   *
   * @return Output of the layer's `call` method.
   *
   * @exception ValueError error in case the layer is missing shape information
   *   for its `build` call.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  // Porting Note: This is a replacement for __call__() in Python.
  apply(t, e) {
    e = e || {}, this.assertNotDisposed();
    const s = Lt(t), o = hL(t), r = pL(t);
    if (o === r)
      throw new E("Arguments to apply() must be all SymbolicTensors or all Tensors");
    return wo(this.name, () => {
      if (!this.built) {
        this.assertInputCompatibility(t);
        const i6 = [];
        for (const a of Lt(t))
          i6.push(a.shape);
        this.build(Xe(i6)), this.built = true, this.initialWeights && this.setWeights(this.initialWeights), this._refCount === null && r && (this._refCount = 1);
      }
      if (this.assertInputCompatibility(t), r) {
        let i6 = this.call(t, e);
        this.supportsMasking && this.setMaskMetadata(t, i6);
        const a = Lt(i6), l = [];
        for (let c of a)
          s.indexOf(c) !== -1 && (c = c.clone()), l.push(c);
        if (i6 = Xe(l), this.activityRegularizer != null)
          throw new yt("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return i6;
      } else {
        const i6 = uL(t), a = this.computeOutputShape(i6);
        let l;
        const c = dL(t);
        if (this.warnOnIncompatibleInputShape(Array.isArray(t) ? i6[0] : i6), a != null && a.length > 0 && Array.isArray(a[0]) ? l = a.map((u, d) => new os(c, u, this, Lt(t), e, this.name, d)) : l = new os(c, a, this, Lt(t), e, this.name), this.addInboundNode(t, l, null, null, i6, a, e), this._refCount++, this.activityRegularizer != null)
          throw new yt("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return l;
      }
    });
  }
  /**
   * Check compatibility between input shape and this layer's batchInputShape.
   *
   * Print warning if any incompatibility is found.
   *
   * @param inputShape Input shape to be checked.
   */
  warnOnIncompatibleInputShape(t) {
    if (this.batchInputShape != null)
      if (t.length !== this.batchInputShape.length)
        console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);
      else {
        let e = false;
        this.batchInputShape.forEach((s, o) => {
          s != null && t[o] != null && t[o] !== s && (e = true);
        }), e && console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`);
      }
  }
  /**
   * Retrieves the output shape(s) of a layer.
   *
   * Only applicable if the layer has only one inbound node, or if all inbound
   * nodes have the same output shape.
   *
   * @returns Output shape or shapes.
   * @throws AttributeError: if the layer is connected to more than one incoming
   *   nodes.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  get outputShape() {
    if (this.inboundNodes == null || this.inboundNodes.length === 0)
      throw new Qn(`The layer ${this.name} has never been called and thus has no defined output shape.`);
    const t = [];
    for (const e of this.inboundNodes) {
      const s = JSON.stringify(e.outputShapes);
      t.indexOf(s) === -1 && t.push(s);
    }
    if (t.length === 1) {
      const e = this.inboundNodes[0].outputShapes;
      return Array.isArray(e) && Array.isArray(e[0]) && e.length === 1 ? e[0] : e;
    } else
      throw new Qn(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`);
  }
  /**
   * Counts the total number of numbers (e.g., float32, int32) in the
   * weights.
   *
   * @returns An integer count.
   * @throws RuntimeError: If the layer is not built yet (in which case its
   *   weights are not defined yet.)
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  countParams() {
    if (!this.built)
      throw new Sn(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);
    return Nl(this.weights);
  }
  /**
   * Creates the layer weights.
   *
   * Must be implemented on all layers that have weights.
   *
   * Called when apply() is called to construct the weights.
   *
   * @param inputShape A `Shape` or array of `Shape` (unused).
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  build(t) {
    this.built = true;
  }
  /**
   * Returns the current values of the weights of the layer.
   *
   * @param trainableOnly Whether to get the values of only trainable weights.
   * @returns Weight values as an `Array` of `tf.Tensor`s.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  getWeights(t = false) {
    return Ed(t ? this.trainableWeights : this.weights);
  }
  /**
   * Sets the weights of the layer, from Tensors.
   *
   * @param weights a list of Tensors. The number of arrays and their shape
   *   must match number of the dimensions of the weights of the layer (i.e.
   *   it should match the output of `getWeights`).
   *
   * @exception ValueError If the provided weights list does not match the
   *   layer's specifications.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  setWeights(t) {
    D(() => {
      const e = this.weights;
      if (e.length !== t.length)
        throw new E(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);
      if (e.length === 0)
        return;
      const s = [], o = Ed(e);
      for (let r = 0; r < o.length; ++r) {
        const i6 = o[r], a = e[r], l = t[r];
        if (!$t(i6.shape, l.shape))
          throw new E(`Layer weight shape ${i6.shape} not compatible with provided weight shape ${l.shape}`);
        s.push([a, l]);
      }
      Tf(s);
    });
  }
  /**
   * Adds a weight variable to the layer.
   *
   * @param name Name of the new weight variable.
   * @param shape The shape of the weight.
   * @param dtype The dtype of the weight.
   * @param initializer An initializer instance.
   * @param regularizer A regularizer instance.
   * @param trainable Whether the weight should be trained via backprop or not
   *   (assuming that the layer itself is also trainable).
   * @param constraint An optional trainable.
   * @return The created weight variable.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  addWeight(t, e, s, o, r, i6, a, l) {
    if (this._addedWeightNames.indexOf(t) !== -1)
      throw new E(`Duplicate weight name ${t} for layer ${this.name}`);
    this._addedWeightNames.push(t), s == null && (s = "float32"), this.fastWeightInitDuringBuild && (o = l != null ? l() : Ut("zeros"));
    const c = o.apply(e, s), u = new iL(c, s, t, i6, a);
    return c.dispose(), r != null && this.addLoss(() => r.apply(u.read())), i6 == null && (i6 = true), i6 ? this._trainableWeights.push(u) : this._nonTrainableWeights.push(u), u;
  }
  /**
   * Set the fast-weight-initialization flag.
   *
   * In cases where the initialized weight values will be immediately
   * overwritten by loaded weight values during model loading, setting
   * the flag to `true` saves unnecessary calls to potentially expensive
   * initializers and speeds up the loading process.
   *
   * @param value Target value of the flag.
   */
  setFastWeightInitDuringBuild(t) {
    this.fastWeightInitDuringBuild = t;
  }
  /**
   * Add losses to the layer.
   *
   * The loss may potentially be conditional on some inputs tensors,
   * for instance activity losses are conditional on the layer's inputs.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  addLoss(t) {
    t == null || Array.isArray(t) && t.length === 0 || (t = Lt(t), this._losses !== void 0 && this._losses !== null && this.losses.push(...t));
  }
  /**
   * Computes the output shape of the layer.
   *
   * Assumes that the layer will be built to match that input shape provided.
   *
   * @param inputShape A shape (tuple of integers) or a list of shape tuples
   *   (one per output tensor of the layer). Shape tuples can include null for
   *   free dimensions, instead of an integer.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  computeOutputShape(t) {
    return t;
  }
  /**
   * Computes an output mask tensor.
   *
   * @param inputs Tensor or list of tensors.
   * @param mask Tensor or list of tensors.
   *
   * @return null or a tensor (or list of tensors, one per output tensor of the
   * layer).
   */
  computeMask(t, e) {
    if (!this.supportsMasking) {
      if (e != null)
        if (Array.isArray(e))
          e.forEach((s) => {
            if (s != null)
              throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
          });
        else
          throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
      return null;
    }
    return e;
  }
  setMaskMetadata(t, e, s) {
    if (!this.supportsMasking)
      return;
    const o = this.computeMask(t, s), r = Lt(e), i6 = Lt(o);
    if (r.length !== i6.length)
      throw new Error(`${this.name} outputs ${r.length} tensors but ${r.length} masks for those tensors`);
    for (let a = 0; a < r.length; a++)
      r[a].kerasMask = i6[a];
  }
  /**
   * Internal method to create an inbound node for the layer.
   *
   * @param inputTensors List of input tensors.
   * @param outputTensors List of output tensors.
   * @param inputMasks List of input masks (a mask can be a tensor, or null).
   * @param outputMasks List of output masks (a mask can be a tensor, or null).
   * @param inputShapes List of input shape tuples.
   * @param outputShapes List of output shape tuples.
   * @param kwargs Dictionary of keyword arguments that were passed to the
   *   `call` method of the layer at the call that created the node.
   */
  addInboundNode(t, e, s, o, r, i6, a = null) {
    const l = Lt(t);
    e = Lt(e), s = Lt(s), o = Lt(o), r = Tl(r), i6 = Tl(i6);
    const c = [], u = [], d = [];
    for (const h of l)
      c.push(h.sourceLayer), u.push(h.nodeIndex), d.push(h.tensorIndex);
    new cu({
      outboundLayer: this,
      inboundLayers: c,
      nodeIndices: u,
      tensorIndices: d,
      inputTensors: l,
      outputTensors: e,
      inputMasks: s,
      outputMasks: o,
      inputShapes: r,
      outputShapes: i6
    }, a);
    for (let h = 0; h < e.length; h++)
      e[h].sourceLayer = this, e[h].nodeIndex = this.inboundNodes.length - 1, e[h].tensorIndex = h;
  }
  /**
   * Returns the config of the layer.
   *
   * A layer config is a TS dictionary (serializable)
   * containing the configuration of a layer.
   * The same layer can be reinstantiated later
   * (without its trained weights) from this configuration.
   *
   * The config of a layer does not include connectivity
   * information, nor the layer class name.  These are handled
   * by 'Container' (one layer of abstraction above).
   *
   * Porting Note: The TS dictionary follows TS naming standards for
   * keys, and uses tfjs-layers type-safe Enums.  Serialization methods
   * should use a helper function to convert to the pythonic storage
   * standard. (see serialization_utils.convertTsToPythonic)
   *
   * @returns TS dictionary of configuration.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  getConfig() {
    const t = { name: this.name, trainable: this.trainable };
    return this.batchInputShape != null && (t.batchInputShape = this.batchInputShape), this.dtype != null && (t.dtype = this.dtype), t;
  }
  /**
   * Dispose the weight variables that this Layer instance holds.
   *
   * @returns {number} Number of disposed variables.
   */
  disposeWeights() {
    return this.weights.forEach((t) => t.dispose()), this.weights.length;
  }
  assertNotDisposed() {
    if (this._refCount === 0)
      throw new Error(`Layer '${this.name}' is already disposed.`);
  }
  /**
   * Attempt to dispose layer's weights.
   *
   * This method decreases the reference count of the Layer object by 1.
   *
   * A Layer is reference-counted. Its reference count is incremented by 1
   * the first item its `apply()` method is called and when it becomes a part
   * of a new `Node` (through calling the `apply()` method on a
   * `tf.SymbolicTensor`).
   *
   * If the reference count of a Layer becomes 0, all the weights will be
   * disposed and the underlying memory (e.g., the textures allocated in WebGL)
   * will be freed.
   *
   * Note: If the reference count is greater than 0 after the decrement, the
   * weights of the Layer will *not* be disposed.
   *
   * After a Layer is disposed, it cannot be used in calls such as `apply()`,
   * `getWeights()` or `setWeights()` anymore.
   *
   * @returns A DisposeResult Object with the following fields:
   *   - refCountAfterDispose: The reference count of the Container after this
   *     `dispose()` call.
   *   - numDisposedVariables: Number of `tf.Variable`s (i.e., weights) disposed
   *     during this `dispose()` call.
   * @throws {Error} If the layer is not built yet, or if the layer has already
   *   been disposed.
   *
   * @doc {heading: 'Models', 'subheading': 'Classes'}
   */
  dispose() {
    if (!this.built)
      throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);
    if (this._refCount === null)
      throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);
    this.assertNotDisposed();
    let t = 0;
    return --this._refCount === 0 && (t = this.disposeWeights()), { refCountAfterDispose: this._refCount, numDisposedVariables: t };
  }
};
function uL(n) {
  n = Lt(n);
  const t = [];
  for (const e of n)
    t.push(e.shape);
  return Xe(t);
}
function dL(n) {
  return "float32";
}
function Vx(n, t, e) {
  if ((t == null || e != null && e > 0) && (t = n.sourceLayer, e = n.nodeIndex), t.inboundNodes.length === 0)
    return [n];
  {
    const s = t.inboundNodes[e];
    if (s.inboundLayers.length === 0)
      return s.inputTensors;
    {
      const o = [];
      for (let r = 0; r < s.inboundLayers.length; r++) {
        const i6 = s.inputTensors[r], a = s.inboundLayers[r], l = s.nodeIndices[r], c = Vx(i6, a, l);
        for (const u of c)
          o.indexOf(u) === -1 && o.push(u);
      }
      return o;
    }
  }
}
function hL(n) {
  let t = true;
  for (const e of Lt(n))
    if (!(e instanceof os)) {
      t = false;
      break;
    }
  return t;
}
function pL(n) {
  let t = true;
  for (const e of Lt(n))
    if (e instanceof os) {
      t = false;
      break;
    }
  return t;
}
var Wa = class extends St {
  constructor(t) {
    if (super({
      dtype: t.dtype,
      name: t.name != null ? t.name : au("input").toString()
    }), t.batchSize == null && (t.batchSize = null), t.sparse == null && (t.sparse = false), this.trainable = false, this.built = true, this.sparse = t.sparse, t.inputShape != null && t.batchInputShape != null)
      throw new E("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
    let e = t.batchInputShape;
    if (e == null) {
      if (t.inputShape == null)
        throw new E("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
      e = [t.batchSize].concat(t.inputShape);
    } else if (t.batchSize != null)
      throw new E("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");
    const s = t.dtype || "float32";
    this.batchInputShape = e, this.dtype = s, this.inputSpec = [{ shape: e }];
    const o = new os(this.dtype, this.batchInputShape, this, [], {}, this.name);
    o.nodeIndex = 0, o.tensorIndex = 0, new cu({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: [o],
      outputTensors: [o],
      inputMasks: [null],
      outputMasks: [null],
      inputShapes: [e],
      outputShapes: [e]
    });
  }
  apply(t, e) {
    throw new E(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`);
  }
  dispose() {
    return { refCountAfterDispose: this._refCount, numDisposedVariables: 0 };
  }
  getConfig() {
    return {
      batchInputShape: this.batchInputShape,
      dtype: this.dtype,
      sparse: this.sparse,
      name: this.name
    };
  }
};
Wa.className = "InputLayer";
_(Wa);
function fL(n) {
  if (n.batchShape == null && n.shape == null)
    throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
  if (n.batchShape != null && n.shape != null)
    throw new E("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
  let t = n.batchShape;
  n.shape != null && t == null && (t = [null].concat(n.shape));
  let e = n.dtype;
  return e == null && (e = "float32"), new Wa({
    batchInputShape: t,
    name: n.name,
    dtype: e,
    sparse: n.sparse
  }).inboundNodes[0].outputTensors[0];
}
function mL(n, t) {
  if (n.dtype == null || n.dtype === t.dtype)
    return t;
  try {
    return tt(t, n.dtype);
  } catch {
    throw new E(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${n.name}' (${n.dtype}).`);
  }
}
var Ds = class _Ds {
  /**
   * Constructor, optionally does copy-construction.
   * @param feeds An Array of `Feed`s, or another `FeedDict`, in which case
   *   copy-construction will be performed.
   */
  constructor(t) {
    if (this.id2Value = {}, this.id2Mask = {}, this.name2Id = {}, t instanceof _Ds)
      for (const e in t.id2Value)
        this.id2Value[e] = t.id2Value[e], e in t.id2Mask && (this.id2Mask[e] = t.id2Mask[e]);
    else {
      if (t == null)
        return;
      for (const e of t)
        this.add(e.key, e.value);
    }
  }
  /**
   * Add a key-value pair to the FeedDict.
   *
   * @param key The key of the feed.
   * @param value The value of the tensor feed.
   * @param mask The value of the mask feed (optional).
   * @returns This `FeedDict`.
   * @throws ValueError: If the key `SymbolicTensor` already exists in the
   *   `FeedDict`.
   */
  add(t, e, s) {
    if (this.id2Value[t.id] == null)
      this.id2Value[t.id] = mL(t, e), this.name2Id[t.name] = t.id, s != null && (this.id2Mask[t.id] = s);
    else
      throw new E(`Duplicate key: name=${t.name}, id=${t.id}`);
    return this;
  }
  /**
   * Add a Feed to the FeedDict.
   * @param feed The new `Feed` to add.
   * @returns This `FeedDict`.
   */
  addFeed(t) {
    this.add(t.key, t.value);
  }
  /**
   * Probe whether a key already exists in the FeedDict.
   * @param key
   */
  hasKey(t) {
    return this.id2Value[t.id] != null;
  }
  /**
   * Get all the SymbolicTensor available in this FeedDict.
   */
  names() {
    return Object.keys(this.name2Id);
  }
  /**
   * Get the feed value for given key.
   * @param key The SymbolicTensor, or its name (as a string), of which the
   *     value is sought.
   * @returns If `key` exists, the corresponding feed value.
   * @throws ValueError: If `key` does not exist in this `FeedDict`.
   */
  getValue(t) {
    if (t instanceof os) {
      if (this.id2Value[t.id] == null)
        throw new E(`Nonexistent key: ${t.name}`);
      return this.id2Value[t.id];
    } else {
      const e = this.name2Id[t];
      if (e == null)
        throw new E(`Feed dict has no SymbolicTensor name: ${t}`);
      return this.id2Value[e];
    }
  }
  /**
   * Get the feed mask for given key.
   * @param key The SymbolicTensor, or its name (as a string), of which the
   *     value is sought.
   * @returns If `key` exists, the corresponding feed mask.
   * @throws ValueError: If `key` does not exist in this `FeedDict`.
   */
  getMask(t) {
    if (t instanceof os) {
      if (this.id2Value[t.id] == null)
        throw new E(`Nonexistent key: ${t.name}`);
      return this.id2Mask[t.id];
    } else {
      const e = this.name2Id[t];
      if (e == null)
        throw new E(`Feed dict has no SymbolicTensor name: ${t}`);
      return this.id2Mask[e];
    }
  }
  /** Dispose all mask Tensors held by this object. */
  disposeMasks() {
    this.id2Mask != null && xt(this.id2Mask);
  }
};
var Rl = new wx();
var $l = new wx();
function gL(n) {
  Rl != null && Rl.setMaxEntries(n), $l != null && $l.setMaxEntries(n);
}
function Yr(n, t, e, s) {
  const o = e == null ? false : e.training, r = Array.isArray(n), i6 = r ? n : [n], a = i6.map((f) => f.name), l = [], c = t.names();
  for (const f of a)
    c.indexOf(f) !== -1 ? l.push(t.getValue(f)) : l.push(null);
  s != null && (s.maxNumTensors = -1 / 0, s.minNumTensors = 1 / 0);
  const u = a.join(",") + "|" + t.names().sort().join(",");
  let d = Rl.get(u), h;
  if (d == null) {
    const f = bL(i6, t);
    d = f.sorted, h = f.recipientCounts, Rl.put(u, d), $l.put(u, h);
  }
  h = {}, o || Object.assign(h, $l.get(u));
  const p = new Ds(t);
  for (let f = 0; f < d.length; ++f) {
    if (s != null) {
      const N = wl().numTensors;
      N > s.maxNumTensors && (s.maxNumTensors = N), N < s.minNumTensors && (s.minNumTensors = N);
    }
    const m = d[f], g = m.sourceLayer;
    if (g instanceof Wa)
      continue;
    const b = [], x6 = [], w = [];
    let y6 = false;
    for (const N of m.inputs) {
      const R = p.getValue(N), M6 = p.getMask(N);
      b.push(R), x6.push(M6), M6 != null && (y6 = true), o || (h[N.name]--, h[N.name] === 0 && !t.hasKey(N) && a.indexOf(N.name) === -1 && !R.isDisposed && N.sourceLayer.stateful !== true && w.push(R));
    }
    y6 && (e = e || {}, e.mask = x6[0]);
    const I = Lt(g.apply(b, e));
    let v = null;
    g.supportsMasking && (v = g.computeMask(b, x6));
    const k6 = yL(m), S = Array.isArray(k6) ? k6 : [k6];
    for (let N = 0; N < S.length; ++N) {
      p.hasKey(S[N]) || p.add(S[N], I[N], Array.isArray(v) ? v[0] : v);
      const R = a.indexOf(S[N].name);
      R !== -1 && (l[R] = I[N]);
    }
    o || xt(w);
  }
  return p.disposeMasks(), r ? l : l[0];
}
function bL(n, t) {
  C(n != null && n.length > 0, () => "Expected at least one fetch, got none");
  let e = [], s = {};
  if (n.length === 1) {
    const o = Um(n[0], t);
    e = o.sorted, s = o.recipientMap;
  } else {
    const o = /* @__PURE__ */ new Set();
    for (const r of n) {
      const { sorted: i6, recipientMap: a } = Um(r, t);
      for (const l of i6)
        o.has(l.name) || (e.push(l), o.add(l.name));
      for (const l in a)
        s[l] == null && (s[l] = /* @__PURE__ */ new Set()), a[l].forEach((c) => s[l].add(c));
    }
  }
  return {
    sorted: e,
    recipientCounts: xL(s)
  };
}
function xL(n) {
  const t = {};
  for (const e in n)
    t[e] = n[e].size;
  return t;
}
function Um(n, t) {
  const e = /* @__PURE__ */ new Set(), s = [], o = {};
  for (const a of t.names())
    e.add(a);
  const r = [], i6 = [];
  for (r.push(n); r.length > 0; ) {
    const a = r[r.length - 1];
    if (e.has(a.name)) {
      r.pop();
      continue;
    }
    const l = i6[i6.length - 1] === r.length - 1;
    if (a.inputs.length === 0 || l)
      r.pop(), s.push(a), e.add(a.name), l && i6.pop();
    else {
      i6.push(r.length - 1);
      for (const c of a.inputs)
        o[c.name] == null && (o[c.name] = /* @__PURE__ */ new Set()), o[c.name].add(a.name), !e.has(c.name) && r.push(c);
    }
  }
  return { sorted: s, recipientMap: o };
}
function yL(n) {
  let t;
  if (n.sourceLayer.inboundNodes.length === 1)
    t = n.sourceLayer.output;
  else {
    let e = null;
    for (let s = 0; s < n.sourceLayer.inboundNodes.length; ++s)
      for (const o of n.sourceLayer.inboundNodes[s].outputTensors)
        if (o.id === n.id) {
          e = s;
          break;
        }
    t = n.sourceLayer.getOutputAt(e);
  }
  return t;
}
var wL = F();
wL.registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES", () => 100, gL);
function Nf(n, t) {
  return D(() => Ve(at(G(n, n), t, true)));
}
var Da = class extends _o {
  getConfig() {
    return {};
  }
};
var zx = class extends Da {
  constructor(t) {
    super(), this.defaultMaxValue = 2, this.defaultAxis = 0, this.maxValue = t.maxValue != null ? t.maxValue : this.defaultMaxValue, this.axis = t.axis != null ? t.axis : this.defaultAxis;
  }
  apply(t) {
    return D(() => {
      const e = Nf(t, this.axis), s = fn(e, 0, this.maxValue);
      return G(t, ut(s, U(ue(), e)));
    });
  }
  getConfig() {
    return { maxValue: this.maxValue, axis: this.axis };
  }
};
zx.className = "MaxNorm";
_(zx);
var Px = class extends Da {
  constructor(t) {
    super(), this.defaultAxis = 0, this.axis = t.axis != null ? t.axis : this.defaultAxis;
  }
  apply(t) {
    return D(() => ut(t, U(ue(), Nf(t, this.axis))));
  }
  getConfig() {
    return { axis: this.axis };
  }
};
Px.className = "UnitNorm";
_(Px);
var Ax = class extends Da {
  apply(t) {
    return Ts(t);
  }
};
Ax.className = "NonNeg";
_(Ax);
var Ox = class extends Da {
  constructor(t) {
    super(), this.defaultMinValue = 0, this.defaultMaxValue = 1, this.defaultRate = 1, this.defaultAxis = 0, this.minValue = t.minValue != null ? t.minValue : this.defaultMinValue, this.maxValue = t.maxValue != null ? t.maxValue : this.defaultMaxValue, this.rate = t.rate != null ? t.rate : this.defaultRate, this.axis = t.axis != null ? t.axis : this.defaultAxis;
  }
  apply(t) {
    return D(() => {
      const e = Nf(t, this.axis), s = U(G(this.rate, fn(e, this.minValue, this.maxValue)), G(1 - this.rate, e));
      return G(t, ut(s, U(ue(), e)));
    });
  }
  getConfig() {
    return {
      minValue: this.minValue,
      maxValue: this.maxValue,
      rate: this.rate,
      axis: this.axis
    };
  }
};
Ox.className = "MinMaxNorm";
_(Ox);
var Ym = {
  maxNorm: "MaxNorm",
  minMaxNorm: "MinMaxNorm",
  nonNeg: "NonNeg",
  unitNorm: "UnitNorm"
};
function he(n) {
  return gf(n);
}
function Qm(n, t = {}) {
  return Ga(n, cn.getMap().classNameMap, t, "constraint");
}
function pe(n) {
  if (n == null)
    return null;
  if (typeof n == "string") {
    const e = { className: n in Ym ? Ym[n] : n, config: {} };
    return Qm(e);
  } else
    return n instanceof Da ? n : Qm(n);
}
async function ao(n) {
  if (n == null)
    return;
  const t = [], e = [], s = [];
  for (const o in n) {
    const r = n[o];
    if (typeof r != "number") {
      const i6 = r;
      t.push(i6.data()), e.push(o), s.push(i6);
    }
  }
  if (t.length > 0) {
    const o = await Promise.all(t);
    for (let r = 0; r < o.length; ++r)
      n[e[r]] = o[r][0];
    xt(s);
  }
}
function Xx(n) {
  if (n != null)
    for (const t in n) {
      const e = n[t];
      typeof e != "number" && e.dispose();
    }
}
var Jm;
(function(n) {
  n[n.SILENT = 0] = "SILENT", n[n.VERBOSE = 1] = "VERBOSE";
})(Jm || (Jm = {}));
var IL = 125;
var hi = class {
  constructor() {
    this.validationData = null;
  }
  setParams(t) {
    this.params = t;
  }
  async onEpochBegin(t, e) {
  }
  async onEpochEnd(t, e) {
  }
  async onBatchBegin(t, e) {
  }
  async onBatchEnd(t, e) {
  }
  async onTrainBegin(t) {
  }
  async onTrainEnd(t) {
  }
  // LayersModel needs to call Callback.setModel(), but cannot actually depend
  // on Callback because that creates a cyclic dependency.  Providing this no-op
  // method on BaseCallback breaks the cycle: this way LayersModel can depend on
  // BaseCallback but not on Callback.  The argument is typed as `Container`
  // (the superclass of LayersModel) to avoid recapitulating the cycle. Callback
  // overrides this method and enforces that the argument is really a
  // LayersModel.
  setModel(t) {
  }
};
var CL = class {
  // TODO(cais): When the need arises, uncomment the following lines and
  // implement the queue for time values.
  // private deltaTBatch: number;
  // private deltaTsBatchBegin: Array<number>;
  // private deltaTsBatchEnd: Array<number>;
  /**
   * Constructor of CallbackList.
   * @param callbacks Array of `Callback` instances.
   * @param queueLength Queue length for keeping running statistics over
   *   callback execution time.
   */
  constructor(t, e = 10) {
    t == null && (t = []), this.callbacks = t, this.queueLength = e;
  }
  append(t) {
    this.callbacks.push(t);
  }
  setParams(t) {
    for (const e of this.callbacks)
      e.setParams(t);
  }
  setModel(t) {
    for (const e of this.callbacks)
      e.setModel(t);
  }
  /**
   * Called at the start of an epoch.
   * @param epoch Index of epoch.
   * @param logs Dictionary of logs.
   */
  async onEpochBegin(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onEpochBegin(t, e);
  }
  /**
   * Called at the end of an epoch.
   * @param epoch Index of epoch.
   * @param logs Dictionary of logs.
   */
  async onEpochEnd(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onEpochEnd(t, e);
  }
  /**
   * Called  right before processing a batch.
   * @param batch Index of batch within the current epoch.
   * @param logs Dictionary of logs.
   */
  async onBatchBegin(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onBatchBegin(t, e);
  }
  /**
   * Called at the end of a batch.
   * @param batch Index of batch within the current epoch.
   * @param logs Dictionary of logs.
   */
  async onBatchEnd(t, e) {
    e == null && (e = {});
    for (const s of this.callbacks)
      await s.onBatchEnd(t, e);
  }
  /**
   * Called at the beginning of training.
   * @param logs Dictionary of logs.
   */
  async onTrainBegin(t) {
    t == null && (t = {});
    for (const e of this.callbacks)
      await e.onTrainBegin(t);
  }
  /**
   * Called at the end of training.
   * @param logs Dictionary of logs.
   */
  async onTrainEnd(t) {
    t == null && (t = {});
    for (const e of this.callbacks)
      await e.onTrainEnd(t);
  }
};
var vL = class extends hi {
  constructor() {
    super();
  }
  async onEpochBegin(t) {
    this.seen = 0, this.totals = {};
  }
  async onBatchEnd(t, e) {
    e == null && (e = {});
    const s = e.size == null ? 0 : e.size;
    this.seen += s;
    for (const o in e) {
      const r = e[o];
      if (typeof r == "number")
        this.totals.hasOwnProperty(o) || (this.totals[o] = 0), this.totals[o] = this.totals[o] + r * s;
      else {
        let i6;
        o in this.totals ? i6 = this.totals[o] : this.totals[o] = 0;
        const a = D(() => U(this.totals[o], G(r, s)));
        this.totals[o] = a, i6 != null && i6.dispose();
      }
    }
  }
  async onEpochEnd(t, e) {
    if (e != null)
      for (const s of this.params.metrics)
        this.totals[s] != null && (typeof this.totals[s] == "number" ? e[s] = this.totals[s] / this.seen : D(() => {
          const o = G(ut(1, this.seen), this.totals[s]);
          e[s] = o, this.totals[s].dispose(), hn(e[s]);
        }));
  }
};
var SL = class extends hi {
  async onTrainBegin(t) {
    this.epoch = [], this.history = {};
  }
  async onEpochEnd(t, e) {
    e == null && (e = {}), this.epoch.push(t);
    for (const s in e)
      this.history[s] == null && (this.history[s] = []), this.history[s].push(e[s]);
  }
  /**
   * Await the values of all losses and metrics.
   */
  async syncData() {
    const t = [], e = [], s = [];
    for (const r in this.history) {
      const i6 = this.history[r];
      for (let a = 0; a < i6.length; ++a)
        if (typeof i6[a] != "number") {
          const l = i6[a];
          t.push(l.data()), e.push(r), s.push(a);
        }
    }
    const o = await Promise.all(t);
    for (let r = 0; r < o.length; ++r)
      this.history[e[r]][s[r]].dispose(), this.history[e[r]][s[r]] = o[r][0];
  }
};
var kL = class extends hi {
  constructor(t, e) {
    if (super(), this.currentEpoch = 0, this.nowFunc = t.nowFunc, this.nextFrameFunc = t.nextFrameFunc || su, this.yieldEvery = e || "auto", this.yieldEvery === "auto" && (this.yieldEvery = IL), this.yieldEvery === "never" && t.onYield != null)
      throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
    pl(this.yieldEvery) && (this.maybeWait = zE(this.maybeWait.bind(this), this.yieldEvery, this.nowFunc)), this.trainBegin = t.onTrainBegin, this.trainEnd = t.onTrainEnd, this.epochBegin = t.onEpochBegin, this.epochEnd = t.onEpochEnd, this.batchBegin = t.onBatchBegin, this.batchEnd = t.onBatchEnd, this.yield = t.onYield;
  }
  async maybeWait(t, e, s) {
    const o = [];
    this.yield != null && (await ao(s), o.push(this.yield(t, e, s))), o.push(this.nextFrameFunc()), await Promise.all(o);
  }
  async onEpochBegin(t, e) {
    this.currentEpoch = t, this.epochBegin != null && (await ao(e), await this.epochBegin(t, e));
  }
  async onEpochEnd(t, e) {
    const s = [];
    this.epochEnd != null && (await ao(e), s.push(this.epochEnd(t, e))), this.yieldEvery === "epoch" && s.push(this.nextFrameFunc()), await Promise.all(s);
  }
  async onBatchBegin(t, e) {
    this.batchBegin != null && (await ao(e), await this.batchBegin(t, e));
  }
  async onBatchEnd(t, e) {
    const s = [];
    this.batchEnd != null && (await ao(e), s.push(this.batchEnd(t, e))), this.yieldEvery === "batch" ? s.push(this.nextFrameFunc()) : pl(this.yieldEvery) && s.push(this.maybeWait(this.currentEpoch, t, e)), await Promise.all(s);
  }
  async onTrainBegin(t) {
    this.trainBegin != null && (await ao(t), await this.trainBegin(t));
  }
  async onTrainEnd(t) {
    this.trainEnd != null && (await ao(t), await this.trainEnd(t));
  }
};
function Kx(n, t) {
  return n == null && (n = {}), n instanceof hi ? [n] : Array.isArray(n) && n[0] instanceof hi ? n : Lt(n).map((s) => new kL(s, t));
}
var wn = class _wn {
  /**
   * Blocks public access to constructor.
   */
  constructor() {
  }
  /**
   * Register a tf.LayersModel.fit() callback constructor.
   *
   * The registered callback constructor will be used to instantiate
   * callbacks for every tf.LayersModel.fit() call afterwards.
   *
   * @param verbosityLevel Level of verbosity at which the `callbackConstructor`
   *   is to be reigstered.
   * @param callbackConstructor A no-arg constructor for `tf.Callback`.
   * @throws Error, if the same callbackConstructor has been registered before,
   *   either at the same or a different `verbosityLevel`.
   */
  static registerCallbackConstructor(t, e) {
    C(t >= 0 && Number.isInteger(t), () => `Verbosity level is expected to be an integer >= 0, but got ${t}`), _wn.checkForDuplicate(e), _wn.constructors[t] == null && (_wn.constructors[t] = []), _wn.constructors[t].push(e);
  }
  static checkForDuplicate(t) {
    for (const e in _wn.constructors)
      _wn.constructors[+e].forEach((o) => {
        if (o === t)
          throw new E("Duplicate callback constructor.");
      });
  }
  /**
   * Clear all registered callback constructors.
   */
  static clear() {
    _wn.constructors = {};
  }
  /**
   * Create callbacks using the registered callback constructors.
   *
   * Given `verbosityLevel`, all constructors registered at that level or above
   * will be called and the instantiated callbacks will be used.
   *
   * @param verbosityLevel: Level of verbosity.
   */
  static createCallbacks(t) {
    const e = [];
    for (const s in _wn.constructors) {
      const o = +s;
      t >= o && e.push(..._wn.constructors[o]);
    }
    return e.map((s) => new s());
  }
};
wn.constructors = {};
function Zx(n, t, e, s, o, r, i6, a, l) {
  const c = new SL(), u = [
    new vL(),
    ...wn.createCallbacks(t)
  ];
  n != null && u.push(...n), u.push(c);
  const d = new CL(u);
  return d.setParams({
    epochs: e,
    initialEpoch: s,
    samples: o,
    steps: r,
    batchSize: i6,
    verbose: t,
    doValidation: a,
    metrics: l
  }), { callbackList: d, history: c };
}
function An(n, t = {}, e = false) {
  return Ga(n, cn.getMap().classNameMap, t, "layer", e);
}
function Gl(n, t) {
  return D(() => {
    n.dtype !== "float32" && (n = tt(n, "float32"));
    const e = at(La(n), t, true), s = Ca(e.shape, ue()), o = Ve(qs(e, s));
    return ut(n, o);
  });
}
function uu(n, t) {
  return D(() => oe(La(it(t, n)), -1));
}
function Rf(n, t) {
  return D(() => oe(me(it(t, n)), -1));
}
function $f(n, t) {
  return D(() => {
    const e = it(n, t), s = fn(me(n), ue(), Number.MAX_VALUE), o = me(ut(e, s));
    return G(100, oe(o, -1));
  });
}
function TL(n, t) {
  return D(() => {
    const e = fn(t, ue(), Number.MAX_VALUE), s = Nn(U(1, e)), o = fn(n, ue(), Number.MAX_VALUE), r = Nn(U(1, o));
    return oe(La(it(s, r)), -1);
  });
}
function NL(n, t) {
  return D(() => {
    const e = qs(0, it(1, G(n, t)));
    return oe(La(e), -1);
  });
}
function RL(n, t) {
  return D(() => {
    const e = qs(0, it(1, G(n, t)));
    return oe(e, -1);
  });
}
function $L(n, t) {
  return D(() => {
    const e = at(G(n, t), -1), s = Pn(G(it(1, n), t), -1);
    return qs(0, U(1, it(s, e)));
  });
}
function GL(n, t) {
  return D(() => {
    const e = Math.log(2), s = it(t, n), o = it(U(s, va(G(-2, s))), e);
    return oe(o, -1);
  });
}
function pi(n, t, e = false) {
  return D(() => {
    if (e)
      t = $p(t);
    else {
      const s = at(t, t.shape.length - 1, true);
      t = ut(t, s);
    }
    return t = fn(t, ue(), 1 - ue()), Yt(at(G(tt(n, "float32"), Nn(t)), t.shape.length - 1));
  });
}
function El(n, t, e = false) {
  return D(() => {
    const s = tt(qc(QE(n)), "int32");
    t = fn(t, ue(), 1 - ue());
    const o = t.shape, r = W(a0(s, o[o.length - 1]), o);
    return pi(r, t, e);
  });
}
function EL(n, t) {
  if (!$t(n.shape, t.shape))
    throw new E(`logits and labels must have the same shape, but got shapes ${JSON.stringify(n.shape)} and ${JSON.stringify(t.shape)}`);
  return D(() => {
    const e = Ts(t), s = Yt(me(t));
    return U(it(e, G(t, n)), hp(mn(s)));
  });
}
function du(n, t) {
  return D(() => {
    let e;
    return e = fn(t, ue(), 1 - ue()), e = Nn(ut(e, it(1, e))), oe(EL(n, e), -1);
  });
}
function LL(n, t) {
  return D(() => {
    const e = fn(n, ue(), 1), s = fn(t, ue(), 1);
    return at(G(n, Nn(ut(e, s))), -1);
  });
}
function ML(n, t) {
  return D(() => {
    const e = Nn(U(ue(), t));
    return oe(it(t, G(n, e)), -1);
  });
}
function Bx(n, t) {
  return D(() => {
    const e = Gl(n, -1), s = Gl(t, -1), o = G(e, s);
    return Yt(at(o, -1));
  });
}
var Ll = {
  meanSquaredError: uu,
  meanAbsoluteError: Rf,
  meanAbsolutePercentageError: $f,
  meanSquaredLogarithmicError: TL,
  squaredHinge: NL,
  hinge: RL,
  categoricalHinge: $L,
  logcosh: GL,
  categoricalCrossentropy: pi,
  sparseCategoricalCrossentropy: El,
  binaryCrossentropy: du,
  kullbackLeiblerDivergence: LL,
  poisson: ML,
  cosineProximity: Bx
};
function Fu(n) {
  if (typeof n == "string") {
    if (n in Ll)
      return Ll[n];
    let t = `Unknown loss ${n}`;
    throw n.toLowerCase().includes("softmaxcrossentropy") && (t = `Unknown loss ${n}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`), new E(t);
  } else
    return n;
}
function Hx(n, t) {
  return D(() => {
    const e = G(0.5, Rn(t)), s = es(rn(t, e), n.dtype);
    return oe(Tn(n, s), -1);
  });
}
function _x(n, t) {
  return D(() => es(Tn(ai(n, -1), ai(t, -1)), "float32"));
}
function Ux(n, t) {
  return D(() => tt(at(ss(Tn(n, 1), Tn(t, 1))), "float32"));
}
function WL(n, t) {
  return D(() => tt(at(ss(Tn(n, 1), Tn(t, 0))), "float32"));
}
function DL(n, t) {
  return D(() => tt(at(ss(Tn(n, 0), Tn(t, 1))), "float32"));
}
function FL(n, t) {
  return D(() => {
    const e = Ux(n, t), s = DL(n, t), o = U(e, s);
    return tt(Ee(rn(o, 0), ut(e, o), 0), "float32");
  });
}
function DQ(n, t) {
  return D(() => {
    const e = Ux(n, t), s = WL(n, t), o = U(e, s);
    return tt(Ee(rn(o, 0), ut(e, o), 0), "float32");
  });
}
function VL(n, t) {
  return du(n, t);
}
function zL(n, t) {
  return n.rank === t.rank && (n = ka(n, [n.rank - 1])), t = ai(t, -1), t.dtype !== n.dtype && (t = tt(t, n.dtype)), tt(Tn(n, t), "float32");
}
var PL = uu;
var AL = uu;
var OL = Rf;
var XL = Rf;
var KL = $f;
var ZL = $f;
var Yx = pi;
var BL = Bx;
var Qx = El;
var Ml = {
  binaryAccuracy: Hx,
  categoricalAccuracy: _x,
  precision: FL,
  categoricalCrossentropy: Yx,
  sparseCategoricalCrossentropy: Qx,
  mse: PL,
  MSE: AL,
  mae: OL,
  MAE: XL,
  mape: KL,
  MAPE: ZL,
  cosine: BL
};
function HL(n) {
  if (typeof n == "string" && n in Ml)
    return Ml[n];
  if (typeof n != "string" && n != null)
    return n;
  throw new E(`Unknown metric ${n}`);
}
function Ua(n) {
  if (Jn(n !== null, `Unknown LossOrMetricFn ${n}`), typeof n == "string")
    return n;
  {
    let t;
    for (const e of Object.keys(Ll))
      if (Ll[e] === n) {
        t = e;
        break;
      }
    if (t !== void 0)
      return t;
    for (const e of Object.keys(Ml))
      if (Ml[e] === n) {
        t = e;
        break;
      }
    return t !== void 0 ? t : n.name;
  }
}
function _L(n) {
  const t = {
    Adagrad: () => tr.adagrad(0.01),
    Adadelta: () => tr.adadelta(1, 0.95, ue()),
    Adam: () => tr.adam(1e-3, 0.9, 0.999, ue()),
    Adamax: () => tr.adamax(2e-3, 0.9, 0.999, ue(), 0),
    RMSProp: () => tr.rmsprop(1e-3, 0.9, 0, ue()),
    SGD: () => tr.sgd(0.01)
  };
  if (t.adagrad = t.Adagrad, t.adadelta = t.Adadelta, t.adam = t.Adam, t.adamax = t.Adamax, t.rmsprop = t.RMSProp, t.sgd = t.SGD, n in t)
    return t[n]();
  throw new E(`Unknown Optimizer ${n}`);
}
var jm = 1 * 1024 * 1024;
function qm(n, t, e = false) {
  if (n == null || typeof n != "object" || Object.getPrototypeOf(n) !== Object.prototype || !Ld(n))
    throw new Error("User-defined metadata is expected to be a JSON object, but is not.");
  if (e) {
    const s = JSON.stringify(n);
    s.length > jm && console.warn(`User-defined metadata of model "${t}" is too large in size (length=${s.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${jm}.`);
  }
}
function Ld(n) {
  if (n === null)
    return true;
  if (typeof n == "object")
    if (Object.getPrototypeOf(n) === Object.prototype) {
      const t = Object.keys(n);
      for (const e of t)
        if (typeof e != "string" || !Ld(n[e]))
          return false;
      return true;
    } else if (Array.isArray(n)) {
      for (const t of n)
        if (!Ld(t))
          return false;
      return true;
    } else
      return false;
  else {
    const t = typeof n;
    return t === "string" || t === "number" || t === "boolean";
  }
}
function UL(n, t, e, s = console.log) {
  const o = QL(n), r = ["Layer (type)", "Input Shape", "Output shape", "Param #"];
  o ? (t = t || 90, e = e || [0.32, 0.61, 0.89, 1]) : (t = t || 115, e = e || [0.24, 0.48, 0.7, 0.8, 1]), e[e.length - 1] <= 1 && (e = e.map((u) => Math.floor(t * u)));
  let i6;
  if (!o) {
    r.push("Receives inputs"), i6 = [];
    for (const u in n.nodesByDepth)
      i6.push(...n.nodesByDepth[u]);
  }
  s("_".repeat(t)), Wl(r, e, s), s("=".repeat(t));
  const a = n.layers;
  for (let u = 0; u < a.length; ++u)
    o ? JL(a[u], e, s) : jL(a[u], e, i6, s), s((u === a.length - 1 ? "=" : "_").repeat(t));
  n.checkTrainableWeightsConsistency();
  const l = YL(n), c = Nl(n.nonTrainableWeights);
  s(`Total params: ${l + c}`), s(`Trainable params: ${l}`), s(`Non-trainable params: ${c}`), s("_".repeat(t));
}
function YL(n) {
  let t;
  return n.collectedTrainableWeights != null ? t = Nl(n.collectedTrainableWeights) : t = Nl(n.trainableWeights), t;
}
function QL(n) {
  let t = true;
  const e = [], s = [];
  for (const o in n.nodesByDepth)
    e.push(n.nodesByDepth[o]);
  for (const o of e) {
    if (o.length > 1 || o.length === 1 && o[0].inboundLayers.length > 1) {
      t = false;
      break;
    }
    s.push(...o);
  }
  if (t)
    for (const o of n.layers) {
      let r = false;
      for (const i6 of o.inboundNodes)
        if (s.indexOf(i6) !== -1)
          if (r) {
            t = false;
            break;
          } else
            r = true;
      if (!t)
        break;
    }
  return t;
}
function Wl(n, t, e = console.log) {
  let s = "";
  for (let o = 0; o < n.length; ++o)
    o > 0 && (s = s.slice(0, s.length - 1) + " "), s += n[o], s = s.slice(0, t[o]), s += " ".repeat(t[o] - s.length);
  e(s);
}
function JL(n, t, e) {
  let s, o;
  try {
    o = n.inboundNodes.map((l) => JSON.stringify(l.inputShapes)).join(",");
  } catch {
    o = "multiple";
  }
  try {
    s = JSON.stringify(n.outputShape);
  } catch {
    s = "multiple";
  }
  const r = n.name, i6 = n.getClassName(), a = [
    `${r} (${i6})`,
    o,
    s,
    n.countParams().toString()
  ];
  Wl(a, t, e);
}
function jL(n, t, e, s) {
  let o, r;
  try {
    r = n.inboundNodes.map((d) => JSON.stringify(d.inputShapes)).join(",");
  } catch {
    r = "multiple";
  }
  try {
    o = JSON.stringify(n.outputShape);
  } catch {
    o = "multiple";
  }
  const i6 = [];
  for (const d of n.inboundNodes)
    if (!(e != null && e.length > 0 && e.indexOf(d) === -1))
      for (let h = 0; h < d.inboundLayers.length; ++h) {
        const p = d.inboundLayers[h].name, f = d.nodeIndices[h], m = d.tensorIndices[h];
        i6.push(`${p}[${f}][${m}]`);
      }
  const a = n.name, l = n.getClassName(), c = i6.length === 0 ? "" : i6[0], u = [
    `${a} (${l})`,
    r,
    o,
    n.countParams().toString(),
    c
  ];
  Wl(u, t, s);
  for (let d = 1; d < i6.length; ++d)
    Wl(["", "", "", "", i6[d]], t, s);
}
function Jx(n, t, e) {
  return (n === "inboundNodes" || n === "outputLayers" || n === "inputLayers") && t === 0 && typeof e == "string";
}
function fi(n, t) {
  if (n === null)
    return null;
  if (typeof n == "string")
    return ho(n);
  if (typeof n == "number" || typeof n == "boolean")
    return n;
  if (n instanceof Array) {
    const e = [], s = n.length;
    for (let o = 0; o < s; ++o) {
      const r = n[o];
      Jx(t, o, r) ? e.push(r) : e.push(fi(r, t));
    }
    return e;
  } else {
    const e = {};
    for (const s of Object.keys(n)) {
      const o = n[s];
      if (s === "name" && typeof o == "string")
        e[s] = o;
      else {
        const r = ho(s);
        e[r] = fi(o, r);
      }
    }
    return e;
  }
}
function Md(n, t) {
  if (n == null)
    return null;
  if (typeof n == "string")
    return us(n);
  if (typeof n == "number" || typeof n == "boolean")
    return n;
  if (n instanceof Array) {
    const e = [], s = n.length;
    for (let o = 0; o < s; ++o) {
      const r = n[o];
      Jx(t, o, r) ? e.push(r) : e.push(Md(r, t));
    }
    return e;
  } else {
    const e = {};
    for (const s of Object.keys(n)) {
      const o = n[s], r = us(s);
      (s === "name" || s === "className") && typeof o == "string" ? e[r] = o : e[r] = Md(o, s);
    }
    return e;
  }
}
var jx = "4.16.0";
var qL = (n) => {
  const t = Object.keys(n);
  if (t.length === 0)
    return false;
  const e = t[0].split("/");
  return !isNaN(parseInt(e[e.length - 1], 10));
};
var Wn = class _Wn extends St {
  constructor(t) {
    if (super({}), this.containerNodes = /* @__PURE__ */ new Set(), this.name = t.name, this.name == null) {
      const x6 = this.getClassName().toLowerCase();
      this.name = au(x6);
    }
    if (this.supportsMasking = false, this.trainable_ = true, Array.isArray(t.inputs) ? this.inputs = t.inputs.slice() : this.inputs = [t.inputs], Array.isArray(t.outputs) ? this.outputs = t.outputs.slice() : this.outputs = [t.outputs], Ps(this.inputs).length !== this.inputs.length)
      throw new E(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((x6) => x6.name)}`);
    Ps(this.outputs).length !== this.outputs.length && console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((x6) => x6.name)}`), this.inputLayers = [], this.inputLayersNodeIndices = [], this.inputLayersTensorIndices = [], this.outputLayers = [], this.outputLayersNodeIndices = [], this.outputLayersTensorIndices = [], this.layers = [], this.internalContainerRefs = [];
    for (const x6 of this.outputs) {
      const w = x6.sourceLayer, y6 = x6.nodeIndex, I = x6.tensorIndex;
      this.outputLayers.push(w), this.outputLayersNodeIndices.push(y6), this.outputLayersTensorIndices.push(I);
    }
    for (const x6 of this.inputs) {
      const w = x6.sourceLayer, y6 = x6.nodeIndex, I = x6.tensorIndex;
      Jn(y6 === 0, "input layer has >1 nodes"), Jn(I === 0, "input layer has >1 tensors"), this.inputLayers.push(w), this.inputLayersNodeIndices.push(y6), this.inputLayersTensorIndices.push(I);
    }
    this.inputNames = [], this.outputNames = [], this.feedInputShapes = [], this.feedInputNames = [], this.feedOutputNames = [];
    for (let x6 = 0; x6 < this.inputLayers.length; x6++) {
      const w = this.inputLayers[x6];
      if (!(w instanceof Wa))
        throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${x6} (0-based) originates from layer type ${w.getClassName()}.`);
      this.inputNames.push(w.name), this.feedInputShapes.push(w.batchInputShape), this.feedInputNames.push(w.name);
    }
    for (const x6 of this.outputLayers)
      this.outputNames.push(x6.name);
    this.internalInputShapes = this.inputs.map((x6) => x6.shape), this.internalOutputShapes = this.outputs.map((x6) => x6.shape);
    const e = {}, s = {}, o = {}, r = {}, i6 = {}, a = [], l = (x6, w, y6, I, v, k6) => {
      (I == null || v == null || k6 == null) && (I = x6.sourceLayer, v = x6.nodeIndex, k6 = x6.tensorIndex);
      const S = I.inboundNodes[v];
      if (y6.indexOf(S) !== -1)
        throw new Sn(`The tensor ${x6.name} at layer "${I.name}" is part of a cycle.`);
      if (w.indexOf(S) !== -1)
        return;
      this.containerNodes.add(_Wn.nodeKey(I, v)), I.id in i6 || (i6[I.id] = Object.keys(i6).length), y6.indexOf(S) === -1 && y6.push(S);
      const N = S.inboundLayers.length;
      for (let R = 0; R < N; R++) {
        const M6 = S.inputTensors[R], V = S.inboundLayers[R], z = S.nodeIndices[R], P = S.tensorIndices[R];
        l(M6, w, y6, V, z, P);
      }
      for (w.push(S); y6.indexOf(S) >= 0; )
        y6.splice(y6.indexOf(S), 1);
      a.push(S);
    }, c = [], u = [];
    for (const x6 of this.outputs)
      l(x6, c, u);
    const d = a.slice().reverse();
    for (const x6 of d) {
      s[x6.id] = x6, x6.id in e || (e[x6.id] = 0);
      let w = e[x6.id];
      const y6 = o[x6.outboundLayer.id] == null ? 0 : o[x6.outboundLayer.id];
      w = Math.max(w, y6), o[x6.outboundLayer.id] = w, r[x6.outboundLayer.id] = x6.outboundLayer, e[x6.id] = w;
      for (let I = 0; I < x6.inboundLayers.length; I++) {
        const v = x6.inboundLayers[I], k6 = x6.nodeIndices[I], S = v.inboundNodes[k6], N = e[S.id] == null ? 0 : e[S.id];
        e[S.id] = Math.max(w + 1, N), s[S.id] = S;
      }
    }
    const h = {};
    for (const x6 in e) {
      const w = e[x6];
      w in h || (h[w] = []), h[w].push(s[x6]);
    }
    const p = {};
    for (const x6 in o) {
      const w = o[x6];
      w in p || (p[w] = []), p[w].push(r[x6]);
    }
    let f = Object.keys(p).map((x6) => parseInt(x6, 10)).sort(Ba);
    this.layers = [];
    for (const x6 of f) {
      const w = p[x6];
      w.sort((y6, I) => {
        const v = i6[y6.id], k6 = i6[I.id];
        return v < k6 ? -1 : v > k6 ? 1 : 0;
      });
      for (const y6 of w)
        y6 instanceof _Wn && this.internalContainerRefs.push(y6), this.layers.push(y6);
    }
    this.layersByDepth = p, f = Object.keys(h).map((x6) => parseInt(x6, 10)).sort(Ba);
    const m = this.inputs.slice(), g = [];
    for (const x6 of f)
      for (const w of h[x6]) {
        const y6 = w.outboundLayer;
        if (y6 != null) {
          for (const I of w.inputTensors)
            if (m.indexOf(I) === -1)
              throw new Sn(`Graph disconnected: cannot obtain value for tensor ${I} at layer "${y6.name}". The following previous layers were accessed without issue: ${g}`);
          for (const I of w.outputTensors)
            m.push(I);
          g.push(y6.name);
        }
      }
    this.nodesByDepth = h;
    const b = this.layers.map((x6) => x6.name);
    for (const x6 of b) {
      const w = b.filter((y6) => y6 === x6).length;
      if (w !== 1)
        throw new Sn(`The name "${x6}" is used ${w} times in the model. All layer names should be unique. Layer names: ` + JSON.stringify(b));
    }
    this.outboundNodes = [], this.inboundNodes = [], new cu({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: this.inputs,
      outputTensors: this.outputs,
      inputMasks: this.inputs.map((x6) => null),
      outputMasks: this.outputs.map((x6) => null),
      inputShapes: this.inputs.map((x6) => x6.shape),
      outputShapes: this.outputs.map((x6) => x6.shape)
    }), this.built = true, this._refCount = 1;
  }
  assertNotDisposed() {
    if (this._refCount === 0)
      throw new Error(`Container '${this.name}' is already disposed.`);
  }
  /**
   * Attempt to dispose a LayersModel's weights.
   *
   * This method decrease the reference count of the LayersModel object by 1.
   *
   * A LayersModel is reference-counted. Its reference count is incremented by 1
   * when it is first constructed and when it is used as a Layer of another
   * LayersModel.
   *
   * If the reference count of a LayersModel becomes 0, the `dispose` method of
   * all its constituent `Layer`s will be called.
   *
   * Note: If the reference count is greater than 0 after the decrement, the
   * `dispose` method of its constituent `Layer`s will *not* be called.
   *
   * After a LayersModel is disposed, it cannot be used in calls such as
   * 'predict`, `evaluate` or `fit` anymore.
   *
   * @returns A DisposeResult Object with the following fields:
   *   - refCountAfterDispose: The reference count of the LayersModel after this
   *     `dispose()` call.
   *   - numDisposedVariables: Number of `tf.Variable`s (i.e., weights) disposed
   *     during this `dispose()` call.
   * @throws {Error} If the layer is not built yet, or if the LayersModel has
   *   already been disposed.
   */
  dispose() {
    this.assertNotDisposed();
    const t = { refCountAfterDispose: null, numDisposedVariables: 0 };
    if (--this._refCount === 0) {
      for (const e of this.layers)
        t.numDisposedVariables += e.dispose().numDisposedVariables;
      for (const e of this.internalContainerRefs)
        t.numDisposedVariables += e.dispose().numDisposedVariables;
    }
    return t.refCountAfterDispose = this._refCount, t;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t) {
    this.layers.forEach((e) => {
      e._trainableWeights.forEach((s) => s.trainable = t);
    }), this.trainable_ = t;
  }
  get trainableWeights() {
    if (this._trainableWeights.length > 0)
      throw new E("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
    if (!this.trainable)
      return [];
    let t = [];
    for (const e of this.layers)
      t = t.concat(e.trainableWeights);
    return t;
  }
  get nonTrainableWeights() {
    const t = [];
    for (const e of this.layers)
      t.push(...e.nonTrainableWeights);
    if (!this.trainable) {
      const e = [];
      for (const s of this.layers)
        e.push(...s.trainableWeights);
      return e.concat(t);
    }
    return t;
  }
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  /**
   * Loads all layer weights from a JSON object.
   *
   * Porting Note: HDF5 weight files cannot be directly loaded in JavaScript /
   *   TypeScript. The utility script at `scripts/pykeras.py` offers means
   *   to convert them into JSON strings compatible with this method.
   * Porting Note: TensorFlow.js Layers supports only loading by name currently.
   *
   * @param weights A JSON mapping weight names to weight values as nested
   *   arrays of numbers, or a `NamedTensorMap`, i.e., a JSON mapping weight
   *   names to `tf.Tensor` objects.
   * @param strict Require that the provided weights exactly match those
   *   required by the container.  Default: `true`.  Passing `false` means that
   *   extra weights and missing weights will be silently ignored.
   */
  loadWeights(t, e = true) {
    const s = {};
    let o = 0;
    const r = qL(t);
    r && this.parseWeights(t);
    for (const a of this.layers)
      for (const [l, c] of a.weights.entries()) {
        const u = r ? `${c.name.split("/").slice(0, -1).join("/") + "/"}${l}` : c.originalName;
        if (s[u] != null)
          throw new E(`Duplicate weight name: ${u}`);
        s[u] = c, o++;
      }
    const i6 = [];
    for (const a in t) {
      let l = a;
      if (s[a] == null) {
        const c = a.split("/");
        l = c.slice(0, -2).concat([c[c.length - 1]]).join("/");
      }
      if (s[l] != null)
        i6.push([s[l], t[a]]);
      else if (e)
        throw new E(`Provided weight data has no target variable: ${a}`);
      delete s[l];
    }
    if (e) {
      const a = [];
      for (const l in s)
        a.push(l);
      if (a.length > 0)
        throw new E(`${a.length} of ${o} weights are not set: ${a}`);
    }
    Tf(i6);
  }
  parseWeights(t) {
    for (const e in Object.keys(t)) {
      const s = e.split("/"), o = ["vars", "layer_checkpoint_dependencies"], r = s.map((i6) => i6.startsWith("_") ? i6.slice(1) : i6).filter((i6) => !o.includes(i6)).join("/");
      r !== e && (t[r] = t[e], delete t[e]);
    }
  }
  /**
   * Util shared between different serialization methods.
   * @returns LayersModel config with Keras version information added.
   */
  updatedConfig() {
    const t = this.getConfig(), e = {};
    return e.className = this.getClassName(), e.config = t, e.kerasVersion = `tfjs-layers ${jx}`, e.backend = "TensorFlow.js", e;
  }
  /**
   * Returns a JSON string containing the network configuration.
   *
   * To load a network from a JSON save file, use
   * models.modelFromJSON(jsonString);
   * @param extraJsonArgs Unused in tfjs-layers, maintained for PyKeras
   * @param returnString Whether the return value should be stringified
   *    (default: `true`).
   * @returns a JSON string if `returnString` (default), or a JSON object if
   *   `!returnString`.
   */
  // tslint:disable-next-line:no-any
  toJSON(t, e = true) {
    const s = Md(this.updatedConfig());
    return e ? JSON.stringify(s) : s;
  }
  /**
   * Call the model on new inputs.
   *
   * In this case `call` just reapplies all ops in the graph to the new inputs
   * (e.g. build a new computational graph from the provided inputs).
   *
   * @param inputs A tensor or list of tensors.
   * @param mask A mask or list of masks. A mask can be either a tensor or null
   *   (no mask).
   *
   * @return A tensor if there is a single output, or a list of tensors if there
   *   are more than one outputs.
   */
  call(t, e) {
    return D(() => {
      t = Lt(t);
      const s = new Ds();
      for (let o = 0; o < this.inputs.length; ++o)
        s.add(this.inputs[o], t[o]);
      return Yr(this.outputs, s, e);
    });
  }
  /**
   * Computes an output mask tensor.
   *
   * @param inputs Tensor or list of tensors.
   * @param mask Tensor or list of tensors.
   *
   * @return null or a tensor (or list of tensors, one per output tensor of the
   * layer).
   */
  computeMask(t, e) {
    return D(() => {
      t = Lt(t);
      let s;
      return e == null ? s = Wo(null, t.length) : s = Lt(e), this.runInternalGraph(t, s)[1];
    });
  }
  /**
   * Computes the output shape of the layer.
   *
   * Assumes that the layer will be built to match that input shape provided.
   *
   * @param inputShape A shape (tuple of integers) or a list of shape tuples
   *   (one per output tensor of the layer). Shape tuples can include null for
   *   free dimensions, instead of an integer.
   */
  computeOutputShape(t) {
    const e = Tl(t);
    if (e.length !== this.inputLayers.length)
      throw new E(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);
    const s = {};
    for (let a = 0; a < e.length; a++) {
      const l = this.inputLayers[a], c = e[a], u = l.name + "_0_0";
      s[u] = c;
    }
    const o = Object.keys(this.nodesByDepth).map((a) => parseInt(a, 10)).sort(Ba);
    if (o.length > 1)
      for (const a of o) {
        const l = this.nodesByDepth[a];
        for (const c of l) {
          const u = c.outboundLayer;
          if (this.inputLayers.map((m) => m.id).indexOf(u.id) !== -1)
            continue;
          const d = [];
          for (let m = 0; m < c.inboundLayers.length; m++) {
            const g = c.inboundLayers[m], b = c.nodeIndices[m], x6 = c.tensorIndices[m], w = `${g.name}_${b}_${x6}`, y6 = s[w];
            d.push(y6);
          }
          const h = u.computeOutputShape(Xe(d)), p = Tl(h), f = u.inboundNodes.indexOf(c);
          for (let m = 0; m < p.length; m++) {
            const g = `${u.name}_${f}_${m}`;
            s[g] = p[m];
          }
        }
      }
    const r = [], i6 = [];
    for (let a = 0; a < this.outputLayers.length; a++) {
      const l = this.outputLayers[a], c = this.outputLayersNodeIndices[a], u = this.outputLayersTensorIndices[a], d = `${l.name}_${c}_${u}`;
      i6.push(d);
    }
    for (let a = 0; a < i6.length; a++) {
      const l = i6[a];
      Jn(l in s), r.push(s[l]);
    }
    return Xe(r);
  }
  /**
   * Computes output tensors for new inputs.
   *
   * Note:
   *   - Expects `inputs` to be a list (potentially with 1 element).
   *
   * @param inputs List of tensors
   * @param masks List of masks (tensors or null).
   * @return Three lists: outputTensors, outputMasks, outputShapes
   */
  runInternalGraph(t, e) {
    e == null && (e = Wo(null, t.length));
    const s = {};
    for (let l = 0; l < this.inputs.length; ++l) {
      const c = this.inputs[l], u = t[l], d = e[l];
      s[c.id] = [u, d];
    }
    const o = Object.keys(this.nodesByDepth).map((l) => parseInt(l, 10)).sort(Ba);
    for (const l of o) {
      const c = this.nodesByDepth[l];
      for (const u of c) {
        const d = u.outboundLayer, h = u.inputTensors, p = u.outputTensors, f = new Array();
        for (const m of h)
          m.id in s && f.push(s[m.id]);
        if (f.length === h.length) {
          let m = {}, g, b, x6, w;
          if (u.callArgs != null && (m = u.callArgs), f.length === 1) {
            const [y6, I] = f[0];
            m.mask == null && (m.mask = I), x6 = Lt(d.call(y6, m)), w = Lt(d.computeMask(y6, I)), g = [y6], b = [I];
          } else
            g = f.map((y6) => y6[0]), b = f.map((y6) => y6[1]), m.mask == null && (m.mask = b), x6 = Lt(d.call(g, m)), w = Lt(d.computeMask(g, b));
          if (d.activityRegularizer)
            throw new yt("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");
          for (let y6 = 0; y6 < p.length; ++y6) {
            const I = p[y6], v = x6[y6], k6 = w[y6];
            s[I.id] = [v, k6];
          }
        }
      }
    }
    const r = [], i6 = [], a = [];
    for (const l of this.outputs) {
      Jn(l.id in s, `Could not compute output ${l.name} : ${l.id}`);
      const [c, u] = s[l.id];
      a.push(c.shape), r.push(c), i6.push(u);
    }
    return [r, i6, a];
  }
  /**
   * Builds a map of internal node keys to node ordering.
   * Used in serializaion a node orderings may change as unused nodes are
   * dropped. Porting Note:  This helper method was pulled out of getConfig to
   * improve readability.
   * @param layers An array of Layers in the model.
   * @returns Map of Node Keys to index order within the layer.
   */
  buildNodeConversionMap(t) {
    const e = {};
    let s;
    for (const o of this.layers) {
      s = o instanceof _Wn ? 1 : 0;
      for (let r = 0; r < o.inboundNodes.length; r++) {
        const i6 = _Wn.nodeKey(o, r);
        this.containerNodes.has(i6) && (e[i6] = s, s += 1);
      }
    }
    return e;
  }
  getLayer(t, e) {
    if (e != null)
      return this.findLayer(e);
    if (t == null)
      throw new E("Provide either a layer name or layer index");
    if (typeof t == "number")
      return this.findLayer(t);
    for (const s of this.layers)
      if (s.name === t)
        return s;
    throw new E(`No such layer: ${t}`);
  }
  findLayer(t) {
    if (this.layers.length <= t)
      throw new E(`Was asked to retrieve layer at index ${t}, but model only has ${this.layers.length} layer(s).`);
    return this.layers[t];
  }
  /**
   * Retrieves the Container's current loss values.
   *
   * Used for regularizers during training.
   */
  calculateLosses() {
    return D(() => {
      const t = [];
      for (const e of this.layers)
        for (let s = 0; s < e.inboundNodes.length; ++s) {
          const o = _Wn.nodeKey(e, s);
          this.containerNodes.has(o) && t.push(...e.calculateLosses());
        }
      return t;
    });
  }
  getConfig() {
    const t = { name: this.name }, e = this.buildNodeConversionMap(this.layers), s = [];
    for (const i6 of this.layers) {
      const a = i6.getClassName(), l = i6.getConfig(), c = [];
      for (let d = 0; d < i6.inboundNodes.length; d++) {
        const h = i6.inboundNodes[d], p = _Wn.nodeKey(i6, d);
        let f = {};
        if (this.containerNodes.has(p)) {
          if (h.callArgs)
            try {
              JSON.stringify(h.callArgs), f = h.callArgs;
            } catch {
              console.warn(`Layer ${i6.name} was passed non-serializable keyword arguments: ${h.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`), f = {};
            }
          if (h.inboundLayers.length > 0) {
            const m = [];
            for (let g = 0; g < h.inboundLayers.length; g++) {
              const b = h.inboundLayers[g], x6 = h.nodeIndices[g], w = h.tensorIndices[g], y6 = _Wn.nodeKey(b, x6);
              let I = e[y6];
              I == null && (I = 0), m.push([b.name, I, w, f]);
            }
            c.push(m);
          }
        }
      }
      const u = {};
      u.name = i6.name, u.className = a, u.config = l, u.inboundNodes = c, s.push(u);
    }
    t.layers = s;
    const o = [];
    for (let i6 = 0; i6 < this.inputLayers.length; i6++) {
      const a = this.inputLayers[i6], l = this.inputLayersNodeIndices[i6], c = _Wn.nodeKey(a, l);
      if (!this.containerNodes.has(c))
        continue;
      let u = e[c];
      u == null && (u = 0);
      const d = this.inputLayersTensorIndices[i6];
      o.push([a.name, u, d]);
    }
    t.inputLayers = o;
    const r = [];
    for (let i6 = 0; i6 < this.outputLayers.length; i6++) {
      const a = this.outputLayers[i6], l = this.outputLayersNodeIndices[i6], c = _Wn.nodeKey(a, l);
      if (!this.containerNodes.has(c))
        continue;
      let u = e[c];
      u == null && (u = 0);
      const d = this.outputLayersTensorIndices[i6];
      r.push([a.name, u, d]);
    }
    return t.outputLayers = r, t;
  }
  /**
   * Instantiates a LayersModel from its config (output of `get_config()`).
   * @param cls the class to create
   * @param config LayersModel config dictionary.
   * @param customObjects An optional dictionary of custom objects.
   * @param fastWeightInit Optional flag to use fast weight initialization
   *   during deserialization. This is applicable to cases in which
   *   the initialization will be immediately overwritten by loaded weight
   *   values. Default: `false`.
   * @returns A LayersModel instance.
   * @throws ValueError: In case of improperly formatted config dict.
   */
  /** @nocollapse */
  static fromConfig(t, e, s = {}, o = false) {
    const r = {}, i6 = {};
    function a(g, b) {
      g.name in i6 ? i6[g.name].push(b) : i6[g.name] = [b];
    }
    function l(g, b) {
      const x6 = [];
      let w;
      for (const y6 of b) {
        const I = y6[0], v = y6[1], k6 = y6[2];
        if (w = y6[3] == null ? {} : y6[3], !(I in r)) {
          a(g, b);
          return;
        }
        const S = r[I];
        if (S.inboundNodes.length <= v) {
          a(g, b);
          return;
        }
        const N = S.inboundNodes[v];
        x6.push(N.outputTensors[k6]);
      }
      x6.length > 0 && g.apply(Xe(x6), w);
    }
    function c(g) {
      const b = g.name, x6 = An(g, e.customObjects != null ? e.customObjects : {});
      x6.setFastWeightInitDuringBuild(o), r[b] = x6, g.inboundNodes.forEach((y6) => {
        if (!(y6 instanceof Array))
          throw new E(`Corrupted configuration, expected array for nodeData: ${y6}`);
        a(x6, y6);
      });
    }
    const u = e.name, d = e.layers;
    for (const g of d)
      c(g);
    for (; !VE(i6); )
      for (const g of d) {
        const b = r[g.name];
        if (b.name in i6) {
          const x6 = i6[b.name];
          delete i6[b.name];
          for (const w of x6)
            l(b, w);
        }
      }
    const h = [], p = [], f = e.inputLayers;
    for (const g of f) {
      const b = g[0], x6 = g[1], w = g[2];
      Jn(b in r);
      const I = r[b].inboundNodes[x6].outputTensors;
      h.push(I[w]);
    }
    const m = e.outputLayers;
    for (const g of m) {
      const b = g[0], x6 = g[1], w = g[2];
      Jn(b in r);
      const I = r[b].inboundNodes[x6].outputTensors;
      p.push(I[w]);
    }
    return new t({ inputs: h, outputs: p, name: u });
  }
  /**
   * Determine whether the container is stateful.
   *
   * Porting Note: this is the equivalent of the stateful @property of
   *   the Container class in PyKeras.
   */
  get stateful() {
    if (this._stateful)
      throw new E("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");
    for (const t of this.layers)
      if (t.stateful)
        return true;
    return false;
  }
  /**
   * Reset the state of all stateful constituent layers (if any).
   *
   * Examples of stateful layers include RNN layers whose `stateful` property
   * is set as `true`.
   */
  resetStates() {
    D(() => {
      this.layers.forEach((t) => {
        t.stateful && t.resetStates();
      });
    });
  }
};
function t3(n, t, e) {
  const s = t.length;
  if (n == null || Array.isArray(n) && n.length === 0)
    return t.map((o) => null);
  if (s === 1)
    return Array.isArray(n) && n.length === 1 ? n : typeof n == "object" && t[0] in n ? [n[t[0]]] : [n];
  if (Array.isArray(n)) {
    if (n.length !== s)
      throw new Error(`Provided ${e} is an array of ${n.length} element(s), but the model has ${s} outputs. Make sure a set of weights is provided for each model output.`);
    return n;
  } else if (typeof n == "object" && Object.keys(n).length > 0 && typeof n[Object.keys(n)[0]] == "object") {
    const o = [];
    return t.forEach((r) => {
      r in n ? o.push(n[r]) : o.push(null);
    }), o;
  } else
    throw new Error(`The model has multiple (${s}) outputs, so ${e} must be either an array with ${s} elements or an object with ${t} keys. Provided ${e} not understood: ${JSON.stringify(n)}`);
}
function qx(n, t) {
  return t3(n, t, "classWeight");
}
async function ty(n, t, e, s) {
  if (t != null || s != null)
    throw new Error("Support sampleWeight is not implemented yet");
  if (e != null) {
    const o = D(() => {
      if (n.shape.length === 1)
        return yo(n);
      if (n.shape.length === 2) {
        if (n.shape[1] > 1)
          return ai(n, 1);
        if (n.shape[1] === 1)
          return W(n, [n.shape[0]]);
        throw new Error(`Encountered unexpected last-dimension size (${n.shape[1]}) during handling of class weights. The size is expected to be >= 1.`);
      } else
        throw new Error(`Unexpected rank of target (y) tensor (${n.rank}) during handling of class weights. The rank is expected to be 1 or 2.`);
    }), r = Array.from(await o.data());
    xt(o);
    const i6 = [];
    return r.forEach((a) => {
      if (e[a] == null)
        throw new Error(`classWeight must contain all classes in the training data. The class ${a} exists in the data but not in classWeight`);
      i6.push(e[a]);
    }), Ze(i6, "float32");
  } else
    return null;
}
function e3(n, t) {
  return G(n, t);
}
var n3 = 32;
function ey(n, t) {
  let e, s;
  const o = t;
  e = o.xs, s = o.ys, C(e != null && s != null, () => `A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`);
  const r = tg("input", n.inputNames, e), i6 = tg("output", n.outputNames, s), a = r[0].shape[0];
  C(r.length === n.inputs.length, () => `LayersModel has ${n.inputs.length} inputs, but the dataset provides ${r.length} inputs.  (Expected input keys: ${JSON.stringify(n.inputNames)})`), C(i6.length === n.outputs.length, () => `LayersModel has ${n.outputs.length} outputs, but the dataset provides ${i6.length} outputs.  (Expected output keys: ${JSON.stringify(n.outputNames)})`);
  for (let l = 0; l < r.length; l++)
    C(r[l].shape[0] === a, () => `Batch size mismatch: input ${n.inputNames[l]} has ${r[l].shape[0]}; expected  ${a} based on input ${n.inputNames[0]}.`);
  for (let l = 0; l < i6.length; l++)
    C(i6[l].shape[0] === a, () => `Batch size mismatch: output ${n.outputNames[l]} has ${i6[l].shape[0]}; expected  ${a} based on input ${n.inputNames[0]}.`);
  return { xs: r, ys: i6 };
}
function tg(n, t, e) {
  if (e instanceof Mt)
    return [e];
  if (Array.isArray(e))
    return C(e.length === t.length, () => `Received an array of ${e.length} Tensors, but expected ${t.length} to match the ${n} keys ${t}.`), e;
  {
    const s = [];
    for (const o of t) {
      if (e[o] == null)
        throw new E(`The feature data generated by the dataset lacks the required ${n} key '${o}'.`);
      s.push(e[o]);
    }
    return s;
  }
}
function s3(n) {
  if (n.length === 3)
    throw new yt("Validation with sample weights is not implemented yet.");
  return { xs: n[0], ys: n[1] };
}
async function o3(n, t, e) {
  const s = e.batchesPerEpoch != null;
  if (C(n.optimizer != null, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."), C(e != null, () => "For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."), C(e.epochs != null && e.epochs > 0 && Number.isInteger(e.epochs), () => `For fitDataset(), config.epochs is expected to be a positive integer, but got ${e.epochs}`), C(!s || e.batchesPerEpoch > 0 && Number.isInteger(e.batchesPerEpoch), () => `For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${e.batchesPerEpoch}`), C(
    // tslint:disable-next-line:no-any
    e.validationSplit == null,
    () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead."
  ), n.isTraining)
    throw new Error("Cannot start training because another fit() call is ongoing.");
  n.isTraining = true;
  try {
    const o = e.validationData != null;
    let r, i6;
    if (o)
      if (eg(e.validationData))
        C(e.validationBatches == null || e.validationBatches > 0 && Number.isInteger(e.validationBatches), () => `For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${e.validationBatches}`);
      else {
        const g = s3(e.validationData);
        r = g.xs, i6 = g.ys;
      }
    const a = n.makeTrainFunction(), l = n.getDedupedMetricsNames();
    let c;
    o ? c = l.slice().concat(l.map((g) => "val_" + g)) : c = l.slice();
    const u = Kx(e.callbacks, e.yieldEvery), d = e.verbose == null ? 1 : e.verbose, { callbackList: h, history: p } = Zx(
      u,
      d,
      e.epochs,
      null,
      null,
      r3(t, e),
      null,
      // Batch size determined by the dataset itself.
      o,
      c
    );
    h.setModel(n), n.history = p, await h.onTrainBegin(), n.stopTraining_ = false;
    let f = e.initialEpoch == null ? 0 : e.initialEpoch, m = await t.iterator();
    for (; f < e.epochs; ) {
      const g = {};
      await h.onEpochBegin(f);
      let b = 0, x6 = 0;
      for (s || (m = await t.iterator()); !s || b < e.batchesPerEpoch; ) {
        const w = await m.next();
        if (s && w.done) {
          console.warn(`You provided \`batchesPerEpoch\` as ${e.batchesPerEpoch}, but your dataset iterator ran out of data after ${b} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${e.batchesPerEpoch * e.epochs} batches). You may need to use the repeat() function when building your dataset.`);
          break;
        }
        if (w.value != null) {
          const { xs: y6, ys: I } = ey(n, w.value), v = {};
          v.batch = x6, v.size = y6[0].shape[0], await h.onBatchBegin(x6, v);
          const k6 = [];
          if (e.classWeight != null) {
            const R = qx(e.classWeight, n.outputNames);
            for (let M6 = 0; M6 < R.length; ++M6)
              k6.push(await ty(I[M6], null, R[M6]));
          }
          const S = y6.concat(I).concat(k6), N = a(S);
          xt(S);
          for (let R = 0; R < l.length; ++R) {
            const M6 = l[R], V = N[R];
            v[M6] = V, hn(V);
          }
          await h.onBatchEnd(x6, v), Xx(v), x6++, b++;
        }
        if (s ? b >= e.batchesPerEpoch : w.done) {
          if (o) {
            let y6;
            eg(e.validationData) ? y6 = Lt(await n.evaluateDataset(e.validationData, { batches: e.validationBatches })) : y6 = Lt(n.evaluate(r, i6, {
              batchSize: e.validationBatchSize == null ? n3 : e.validationBatchSize,
              verbose: 0
            }));
            for (let I = 0; I < n.metricsNames.length; ++I)
              g[`val_${n.metricsNames[I]}`] = y6[I];
          }
          break;
        }
        if (n.stopTraining_)
          break;
      }
      if (await h.onEpochEnd(f, g), f++, n.stopTraining_)
        break;
    }
    return await h.onTrainEnd(), await n.history.syncData(), n.history;
  } finally {
    n.isTraining = false;
  }
}
function r3(n, t) {
  let e = null;
  return t.batchesPerEpoch != null ? e = t.batchesPerEpoch : Number.isFinite(n.size) && (e = n.size), e;
}
function eg(n) {
  return typeof n.iterator == "function";
}
function i3(n) {
  return typeof n.next == "function";
}
async function a3(n, t, e) {
  e = e || {};
  const s = e.batches != null, o = n.testFunction;
  let r = [];
  if (e.verbose > 0)
    throw new yt("Verbose mode is not implemented yet.");
  C(!s || e.batches > 0 && Number.isInteger(e.batches), () => `Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(e.batches)}`);
  const i6 = i3(t) ? t : await t.iterator();
  let a = 0, l = 0;
  for (; !s || l < e.batches; ) {
    const c = await i6.next();
    if (r = D(() => {
      if (c.value) {
        const { xs: u, ys: d } = ey(n, c.value), h = u.concat(d), p = D(() => o(h));
        if (xt(h), l === 0)
          for (let m = 0; m < p.length; ++m)
            r.push(gt(0));
        const f = h[0].shape[0];
        for (let m = 0; m < p.length; ++m) {
          const g = p[m], b = r[m];
          r[m] = D(() => U(r[m], G(f, g))), l > 0 && xt(b);
        }
        xt(p), a += f, ++l;
      }
      return r;
    }), c.done) {
      s && console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${e.batches} batches). You may need to use the repeat() function when building your dataset.`);
      break;
    }
  }
  for (let c = 0; c < r.length; ++c) {
    const u = r[c];
    r[c] = ut(r[c], a), xt(u);
  }
  return Xe(r);
}
function Vu(n) {
  C(n > 0 && Number.isInteger(n), () => `batchSize is required to be a positive integer, but got ${n}`);
}
function Xr(n, t, e) {
  return n == null ? [null] : Array.isArray(n) ? n.map((s) => Io(s, t, e - t)) : Io(n, t, e - t);
}
function Wd(n, t) {
  return D(() => n == null ? null : Array.isArray(n) ? n.map((e) => Wd(e, t)) : Rx(n, t.dtype === "int32" ? t : tt(t, "int32")));
}
function zu(n, t) {
  const e = [];
  let s = 0, o = null;
  for (; s < n; )
    o = s + t, o >= n && (o = n), e.push([s, o]), s = o;
  return e;
}
function ny(n) {
  const t = [];
  n instanceof Mt && (n = [n]);
  for (let e = 0; e < n.length; ++e) {
    const s = n[e];
    if (s.rank === 1)
      t.push(Ea(s, 1));
    else {
      if (s.rank === 0)
        throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
      t.push(s);
    }
  }
  return t;
}
function Mn(n, t) {
  if (n == null)
    return;
  const e = [];
  if (t instanceof Mt)
    e.push(t.id);
  else if (Array.isArray(t))
    t.forEach((o) => e.push(o.id));
  else if (t != null)
    for (const o in t) {
      const r = t[o];
      e.push(r.id);
    }
  const s = [];
  if (n instanceof Mt)
    e.indexOf(n.id) === -1 && s.push(n);
  else if (Array.isArray(n))
    n.forEach((o) => {
      e.indexOf(o.id) === -1 && s.push(o);
    });
  else if (n != null)
    for (const o in n) {
      const r = n[o];
      e.indexOf(r.id) === -1 && s.push(r);
    }
  s.forEach((o) => {
    o.isDisposed || o.dispose();
  });
}
function l3(n) {
  return n instanceof Mt;
}
function Dd(n) {
  return Array.isArray(n);
}
function ng(n) {
  return !l3(n) && !Dd(n);
}
function sg(n, t, e, s = true, o = "") {
  if (t == null || t.length === 0) {
    if (n != null) {
      let i6 = false;
      if (Dd(n) && n.length > 0)
        i6 = true;
      else if (ng(n)) {
        for (const a in n)
          if (n.hasOwnProperty(a)) {
            i6 = true;
            break;
          }
      } else
        i6 = true;
      if (i6)
        throw new E(`Error when checking model ${o} expected no data, but got ${n}`);
    }
    return [];
  }
  if (n == null)
    return t.map((i6) => null);
  let r;
  if (ng(n)) {
    n = n, r = [];
    for (const i6 of t) {
      if (n[i6] == null)
        throw new E(`No data provided for "${i6}". Need data for each key in: ${t}`);
      r.push(n[i6]);
    }
  } else if (Dd(n)) {
    if (n = n, n.length !== t.length)
      throw new E(`Error when checking model ${o}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${n}`);
    r = n;
  } else {
    if (n = n, t.length > 1)
      throw new E(`The model ${o} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${n.shape}`);
    r = [n];
  }
  if (r = ny(r), e != null)
    for (let i6 = 0; i6 < t.length; ++i6) {
      if (e[i6] == null)
        continue;
      const a = r[i6];
      if (a.shape.length !== e[i6].length)
        throw new E(`Error when checking ${o}: expected ${t[i6]} to have ${e[i6].length} dimension(s). but got array with shape ${a.shape}`);
      for (let l = 0; l < e[i6].length; ++l) {
        if (l === 0 && !s)
          continue;
        const c = a.shape[l], u = e[i6][l];
        if (u != null && u >= 0 && c !== u)
          throw new E(`${o} expected a batch of elements where each example has shape [${e[i6].slice(1, e[i6].length)}] (i.e.,tensor shape [*,${e[i6].slice(1, e[i6].length)}]) but the ${o} received an input with ${a.shape[0]} examples, each with shape [${a.shape.slice(1, a.shape.length)}] (tensor shape [${a.shape}])`);
      }
    }
  return r;
}
function c3(n, t, e) {
  const s = Ps(n.map((r) => r.shape[0]));
  s.sort();
  const o = Ps(t.map((r) => r.shape[0]));
  if (o.sort(), s.length > 1)
    throw new E(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(n.map((r) => r.shape))}`);
  if (o.length > 1)
    throw new E(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map((r) => r.shape))}`);
  if (s.length > 0 && o.length > 0 && !$t(s, o))
    throw new E(`Input Tensors should have the same number of samples as target Tensors. Found ${s[0]} input sample(s) and ${o[0]} target sample(s).`);
}
function u3(n, t, e) {
  const s = [
    uu,
    du,
    pi
  ];
  for (let o = 0; o < n.length; ++o) {
    const r = n[o], i6 = t[o], a = e[o];
    if (i6 != null) {
      if (i6 === pi && r.shape[r.shape.length - 1] === 1)
        throw new E(`You are passing a target array of shape ${r.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);
      if (s.indexOf(i6) !== -1) {
        const l = r.shape.slice(1), c = a.slice(1);
        for (let u = 0; u < l.length; ++u) {
          const d = l[u], h = c[u];
          if (h != null && d !== h)
            throw new E(`A target Tensor with shape ${r.shape} was passed for an output of shape ${a}, while using a loss function that expects targets to have the same shape as the output.`);
        }
      }
    }
  }
}
function og(n, t, e, s = true, o = "") {
  let r;
  if (Array.isArray(n)) {
    if (n.length !== t.length)
      throw new E(`Error when checking model ${o}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${n.length} Tensors(s).`);
    r = n;
  } else {
    if (t.length > 1)
      throw new E(`The model expects ${t.length} ${o} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(n.shape)}.`);
    r = [n];
  }
  if (e != null)
    for (let i6 = 0; i6 < t.length; ++i6) {
      if (e[i6] == null)
        continue;
      const a = r[i6];
      if (a.shape.length !== e[i6].length)
        throw new E(`Error when checking ${o}: expected ${t[i6]} to have ${e[i6].length} dimension(s), but got array with shape ${JSON.stringify(a.shape)}`);
      for (let l = 0; l < e[i6].length; ++l) {
        if (l === 0 && !s)
          continue;
        const c = a.shape[l], u = e[i6][l];
        if (u != null && u !== c)
          throw new E(`Error when checking ${o}: expected ${t[i6]} to have shape ${JSON.stringify(e[i6])} but got array with shape ${JSON.stringify(a.shape)}.`);
      }
    }
}
function d3(n, t) {
  if (n == null || Array.isArray(n) && n.length === 0)
    return t.map((s) => []);
  let e;
  if (typeof n == "string" || typeof n == "function")
    e = [n];
  else if (Array.isArray(n) || typeof n == "object")
    e = n;
  else
    throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${n}`);
  if (Array.isArray(e))
    return t.map((s) => e);
  {
    const s = [];
    for (const o of t) {
      let r = e.hasOwnProperty(o) ? e[o] : [];
      Array.isArray(r) || (r = [r]), s.push(r);
    }
    return s;
  }
}
var h3 = "layers-model";
var ur = class extends Wn {
  constructor(t) {
    super(t), this.isTraining = false;
  }
  /**
   * Print a text summary of the model's layers.
   *
   * The summary includes
   * - Name and type of all layers that comprise the model.
   * - Output shape(s) of the layers
   * - Number of weight parameters of each layer
   * - If the model has non-sequential-like topology, the inputs each layer
   *   receives
   * - The total number of trainable and non-trainable parameters of the model.
   *
   * ```js
   * const input1 = tf.input({shape: [10]});
   * const input2 = tf.input({shape: [20]});
   * const dense1 = tf.layers.dense({units: 4}).apply(input1);
   * const dense2 = tf.layers.dense({units: 8}).apply(input2);
   * const concat = tf.layers.concatenate().apply([dense1, dense2]);
   * const output =
   *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);
   *
   * const model = tf.model({inputs: [input1, input2], outputs: output});
   * model.summary();
   * ```
   *
   * @param lineLength Custom line length, in number of characters.
   * @param positions Custom widths of each of the columns, as either
   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number
   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to
   *   right-most (i.e., ending) position of a column.
   * @param printFn Custom print function. Can be used to replace the default
   *   `console.log`. For example, you can use `x => {}` to mute the printed
   *   messages in the console.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  summary(t, e, s = console.log) {
    if (!this.built)
      throw new E("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");
    UL(this, t, e, s);
  }
  /**
   * Configures and prepares the model for training and evaluation.  Compiling
   * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`
   * or `evaluate` on an un-compiled model will throw an error.
   *
   * @param args a `ModelCompileArgs` specifying the loss, optimizer, and
   * metrics to be used for fitting and evaluating this model.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  compile(t) {
    if (t.loss == null && (t.loss = []), this.loss = t.loss, typeof t.optimizer == "string")
      this.optimizer_ = _L(t.optimizer), this.isOptimizerOwned = true;
    else {
      if (!(t.optimizer instanceof eo))
        throw new E("User-defined optimizer must be an instance of tf.Optimizer.");
      this.optimizer_ = t.optimizer, this.isOptimizerOwned = false;
    }
    let e = [];
    if (!Array.isArray(t.loss) && typeof t.loss != "string" && typeof t.loss != "function") {
      t.loss = t.loss;
      for (const i6 in t.loss)
        if (this.outputNames.indexOf(i6) === -1)
          throw new E(`Unknown entry in loss dictionary: "${i6}". Only expected the following keys: ${this.outputNames}`);
      for (const i6 of this.outputNames)
        t.loss[i6] == null && console.warn(`Output "${i6}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${i6} during training`), e.push(Fu(t.loss[i6]));
    } else if (Array.isArray(t.loss)) {
      if (t.loss.length !== this.outputs.length)
        throw new E(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);
      e = t.loss.map((a) => Fu(a));
    } else {
      const i6 = Fu(t.loss);
      this.outputs.forEach((a) => {
        e.push(i6);
      });
    }
    this.lossFunctions = e, this.feedOutputNames = [], this.feedOutputShapes = [], this.feedLossFns = [];
    for (let i6 = 0; i6 < this.outputs.length; ++i6) {
      const a = this.internalOutputShapes[i6], l = this.outputNames[i6];
      this.feedOutputNames.push(l), this.feedOutputShapes.push(a), this.feedLossFns.push(this.lossFunctions[i6]);
    }
    const s = [];
    this.metrics = t.metrics, this.metricsNames = ["loss"], this.metricsTensors = [], wo("loss", () => {
      for (let i6 = 0; i6 < this.outputs.length; ++i6) {
        if (s.indexOf(i6) !== -1)
          continue;
        const a = this.lossFunctions[i6];
        this.outputs.length > 1 && (this.metricsTensors.push([a, i6]), this.metricsNames.push(this.outputNames[i6] + "_loss"));
      }
    });
    const o = d3(t.metrics, this.outputNames), r = (i6, a, l) => {
      this.outputNames.length > 1 && (a = this.outputNames[i6] + "_" + a), this.metricsNames.push(a), this.metricsTensors.push([l, i6]);
    };
    wo("metric", () => {
      for (let i6 = 0; i6 < this.outputs.length; ++i6) {
        if (s.indexOf(i6) !== -1)
          continue;
        const a = o[i6];
        ((c) => {
          const u = "";
          let d, h, p;
          for (const f of c) {
            if (typeof f == "string" && ["accuracy", "acc", "crossentropy", "ce"].indexOf(f) !== -1) {
              const g = this.internalOutputShapes[i6];
              g[g.length - 1] === 1 || this.lossFunctions[i6] === du ? ["accuracy", "acc"].indexOf(f) !== -1 ? h = Hx : ["crossentropy", "ce"].indexOf(f) !== -1 && (h = VL) : this.lossFunctions[i6] === El ? ["accuracy", "acc"].indexOf(f) !== -1 ? h = zL : ["crossentropy", "ce"].indexOf(f) !== -1 && (h = Qx) : ["accuracy", "acc"].indexOf(f) !== -1 ? h = _x : ["crossentropy", "ce"].indexOf(f) !== -1 && (h = Yx);
              let b;
              ["accuracy", "acc"].indexOf(f) !== -1 ? b = "acc" : ["crossentropy", "ce"].indexOf(f) !== -1 && (b = "ce"), p = h, d = u + b;
            } else
              p = HL(f), d = u + Ua(f);
            let m;
            wo(d, () => {
              m = p;
            }), r(i6, d, m);
          }
        })(a);
      }
    }), this.collectedTrainableWeights = this.trainableWeights;
  }
  /**
   * Check trainable weights count consistency.
   *
   * This will raise a warning if `this.trainableWeights` and
   * `this.collectedTrainableWeights` are inconsistent (i.e., have different
   * numbers of parameters).
   * Inconsistency will typically arise when one modifies `model.trainable`
   * without calling `model.compile()` again.
   */
  checkTrainableWeightsConsistency() {
    this.collectedTrainableWeights != null && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
  }
  /**
   * Returns the loss value & metrics values for the model in test mode.
   *
   * Loss and metrics are specified during `compile()`, which needs to happen
   * before calls to `evaluate()`.
   *
   * Computation is done in batches.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const result = model.evaluate(
   *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});
   * result.print();
   * ```
   *
   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the
   * model has multiple inputs.
   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the
   * model has multiple outputs.
   * @param args A `ModelEvaluateArgs`, containing optional fields.
   *
   * @return `Scalar` test loss (if the model has a single output and no
   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs
   *   and/or metrics). The attribute `model.metricsNames`
   *   will give you the display labels for the scalar outputs.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  evaluate(t, e, s = {}) {
    const o = s.batchSize == null ? 32 : s.batchSize;
    Vu(o);
    const i6 = this.standardizeUserDataXY(t, e, true, o);
    try {
      const a = i6[0].concat(i6[1]);
      this.makeTestFunction();
      const l = this.testFunction, c = this.testLoop(l, a, o, s.verbose, s.steps);
      return Xe(c);
    } finally {
      Mn(i6[0], t), Mn(i6[1], e);
    }
  }
  // TODO(cais): Add code snippet below once real dataset objects are
  //   available.
  /**
   * Evaluate model using a dataset object.
   *
   * Note: Unlike `evaluate()`, this method is asynchronous (`async`).
   *
   * @param dataset A dataset object. Its `iterator()` method is expected
   *   to generate a dataset iterator object, the `next()` method of which
   *   is expected to produce data batches for evaluation. The return value
   *   of the `next()` call ought to contain a boolean `done` field and a
   *   `value` field. The `value` field is expected to be an array of two
   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
   *   case is for models with exactly one input and one output (e.g.
   *   a sequential model). The latter case is for models with multiple
   *   inputs and/or multiple outputs. Of the two items in the array, the
   *   first is the input feature(s) and the second is the output target(s).
   * @param args A configuration object for the dataset-based evaluation.
   * @returns Loss and metric values as an Array of `Scalar` objects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async evaluateDataset(t, e) {
    return this.makeTestFunction(), a3(this, t, e);
  }
  /**
   * Get number of samples provided for training, evaluation or prediction.
   *
   * @param ins Input `tf.Tensor`.
   * @param batchSize Integer batch size, optional.
   * @param steps Total number of steps (batches of samples) before
   * declaring loop finished. Optional.
   * @param stepsName The public API's parameter name for `steps`.
   * @returns Number of samples provided.
   */
  checkNumSamples(t, e, s, o = "steps") {
    let r;
    if (s != null) {
      if (r = null, e != null)
        throw new E(`If ${o} is set, batchSize must be null or undefined.Got batchSize = ${e}`);
    } else if (t != null)
      Array.isArray(t) ? r = t[0].shape[0] : r = t.shape[0];
    else
      throw new E(`Either the input data should have a defined shape, or ${o} shoud be specified.`);
    return r;
  }
  /**
   * Execute internal tensors of the model with input data feed.
   * @param inputs Input data feed. Must match the inputs of the model.
   * @param outputs Names of the output tensors to be fetched. Must match
   *   names of the SymbolicTensors that belong to the graph.
   * @returns Fetched values for `outputs`.
   */
  execute(t, e) {
    if (Array.isArray(e) && e.length === 0)
      throw new E("`outputs` is an empty Array, which is not allowed.");
    const s = Array.isArray(e), o = s ? e : [e], r = this.retrieveSymbolicTensors(o), i6 = new Ds();
    if (t instanceof Mt && (t = [t]), Array.isArray(t)) {
      if (t.length !== this.inputs.length)
        throw new E(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);
      for (let l = 0; l < this.inputs.length; ++l)
        i6.add(this.inputs[l], t[l]);
    } else
      for (const l of this.inputs) {
        const c = t[l.name];
        if (c == null)
          throw new E(`No value is provided for the model's input ${l.name}`);
        i6.add(l, c);
      }
    const a = Yr(r, i6);
    return s ? a : a[0];
  }
  /**
   * Retrieve the model's internal symbolic tensors from symbolic-tensor names.
   */
  retrieveSymbolicTensors(t) {
    const e = Wo(null, t.length);
    let s = t.length;
    for (const o of this.layers) {
      const r = Array.isArray(o.output) ? o.output : [o.output], i6 = r.map((a) => a.name);
      for (let a = 0; a < t.length; ++a) {
        const l = i6.indexOf(t[a]);
        if (l !== -1 && (e[a] = r[l], s--), s === 0)
          break;
      }
      if (s === 0)
        break;
    }
    if (s > 0) {
      const o = [];
      throw e.forEach((r, i6) => {
        r == null && o.push(t[i6]);
      }), new E(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(o)}`);
    }
    return e;
  }
  /**
   * Helper method to loop over some data in batches.
   *
   * Porting Note: Not using the functional approach in the Python equivalent
   *   due to the imperative backend.
   * Porting Note: Does not support step mode currently.
   *
   * @param ins: input data
   * @param batchSize: integer batch size.
   * @param verbose: verbosity model
   * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of
   *   `tf.Tensor` (if multipe outputs).
   */
  predictLoop(t, e = 32, s = false) {
    return D(() => {
      const o = this.checkNumSamples(t);
      if (s)
        throw new yt("Verbose predictLoop() is not implemented yet.");
      const r = zu(o, e), i6 = this.outputs.map((a) => []);
      for (let a = 0; a < r.length; ++a)
        D(() => {
          const c = r[a][0], u = r[a][1], d = Xr(t, c, u), h = [];
          if (Array.isArray(d))
            for (let f = 0; f < d.length; ++f)
              h.push({ key: this.inputs[f], value: d[f] });
          else
            h.push({ key: this.inputs[0], value: d });
          const p = new Ds(h);
          return Yr(this.outputs, p);
        }).forEach((c, u) => i6[u].push(c));
      return Xe(i6.map((a) => Ge(a, 0)));
    });
  }
  /**
   * Generates output predictions for the input samples.
   *
   * Computation is done in batches.
   *
   * Note: the "step" mode of predict() is currently not supported.
   *   This is because the TensorFlow.js core backend is imperative only.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();
   * ```
   *
   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if
   *   the model has multiple inputs.
   * @param args A `ModelPredictArgs` object containing optional fields.
   *
   * @return Prediction results as a `tf.Tensor`(s).
   *
   * @exception ValueError In case of mismatch between the provided input data
   *   and the model's expectations, or in case a stateful model receives a
   *   number of samples that is not a multiple of the batch size.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predict(t, e = {}) {
    const s = ny(t);
    og(s, this.inputNames, this.feedInputShapes, false);
    try {
      const o = e.batchSize == null ? 32 : e.batchSize;
      return Vu(o), this.predictLoop(s, o);
    } finally {
      Mn(s, t);
    }
  }
  /**
   * Returns predictions for a single batch of samples.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.predictOnBatch(tf.ones([8, 10])).print();
   * ```
   * @param x: Input samples, as a Tensor (for models with exactly one
   *   input) or an array of Tensors (for models with more than one input).
   * @return Tensor(s) of predictions
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predictOnBatch(t) {
    og(t, this.inputNames, this.feedInputShapes, true);
    const e = (Array.isArray(t) ? t[0] : t).shape[0];
    return this.predictLoop(t, e);
  }
  standardizeUserDataXY(t, e, s = true, o) {
    if (this.optimizer_ == null)
      throw new Sn("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
    const r = [];
    for (let i6 = 0; i6 < this.feedOutputShapes.length; ++i6) {
      const a = this.feedOutputShapes[i6];
      this.feedLossFns[i6] === El ? r.push(a.slice(0, a.length - 1).concat([1])) : r.push(a);
    }
    if (t = sg(t, this.feedInputNames, this.feedInputShapes, false, "input"), e = sg(e, this.feedOutputNames, r, false, "target"), c3(t, e), u3(e, this.feedLossFns, this.feedOutputShapes), this.stateful && o != null && o > 0 && t[0].shape[0] % o !== 0)
      throw new E(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${o}. Found: ${t[0].shape[0]} sample(s).`);
    return [t, e];
  }
  async standardizeUserData(t, e, s, o, r = true, i6) {
    const [a, l] = this.standardizeUserDataXY(t, e, r, i6);
    if (s != null)
      throw new Error("sample weight is not supported yet.");
    let c = null;
    if (o != null) {
      const u = qx(o, this.outputNames);
      c = [];
      for (let d = 0; d < u.length; ++d)
        c.push(await ty(l[d], null, u[d]));
    }
    return [a, l, c];
  }
  /**
   * Loop over some test data in batches.
   * @param f A Function returning a list of tensors.
   * @param ins Array of tensors to be fed to `f`.
   * @param batchSize Integer batch size or `null` / `undefined`.
   * @param verbose verbosity mode.
   * @param steps Total number of steps (batches of samples) before
   * declaring test finished. Ignored with the default value of `null` /
   * `undefined`.
   * @returns Array of Scalars.
   */
  testLoop(t, e, s, o = 0, r) {
    return D(() => {
      const i6 = this.checkNumSamples(e, s, r, "steps"), a = [];
      if (o > 0)
        throw new yt("Verbose mode is not implemented yet.");
      if (r != null)
        throw new yt("steps mode in testLoop() is not implemented yet");
      {
        const l = zu(i6, s), c = Ze(Kn(0, i6));
        for (let u = 0; u < l.length; ++u) {
          const d = l[u][0], h = l[u][1], p = Io(c, d, h - d), f = Wd(e, p), m = t(f);
          if (u === 0)
            for (let g = 0; g < m.length; ++g)
              a.push(gt(0));
          for (let g = 0; g < m.length; ++g) {
            const b = m[g];
            a[g] = U(a[g], G(h - d, b));
          }
        }
        for (let u = 0; u < a.length; ++u)
          a[u] = ut(a[u], i6);
      }
      return a;
    });
  }
  getDedupedMetricsNames() {
    const t = this.metricsNames, e = [];
    for (let s = 0; s < t.length; ++s) {
      const o = t[s];
      let r = o;
      if (Xm(t, o) > 1) {
        const i6 = Xm(t.slice(0, s), o);
        r += `_${i6}`;
      }
      e.push(r);
    }
    return e;
  }
  /**
   * Creates a function that performs the following actions:
   *
   * 1. computes the losses
   * 2. sums them to get the total loss
   * 3. call the optimizer computes the gradients of the LayersModel's
   *    trainable weights w.r.t. the total loss and update the variables
   * 4. calculates the metrics
   * 5. returns the values of the losses and metrics.
   */
  makeTrainFunction() {
    return (t) => {
      const e = [], s = t.slice(0, this.inputs.length), o = t.slice(this.inputs.length, this.inputs.length + this.outputs.length), r = t.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2), i6 = [], a = () => {
        const d = [];
        for (let m = 0; m < this.inputs.length; ++m)
          d.push({ key: this.inputs[m], value: s[m] });
        const h = new Ds(d), p = Yr(this.outputs, h, { training: true });
        let f;
        for (let m = 0; m < this.lossFunctions.length; ++m) {
          const g = this.lossFunctions[m];
          let b = g(o[m], p[m]);
          r[m] != null && (b = e3(b, r[m]));
          const x6 = oe(b);
          e.push(x6), m === 0 ? f = b : f = U(f, b);
        }
        for (let m = 0; m < this.metricsTensors.length; ++m) {
          let g;
          if (this.outputs.length > 1 && m < this.outputs.length)
            g = e[m];
          else {
            const b = this.metricsTensors[m][0], x6 = this.metricsTensors[m][1];
            g = oe(b(o[x6], p[x6]));
          }
          hn(g), i6.push(g);
        }
        return f = oe(f), this.calculateLosses().forEach((m) => {
          f = U(f, m);
        }), f;
      }, l = this.collectedTrainableWeights.map((d) => d.read());
      return [this.optimizer_.minimize(a, true, l)].concat(i6);
    };
  }
  /**
   * Create a function which, when invoked with an array of `tf.Tensor`s as a
   * batch of inputs, returns the prespecified loss and metrics of the model
   * under the batch of input data.
   */
  makeTestFunction() {
    this.testFunction = (t) => D(() => {
      const e = [];
      let s;
      const o = t.slice(0, this.inputs.length), r = t.slice(this.inputs.length, this.inputs.length + this.outputs.length), i6 = [];
      for (let c = 0; c < this.inputs.length; ++c)
        i6.push({ key: this.inputs[c], value: o[c] });
      const a = new Ds(i6), l = Yr(this.outputs, a);
      for (let c = 0; c < this.lossFunctions.length; ++c) {
        const u = this.lossFunctions[c], d = oe(u(r[c], l[c]));
        c === 0 ? s = d : s = U(s, d), e.push(s);
      }
      for (let c = 0; c < this.metricsTensors.length; ++c) {
        const u = this.metricsTensors[c][0], d = this.metricsTensors[c][1], h = oe(u(r[d], l[d]));
        e.push(h);
      }
      return e;
    });
  }
  /**
   * Trains the model for a fixed number of epochs (iterations on a
   * dataset).
   *
   * ```js
   * const model = tf.sequential({
   *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * for (let i = 1; i < 5 ; ++i) {
   *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {
   *       batchSize: 4,
   *       epochs: 3
   *   });
   *   console.log("Loss after Epoch " + i + " : " + h.history.loss[0]);
   * }
   * ```
   *
   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the
   * model has multiple inputs. If all inputs in the model are named, you
   * can also pass a dictionary mapping input names to `tf.Tensor`s.
   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if
   * the model has multiple outputs. If all outputs in the model are named,
   * you can also pass a dictionary mapping output names to `tf.Tensor`s.
   * @param args A `ModelFitArgs`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @exception ValueError In case of mismatch between the provided input
   * data and what the model expects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async fit(t, e, s = {}) {
    if (this.isTraining)
      throw new Error("Cannot start training because another fit() call is ongoing.");
    this.isTraining = true;
    let o, r, i6, a, l, c, u, d, h;
    try {
      const p = s.batchSize == null ? 32 : s.batchSize;
      Vu(p);
      const m = await this.standardizeUserData(t, e, s.sampleWeight, s.classWeight, false, p);
      o = m[0], r = m[1], h = m[2];
      let g = false, b;
      if (s.validationData != null && s.validationData.length > 0) {
        if (g = true, s.validationData.length === 2)
          l = s.validationData[0], c = s.validationData[1];
        else
          throw s.validationData.length === 3 ? new yt("validationData including sample weights is not supported yet.") : new E(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${s.validationData} is invalid.`);
        const R = await this.standardizeUserData(
          l,
          c,
          null,
          /** Unused sample weights. */
          null,
          true,
          p
        );
        u = R[0], d = R[1], b = u.concat(d);
      } else if (s.validationSplit != null && s.validationSplit > 0 && s.validationSplit < 1) {
        g = true;
        const N = Math.floor(o[0].shape[0] * (1 - s.validationSplit)), R = o[0].shape[0];
        u = Xr(o, N, R), i6 = o, o = Xr(o, 0, N), d = Xr(r, N, R), a = r, r = Xr(r, 0, N), b = u.concat(d);
      } else
        s.validationSteps != null && (g = true);
      const x6 = o.concat(r).concat(h);
      this.checkTrainableWeightsConsistency();
      const w = this.makeTrainFunction(), y6 = this.getDedupedMetricsNames();
      let I, v;
      g ? (this.makeTestFunction(), I = this.testFunction, v = y6.slice().concat(y6.map((N) => "val_" + N))) : (I = null, b = [], v = y6.slice());
      const k6 = Kx(s.callbacks, s.yieldEvery);
      return await this.fitLoop(w, x6, y6, p, s.epochs, s.verbose, k6, I, b, s.shuffle, v, s.initialEpoch, null, null);
    } finally {
      this.isTraining = false, Mn(o, t), Mn(r, e), Mn(i6, t), Mn(a, e), Mn(u, l), Mn(d, c), h != null && xt(h);
    }
  }
  /**
   * Abstract fit function for `f(ins)`.
   * @param f A Function returning a list of tensors. For training, this
   *   function is expected to perform the updates to the variables.
   * @param ins List of tensors to be fed to `f`.
   * @param outLabels List of strings, display names of the outputs of `f`.
   * @param batchSize Integer batch size or `== null` if unknown. Default : 32.
   * @param epochs Number of times to iterate over the data. Default : 1.
   * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.
   * @param callbacks List of callbacks to be called during training.
   * @param valF Function to call for validation.
   * @param valIns List of tensors to be fed to `valF`.
   * @param shuffle Whether to shuffle the data at the beginning of every
   * epoch. Default : true.
   * @param callbackMetrics List of strings, the display names of the metrics
   *   passed to the callbacks. They should be the concatenation of the
   *   display names of the outputs of `f` and the list of display names
   *   of the outputs of `valF`.
   * @param initialEpoch Epoch at which to start training (useful for
   *   resuming a previous training run). Default : 0.
   * @param stepsPerEpoch Total number of steps (batches on samples) before
   *   declaring one epoch finished and starting the next epoch. Ignored with
   *   the default value of `undefined` or `null`.
   * @param validationSteps Number of steps to run validation for (only if
   *   doing validation from data tensors). Not applicable for tfjs-layers.
   * @returns A `History` object.
   */
  async fitLoop(t, e, s, o, r, i6, a, l, c, u, d, h, p, f) {
    o == null && (o = 32), r == null && (r = 1), u == null && (u = true), h == null && (h = 0);
    let m = false;
    if (l != null && c != null && (m = true), f != null && (m = true, p == null))
      throw new E("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
    const g = this.checkNumSamples(e, o, p, "steps_per_epoch");
    let b;
    g != null && (b = Kn(0, g)), i6 == null && (i6 = 1);
    const { callbackList: x6, history: w } = Zx(a, i6, r, h, g, p, o, m, d);
    x6.setModel(this), this.history = w, await x6.onTrainBegin(), this.stopTraining_ = false;
    for (let y6 = h; y6 < r; ++y6) {
      await x6.onEpochBegin(y6);
      const I = {};
      if (p != null)
        throw new yt("stepsPerEpoch mode is not implemented yet.");
      {
        if (u === "batch")
          throw new yt("batch shuffling is not implemneted yet");
        u && Ud(b);
        const v = Ze(b), k6 = zu(g, o);
        for (let S = 0; S < k6.length; ++S) {
          const N = {};
          if (await x6.onBatchBegin(S, N), D(() => {
            const R = k6[S][0], M6 = k6[S][1], V = Io(v, R, M6 - R);
            N.batch = S, N.size = M6 - R;
            const z = Wd(e, V), P = t(z);
            for (let A = 0; A < s.length; ++A) {
              const O = s[A], B6 = P[A];
              N[O] = B6, hn(B6);
            }
            if (S === k6.length - 1 && m) {
              const A = this.testLoop(l, c, o);
              for (let O = 0; O < s.length; ++O) {
                const B6 = s[O], Z = A[O];
                hn(Z), I["val_" + B6] = Z;
              }
            }
          }), await x6.onBatchEnd(S, N), Xx(N), this.stopTraining_)
            break;
        }
        v.dispose();
      }
      if (await x6.onEpochEnd(y6, I), this.stopTraining_)
        break;
    }
    return await x6.onTrainEnd(), await this.history.syncData(), this.history;
  }
  // TODO(cais): Add code snippet below when it's possible to instantiate
  //   actual dataset objects.
  /**
   * Trains the model using a dataset object.
   *
   * @param dataset A dataset object. Its `iterator()` method is expected
   *   to generate a dataset iterator object, the `next()` method of which
   *   is expected to produce data batches for training. The return value
   *   of the `next()` call ought to contain a boolean `done` field and a
   *   `value` field. The `value` field is expected to be an array of two
   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
   *   case is for models with exactly one input and one output (e.g.
   *   a sequential model). The latter case is for models with multiple
   *   inputs and/or multiple outputs.
   *   Of the two items in the array, the first is the input feature(s) and
   *   the second is the output target(s).
   * @param args A `ModelFitDatasetArgs`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async fitDataset(t, e) {
    return o3(this, t, e);
  }
  /**
   * Runs a single gradient update on a single batch of data.
   *
   * This method differs from `fit()` and `fitDataset()` in the following
   * regards:
   *   - It operates on exactly one batch of data.
   *   - It returns only the loss and metric values, instead of
   *     returning the batch-by-batch loss and metric values.
   *   - It doesn't support fine-grained options such as verbosity and
   *     callbacks.
   *
   * @param x Input data. It could be one of the following:
   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has
   *     multiple inputs).
   *   - An Object mapping input names to corresponding `tf.Tensor` (if the
   *     model has named inputs).
   * @param y Target data. It could be either a `tf.Tensor` or multiple
   *   `tf.Tensor`s. It should be consistent with `x`.
   * @returns Training loss or losses (in case the model has
   *   multiple outputs), along with metrics (if any), as numbers.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async trainOnBatch(t, e) {
    const s = await this.standardizeUserData(t, e), o = s[0], r = s[1], a = this.makeTrainFunction()(o.concat(r)), l = [];
    for (const c of a) {
      const u = await c.data();
      l.push(u[0]);
    }
    return xt(a), Mn(s[0], t), Mn(s[1], e), Xe(l);
  }
  /**
   * Extract weight values of the model.
   *
   * @param config: An instance of `io.SaveConfig`, which specifies
   * model-saving options such as whether only trainable weights are to be
   * saved.
   * @returns A `NamedTensorMap` mapping original weight names (i.e.,
   *   non-uniqueified weight names) to their values.
   */
  getNamedWeights(t) {
    const e = [], s = t != null && t.trainableOnly, o = s ? this.trainableWeights : this.weights, r = this.getWeights(s);
    for (let i6 = 0; i6 < o.length; ++i6)
      s && !o[i6].trainable || e.push({ name: o[i6].originalName, tensor: r[i6] });
    return e;
  }
  /**
   * Setter used for force stopping of LayersModel.fit() (i.e., training).
   *
   * Example:
   *
   * ```js
   * const input = tf.input({shape: [10]});
   * const output = tf.layers.dense({units: 1}).apply(input);
   * const model = tf.model({inputs: [input], outputs: [output]});
   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});
   * const xs = tf.ones([8, 10]);
   * const ys = tf.zeros([8, 1]);
   *
   * const history = await model.fit(xs, ys, {
   *   epochs: 10,
   *   callbacks: {
   *     onEpochEnd: async (epoch, logs) => {
   *       if (epoch === 2) {
   *         model.stopTraining = true;
   *       }
   *     }
   *   }
   * });
   *
   * // There should be only 3 values in the loss array, instead of 10
   * values,
   * // due to the stopping after 3 epochs.
   * console.log(history.history.loss);
   * ```
   */
  set stopTraining(t) {
    this.stopTraining_ = t;
  }
  get stopTraining() {
    return this.stopTraining_;
  }
  get optimizer() {
    return this.optimizer_;
  }
  set optimizer(t) {
    this.optimizer_ !== t && (this.optimizer_ = t, this.isOptimizerOwned = false);
  }
  dispose() {
    const t = super.dispose();
    if (t.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {
      const e = wl().numTensors;
      this.optimizer_.dispose(), t.numDisposedVariables += e - wl().numTensors;
    }
    return t;
  }
  getLossIdentifiers() {
    let t;
    if (typeof this.loss == "string")
      t = us(this.loss);
    else if (Array.isArray(this.loss)) {
      for (const e of this.loss)
        if (typeof e != "string")
          throw new Error("Serialization of non-string loss is not supported.");
      t = this.loss.map((e) => us(e));
    } else {
      const e = Object.keys(this.loss);
      t = {};
      const s = this.loss;
      for (const o of e)
        if (typeof s[o] == "string")
          t[o] = us(s[o]);
        else
          throw new Error("Serialization of non-string loss is not supported.");
    }
    return t;
  }
  getMetricIdentifiers() {
    if (typeof this.metrics == "string" || typeof this.metrics == "function")
      return [us(Ua(this.metrics))];
    if (Array.isArray(this.metrics))
      return this.metrics.map((t) => us(Ua(t)));
    {
      const t = {};
      for (const e in this.metrics)
        t[e] = us(Ua(this.metrics[e]));
      return t;
    }
  }
  getTrainingConfig() {
    return {
      loss: this.getLossIdentifiers(),
      metrics: this.getMetricIdentifiers(),
      optimizer_config: {
        class_name: this.optimizer.getClassName(),
        config: this.optimizer.getConfig()
      }
    };
  }
  loadTrainingConfig(t) {
    if (t.weighted_metrics != null)
      throw new Error("Loading weight_metrics is not supported yet.");
    if (t.loss_weights != null)
      throw new Error("Loading loss_weights is not supported yet.");
    if (t.sample_weight_mode != null)
      throw new Error("Loading sample_weight_mode is not supported yet.");
    const e = fi(t.optimizer_config), s = An(e);
    let o;
    if (typeof t.loss == "string")
      o = ho(t.loss);
    else if (Array.isArray(t.loss))
      o = t.loss.map((i6) => ho(i6));
    else if (t.loss != null) {
      o = {};
      for (const i6 in t.loss)
        o[i6] = ho(t.loss[i6]);
    }
    let r;
    if (Array.isArray(t.metrics))
      r = t.metrics.map((i6) => ho(i6));
    else if (t.metrics != null) {
      r = {};
      for (const i6 in t.metrics)
        r[i6] = ho(t.metrics[i6]);
    }
    this.compile({ loss: o, metrics: r, optimizer: s });
  }
  /**
   * Save the configuration and/or weights of the LayersModel.
   *
   * An `IOHandler` is an object that has a `save` method of the proper
   * signature defined. The `save` method manages the storing or
   * transmission of serialized data ("artifacts") that represent the
   * model's topology and weights onto or via a specific medium, such as
   * file downloads, local storage, IndexedDB in the web browser and HTTP
   * requests to a server. TensorFlow.js provides `IOHandler`
   * implementations for a number of frequently used saving mediums, such as
   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`
   * for more details.
   *
   * This method also allows you to refer to certain types of `IOHandler`s
   * as URL-like string shortcuts, such as 'localstorage://' and
   * 'indexeddb://'.
   *
   * Example 1: Save `model`'s topology and weights to browser [local
   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);
   * then load it back.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * console.log('Prediction from original model:');
   * model.predict(tf.ones([1, 3])).print();
   *
   * const saveResults = await model.save('localstorage://my-model-1');
   *
   * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');
   * console.log('Prediction from loaded model:');
   * loadedModel.predict(tf.ones([1, 3])).print();
   * ```
   *
   * Example 2. Saving `model`'s topology and weights to browser
   * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);
   * then load it back.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * console.log('Prediction from original model:');
   * model.predict(tf.ones([1, 3])).print();
   *
   * const saveResults = await model.save('indexeddb://my-model-1');
   *
   * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');
   * console.log('Prediction from loaded model:');
   * loadedModel.predict(tf.ones([1, 3])).print();
   * ```
   *
   * Example 3. Saving `model`'s topology and weights as two files
   * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from
   * browser.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * const saveResults = await model.save('downloads://my-model-1');
   * ```
   *
   * Example 4. Send  `model`'s topology and weights to an HTTP server.
   * See the documentation of `tf.io.http` for more details
   * including specifying request parameters and implementation of the
   * server.
   *
   * ```js
   * const model = tf.sequential(
   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
   * const saveResults = await model.save('http://my-server/model/upload');
   * ```
   *
   * @param handlerOrURL An instance of `IOHandler` or a URL-like,
   * scheme-based string shortcut for `IOHandler`.
   * @param config Options for saving the model.
   * @returns A `Promise` of `SaveResult`, which summarizes the result of
   * the saving, such as byte sizes of the saved artifacts for the model's
   *   topology and weight values.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  async save(t, e) {
    if (typeof t == "string") {
      const c = Z2(t);
      if (c.length === 0)
        throw new E(`Cannot find any save handlers for URL '${t}'`);
      if (c.length > 1)
        throw new E(`Found more than one (${c.length}) save handlers for URL '${t}'`);
      t = c[0];
    }
    if (t.save == null)
      throw new E("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    const s = await Cm(this.getNamedWeights(e)), a = {
      modelTopology: this.toJSON(null, false),
      format: h3,
      generatedBy: `TensorFlow.js tfjs-layers v${jx}`,
      convertedBy: null
    };
    if ((e == null ? false : e.includeOptimizer) && this.optimizer != null) {
      a.trainingConfig = this.getTrainingConfig();
      const c = "optimizer", { data: u, specs: d } = await Cm(await this.optimizer.getWeights(), c);
      s.specs.push(...d), s.data = F2([s.data, u]);
    }
    return this.userDefinedMetadata != null && (qm(this.userDefinedMetadata, this.name, true), a.userDefinedMetadata = this.userDefinedMetadata), a.weightData = s.data, a.weightSpecs = s.specs, t.save(a);
  }
  /**
   * Set user-defined metadata.
   *
   * The set metadata will be serialized together with the topology
   * and weights of the model during `save()` calls.
   *
   * @param setUserDefinedMetadata
   */
  setUserDefinedMetadata(t) {
    qm(t, this.name), this.userDefinedMetadata = t;
  }
  /**
   * Get user-defined metadata.
   *
   * The metadata is supplied via one of the two routes:
   *   1. By calling `setUserDefinedMetadata()`.
   *   2. Loaded during model loading (if the model is constructed
   *      via `tf.loadLayersModel()`.)
   *
   * If no user-defined metadata is available from either of the
   * two routes, this function will return `undefined`.
   */
  getUserDefinedMetadata() {
    return this.userDefinedMetadata;
  }
};
ur.className = "Model";
_(ur);
var sy = class extends ur {
};
sy.className = "Functional";
_(sy);
async function FQ(n, t) {
  "modelTopology" in n || (n = { modelTopology: n }), n = n;
  let e = n.modelTopology;
  e.model_config != null && (e = e.model_config);
  const s = fi(e), o = An(s, t);
  if (n.weightsManifest != null) {
    const r = await a$(n.weightsManifest, n.pathPrefix, o.weights.map((a) => a.originalName)), i6 = {};
    for (const a of o.weights)
      i6[a.originalName] = r[a.originalName];
    o.loadWeights(i6), xt(r);
  }
  return o;
}
async function VQ(n, t) {
  if (t == null && (t = {}), typeof n == "string") {
    const e = B2(n, t);
    if (e.length === 0)
      e.push(h$(n, t));
    else if (e.length > 1)
      throw new E(`Found more than one (${e.length}) load handlers for URL '${n}'`);
    n = e[0];
  }
  return p3(n, void 0, t);
}
async function p3(n, t, e) {
  if (e == null && (e = {}), n.load == null)
    throw new E("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
  const s = await n.load();
  let o = s.modelTopology;
  o.model_config != null && (o = o.model_config);
  const r = e.strict == null ? true : e.strict, i6 = s.weightData != null && s.weightSpecs != null && r, a = An(fi(o), t, i6), l = s.trainingConfig;
  if (l != null && a.loadTrainingConfig(l), s.userDefinedMetadata != null && a.setUserDefinedMetadata(s.userDefinedMetadata), s.weightData != null) {
    if (s.weightSpecs == null)
      throw new E("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");
    const { modelWeights: c, optimizerWeights: u } = f3(s.weightData, s.weightSpecs);
    a.loadWeights(c, r), a.optimizer != null && u.length > 0 && await a.optimizer.setWeights(u), xt(c), xt(u.map((d) => d.tensor));
  }
  return a;
}
function f3(n, t) {
  const e = Ab(n, t), s = {}, o = [];
  return t.forEach((r) => {
    r.group === "optimizer" ? o.push({ name: r.name, tensor: e[r.name] }) : s[r.name] = e[r.name];
  }), { modelWeights: s, optimizerWeights: o };
}
var mi = class _mi extends ur {
  constructor(t) {
    if (super({ inputs: [], outputs: [] }), t = t || {}, this.trainable = true, this.built = false, this.name = t.name != null ? t.name : au("sequential_"), t.layers != null)
      for (const e of t.layers)
        this.add(e);
  }
  // Helper function to Sequential.add  Throws if the new output shape will be
  // invalid.
  checkShape(t) {
    if (t.inboundNodes[0].outputTensors[0].shape.some((s) => s < 0))
      throw new E(`Negative dimension size caused by adding layer ${t.name} with input shape [${t.inboundNodes[0].inputTensors[0].shape}]`);
  }
  /**
   * Adds a layer instance on top of the layer stack.
   *
   * ```js
   *  const model = tf.sequential();
   *  model.add(tf.layers.dense({units: 8, inputShape: [1]}));
   *  model.add(tf.layers.dense({units: 4, activation: 'relu6'}));
   *  model.add(tf.layers.dense({units: 1, activation: 'relu6'}));
   *  // Note that the untrained model is random at this point.
   *  model.predict(tf.randomNormal([10, 1])).print();
   * ```
   * @param layer Layer instance.
   *
   * @exception ValueError In case the `layer` argument does not know its
   * input shape.
   * @exception ValueError In case the `layer` argument has multiple output
   *   tensors, or is already connected somewhere else (forbidden in
   *   `Sequential` models).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  add(t) {
    const e = t instanceof _mi || t instanceof ur;
    let s;
    if (e) {
      if (s = t, s.outputs.length !== 1)
        throw new E("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      if (s.inputs.length !== 1)
        throw new E("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
    }
    if (this.outputs.length === 0) {
      if (t.inboundNodes.length === 0) {
        if (t.batchInputShape == null)
          throw new E("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");
        const o = fL({
          batchShape: t.batchInputShape,
          dtype: t.dtype,
          name: t.name + "_input"
        });
        t.apply(o);
      }
      if (e)
        this.outputs = s.outputs, this.inputs = s.inputs;
      else {
        if (t.inboundNodes.length !== 1)
          throw new E(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);
        if (t.inboundNodes[0].outputTensors.length !== 1)
          throw new E("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        this.checkShape(t), this.outputs = [t.inboundNodes[0].outputTensors[0]], this.inputs = Vx(this.outputs[0]);
      }
      this.inboundNodes = [], new cu({
        outboundLayer: this,
        inboundLayers: [],
        nodeIndices: [],
        tensorIndices: [],
        inputTensors: this.inputs,
        outputTensors: this.outputs,
        // no model-level masking for now
        inputMasks: Wo(null, this.inputs.length),
        outputMasks: [null],
        inputShapes: this.inputs.map((o) => o.shape),
        outputShapes: this.outputs[0].shape
      });
    } else {
      const o = t.apply(this.outputs[0]);
      if (Array.isArray(o))
        throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      this.checkShape(t), this.outputs = [o], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
    this.layers.push(t), this.built = false;
  }
  /**
   * Removes the last layer in the model.
   *
   * @exception TypeError if there are no layers in the model.
   */
  pop() {
    if (this.layers.length === 0)
      throw new TypeError("There are no layers in the model.");
    if (this.layers.pop(), this.layers.length === 0)
      this.outputs = [], this.inboundNodes = [], this.outboundNodes = [];
    else {
      const t = this.layers.length - 1;
      this.layers[t].outboundNodes = [], this.outputs = [this.layers[t].output], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
  }
  call(t, e) {
    return this.model == null && this.build(), this.model.call(t, e);
  }
  build(t) {
    if (Rt(t), this.inputs.length === 0 || this.outputs.length === 0)
      throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
    this.model = new ur({
      inputs: this.inputs,
      outputs: this.outputs[0],
      name: this.name + "_model"
    }), this.model.trainable = this.trainable, this.supportsMasking = this.model.supportsMasking, this.inputLayers = this.model.inputLayers, this.inputLayersNodeIndices = this.model.inputLayersNodeIndices, this.inputLayersTensorIndices = this.model.inputLayersTensorIndices, this.outputLayers = this.model.outputLayers, this.outputLayersNodeIndices = this.model.outputLayersNodeIndices, this.outputLayersTensorIndices = this.model.outputLayersTensorIndices, this.nodesByDepth = this.model.nodesByDepth, this.containerNodes = this.model.containerNodes, this.outputNames = this.model.outputNames, this.inputNames = this.model.inputNames, this.built = true;
  }
  countParams() {
    return this.built || this.build(), super.countParams();
  }
  /**
   * Print a text summary of the Sequential model's layers.
   *
   * The summary includes
   * - Name and type of all layers that comprise the model.
   * - Output shape(s) of the layers
   * - Number of weight parameters of each layer
   * - The total number of trainable and non-trainable parameters of the
   * model.
   *
   * ```js
   * const model = tf.sequential();
   * model.add(
   *     tf.layers.dense({units: 100, inputShape: [10], activation: 'relu'}));
   * model.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));
   *
   * model.summary();
   * ```
   *
   * @param lineLength Custom line length, in number of characters.
   * @param positions Custom widths of each of the columns, as either
   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number
   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to
   *   right-most (i.e., ending) position of a column.
   * @param printFn Custom print function. Can be used to replace the default
   *   `console.log`. For example, you can use `x => {}` to mute the printed
   *   messages in the console.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  summary(t, e, s = console.log) {
    this.built || this.build(), super.summary(t, e, s);
  }
  /**
   * Sets the weights of the model.
   *
   * @param weights Should be a list of Tensors with shapes and types matching
   *   the output of `model.getWeights()`.
   */
  setWeights(t) {
    this.model == null && this.build(), this.model.setWeights(t);
  }
  /**
   * Returns the loss value & metrics values for the model in test mode.
   *
   * Loss and metrics are specified during `compile()`, which needs to happen
   * before calls to `evaluate()`.
   *
   * Computation is done in batches.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const result = model.evaluate(tf.ones([8, 10]), tf.ones([8, 1]), {
   *   batchSize: 4,
   * });
   * result.print();
   * ```
   *
   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the
   * model has multiple inputs.
   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the
   * model has multiple outputs.
   * @param args A `ModelEvaluateConfig`, containing optional fields.
   *
   * @return `Scalar` test loss (if the model has a single output and no
   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs
   *   and/or metrics). The attribute `model.metricsNames`
   *   will give you the display labels for the scalar outputs.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  evaluate(t, e, s = {}) {
    if (!this.built)
      throw new Sn("The model needs to be compiled before being used.");
    return this.model.evaluate(t, e, s);
  }
  // TODO(cais): Add code snippet below once real dataset objects are
  //   available.
  /**
   * Evaluate model using a dataset object.
   *
   * Note: Unlike `evaluate()`, this method is asynchronous (`async`).
   *
   * @param dataset A dataset object. Its `iterator()` method is expected
   *   to generate a dataset iterator object, the `next()` method of which
   *   is expected to produce data batches for evaluation. The return value
   *   of the `next()` call ought to contain a boolean `done` field and a
   *   `value` field. The `value` field is expected to be an array of two
   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
   *   case is for models with exactly one input and one output (e.g.
   *   a sequential model). The latter case is for models with multiple
   *   inputs and/or multiple outputs. Of the two items in the array, the
   *   first is the input feature(s) and the second is the output target(s).
   * @param args A configuration object for the dataset-based evaluation.
   * @returns Loss and metric values as an Array of `Scalar` objects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async evaluateDataset(t, e) {
    if (!this.built)
      throw new Sn("The model needs to be compiled before being used.");
    return this.model.evaluateDataset(t, e);
  }
  /**
   * Generates output predictions for the input samples.
   *
   * Computation is done in batches.
   *
   * Note: the "step" mode of predict() is currently not supported.
   *   This is because the TensorFlow.js core backend is imperative only.
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.predict(tf.ones([2, 10])).print();
   * ```
   *
   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if
   *   the model has multiple inputs.
   * @param conifg A `ModelPredictConfig` object containing optional fields.
   *
   * @return `tf.Tensor`(s) of predictions.
   *
   * @exception ValueError In case of mismatch between the provided input data
   *   and the model's expectations, or in case a stateful model receives a
   *   number of samples that is not a multiple of the batch size.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predict(t, e = {}) {
    return this.model == null && this.build(), this.model.predict(t, e);
  }
  /**
   * Returns predictions for a single batch of samples.
   *
   * @param x: Input samples, as a Tensor, or list of Tensors (if the model
   *   has multiple inputs).
   * @return Tensor(s) of predictions
   */
  predictOnBatch(t) {
    return this.model == null && this.build(), this.model.predictOnBatch(t);
  }
  /**
   * See `LayersModel.compile`.
   *
   * @param args
   */
  compile(t) {
    this.build(), this.model.compile(t), this.optimizer_ = this.model.optimizer, this.isOptimizerOwned = this.model.isOptimizerOwned, this.loss = this.model.loss, this.metrics = this.model.metrics, this.metricsTensors = this.model.metricsTensors, this.metricsNames = this.model.metricsNames;
  }
  get optimizer() {
    return this.model == null ? void 0 : this.model.optimizer;
  }
  set optimizer(t) {
    this.model.optimizer = t;
  }
  /**
   * Trains the model for a fixed number of epochs (iterations on a dataset).
   *
   * ```js
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const history = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {
   *   batchSize: 4,
   *   epochs: 3
   * });
   * console.log(history.history.loss[0]);
   * ```
   *
   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the
   * model has multiple inputs. If all inputs in the model are named, you can
   * also pass a dictionary mapping input names to `tf.Tensor`s.
   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if
   * the model has multiple outputs. If all outputs in the model are named, you
   *  can also pass a dictionary mapping output names to `tf.Tensor`s.
   * @param args  A `ModelFitConfig`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @exception ValueError In case of mismatch between the provided input data
   *   and what the model expects.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async fit(t, e, s = {}) {
    if (!this.built)
      throw new Sn("The model needs to be compiled before being used.");
    return this.model.fit(t, e, s);
  }
  /**
   * Trains the model using a dataset object.
   *
   * ```js
   * const xArray = [
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
   * ];
   * const yArray = [1, 1, 1, 1];
   * // Create a dataset from the JavaScript array.
   * const xDataset = tf.data.array(xArray);
   * const yDataset = tf.data.array(yArray);
   * // Zip combines the `x` and `y` Datasets into a single Dataset, the
   * // iterator of which will return an object containing of two tensors,
   * // corresponding to `x` and `y`.  The call to `batch(4)` will bundle
   * // four such samples into a single object, with the same keys now pointing
   * // to tensors that hold 4 examples, organized along the batch dimension.
   * // The call to `shuffle(4)` causes each iteration through the dataset to
   * // happen in a different order.  The size of the shuffle window is 4.
   * const xyDataset = tf.data.zip({xs: xDataset, ys: yDataset})
   *     .batch(4)
   *     .shuffle(4);
   * const model = tf.sequential({
   *   layers: [tf.layers.dense({units: 1, inputShape: [9]})]
   * });
   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
   * const history = await model.fitDataset(xyDataset, {
   *   epochs: 4,
   *   callbacks: {onEpochEnd: (epoch, logs) => console.log(logs.loss)}
   * });
   * ```
   *
   * @param dataset A dataset object. Its `iterator()` method is expected to
   *   generate a dataset iterator object, the `next()` method of which is
   *   expected to produce data batches for evaluation. The return value of the
   *   `next()` call ought to contain a boolean `done` field and a `value`
   *   field.
   *
   *   The `value` field is expected to be an object of with fields
   *   `xs` and `ys`, which point to the feature tensor and the target tensor,
   *   respectively. This case is for models with exactly one input and one
   *   output (e.g. a sequential model). For example:
   *   ```js
   *   {value: {xs: xsTensor, ys: ysTensor}, done: false}
   *   ```
   *
   *   If the model has multiple inputs, the `xs` field of `value` should
   *   be an object mapping input names to their respective feature tensors.
   *   For example:
   *   ```js
   *   {
   *     value: {
   *       xs: {
   *         input_1: xsTensor1,
   *         input_2: xsTensor2
   *       },
   *       ys: ysTensor
   *     },
   *     done: false
   *   }
   *   ```
   *   If the model has multiple outputs, the `ys` field of `value` should
   *   be an object mapping output names to their respective target tensors.
   *   For example:
   *   ```js
   *   {
   *     value: {
   *       xs: xsTensor,
   *       ys: {
   *         output_1: ysTensor1,
   *         output_2: ysTensor2
   *       },
   *     },
   *     done: false
   *   }
   *   ```
   * @param args A `ModelFitDatasetArgs`, containing optional fields.
   *
   * @return A `History` instance. Its `history` attribute contains all
   *   information collected during training.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  async fitDataset(t, e) {
    if (!this.built)
      throw new Sn("The model needs to be compiled before being used.");
    return this.model.fitDataset(t, e);
  }
  /**
   * Runs a single gradient update on a single batch of data.
   *
   * This method differs from `fit()` and `fitDataset()` in the following
   * regards:
   *   - It operates on exactly one batch of data.
   *   - It returns only the loss and metric values, instead of
   *     returning the batch-by-batch loss and metric values.
   *   - It doesn't support fine-grained options such as verbosity and
   *     callbacks.
   *
   * @param x Input data. It could be one of the following:
   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has
   *     multiple inputs).
   *   - An Object mapping input names to corresponding `tf.Tensor` (if the
   *     model has named inputs).
   * @param y Target data. It could be either a `tf.Tensor` or multiple
   *   `tf.Tensor`s. It should be consistent with `x`.
   * @returns Training loss or losses (in case the model has
   *   multiple outputs), along with metrics (if any), as numbers.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async trainOnBatch(t, e) {
    return this.model.trainOnBatch(t, e);
  }
  /* See parent class for JsDoc */
  /** @nocollapse */
  static fromConfig(t, e, s = {}, o = false) {
    let r, i6 = {};
    if (e instanceof Array) {
      if (e[0].className == null || e[0].className === "Merge")
        throw new E("Legacy serialization format not supported yet.");
      r = e;
    } else
      C(e.layers != null, () => "When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."), r = e.layers, delete e.layers, i6 = e;
    const a = new t(i6);
    if (!(a instanceof _mi))
      throw new yt(`Sequential.fromConfig called on non-Sequential input: ${a}`);
    for (const l of r) {
      const u = An(l, void 0, o);
      o && u.setFastWeightInitDuringBuild(true), a.add(u);
    }
    return a;
  }
  /**
   * Setter used for force stopping of LayersModel.fit() (i.e., training).
   *
   * Example:
   *
   * ```js
   * const model = tf.sequential();
   * model.add(tf.layers.dense({units: 1, inputShape: [10]}));
   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});
   * const xs = tf.ones([8, 10]);
   * const ys = tf.zeros([8, 1]);
   *
   * const history = await model.fit(xs, ys, {
   *   epochs: 10,
   *   callbacks: {
   *     onEpochEnd: async (epoch, logs) => {
   *       if (epoch === 2) {
   *         model.stopTraining = true;
   *       }
   *     }
   *   }
   * });
   *
   * // There should be only 3 values in the loss array, instead of 10 values,
   * // due to the stopping after 3 epochs.
   * console.log(history.history.loss);
   * ```
   */
  set stopTraining(t) {
    if (this.model == null)
      throw new E("Cannot set the stopTraining property of a sequential model before it is compiled.");
    this.model.stopTraining = t;
  }
  get stopTraining() {
    if (this.model == null)
      throw new E("Cannot get the stopTraining property of a sequential model before it is compiled.");
    return this.model.stopTraining;
  }
  // TODO(cais): Override get trainableWeights() here
  // tslint:disable-next-line:no-any
  getConfig() {
    const t = [];
    for (const e of this.layers) {
      const s = {};
      s.className = e.getClassName(), s.config = e.getConfig(), t.push(s);
    }
    return { name: this.name, layers: t };
  }
};
mi.className = "Sequential";
_(mi);
var Ye = class extends _o {
  getConfig() {
    return {};
  }
};
var oy = class extends Ye {
  /**
   * Calculate the activation function.
   *
   * @param x: Input.
   * @param alpha: Scaling factor the negative section.
   * @return Output of the ELU activation.
   */
  apply(t, e = 1) {
    return jE(t, e);
  }
};
oy.className = "elu";
_(oy);
var ry = class extends Ye {
  apply(t) {
    return h0(t);
  }
};
ry.className = "selu";
_(ry);
var iy = class extends Ye {
  apply(t) {
    return Ts(t);
  }
};
iy.className = "relu";
_(iy);
var ay = class extends Ye {
  apply(t) {
    return D(() => br(6, Ts(t)));
  }
};
ay.className = "relu6";
_(ay);
var ly = class extends Ye {
  apply(t) {
    return t;
  }
};
ly.className = "linear";
_(ly);
var cy = class extends Ye {
  apply(t) {
    return kr(t);
  }
};
cy.className = "sigmoid";
_(cy);
var uy = class extends Ye {
  apply(t) {
    return tL(t);
  }
};
uy.className = "hardSigmoid";
_(uy);
var dy = class extends Ye {
  apply(t) {
    return va(t);
  }
};
dy.className = "softplus";
_(dy);
var hy = class extends Ye {
  apply(t) {
    return qE(t);
  }
};
hy.className = "softsign";
_(hy);
var py = class extends Ye {
  apply(t) {
    return sp(t);
  }
};
py.className = "tanh";
_(py);
var Gf = class extends Ye {
  /**
   * Calculate the activation function.
   *
   * @param x Tensor.
   * @param axis Integer, axis along which the softmax normalization is applied.
   * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be
   * an error.
   *
   * @returns a Tensor of the same shape as x
   *
   * @throws ValueError: In case `dim(x) < 2`.
   */
  apply(t, e = -1) {
    return $p(t, e);
  }
};
Gf.className = "softmax";
_(Gf);
var fy = class extends Ye {
  /**
   * Calculate the activation function of log softmax:
   * log( exp(x_i) / sum(exp(x)) )
   *
   * @param x Tensor.
   * @param axis Integer, axis along which the softmax normalization is applied.
   * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be
   * an error.
   *
   * @returns a Tensor of the same shape as x
   *
   * @throws ValueError: In case `dim(x) < 2`.
   */
  apply(t, e = -1) {
    return r0(t, e);
  }
};
fy.className = "logSoftmax";
_(fy);
var my = class extends Ye {
  /**
   * Calculate the activation function.
   *
   * @param x Tensor.
   * @param alpha Scaling factor for the sigmoid function.
   * @returns a Tensor of the same shape as x
   */
  apply(t, e = 1) {
    return D(() => G(kr(G(t, e)), t));
  }
};
my.className = "swish";
_(my);
var gy = class extends Ye {
  /**
   * Calculate the activation function.
   *
   * @param x Tensor.
   * @returns a Tensor of the same shape as x
   */
  apply(t) {
    return D(() => G(t, sp(va(t))));
  }
};
gy.className = "mish";
_(gy);
function Hs(n) {
  return n.getClassName();
}
function Pu(n, t = {}) {
  return Ga(n, cn.getMap().classNameMap, t, "activation");
}
function _s(n) {
  if (n == null) {
    const t = {};
    return t.className = "linear", t.config = {}, Pu(t);
  }
  if (typeof n == "string") {
    const t = {};
    return t.className = n, t.config = {}, Pu(t);
  } else
    return n instanceof Ye ? n : Pu(n);
}
function Ef(n) {
  if (n != null && typeof n != "object")
    throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${n}`);
}
var by = class extends _o {
};
var hu = class extends by {
  constructor(t) {
    super(), Ef(t), this.l1 = t == null || t.l1 == null ? 0.01 : t.l1, this.l2 = t == null || t.l2 == null ? 0.01 : t.l2, this.hasL1 = this.l1 !== 0, this.hasL2 = this.l2 !== 0;
  }
  /**
   * Porting note: Renamed from __call__.
   * @param x Variable of which to calculate the regularization score.
   */
  apply(t) {
    return D(() => {
      let e = be([1]);
      return this.hasL1 && (e = U(e, at(G(this.l1, me(t))))), this.hasL2 && (e = U(e, at(G(this.l2, La(t))))), W(e, []);
    });
  }
  getConfig() {
    return { l1: this.l1, l2: this.l2 };
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t({ l1: e.l1, l2: e.l2 });
  }
};
hu.className = "L1L2";
_(hu);
function AQ(n) {
  return Ef(n), new hu({ l1: n != null ? n.l1 : null, l2: 0 });
}
function OQ(n) {
  return Ef(n), new hu({ l2: n != null ? n.l2 : null, l1: 0 });
}
var rg = {
  l1l2: "L1L2"
};
function zt(n) {
  return gf(n);
}
function ig(n, t = {}) {
  return Ga(n, cn.getMap().classNameMap, t, "regularizer");
}
function Qt(n) {
  if (n == null)
    return null;
  if (typeof n == "string") {
    const e = { className: n in rg ? rg[n] : n, config: {} };
    return ig(e);
  } else
    return n instanceof by ? n : ig(n);
}
var xy = class extends St {
  constructor(t) {
    super(t ?? {}), this.supportsMasking = true, t != null && (this.maxValue = t.maxValue);
  }
  call(t, e) {
    t = mt(t);
    let s = Ts(t);
    return this.maxValue != null && (s = fn(s, 0, this.maxValue)), s;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { maxValue: this.maxValue }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
xy.className = "ReLU";
_(xy);
var yy = class extends St {
  constructor(t) {
    super(t ?? {}), this.DEFAULT_ALPHA = 0.3, t == null && (t = {}), this.alpha = t.alpha == null ? this.DEFAULT_ALPHA : t.alpha;
  }
  call(t, e) {
    const s = mt(t);
    return dp(s, this.alpha);
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { alpha: this.alpha }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
yy.className = "LeakyReLU";
_(yy);
var wy = class extends St {
  constructor(t) {
    if (super(t ?? {}), this.DEFAULT_ALPHA_INITIALIZER = "zeros", t == null && (t = {}), this.supportsMasking = true, this.alphaInitializer = Ut(t.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER), this.alphaRegularizer = Qt(t.alphaRegularizer), this.alphaConstraint = pe(t.alphaConstraint), t.sharedAxes == null)
      this.sharedAxes = null;
    else if (Array.isArray(t.sharedAxes))
      this.sharedAxes = t.sharedAxes;
    else if (typeof t.sharedAxes == "number")
      this.sharedAxes = [t.sharedAxes];
    else
      throw new E(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`);
  }
  build(t) {
    t = Rt(t);
    const e = t.slice(1);
    if (this.sharedAxes != null)
      for (const o of this.sharedAxes)
        e[o - 1] = 1;
    this.alpha = this.addWeight("alpha", e, "float32", this.alphaInitializer, this.alphaRegularizer, true, this.alphaConstraint);
    const s = {};
    if (this.sharedAxes != null)
      for (let o = 1; o < t.length; ++o)
        s[o] = t[o];
    this.inputSpec = [new de({
      ndim: t.length,
      axes: s
    })], this.built = true;
  }
  call(t, e) {
    return t = mt(t), yp(t, this.alpha.read());
  }
  getConfig() {
    const t = {
      alphaInitializer: jt(this.alphaInitializer),
      alphaRegularizer: zt(this.alphaRegularizer),
      alphaConstraint: he(this.alphaConstraint),
      sharedAxes: this.sharedAxes
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
wy.className = "PReLU";
_(wy);
var Iy = class extends St {
  constructor(t) {
    if (super(t ?? {}), this.DEFAULT_ALPHA = 1, t == null && (t = {}), t.alpha != null && t.alpha !== this.DEFAULT_ALPHA)
      throw new yt(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);
    this.alpha = t.alpha == null ? this.DEFAULT_ALPHA : t.alpha;
  }
  call(t, e) {
    const s = mt(t);
    return Jc(s);
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { alpha: this.alpha }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Iy.className = "ELU";
_(Iy);
var Cy = class extends St {
  constructor(t) {
    super(t ?? {}), this.DEFAULT_THETA = 1, t == null && (t = {}), this.theta = t.theta == null ? this.DEFAULT_THETA : t.theta;
  }
  call(t, e) {
    const s = mt(t);
    return G(s, tt(rn(s, this.theta), "float32"));
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { theta: this.theta }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Cy.className = "ThresholdedReLU";
_(Cy);
var vy = class extends St {
  constructor(t) {
    super(t ?? {}), this.DEFAULT_AXIS = 1, t == null && (t = {}), this.softmax = new Gf().apply, this.axis = t.axis == null ? this.DEFAULT_AXIS : t.axis;
  }
  call(t, e) {
    return D(() => {
      let s = mt(t);
      const o = e.mask;
      if (o != null) {
        const r = G(it(ks(s.shape), tt(o, s.dtype)), gt(-1e9));
        s = U(s, r);
      }
      return this.axis instanceof Array ? this.axis.length > 1 ? mn(it(s, pp(s, this.axis, true))) : this.softmax(s, this.axis[0]) : this.softmax(s, this.axis);
    });
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = { axis: this.axis }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
vy.className = "Softmax";
_(vy);
function dr(n, t, e) {
  if (typeof n == "number")
    return Wo(n, t);
  if (n.length !== t)
    throw new E(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${n.length} elements.`);
  for (let s = 0; s < t; ++s) {
    const o = n[s];
    if (!UE(o))
      throw new E(`The ${e} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(n)} including a non-integer number ${o}`);
  }
  return n;
}
function On(n, t, e, s, o = 1) {
  if (n == null)
    return n;
  const r = t + (t - 1) * (o - 1);
  let i6;
  return e === "same" ? i6 = n : i6 = n - r + 1, Math.floor((i6 + s - 1) / s);
}
function jn(n, t, e, s) {
  if (n == null)
    return null;
  if (s === "valid")
    n = n * t + Bs([e - t, 0]);
  else if (s === "same")
    n = n * t;
  else
    throw new E(`Unsupport padding mode: ${s}.`);
  return n;
}
function Lf(n, t) {
  return D(() => (ae(t), t === "channelsFirst" ? kt(n, [0, 2, 3, 1]) : n));
}
function Sy(n, t) {
  return D(() => (ae(t), t === "channelsFirst" ? kt(n, [0, 2, 3, 4, 1]) : n));
}
function m3(n, t, e, s = 1, o = "valid", r, i6 = 1) {
  return D(() => {
    if (r == null && (r = Zn()), ae(r), n.shape.length !== 3)
      throw new E(`The input of a conv1dWithBias operation should be 3, but is ${n.shape.length} instead.`);
    if (t.shape.length !== 3)
      throw new E(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);
    if (e != null && e.shape.length !== 1)
      throw new E(`The bias for a conv1dWithBias operation should be 1, but is ${t.shape.length} instead`);
    if (r === "channelsFirst" && (n = kt(n, [0, 2, 1])), o === "causal")
      throw new yt("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    let a = Jb(n, t, s, o === "same" ? "same" : "valid", "NWC", i6);
    return e != null && (a = _n(a, e)), a;
  });
}
function ag(n, t, e, s = [1, 1], o = "valid", r, i6, a = null) {
  return D(() => {
    if (r == null && (r = Zn()), ae(r), n.rank !== 3 && n.rank !== 4)
      throw new E(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${n.rank}.`);
    if (t.rank !== 3 && t.rank !== 4)
      throw new E(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${n.rank}.`);
    let l = Lf(n, r);
    if (o === "causal")
      throw new yt("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    return l = IN({
      x: l,
      filter: t,
      strides: s,
      pad: o === "same" ? "same" : "valid",
      dilations: i6,
      dataFormat: "NHWC",
      bias: e,
      activation: a
    }), r === "channelsFirst" && (l = kt(l, [0, 3, 1, 2])), l;
  });
}
function g3(n, t, e, s = [1, 1, 1], o = "valid", r, i6) {
  return D(() => {
    if (r == null && (r = Zn()), ae(r), n.rank !== 4 && n.rank !== 5)
      throw new E(`conv3dWithBias expects input to be of rank 4 or 5, but received ${n.rank}.`);
    if (t.rank !== 4 && t.rank !== 5)
      throw new E(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${n.rank}.`);
    let a = Sy(n, r);
    if (o === "causal")
      throw new yt("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
    return a = IS(a, t, s, o === "same" ? "same" : "valid", "NDHWC", i6), e != null && (a = _n(a, e)), r === "channelsFirst" && (a = kt(a, [0, 4, 1, 2, 3])), a;
  });
}
var pu = class _pu extends St {
  constructor(t, e) {
    if (super(e), this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", _pu.verifyArgs(e), this.rank = t, xe(this.rank, "rank"), this.rank !== 1 && this.rank !== 2 && this.rank !== 3)
      throw new yt(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);
    if (this.kernelSize = dr(e.kernelSize, t, "kernelSize"), this.strides = dr(e.strides == null ? 1 : e.strides, t, "strides"), this.padding = e.padding == null ? "valid" : e.padding, gn(this.padding), this.dataFormat = e.dataFormat == null ? "channelsLast" : e.dataFormat, ae(this.dataFormat), this.activation = _s(e.activation), this.useBias = e.useBias == null ? true : e.useBias, this.biasInitializer = Ut(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.biasConstraint = pe(e.biasConstraint), this.biasRegularizer = Qt(e.biasRegularizer), this.activityRegularizer = Qt(e.activityRegularizer), this.dilationRate = dr(e.dilationRate == null ? 1 : e.dilationRate, t, "dilationRate"), this.rank === 1 && Array.isArray(this.dilationRate) && this.dilationRate.length !== 1)
      throw new E(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    if (this.rank === 2) {
      if (typeof this.dilationRate == "number")
        this.dilationRate = [this.dilationRate, this.dilationRate];
      else if (this.dilationRate.length !== 2)
        throw new E(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    } else if (this.rank === 3) {
      if (typeof this.dilationRate == "number")
        this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];
      else if (this.dilationRate.length !== 3)
        throw new E(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    }
  }
  static verifyArgs(t) {
    if (Jn("kernelSize" in t, "required key 'kernelSize' not in config"), typeof t.kernelSize != "number" && !bf(t.kernelSize, "number", 1, 3))
      throw new E(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`);
  }
  getConfig() {
    const t = {
      kernelSize: this.kernelSize,
      strides: this.strides,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      activation: Hs(this.activation),
      useBias: this.useBias,
      biasInitializer: jt(this.biasInitializer),
      biasRegularizer: zt(this.biasRegularizer),
      activityRegularizer: zt(this.activityRegularizer),
      biasConstraint: he(this.biasConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var $r = class _$r extends pu {
  constructor(t, e) {
    super(t, e), this.kernel = null, _$r.verifyArgs(e), this.filters = e.filters, xe(this.filters, "filters"), this.kernelInitializer = Ut(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.kernelConstraint = pe(e.kernelConstraint), this.kernelRegularizer = Qt(e.kernelRegularizer);
  }
  build(t) {
    t = Rt(t);
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null)
      throw new E(`The channel dimension of the input should be defined. Found ${t[e]}`);
    const s = t[e], o = this.kernelSize.concat([s, this.filters]);
    this.kernel = this.addWeight("kernel", o, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [{ ndim: this.rank + 2, axes: { [e]: s } }], this.built = true;
  }
  call(t, e) {
    return D(() => {
      t = mt(t);
      let s;
      const o = this.bias == null ? null : this.bias.read(), r = Cx(this.activation.getClassName());
      if (r != null && this.rank === 2)
        s = ag(t, this.kernel.read(), o, this.strides, this.padding, this.dataFormat, this.dilationRate, r);
      else {
        if (this.rank === 1)
          s = m3(t, this.kernel.read(), o, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);
        else if (this.rank === 2)
          s = ag(t, this.kernel.read(), o, this.strides, this.padding, this.dataFormat, this.dilationRate);
        else if (this.rank === 3)
          s = g3(t, this.kernel.read(), o, this.strides, this.padding, this.dataFormat, this.dilationRate);
        else
          throw new yt("convolutions greater than 3D are not implemented yet.");
        this.activation != null && (s = this.activation.apply(s));
      }
      return s;
    });
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = [], s = this.dataFormat === "channelsLast" ? t.slice(1, t.length - 1) : t.slice(2);
    for (let r = 0; r < s.length; ++r) {
      const i6 = On(s[r], this.kernelSize[r], this.padding, this.strides[r], typeof this.dilationRate == "number" ? this.dilationRate : this.dilationRate[r]);
      e.push(i6);
    }
    let o = [t[0]];
    return this.dataFormat === "channelsLast" ? (o = o.concat(e), o.push(this.filters)) : (o.push(this.filters), o = o.concat(e)), o;
  }
  getConfig() {
    const t = {
      filters: this.filters,
      kernelInitializer: jt(this.kernelInitializer),
      kernelRegularizer: zt(this.kernelRegularizer),
      kernelConstraint: he(this.kernelConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  static verifyArgs(t) {
    if (!("filters" in t) || typeof t.filters != "number" || t.filters < 1)
      throw new E(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t.filters)}`);
  }
};
var Fa = class _Fa extends $r {
  constructor(t) {
    super(2, t), _Fa.verifyArgs(t);
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, t;
  }
  static verifyArgs(t) {
    if (typeof t.kernelSize != "number" && !bf(t.kernelSize, "number", 1, 2))
      throw new E(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`);
  }
};
Fa.className = "Conv2D";
_(Fa);
var Va = class _Va extends $r {
  constructor(t) {
    super(3, t), _Va.verifyArgs(t);
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, t;
  }
  static verifyArgs(t) {
    if (typeof t.kernelSize != "number" && !(Array.isArray(t.kernelSize) && (t.kernelSize.length === 1 || t.kernelSize.length === 3)))
      throw new E(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`);
  }
};
Va.className = "Conv3D";
_(Va);
var ky = class extends Fa {
  constructor(t) {
    if (super(t), this.inputSpec = [new de({ ndim: 4 })], this.padding !== "same" && this.padding !== "valid")
      throw new E(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
  }
  build(t) {
    if (t = Rt(t), t.length !== 4)
      throw new E("Input should have rank 4; Received input shape: " + JSON.stringify(t));
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null)
      throw new E("The channel dimension of the inputs should be defined. Found `None`.");
    const s = t[e], o = this.kernelSize.concat([this.filters, s]);
    this.kernel = this.addWeight("kernel", o, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [new de({ ndim: 4, axes: { [e]: s } })], this.built = true;
  }
  call(t, e) {
    return D(() => {
      let s = mt(t);
      if (s.shape.length !== 4)
        throw new E(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);
      const o = s.shape, r = o[0];
      let i6, a;
      this.dataFormat === "channelsFirst" ? (i6 = 2, a = 3) : (i6 = 1, a = 2);
      const l = o[i6], c = o[a], u = this.kernelSize[0], d = this.kernelSize[1], h = this.strides[0], p = this.strides[1], f = jn(l, h, u, this.padding), m = jn(c, p, d, this.padding), g = [r, f, m, this.filters];
      this.dataFormat !== "channelsLast" && (s = kt(s, [0, 2, 3, 1]));
      let b = jb(s, this.kernel.read(), g, this.strides, this.padding);
      return this.dataFormat !== "channelsLast" && (b = kt(b, [0, 3, 1, 2])), this.bias != null && (b = _n(b, this.bias.read(), this.dataFormat)), this.activation != null && (b = this.activation.apply(b)), b;
    });
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = t.slice();
    let s, o, r;
    this.dataFormat === "channelsFirst" ? (s = 1, o = 2, r = 3) : (s = 3, o = 1, r = 2);
    const i6 = this.kernelSize[0], a = this.kernelSize[1], l = this.strides[0], c = this.strides[1];
    return e[s] = this.filters, e[o] = jn(e[o], l, i6, this.padding), e[r] = jn(e[r], c, a, this.padding), e;
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.dilationRate, t;
  }
};
ky.className = "Conv2DTranspose";
_(ky);
var Ty = class extends Va {
  constructor(t) {
    if (super(t), this.inputSpec = [new de({ ndim: 5 })], this.padding !== "same" && this.padding !== "valid")
      throw new E(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
  }
  build(t) {
    if (t = Rt(t), t.length !== 5)
      throw new E("Input should have rank 5; Received input shape: " + JSON.stringify(t));
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null)
      throw new E("The channel dimension of the inputs should be defined. Found `None`.");
    const s = t[e], o = this.kernelSize.concat([this.filters, s]);
    this.kernel = this.addWeight("kernel", o, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [new de({ ndim: 5, axes: { [e]: s } })], this.built = true;
  }
  call(t, e) {
    return D(() => {
      let s = mt(t);
      if (s.shape.length !== 5)
        throw new E(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);
      const o = s.shape, r = o[0];
      let i6, a, l;
      this.dataFormat === "channelsFirst" ? (l = 2, i6 = 3, a = 4) : (l = 1, i6 = 2, a = 3);
      const c = o[l], u = o[i6], d = o[a], h = this.kernelSize[0], p = this.kernelSize[1], f = this.kernelSize[2], m = this.strides[0], g = this.strides[1], b = this.strides[2], x6 = jn(c, m, h, this.padding), w = jn(u, g, p, this.padding), y6 = jn(d, b, f, this.padding), I = [r, x6, w, y6, this.filters];
      this.dataFormat !== "channelsLast" && (s = kt(s, [0, 2, 3, 4, 1]));
      let v = SS(s, this.kernel.read(), I, this.strides, this.padding);
      return this.dataFormat !== "channelsLast" && (v = kt(v, [0, 4, 1, 2, 3])), this.bias !== null && (v = _n(v, this.bias.read(), this.dataFormat)), this.activation !== null && (v = this.activation.apply(v)), v;
    });
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = t.slice();
    let s, o, r, i6;
    this.dataFormat === "channelsFirst" ? (s = 1, o = 2, r = 3, i6 = 4) : (s = 4, o = 1, r = 2, i6 = 3);
    const a = this.kernelSize[0], l = this.kernelSize[1], c = this.kernelSize[2], u = this.strides[0], d = this.strides[1], h = this.strides[2];
    return e[s] = this.filters, e[o] = jn(e[o], u, a, this.padding), e[r] = jn(e[r], d, l, this.padding), e[i6] = jn(e[i6], h, c, this.padding), e;
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.dilationRate, t;
  }
};
Ty.className = "Conv3DTranspose";
_(Ty);
var Ny = class extends $r {
  constructor(t, e) {
    if (super(t, e), this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform", this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform", this.depthwiseKernel = null, this.pointwiseKernel = null, e.filters == null)
      throw new E("The `filters` configuration field is required by SeparableConv, but is unspecified.");
    if (e.kernelInitializer != null || e.kernelRegularizer != null || e.kernelConstraint != null)
      throw new E("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
    if (e.padding != null && e.padding !== "same" && e.padding !== "valid")
      throw new E(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);
    this.depthMultiplier = e.depthMultiplier == null ? 1 : e.depthMultiplier, this.depthwiseInitializer = Ut(e.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER), this.depthwiseRegularizer = Qt(e.depthwiseRegularizer), this.depthwiseConstraint = pe(e.depthwiseConstraint), this.pointwiseInitializer = Ut(e.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER), this.pointwiseRegularizer = Qt(e.pointwiseRegularizer), this.pointwiseConstraint = pe(e.pointwiseConstraint);
  }
  build(t) {
    if (t = Rt(t), t.length < this.rank + 2)
      throw new E(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank + 2}, but received input shape: ${JSON.stringify(t)}`);
    const e = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[e] == null || t[e] < 0)
      throw new E(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[e])}`);
    const s = t[e], o = this.kernelSize.concat([s, this.depthMultiplier]), r = [];
    for (let a = 0; a < this.rank; ++a)
      r.push(1);
    r.push(s * this.depthMultiplier, this.filters);
    const i6 = true;
    this.depthwiseKernel = this.addWeight("depthwise_kernel", o, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, i6, this.depthwiseConstraint), this.pointwiseKernel = this.addWeight("pointwise_kernel", r, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, i6, this.pointwiseConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, i6, this.biasConstraint) : this.bias = null, this.inputSpec = [new de({ ndim: this.rank + 2, axes: { [e]: s } })], this.built = true;
  }
  call(t, e) {
    return D(() => {
      t = mt(t);
      let s;
      if (this.rank === 1)
        throw new yt("1D separable convolution is not implemented yet.");
      return this.rank === 2 && (this.dataFormat === "channelsFirst" && (t = kt(t, [0, 2, 3, 1])), s = p0(t, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC")), this.useBias && (s = _n(s, this.bias.read(), this.dataFormat)), this.activation != null && (s = this.activation.apply(s)), this.dataFormat === "channelsFirst" && (s = kt(s, [0, 3, 1, 2])), s;
    });
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, delete t.kernelInitializer, delete t.kernelRegularizer, delete t.kernelConstraint, t.depthwiseInitializer = jt(this.depthwiseInitializer), t.pointwiseInitializer = jt(this.pointwiseInitializer), t.depthwiseRegularizer = zt(this.depthwiseRegularizer), t.pointwiseRegularizer = zt(this.pointwiseRegularizer), t.depthwiseConstraint = he(this.depthwiseConstraint), t.pointwiseConstraint = he(this.pointwiseConstraint), t;
  }
};
Ny.className = "SeparableConv";
var Ry = class extends Ny {
  constructor(t) {
    super(2, t);
  }
};
Ry.className = "SeparableConv2D";
_(Ry);
var fu = class _fu extends $r {
  constructor(t) {
    super(1, t), _fu.verifyArgs(t), this.inputSpec = [{ ndim: 3 }];
  }
  getConfig() {
    const t = super.getConfig();
    return delete t.rank, delete t.dataFormat, t;
  }
  static verifyArgs(t) {
    if (typeof t.kernelSize != "number" && !bf(t.kernelSize, "number", 1, 1))
      throw new E(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`);
  }
};
fu.className = "Conv1D";
_(fu);
var $y = class extends St {
  constructor(t) {
    super(t), typeof t.cropping == "number" ? this.cropping = [[t.cropping, t.cropping], [t.cropping, t.cropping]] : typeof t.cropping[0] == "number" ? this.cropping = [
      [t.cropping[0], t.cropping[0]],
      [t.cropping[1], t.cropping[1]]
    ] : this.cropping = t.cropping, this.dataFormat = t.dataFormat === void 0 ? "channelsLast" : t.dataFormat, this.inputSpec = [{ ndim: 4 }];
  }
  computeOutputShape(t) {
    return this.dataFormat === "channelsFirst" ? [
      t[0],
      t[1],
      t[2] - this.cropping[0][0] - this.cropping[0][1],
      t[3] - this.cropping[1][0] - this.cropping[1][1]
    ] : [
      t[0],
      t[1] - this.cropping[0][0] - this.cropping[0][1],
      t[2] - this.cropping[1][0] - this.cropping[1][1],
      t[3]
    ];
  }
  call(t, e) {
    return D(() => {
      if (t = mt(t), this.dataFormat === "channelsLast") {
        const s = _a(t, this.cropping[0][0], t.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);
        return _a(s, this.cropping[1][0], t.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
      } else {
        const s = _a(t, this.cropping[0][0], t.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);
        return _a(s, this.cropping[1][0], t.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
      }
    });
  }
  getConfig() {
    const t = { cropping: this.cropping, dataFormat: this.dataFormat }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
$y.className = "Cropping2D";
_($y);
var Gy = class extends St {
  constructor(t) {
    super(t), this.DEFAULT_SIZE = [2, 2], this.inputSpec = [{ ndim: 4 }], this.size = t.size == null ? this.DEFAULT_SIZE : t.size, this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), this.interpolation = t.interpolation == null ? "nearest" : t.interpolation, BE(this.interpolation);
  }
  computeOutputShape(t) {
    if (this.dataFormat === "channelsFirst") {
      const e = t[2] == null ? null : this.size[0] * t[2], s = t[3] == null ? null : this.size[1] * t[3];
      return [t[0], t[1], e, s];
    } else {
      const e = t[1] == null ? null : this.size[0] * t[1], s = t[2] == null ? null : this.size[1] * t[2];
      return [t[0], e, s, t[3]];
    }
  }
  call(t, e) {
    return D(() => {
      let s = mt(t);
      const o = s.shape;
      if (this.dataFormat === "channelsFirst") {
        s = kt(s, [0, 2, 3, 1]);
        const r = this.size[0] * o[2], i6 = this.size[1] * o[3], a = this.interpolation === "nearest" ? fs.resizeNearestNeighbor(s, [r, i6]) : fs.resizeBilinear(s, [r, i6]);
        return kt(a, [0, 3, 1, 2]);
      } else {
        const r = this.size[0] * o[1], i6 = this.size[1] * o[2];
        return this.interpolation === "nearest" ? fs.resizeNearestNeighbor(s, [r, i6]) : fs.resizeBilinear(s, [r, i6]);
      }
    });
  }
  getConfig() {
    const t = {
      size: this.size,
      dataFormat: this.dataFormat,
      interpolation: this.interpolation
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Gy.className = "UpSampling2D";
_(Gy);
function b3(n, t, e = [1, 1], s = "valid", o, r) {
  return D(() => {
    o == null && (o = Zn()), ae(o);
    let i6 = Lf(n, o);
    if (n.rank !== 4)
      throw new E(`Input for depthwiseConv2d is required to be 4-D, but is instead ${n.rank}-D`);
    if (t.rank !== 4)
      throw new E(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);
    return i6 = ap(i6, t, e, s === "same" ? "same" : "valid", "NHWC", r), o === "channelsFirst" && (i6 = kt(i6, [0, 3, 1, 2])), i6;
  });
}
var Ey = class extends pu {
  constructor(t) {
    super(2, t), this.depthwiseKernel = null, this.depthMultiplier = t.depthMultiplier == null ? 1 : t.depthMultiplier, this.depthwiseInitializer = Ut(t.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.depthwiseConstraint = pe(t.depthwiseConstraint), this.depthwiseRegularizer = Qt(t.depthwiseRegularizer);
  }
  build(t) {
    if (t = Rt(t), t.length < 4)
      throw new E(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);
    const e = this.dataFormat === "channelsFirst" ? 1 : 3;
    if (t[e] == null || t[e] < 0)
      throw new E(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);
    const s = t[e], o = [
      this.kernelSize[0],
      this.kernelSize[1],
      s,
      this.depthMultiplier
    ];
    this.depthwiseKernel = this.addWeight("depthwise_kernel", o, null, this.depthwiseInitializer, this.depthwiseRegularizer, true, this.depthwiseConstraint), this.useBias ? this.bias = this.addWeight("bias", [s * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  call(t, e) {
    return D(() => {
      t = mt(t);
      let s = b3(t, this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
      return this.useBias && (s = _n(s, this.bias.read(), this.dataFormat)), this.activation != null && (s = this.activation.apply(s)), s;
    });
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = this.dataFormat === "channelsFirst" ? t[2] : t[1], s = this.dataFormat === "channelsFirst" ? t[3] : t[2], o = this.dataFormat === "channelsFirst" ? t[1] * this.depthMultiplier : t[3] * this.depthMultiplier, r = On(e, this.kernelSize[0], this.padding, this.strides[0]), i6 = On(s, this.kernelSize[1], this.padding, this.strides[1]);
    return this.dataFormat === "channelsFirst" ? [t[0], o, r, i6] : [t[0], r, i6, o];
  }
  getConfig() {
    const t = super.getConfig();
    return t.depthMultiplier = this.depthMultiplier, t.depthwiseInitializer = jt(this.depthwiseInitializer), t.depthwiseRegularizer = zt(this.depthwiseRegularizer), t.depthwiseConstraint = he(this.depthwiseRegularizer), t;
  }
};
Ey.className = "DepthwiseConv2D";
_(Ey);
function Ly(n, t, e, s) {
  if (Array.isArray(n)) {
    if (t != null || e != null)
      throw new E("When inputs is an array, neither initialState or constants should be provided");
    s != null && (e = n.slice(n.length - s, n.length), n = n.slice(0, n.length - s)), n.length > 1 && (t = n.slice(1, n.length)), n = n[0];
  }
  function o(r) {
    return r == null || Array.isArray(r) ? r : [r];
  }
  return t = o(t), e = o(e), { inputs: n, initialState: t, constants: e };
}
function My(n, t, e, s = false, o, r, i6 = false, a = false) {
  return D(() => {
    const l = t.shape.length;
    if (l < 3)
      throw new E(`Input should be at least 3D, but is ${l}D.`);
    const c = [1, 0].concat(Kn(2, l));
    if (t = kt(t, c), r != null)
      throw new yt("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
    i6 && console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."), o != null && (o = tt(tt(o, "bool"), "float32"), o.rank === l - 1 && (o = Oe(o, -1)), o = kt(o, c)), s && (t = Lo(t, 0), o != null && (o = Lo(o, 0)));
    const u = [];
    let d, h = e;
    const p = t.shape[0], f = Mo(t);
    let m;
    o != null && (m = Mo(o));
    for (let b = 0; b < p; ++b) {
      const x6 = f[b], w = D(() => n(x6, h));
      if (o == null)
        d = w[0], h = w[1];
      else {
        const y6 = D(() => {
          const I = m[b], v = it(Rn(I), I), k6 = U(G(w[0], I), G(h[0], v)), S = h.map((N, R) => U(G(w[1][R], I), G(N, v)));
          return { output: k6, newStates: S };
        });
        d = y6.output, h = y6.newStates;
      }
      a && u.push(d);
    }
    let g;
    return a && (g = Xn(u, 1)), [d, g, h];
  });
}
var no = class _no extends St {
  constructor(t) {
    super(t);
    let e;
    if (t.cell == null)
      throw new E("cell property is missing for the constructor of RNN.");
    if (Array.isArray(t.cell) ? e = new Df({ cells: t.cell }) : e = t.cell, e.stateSize == null)
      throw new E("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
    this.cell = e, this.returnSequences = t.returnSequences == null ? false : t.returnSequences, this.returnState = t.returnState == null ? false : t.returnState, this.goBackwards = t.goBackwards == null ? false : t.goBackwards, this._stateful = t.stateful == null ? false : t.stateful, this.unroll = t.unroll == null ? false : t.unroll, this.supportsMasking = true, this.inputSpec = [new de({ ndim: 3 })], this.stateSpec = null, this.states_ = null, this.numConstants = null, this.keptStates = [];
  }
  // Porting Note: This is the equivalent of `RNN.states` property getter in
  //   PyKeras.
  getStates() {
    if (this.states_ == null) {
      const t = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      return Kn(0, t).map((e) => null);
    } else
      return this.states_;
  }
  // Porting Note: This is the equivalent of the `RNN.states` property setter in
  //   PyKeras.
  setStates(t) {
    this.states_ = t;
  }
  computeOutputShape(t) {
    Gd(t) && (t = t[0]), t = t;
    let e = this.cell.stateSize;
    Array.isArray(e) || (e = [e]);
    const s = e[0];
    let o;
    if (this.returnSequences ? o = [t[0], t[1], s] : o = [t[0], s], this.returnState) {
      const r = [];
      for (const i6 of e)
        r.push([t[0], i6]);
      return [o].concat(r);
    } else
      return o;
  }
  computeMask(t, e) {
    return D(() => {
      Array.isArray(e) && (e = e[0]);
      const s = this.returnSequences ? e : null;
      if (this.returnState) {
        const o = this.states.map((r) => null);
        return [s].concat(o);
      } else
        return s;
    });
  }
  /**
   * Get the current state tensors of the RNN.
   *
   * If the state hasn't been set, return an array of `null`s of the correct
   * length.
   */
  get states() {
    if (this.states_ == null) {
      const t = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1, e = [];
      for (let s = 0; s < t; ++s)
        e.push(null);
      return e;
    } else
      return this.states_;
  }
  set states(t) {
    this.states_ = t;
  }
  build(t) {
    if (this.numConstants != null)
      throw new yt("Constants support is not implemented in RNN yet.");
    Gd(t) && (t = t[0]), t = t;
    const e = this.stateful ? t[0] : null, s = t.slice(2);
    this.inputSpec[0] = new de({ shape: [e, null, ...s] });
    const o = [t[0]].concat(t.slice(2));
    this.cell.build(o);
    let r;
    if (Array.isArray(this.cell.stateSize) ? r = this.cell.stateSize : r = [this.cell.stateSize], this.stateSpec != null) {
      if (!$t(this.stateSpec.map((i6) => i6.shape[i6.shape.length - 1]), r))
        throw new E(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`);
    } else
      this.stateSpec = r.map((i6) => new de({ shape: [null, i6] }));
    this.stateful && this.resetStates();
  }
  /**
   * Reset the state tensors of the RNN.
   *
   * If the `states` argument is `undefined` or `null`, will set the
   * state tensor(s) of the RNN to all-zero tensors of the appropriate
   * shape(s).
   *
   * If `states` is provided, will set the state tensors of the RNN to its
   * value.
   *
   * @param states Optional externally-provided initial states.
   * @param training Whether this call is done during training. For stateful
   *   RNNs, this affects whether the old states are kept or discarded. In
   *   particular, if `training` is `true`, the old states will be kept so
   *   that subsequent backpropgataion through time (BPTT) may work properly.
   *   Else, the old states will be discarded.
   */
  resetStates(t, e = false) {
    D(() => {
      if (!this.stateful)
        throw new Qn("Cannot call resetStates() on an RNN Layer that is not stateful.");
      const s = this.inputSpec[0].shape[0];
      if (s == null)
        throw new E("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (this.states_ == null)
        Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((o) => be([s, o])) : this.states_ = [be([s, this.cell.stateSize])];
      else if (t == null)
        xt(this.states_), this.keptStates != null && (xt(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((o) => be([s, o])) : this.states_[0] = be([s, this.cell.stateSize]);
      else {
        if (Array.isArray(t) || (t = [t]), t.length !== this.states_.length)
          throw new E(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);
        e === true ? this.keptStates.push(this.states_.slice()) : xt(this.states_);
        for (let o = 0; o < this.states_.length; ++o) {
          const r = t[o], i6 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[o] : this.cell.stateSize, a = [s, i6];
          if (!$t(r.shape, a))
            throw new E(`State ${o} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${r.shape}`);
          this.states_[o] = r;
        }
      }
      this.states_ = this.states_.map((o) => hn(o.clone()));
    });
  }
  apply(t, e) {
    let s = e == null ? null : e.initialState, o = e == null ? null : e.constants;
    e == null && (e = {});
    const r = Ly(t, s, o, this.numConstants);
    t = r.inputs, s = r.initialState, o = r.constants;
    let i6 = [], a = [];
    if (s != null) {
      e.initialState = s, i6 = i6.concat(s), this.stateSpec = [];
      for (const c of s)
        this.stateSpec.push(new de({ shape: c.shape }));
      a = a.concat(this.stateSpec);
    }
    if (o != null && (e.constants = o, i6 = i6.concat(o), this.numConstants = o.length), i6[0] instanceof os) {
      const c = [t].concat(i6), u = this.inputSpec.concat(a), d = this.inputSpec;
      this.inputSpec = u;
      const h = super.apply(c, e);
      return this.inputSpec = d, h;
    } else
      return super.apply(t, e);
  }
  // tslint:disable-next-line:no-any
  call(t, e) {
    return D(() => {
      const s = e == null ? null : e.mask, o = e == null ? null : e.training;
      let r = e == null ? null : e.initialState;
      t = mt(t), r == null && (this.stateful ? r = this.states_ : r = this.getInitialState(t));
      const i6 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      if (r.length !== i6)
        throw new E(`RNN Layer has ${i6} state(s) but was passed ${r.length} initial state(s).`);
      this.unroll && console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
      const a = { training: o }, c = My((f, m) => {
        const g = this.cell.call([f].concat(m), a);
        return [g[0], g.slice(1)];
      }, t, r, this.goBackwards, s, null, this.unroll, this.returnSequences), u = c[0], d = c[1], h = c[2];
      this.stateful && this.resetStates(h, o);
      const p = this.returnSequences ? d : u;
      return this.returnState ? [p].concat(h) : p;
    });
  }
  getInitialState(t) {
    return D(() => {
      let e = be(t.shape);
      return e = at(e, [1, 2]), e = Ea(e), Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map((s) => s > 1 ? Rd(e, [1, s]) : e) : this.cell.stateSize > 1 ? [Rd(e, [1, this.cell.stateSize])] : [e];
    });
  }
  get trainableWeights() {
    return this.trainable ? this.cell.trainableWeights : [];
  }
  get nonTrainableWeights() {
    return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights;
  }
  setFastWeightInitDuringBuild(t) {
    super.setFastWeightInitDuringBuild(t), this.cell != null && this.cell.setFastWeightInitDuringBuild(t);
  }
  getConfig() {
    const t = super.getConfig(), e = {
      returnSequences: this.returnSequences,
      returnState: this.returnState,
      goBackwards: this.goBackwards,
      stateful: this.stateful,
      unroll: this.unroll
    };
    this.numConstants != null && (e.numConstants = this.numConstants);
    const s = this.cell.getConfig();
    return this.getClassName() === _no.className && (e.cell = {
      className: this.cell.getClassName(),
      config: s
    }), Object.assign(Object.assign(Object.assign({}, s), t), e);
  }
  /** @nocollapse */
  static fromConfig(t, e, s = {}) {
    const o = e.cell, r = An(o, s);
    return new t(Object.assign(e, { cell: r }));
  }
};
no.className = "RNN";
_(no);
var mu = class extends St {
};
var Mf = class extends mu {
  constructor(t) {
    super(t), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = t.units, xe(this.units, "units"), this.activation = _s(t.activation == null ? this.DEFAULT_ACTIVATION : t.activation), this.useBias = t.useBias == null ? true : t.useBias, this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Ut(t.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = Qt(t.kernelRegularizer), this.recurrentRegularizer = Qt(t.recurrentRegularizer), this.biasRegularizer = Qt(t.biasRegularizer), this.kernelConstraint = pe(t.kernelConstraint), this.recurrentConstraint = pe(t.recurrentConstraint), this.biasConstraint = pe(t.biasConstraint), this.dropout = xr([1, Bs([0, t.dropout == null ? 0 : t.dropout])]), this.recurrentDropout = xr([
      1,
      Bs([0, t.recurrentDropout == null ? 0 : t.recurrentDropout])
    ]), this.dropoutFunc = t.dropoutFunc, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t) {
    t = Rt(t), this.kernel = this.addWeight("kernel", [t[t.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  // Porting Note: PyKeras' equivalent of this method takes two tensor inputs:
  //   `inputs` and `states`. Here, the two tensors are combined into an
  //   `Tensor[]` Array as the first input argument.
  //   Similarly, PyKeras' equivalent of this method returns two values:
  //    `output` and `[output]`. Here the two are combined into one length-2
  //    `Tensor[]`, consisting of `output` repeated.
  call(t, e) {
    return D(() => {
      if (t = t, t.length !== 2)
        throw new E(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);
      let s = t[1];
      t = t[0];
      const o = e.training == null ? false : e.training;
      0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Us({
        ones: () => Rn(t),
        rate: this.dropout,
        training: o,
        dropoutFunc: this.dropoutFunc
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Us({
        ones: () => Rn(s),
        rate: this.recurrentDropout,
        training: o,
        dropoutFunc: this.dropoutFunc
      }));
      let r;
      const i6 = this.dropoutMask, a = this.recurrentDropoutMask;
      i6 != null ? r = ns(G(t, i6), this.kernel.read()) : r = ns(t, this.kernel.read()), this.bias != null && (r = _n(r, this.bias.read())), a != null && (s = G(s, a));
      let l = U(r, ns(s, this.recurrentKernel.read()));
      return this.activation != null && (l = this.activation.apply(l)), [l, l];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = {
      units: this.units,
      activation: Hs(this.activation),
      useBias: this.useBias,
      kernelInitializer: jt(this.kernelInitializer),
      recurrentInitializer: jt(this.recurrentInitializer),
      biasInitializer: jt(this.biasInitializer),
      kernelRegularizer: zt(this.kernelRegularizer),
      recurrentRegularizer: zt(this.recurrentRegularizer),
      biasRegularizer: zt(this.biasRegularizer),
      activityRegularizer: zt(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      recurrentConstraint: he(this.recurrentConstraint),
      biasConstraint: he(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout
    };
    return Object.assign(Object.assign({}, t), e);
  }
};
Mf.className = "SimpleRNNCell";
_(Mf);
var Wy = class extends no {
  constructor(t) {
    t.cell = new Mf(t), super(t);
  }
  call(t, e) {
    return D(() => {
      this.cell.dropoutMask != null && (xt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (xt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e);
  }
};
Wy.className = "SimpleRNN";
_(Wy);
var Wf = class extends mu {
  constructor(t) {
    if (super(t), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", t.resetAfter)
      throw new E("GRUCell does not support reset_after parameter set to true.");
    this.units = t.units, xe(this.units, "units"), this.activation = _s(t.activation === void 0 ? this.DEFAULT_ACTIVATION : t.activation), this.recurrentActivation = _s(t.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : t.recurrentActivation), this.useBias = t.useBias == null ? true : t.useBias, this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Ut(t.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = Qt(t.kernelRegularizer), this.recurrentRegularizer = Qt(t.recurrentRegularizer), this.biasRegularizer = Qt(t.biasRegularizer), this.kernelConstraint = pe(t.kernelConstraint), this.recurrentConstraint = pe(t.recurrentConstraint), this.biasConstraint = pe(t.biasConstraint), this.dropout = xr([1, Bs([0, t.dropout == null ? 0 : t.dropout])]), this.recurrentDropout = xr([
      1,
      Bs([0, t.recurrentDropout == null ? 0 : t.recurrentDropout])
    ]), this.dropoutFunc = t.dropoutFunc, this.implementation = t.implementation, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t) {
    t = Rt(t);
    const e = t[t.length - 1];
    this.kernel = this.addWeight("kernel", [e, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  call(t, e) {
    return D(() => {
      if (t = t, t.length !== 2)
        throw new E(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);
      const s = e.training == null ? false : e.training;
      let o = t[1];
      t = t[0], 0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Us({
        ones: () => Rn(t),
        rate: this.dropout,
        training: s,
        count: 3,
        dropoutFunc: this.dropoutFunc
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Us({
        ones: () => Rn(o),
        rate: this.recurrentDropout,
        training: s,
        count: 3,
        dropoutFunc: this.dropoutFunc
      }));
      const r = this.dropoutMask, i6 = this.recurrentDropoutMask;
      let a, l, c;
      0 < this.dropout && this.dropout < 1 && (t = G(t, r[0]));
      let u = ns(t, this.kernel.read());
      this.useBias && (u = _n(u, this.bias.read())), 0 < this.recurrentDropout && this.recurrentDropout < 1 && (o = G(o, i6[0]));
      const d = this.recurrentKernel.read(), [h, p] = pn(d, [2 * this.units, this.units], d.rank - 1), f = ns(o, h), [m, g, b] = pn(u, 3, u.rank - 1), [x6, w] = pn(f, 2, f.rank - 1);
      a = this.recurrentActivation.apply(U(m, x6)), l = this.recurrentActivation.apply(U(g, w));
      const y6 = ns(G(l, o), p);
      c = this.activation.apply(U(b, y6));
      const I = U(G(a, o), G(U(1, Yt(a)), c));
      return [I, I];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = {
      units: this.units,
      activation: Hs(this.activation),
      recurrentActivation: Hs(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: jt(this.kernelInitializer),
      recurrentInitializer: jt(this.recurrentInitializer),
      biasInitializer: jt(this.biasInitializer),
      kernelRegularizer: zt(this.kernelRegularizer),
      recurrentRegularizer: zt(this.recurrentRegularizer),
      biasRegularizer: zt(this.biasRegularizer),
      activityRegularizer: zt(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      recurrentConstraint: he(this.recurrentConstraint),
      biasConstraint: he(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation,
      resetAfter: false
    };
    return Object.assign(Object.assign({}, t), e);
  }
};
Wf.className = "GRUCell";
_(Wf);
var Dy = class extends no {
  constructor(t) {
    t.implementation === 0 && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), t.cell = new Wf(t), super(t);
  }
  call(t, e) {
    return D(() => {
      this.cell.dropoutMask != null && (xt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (xt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return e.implmentation === 0 && (e.implementation = 1), new t(e);
  }
};
Dy.className = "GRU";
_(Dy);
var gu = class extends mu {
  constructor(t) {
    super(t), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = t.units, xe(this.units, "units"), this.activation = _s(t.activation === void 0 ? this.DEFAULT_ACTIVATION : t.activation), this.recurrentActivation = _s(t.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : t.recurrentActivation), this.useBias = t.useBias == null ? true : t.useBias, this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = Ut(t.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.unitForgetBias = t.unitForgetBias, this.kernelRegularizer = Qt(t.kernelRegularizer), this.recurrentRegularizer = Qt(t.recurrentRegularizer), this.biasRegularizer = Qt(t.biasRegularizer), this.kernelConstraint = pe(t.kernelConstraint), this.recurrentConstraint = pe(t.recurrentConstraint), this.biasConstraint = pe(t.biasConstraint), this.dropout = xr([1, Bs([0, t.dropout == null ? 0 : t.dropout])]), this.recurrentDropout = xr([
      1,
      Bs([0, t.recurrentDropout == null ? 0 : t.recurrentDropout])
    ]), this.dropoutFunc = t.dropoutFunc, this.implementation = t.implementation, this.stateSize = [this.units, this.units], this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t) {
    var e;
    t = Rt(t);
    const s = t[t.length - 1];
    this.kernel = this.addWeight("kernel", [s, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
    let o;
    if (this.useBias) {
      if (this.unitForgetBias) {
        const r = this.biasInitializer, i6 = this.units;
        o = new (e = class extends Gn {
          apply(l, c) {
            const u = r.apply([i6]), d = new yf().apply([i6]), h = r.apply([i6 * 2]);
            return Zm(Zm(u, d), h);
          }
        }, /** @nocollapse */
        e.className = "CustomInit", e)();
      } else
        o = this.biasInitializer;
      this.bias = this.addWeight("bias", [this.units * 4], null, o, this.biasRegularizer, true, this.biasConstraint);
    } else
      this.bias = null;
    this.built = true;
  }
  call(t, e) {
    return D(() => {
      const s = e.training == null ? false : e.training;
      if (t = t, t.length !== 3)
        throw new E(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);
      let o = t[1];
      const r = t[2];
      t = t[0], 0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Us({
        ones: () => Rn(t),
        rate: this.dropout,
        training: s,
        count: 4,
        dropoutFunc: this.dropoutFunc
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Us({
        ones: () => Rn(o),
        rate: this.recurrentDropout,
        training: s,
        count: 4,
        dropoutFunc: this.dropoutFunc
      }));
      const i6 = this.dropoutMask, a = this.recurrentDropoutMask;
      let l, c, u, d;
      0 < this.dropout && this.dropout < 1 && (t = G(t, i6[0]));
      let h = ns(t, this.kernel.read());
      0 < this.recurrentDropout && this.recurrentDropout < 1 && (o = G(o, a[0])), h = U(h, ns(o, this.recurrentKernel.read())), this.useBias && (h = _n(h, this.bias.read()));
      const [p, f, m, g] = pn(h, 4, h.rank - 1);
      l = this.recurrentActivation.apply(p), c = this.recurrentActivation.apply(f), u = U(G(c, r), G(l, this.activation.apply(m))), d = this.recurrentActivation.apply(g);
      const b = G(d, this.activation.apply(u));
      return [b, b, u];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = {
      units: this.units,
      activation: Hs(this.activation),
      recurrentActivation: Hs(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: jt(this.kernelInitializer),
      recurrentInitializer: jt(this.recurrentInitializer),
      biasInitializer: jt(this.biasInitializer),
      unitForgetBias: this.unitForgetBias,
      kernelRegularizer: zt(this.kernelRegularizer),
      recurrentRegularizer: zt(this.recurrentRegularizer),
      biasRegularizer: zt(this.biasRegularizer),
      activityRegularizer: zt(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      recurrentConstraint: he(this.recurrentConstraint),
      biasConstraint: he(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation
    };
    return Object.assign(Object.assign({}, t), e);
  }
};
gu.className = "LSTMCell";
_(gu);
var Fy = class extends no {
  constructor(t) {
    t.implementation === 0 && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), t.cell = new gu(t), super(t);
  }
  call(t, e) {
    return D(() => {
      this.cell.dropoutMask != null && (xt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (xt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return e.implmentation === 0 && (e.implementation = 1), new t(e);
  }
};
Fy.className = "LSTM";
_(Fy);
var Df = class extends mu {
  constructor(t) {
    super(t), this.cells = t.cells;
  }
  get stateSize() {
    const t = [];
    for (const e of this.cells.slice().reverse())
      Array.isArray(e.stateSize) ? t.push(...e.stateSize) : t.push(e.stateSize);
    return t;
  }
  call(t, e) {
    return D(() => {
      t = t;
      let s = t.slice(1);
      const o = [];
      for (const a of this.cells.slice().reverse())
        Array.isArray(a.stateSize) ? o.push(s.splice(0, a.stateSize.length)) : o.push(s.splice(0, 1));
      o.reverse();
      const r = [];
      let i6;
      for (let a = 0; a < this.cells.length; ++a) {
        const l = this.cells[a];
        s = o[a], a === 0 ? i6 = [t[0]].concat(s) : i6 = [i6[0]].concat(s), i6 = l.call(i6, e), r.push(i6.slice(1));
      }
      s = [];
      for (const a of r.slice().reverse())
        s.push(...a);
      return [i6[0]].concat(s);
    });
  }
  build(t) {
    Gd(t) && (t = t[0]), t = t;
    let e;
    this.cells.forEach((s, o) => {
      wo(`RNNCell_${o}`, () => {
        s.build(t), Array.isArray(s.stateSize) ? e = s.stateSize[0] : e = s.stateSize, t = [t[0], e];
      });
    }), this.built = true;
  }
  getConfig() {
    const t = super.getConfig(), e = (r) => ({
      className: r.getClassName(),
      config: r.getConfig()
    }), o = { cells: this.cells.map(e) };
    return Object.assign(Object.assign({}, t), o);
  }
  /** @nocollapse */
  static fromConfig(t, e, s = {}) {
    const o = [];
    for (const r of e.cells)
      o.push(An(r, s));
    return new t({ cells: o });
  }
  get trainableWeights() {
    if (!this.trainable)
      return [];
    const t = [];
    for (const e of this.cells)
      t.push(...e.trainableWeights);
    return t;
  }
  get nonTrainableWeights() {
    const t = [];
    for (const e of this.cells)
      t.push(...e.nonTrainableWeights);
    if (!this.trainable) {
      const e = [];
      for (const s of this.cells)
        e.push(...s.trainableWeights);
      return e.concat(t);
    }
    return t;
  }
  /**
   * Retrieve the weights of a the model.
   *
   * @returns A flat `Array` of `tf.Tensor`s.
   */
  getWeights() {
    const t = [];
    for (const e of this.cells)
      t.push(...e.weights);
    return Ed(t);
  }
  /**
   * Set the weights of the model.
   *
   * @param weights An `Array` of `tf.Tensor`s with shapes and types matching
   *     the output of `getWeights()`.
   */
  setWeights(t) {
    const e = [];
    for (const s of this.cells) {
      const o = s.weights.length, r = t.splice(o);
      for (let i6 = 0; i6 < s.weights.length; ++i6)
        e.push([s.weights[i6], r[i6]]);
    }
    Tf(e);
  }
};
Df.className = "StackedRNNCells";
_(Df);
function Us(n) {
  const { ones: t, rate: e, training: s = false, count: o = 1, dropoutFunc: r } = n, i6 = () => r != null ? r(t(), e) : $x(t(), e), a = () => Ma(i6, t, s);
  return !o || o <= 1 ? hn(a().clone()) : Array(o).fill(void 0).map(a).map((c) => hn(c.clone()));
}
var x3 = function(n, t) {
  var e = {};
  for (var s in n)
    Object.prototype.hasOwnProperty.call(n, s) && t.indexOf(s) < 0 && (e[s] = n[s]);
  if (n != null && typeof Object.getOwnPropertySymbols == "function")
    for (var o = 0, s = Object.getOwnPropertySymbols(n); o < s.length; o++)
      t.indexOf(s[o]) < 0 && Object.prototype.propertyIsEnumerable.call(n, s[o]) && (e[s[o]] = n[s[o]]);
  return e;
};
var Vy = class extends no {
  constructor(t) {
    if (t.unroll)
      throw new yt("Unrolling is not possible with convolutional RNNs.");
    if (Array.isArray(t.cell))
      throw new yt("It is not possible at the moment to stack convolutional cells.");
    super(t), this.inputSpec = [new de({ ndim: 5 })];
  }
  call(t, e) {
    return D(() => {
      if (this.cell.dropoutMask != null && (xt(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (xt(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), e && e.constants)
        throw new E("ConvRNN2D cell does not support constants");
      const s = e == null ? null : e.mask, o = e == null ? null : e.training, r = e == null ? null : e.initialState;
      return super.call(t, { mask: s, training: o, initialState: r });
    });
  }
  computeOutputShape(t) {
    let e = this.computeSingleOutputShape(t);
    return this.returnSequences || (e = [e[0], ...e.slice(2)]), this.returnState && (e = [e, ...Array(2).fill([t[0], ...e.slice(-3)])]), e;
  }
  getInitialState(t) {
    return D(() => {
      const { stateSize: e } = this.cell, s = t.shape, o = this.computeSingleOutputShape(s), r = [o[0], ...o.slice(2)], i6 = be(r);
      return Array.isArray(e) ? Array(e.length).fill(i6) : [i6];
    });
  }
  resetStates(t, e = false) {
    D(() => {
      if (!this.stateful)
        throw new Qn("Cannot call resetStates() on an RNN Layer that is not stateful.");
      const s = this.inputSpec[0].shape, o = this.computeSingleOutputShape(s), r = [o[0], ...o.slice(2)];
      if (s[0] == null)
        throw new E("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (this.getStates() == null)
        Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => be(r)) : this.states_ = [be(r)];
      else if (t == null)
        xt(this.states_), this.keptStates != null && (xt(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => be(r)) : this.states_[0] = be(r);
      else {
        if (Array.isArray(t) || (t = [t]), t.length !== this.states_.length)
          throw new E(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);
        e ? this.keptStates.push(this.states_.slice()) : xt(this.states_);
        for (let a = 0; a < this.states_.length; ++a) {
          const l = t[a], c = r;
          if (!$t(l.shape, c))
            throw new E(`State ${a} is incompatible with layer ${this.name}: expected shape=${c}, received shape=${l.shape}`);
          this.states_[a] = l;
        }
      }
      this.states_ = this.states_.map((a) => hn(a.clone()));
    });
  }
  computeSingleOutputShape(t) {
    const { dataFormat: e, filters: s, kernelSize: o, padding: r, strides: i6, dilationRate: a } = this.cell, l = e === "channelsFirst", c = t[l ? 3 : 2], u = t[l ? 4 : 3], d = On(c, o[0], r, i6[0], a[0]), h = On(u, o[1], r, i6[1], a[1]);
    return [
      ...t.slice(0, 2),
      ...l ? [s, d, h] : [d, h, s]
    ];
  }
};
Vy.className = "ConvRNN2D";
var Ff = class extends gu {
  constructor(t) {
    const { filters: e, kernelSize: s, strides: o, padding: r, dataFormat: i6, dilationRate: a } = t;
    super(Object.assign(Object.assign({}, t), { units: e })), this.filters = e, xe(this.filters, "filters"), this.kernelSize = dr(s, 2, "kernelSize"), this.kernelSize.forEach((l) => xe(l, "kernelSize")), this.strides = dr(o || 1, 2, "strides"), this.strides.forEach((l) => xe(l, "strides")), this.padding = r || "valid", gn(this.padding), this.dataFormat = i6 || "channelsLast", ae(this.dataFormat), this.dilationRate = dr(a || 1, 2, "dilationRate"), this.dilationRate.forEach((l) => xe(l, "dilationRate"));
  }
  build(t) {
    var e;
    t = Rt(t);
    const s = this.dataFormat === "channelsFirst" ? 1 : t.length - 1;
    if (t[s] == null)
      throw new E(`The channel dimension of the input should be defined. Found ${t[s]}`);
    const o = t[s], r = 4, i6 = this.kernelSize.concat([o, this.filters * r]);
    this.kernel = this.addWeight("kernel", i6, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    const a = this.kernelSize.concat([this.filters, this.filters * r]);
    if (this.recurrentKernel = this.addWeight("recurrent_kernel", a, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias) {
      let l;
      if (this.unitForgetBias) {
        const c = this.biasInitializer, u = this.filters;
        l = new (e = class extends Gn {
          apply(h, p) {
            const f = c.apply([u]), m = ks([u]), g = c.apply([u * 2]);
            return xf([f, m, g]);
          }
        }, /** @nocollapse */
        e.className = "CustomInit", e)();
      } else
        l = this.biasInitializer;
      this.bias = this.addWeight("bias", [this.filters * r], null, l, this.biasRegularizer, true, this.biasConstraint);
    }
    this.built = true;
  }
  call(t, e) {
    return D(() => {
      if (t.length !== 3)
        throw new E(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);
      const s = e.training || false, o = t[0], r = t[1], i6 = t[2], a = 4;
      0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = Us({
        ones: () => Rn(o),
        rate: this.dropout,
        training: s,
        count: a,
        dropoutFunc: this.dropoutFunc
      }));
      const l = this.dropoutMask, c = (Y, Q6, j) => !Q6 || !Q6[j] ? Y : G(Q6[j], Y);
      let u = c(o, l, 0), d = c(o, l, 1), h = c(o, l, 2), p = c(o, l, 3);
      0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = Us({
        ones: () => Rn(r),
        rate: this.recurrentDropout,
        training: s,
        count: a,
        dropoutFunc: this.dropoutFunc
      }));
      const f = this.recurrentDropoutMask;
      let m = c(r, f, 0), g = c(r, f, 1), b = c(r, f, 2), x6 = c(r, f, 3);
      const w = 3, [y6, I, v, k6] = pn(this.kernel.read(), a, w), [S, N, R, M6] = this.useBias ? pn(this.bias.read(), a) : [null, null, null, null];
      u = this.inputConv(u, y6, S, this.padding), d = this.inputConv(d, I, N, this.padding), h = this.inputConv(h, v, R, this.padding), p = this.inputConv(p, k6, M6, this.padding);
      const [V, z, P, A] = pn(this.recurrentKernel.read(), a, w);
      m = this.recurrentConv(m, V), g = this.recurrentConv(g, z), b = this.recurrentConv(b, P), x6 = this.recurrentConv(x6, A);
      const O = this.recurrentActivation.apply(U(u, m)), B6 = this.recurrentActivation.apply(U(d, g)), Z = U(G(B6, i6), G(O, this.activation.apply(U(h, b)))), H6 = G(this.recurrentActivation.apply(U(p, x6)), this.activation.apply(Z));
      return [H6, H6, Z];
    });
  }
  getConfig() {
    const t = super.getConfig(), e = x3(t, ["units"]), s = {
      filters: this.filters,
      kernelSize: this.kernelSize,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      strides: this.strides
    };
    return Object.assign(Object.assign({}, e), s);
  }
  inputConv(t, e, s, o) {
    const r = $o(t, e, this.strides, o || "valid", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC", this.dilationRate);
    return s ? _n(r, s, this.dataFormat) : r;
  }
  recurrentConv(t, e) {
    return $o(t, e, 1, "same", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC");
  }
};
Ff.className = "ConvLSTM2DCell";
_(Ff);
var zy = class extends Vy {
  constructor(t) {
    const e = new Ff(t);
    super(Object.assign(Object.assign({}, t), { cell: e }));
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    return new t(e);
  }
};
zy.className = "ConvLSTM2D";
_(zy);
var Vf = class extends St {
  constructor(t) {
    super(t), this.rate = Math.max(Math.min(t.rate, 1), 0), this.noiseShape = t.noiseShape, this.seed = t.seed, this.supportsMasking = true;
  }
  getNoiseShape(t) {
    if (this.noiseShape == null)
      return this.noiseShape;
    const e = t.shape, s = [];
    for (let o = 0; o < this.noiseShape.length; ++o)
      s.push(this.noiseShape[o] == null ? e[o] : this.noiseShape[o]);
    return s;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      if (0 < this.rate && this.rate < 1) {
        const o = e.training == null ? false : e.training, r = this.getNoiseShape(s);
        return Ma(() => $x(s, this.rate, r, this.seed), () => s, o);
      }
      return t;
    });
  }
  getConfig() {
    const t = {
      rate: this.rate,
      noiseShape: this.noiseShape,
      seed: this.seed
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  dispose() {
    return super.dispose();
  }
};
Vf.className = "Dropout";
_(Vf);
var Py = class extends Vf {
  constructor(t) {
    super(t), this.inputSpec = [{ ndim: 3 }];
  }
  getNoiseShape(t) {
    const e = t.shape;
    return [e[0], 1, e[2]];
  }
};
Py.className = "SpatialDropout1D";
_(Py);
var Ay = class extends St {
  constructor(t) {
    if (super(t), this.activation = null, this.useBias = true, this.kernel = null, this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", t.batchInputShape == null && t.inputShape == null && t.inputDim != null) {
      let e = null;
      t.batchSize != null && (e = t.batchSize), this.batchInputShape = [e, t.inputDim];
    }
    this.units = t.units, xe(this.units, "units"), this.activation = _s(t.activation), t.useBias != null && (this.useBias = t.useBias), this.kernelInitializer = Ut(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.biasInitializer = Ut(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelConstraint = pe(t.kernelConstraint), this.biasConstraint = pe(t.biasConstraint), this.kernelRegularizer = Qt(t.kernelRegularizer), this.biasRegularizer = Qt(t.biasRegularizer), this.activityRegularizer = Qt(t.activityRegularizer), this.supportsMasking = true, this.inputSpec = [{ minNDim: 2 }];
  }
  build(t) {
    t = Rt(t);
    const e = t[t.length - 1];
    this.kernel == null && (this.kernel = this.addWeight("kernel", [e, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint))), this.inputSpec = [{ minNDim: 2, axes: { [-1]: e } }], this.built = true;
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = t.slice();
    return e[e.length - 1] = this.units, e;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t), o = Cx(this.activation.getClassName());
      let r;
      return o != null ? r = ns(s, this.kernel.read(), o, this.bias ? this.bias.read() : null) : (r = ns(s, this.kernel.read()), this.bias != null && (r = _n(r, this.bias.read())), this.activation != null && (r = this.activation.apply(r))), r;
    });
  }
  getConfig() {
    const t = {
      units: this.units,
      activation: Hs(this.activation),
      useBias: this.useBias,
      kernelInitializer: jt(this.kernelInitializer),
      biasInitializer: jt(this.biasInitializer),
      kernelRegularizer: zt(this.kernelRegularizer),
      biasRegularizer: zt(this.biasRegularizer),
      activityRegularizer: zt(this.activityRegularizer),
      kernelConstraint: he(this.kernelConstraint),
      biasConstraint: he(this.biasConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Ay.className = "Dense";
_(Ay);
var Oy = class extends St {
  constructor(t) {
    t = t || {}, super(t), this.inputSpec = [{ minNDim: 3 }], this.dataFormat = t.dataFormat;
  }
  computeOutputShape(t) {
    t = Rt(t);
    for (const e of t.slice(1))
      if (e == null)
        throw new E(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);
    return [t[0], As(t, 1)];
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      let s = mt(t);
      if (this.dataFormat === "channelsFirst" && s.rank > 1) {
        const o = [0];
        for (let r = 2; r < s.rank; ++r)
          o.push(r);
        o.push(1), s = kt(s, o);
      }
      return JE(s);
    });
  }
  getConfig() {
    const t = {};
    this.dataFormat != null && (t.dataFormat = this.dataFormat);
    const e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Oy.className = "Flatten";
_(Oy);
var Xy = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.activation = _s(t.activation);
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      return this.activation.apply(s);
    });
  }
  getConfig() {
    const t = { activation: Hs(this.activation) }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Xy.className = "Activation";
_(Xy);
var Ky = class extends St {
  constructor(t) {
    super(t), this.n = t.n, this.inputSpec = [{ ndim: 2 }];
  }
  computeOutputShape(t) {
    return [t[0], this.n, t[1]];
  }
  call(t, e) {
    return D(() => (t = mt(t), YE(t, this.n)));
  }
  getConfig() {
    const t = {
      n: this.n
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Ky.className = "RepeatVector";
_(Ky);
var Zy = class extends St {
  constructor(t) {
    super(t), this.targetShape = t.targetShape;
    for (let e = 0; e < this.targetShape.length; ++e)
      this.isUnknown(this.targetShape[e]) && (this.targetShape[e] = null);
  }
  isUnknown(t) {
    return t < 0 || t == null;
  }
  /**
   * Finds and replaces a missing dimension in output shape.
   *
   * This is a near direct port of the internal Numpy function
   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.
   *
   * @param inputShape: Original shape of array begin reshape.
   * @param outputShape: Target shape of the array, with at most a single
   * `null` or negative number, which indicates an underdetermined dimension
   * that should be derived from `inputShape` and the known dimensions of
   *   `outputShape`.
   * @returns: The output shape with `null` replaced with its computed value.
   * @throws: ValueError: If `inputShape` and `outputShape` do not match.
   */
  fixUnknownDimension(t, e) {
    const s = "Total size of new array must be unchanged.", o = e.slice();
    let r = 1, i6 = null;
    for (let l = 0; l < o.length; ++l) {
      const c = o[l];
      if (this.isUnknown(c))
        if (i6 === null)
          i6 = l;
        else
          throw new E("Can only specifiy one unknown dimension.");
      else
        r *= c;
    }
    const a = As(t);
    if (i6 !== null) {
      if (r === 0 || a % r !== 0)
        throw new E(s);
      o[i6] = a / r;
    } else if (a !== r)
      throw new E(s);
    return o;
  }
  computeOutputShape(t) {
    let e = false;
    for (let s = 0; s < t.length; ++s)
      if (this.isUnknown(t[s])) {
        e = true;
        break;
      }
    return e ? t.slice(0, 1).concat(this.targetShape) : t.slice(0, 1).concat(this.fixUnknownDimension(t.slice(1), this.targetShape));
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t), o = s.shape, r = o.slice(0, 1).concat(this.fixUnknownDimension(o.slice(1), this.targetShape));
      return W(s, r);
    });
  }
  getConfig() {
    const t = {
      targetShape: this.targetShape
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
Zy.className = "Reshape";
_(Zy);
var By = class extends St {
  constructor(t) {
    if (super(t), t.dims == null)
      throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
    if (!Array.isArray(t.dims))
      throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);
    const e = Kn(1, t.dims.length + 1);
    if (!$t(t.dims.slice().sort(), e))
      throw new Error("Invalid permutation `dims`: " + JSON.stringify(t.dims) + " `dims` must contain consecutive integers starting from 1.");
    this.dims = t.dims, this.dimsIncludingBatch = [0].concat(this.dims), this.inputSpec = [new de({ ndim: this.dims.length + 1 })];
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = t.slice();
    return this.dims.forEach((s, o) => {
      e[o + 1] = t[s];
    }), e;
  }
  call(t, e) {
    return kt(mt(t), this.dimsIncludingBatch);
  }
  getConfig() {
    const t = {
      dims: this.dims
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
By.className = "Permute";
_(By);
var Hy = class extends St {
  constructor(t) {
    super(t ?? {}), this.supportsMasking = true, t != null ? this.maskValue = t.maskValue == null ? 0 : t.maskValue : this.maskValue = 0;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { maskValue: this.maskValue };
    return Object.assign(e, t), e;
  }
  computeMask(t, e) {
    const s = mt(t);
    return Id(ui(s, this.maskValue), -1);
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t), i6 = Id(ui(s, this.maskValue), -1, true);
      return G(s, tt(i6, s.dtype));
    });
  }
};
Hy.className = "Masking";
_(Hy);
var _y = class extends St {
  constructor(t) {
    if (super(t), this.embeddings = null, this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform", t.batchInputShape == null && t.inputShape == null) {
      let e = null;
      t.batchSize != null && (e = t.batchSize), t.inputLength == null ? this.batchInputShape = [e, null] : this.batchInputShape = [e].concat(Lt(t.inputLength));
    }
    this.inputDim = t.inputDim, xe(this.inputDim, "inputDim"), this.outputDim = t.outputDim, xe(this.outputDim, "outputDim"), this.embeddingsInitializer = Ut(t.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER), this.embeddingsRegularizer = Qt(t.embeddingsRegularizer), this.activityRegularizer = Qt(t.activityRegularizer), this.embeddingsConstraint = pe(t.embeddingsConstraint), this.maskZero = t.maskZero, this.supportsMasking = t.maskZero, this.inputLength = t.inputLength;
  }
  build(t) {
    this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint), this.built = true;
  }
  // Override warnOnIncompatibleInputShape because an embedding layer allows
  // the input to have varying ranks.
  warnOnIncompatibleInputShape(t) {
  }
  computeMask(t, e) {
    return D(() => this.maskZero ? (t = mt(t), ui(t, Tt(t))) : null);
  }
  computeOutputShape(t) {
    if (t = Rt(t), this.inputLength == null)
      return [...t, this.outputDim];
    const e = Lt(this.inputLength);
    if (e.length !== t.length - 1)
      throw new E(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);
    {
      let s = 0;
      for (let o = 0; o < e.length; ++o) {
        const r = e[o], i6 = t[o + 1];
        if (r != null && i6 != null && r !== i6)
          throw new E(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);
        r == null && (e[s] = i6), s++;
      }
    }
    return [t[0], ...e, this.outputDim];
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      let s = mt(t);
      s.dtype !== "int32" && (s = es(s, "int32"));
      const o = Rx(this.embeddings.read(), W(s, [s.size]));
      return W(o, Rt(this.computeOutputShape(s.shape)));
    });
  }
  getConfig() {
    const t = {
      inputDim: this.inputDim,
      outputDim: this.outputDim,
      embeddingsInitializer: jt(this.embeddingsInitializer),
      embeddingsRegularizer: zt(this.embeddingsRegularizer),
      activityRegularizer: zt(this.activityRegularizer),
      embeddingsConstraint: he(this.embeddingsConstraint),
      maskZero: this.maskZero,
      inputLength: this.inputLength
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
_y.className = "Embedding";
_(_y);
var Yo = class extends St {
  constructor(t) {
    super(t || {}), this.supportsMasking = true;
  }
  /**
   * Logic for merging multiple tensors, to be overridden by subclasses.
   * @param inputs
   */
  mergeFunction(t) {
    throw new yt();
  }
  /**
   * Computes the shape of the result of an elementwise operation.
   *
   * @param shape1: Shape of the first tensor.
   * @param shape2: Shape of the second tensor.
   * @returns Expected output shape when an elementwise operation is carried
   *   out on 2 tensors with shapes `shape1` and `shape2`.
   * @throws ValueError: If `shape1` and `shape2` are not compatible for
   *   element-wise operations.
   */
  computeElementwiseOpOutputShape(t, e) {
    if (t == null || e == null)
      return null;
    if (t.length < e.length)
      return this.computeElementwiseOpOutputShape(e, t);
    if (e.length === 0)
      return t;
    const s = t.slice(0, t.length - e.length);
    for (let o = 0; o < e.length; ++o) {
      const r = t[t.length - e.length + o], i6 = e[o];
      if (r == null || i6 == null || r < 0 || i6 < 0)
        s.push(null);
      else if (r === 1)
        s.push(i6);
      else if (i6 === 1)
        s.push(r);
      else {
        if (r !== i6)
          throw new E("Operands could not be broadcast together with shapes " + JSON.stringify(t) + " " + JSON.stringify(e));
        s.push(r);
      }
    }
    return s;
  }
  build(t) {
    if (Array.isArray(t) && !Array.isArray(t[0]) && (t = [Rt(t)]), t = t, t.length < 2)
      throw new E(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);
    let e = [];
    for (const r of t)
      r != null && r[0] !== null && e.push(r[0]);
    if (e = Ps(e), e.length > 1)
      throw new E(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);
    let s = t[0] == null ? null : t[0].slice(1);
    for (let r = 1; r < t.length; ++r) {
      const i6 = t[r] == null ? null : t[r].slice(1);
      s = this.computeElementwiseOpOutputShape(s, i6);
    }
    const o = t.map((r) => r.length);
    t.indexOf(null) === -1 && Ps(o).length === 1 ? this.reshapeRequired = false : this.reshapeRequired = true;
  }
  call(t, e) {
    return D(() => {
      if (t = t, this.reshapeRequired) {
        const s = [], o = t.map((r) => r.rank);
        if (o.indexOf(null) === -1) {
          const r = Bs(o);
          for (let i6 of t) {
            const a = i6.rank;
            for (let l = 0; l < r - a; ++l)
              i6 = Ea(i6, 1);
            s.push(i6);
          }
          return this.mergeFunction(s);
        } else {
          let r = false;
          for (const l of t) {
            const c = l.rank;
            if (c == null) {
              const u = l.shape, d = u[0], h = u.slice(1).concat([d]);
              let p = W(l, [d].concat(As(u.slice(1))));
              p = kt(p, [1, 0]), p = W(p, h), s.push(p), r = true;
            } else if (c > 1) {
              const u = Kn(1, c).concat([0]);
              s.push(kt(l, u)), r = true;
            } else
              s.push(l);
          }
          let i6 = this.mergeFunction(s);
          const a = i6.rank;
          if (r) {
            if (a == null) {
              const l = i6.shape, c = l.length, u = l[c - 1], d = [u].concat(l.slice(0, l.length - 1));
              i6 = W(kt(W(i6, [-1, u]), [1, 0]), d);
            } else if (a > 1) {
              const l = [a - 1].concat(Kn(0, a - 1));
              i6 = kt(i6, l);
            }
          }
          return i6;
        }
      } else
        return this.mergeFunction(t);
    });
  }
  computeOutputShape(t) {
    t = t;
    let e;
    t[0] == null ? e = null : e = t[0].slice(1);
    for (let o = 1; o < t.length; ++o) {
      const r = t[o] == null ? null : t[o].slice(1);
      e = this.computeElementwiseOpOutputShape(e, r);
    }
    let s = [];
    for (const o of t)
      o != null && o[0] !== null && s.push(o[0]);
    return s = Ps(s), s.length === 1 ? e = s.concat(e) : e = [null].concat(e), e;
  }
  computeMask(t, e) {
    return D(() => {
      if (e == null)
        return null;
      if (!Array.isArray(e))
        throw new E("`mask` should be an Array");
      if (!Array.isArray(t))
        throw new E("`inputs` should be an Array");
      if (e.length !== t.length)
        throw new E(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);
      if (e.every((o) => o == null))
        return null;
      e = e.map((o) => o == null ? o : Oe(o, 0));
      let s = e[0];
      for (let o = 1; o < e.length - 1; ++o)
        s = ss(s, e[o]);
      return s;
    });
  }
};
var Uy = class extends Yo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0].clone();
      for (let s = 1; s < t.length; ++s)
        e = U(e, t[s]);
      return e;
    });
  }
};
Uy.className = "Add";
_(Uy);
var Yy = class extends Yo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0].clone();
      for (let s = 1; s < t.length; ++s)
        e = G(e, t[s]);
      return e;
    });
  }
};
Yy.className = "Multiply";
_(Yy);
var Qy = class extends Yo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0].clone();
      for (let s = 1; s < t.length; ++s)
        e = U(e, t[s]);
      return G(1 / t.length, e);
    });
  }
};
Qy.className = "Average";
_(Qy);
var Jy = class extends Yo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0];
      for (let s = 1; s < t.length; ++s)
        e = qs(e, t[s]);
      return e;
    });
  }
};
Jy.className = "Maximum";
_(Jy);
var jy = class extends Yo {
  constructor(t) {
    super(t);
  }
  mergeFunction(t) {
    return D(() => {
      let e = t[0];
      for (let s = 1; s < t.length; ++s)
        e = br(e, t[s]);
      return e;
    });
  }
};
jy.className = "Minimum";
_(jy);
var qy = class extends Yo {
  constructor(t) {
    super(t), this.DEFAULT_AXIS = -1, t == null && (t = {}), this.axis = t.axis == null ? this.DEFAULT_AXIS : t.axis, this.supportsMasking = true, this.reshapeRequired = false;
  }
  build(t) {
    if (!(Array.isArray(t) && Array.isArray(t[0])) || t.length === 1)
      throw new E("A `Concatenate` layer should be called on a list of at least 2 inputs");
    t = t;
    let e = true;
    for (const o of t)
      if (o != null) {
        e = false;
        break;
      }
    if (e)
      return;
    const s = [];
    for (let o = 0; o < t.length; ++o) {
      const r = t[o].slice();
      r.splice(this.axis, 1);
      let i6 = false;
      for (const a of s)
        if ($t(a, r)) {
          i6 = true;
          break;
        }
      i6 || s.push(r);
    }
    if (s.length > 1)
      throw new E("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(t));
  }
  mergeFunction(t) {
    return D(() => xf(t, this.axis));
  }
  computeOutputShape(t) {
    if (!(Array.isArray(t) && Array.isArray(t[0])))
      throw new E("A `Concatenate` layer should be called on a list of inputs.");
    const e = t, s = e[0].slice(), o = this.axis < 0 ? s.length + this.axis : this.axis;
    for (const r of e.slice(1)) {
      if (s[o] == null || r[o] == null) {
        s[o] = null;
        break;
      }
      s[o] += r[o];
    }
    return s;
  }
  computeMask(t, e) {
    if (e == null)
      return null;
    if (!Array.isArray(e))
      throw new E("`mask` should be an array for Concatenate");
    if (!Array.isArray(t))
      throw new E("`inputs` should be an array for Concatenate");
    if (e.length !== t.length)
      throw new E(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);
    return D(() => {
      let s = true;
      if (e.forEach((i6) => {
        if (i6 != null) {
          s = false;
          return;
        }
      }), s)
        return null;
      const o = [];
      for (let i6 = 0; i6 < t.length; ++i6)
        e[i6] == null ? o.push(tt(Rn(t[i6]), "bool")) : e[i6].rank < t[i6].rank ? o.push(Oe(e[i6], -1)) : o.push(e[i6]);
      const r = Ge(o, this.axis);
      return Qb(r, -1, false);
    });
  }
  getConfig() {
    const t = {
      axis: this.axis
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
qy.className = "Concatenate";
_(qy);
function Kr(n, t) {
  for (; n < 0; )
    n += t;
  return n;
}
function y3(n, t, e) {
  if (n.shape.length > 3 || t.shape.length > 3)
    throw new yt("batchDot is not implemented for tensors of 4D or higher rank yet");
  if (C(n.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, but got ${n.shape.length}`), C(n.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`), typeof e == "number" && (e = [e, e]), n.dtype === "complex64" || t.dtype === "complex64")
    throw new yt("batchDot is not implemented for complex64-type Tensors yet.");
  const s = n.shape.length, o = t.shape.length;
  e == null && (e = [s - 1, o - 2]);
  const r = e;
  return D(() => {
    let i6;
    if (s > o) {
      i6 = s - o;
      const l = [];
      for (let c = 0; c < i6; ++c)
        l.push(1);
      t = W(t, t.shape.concat(l));
    } else if (o > s) {
      i6 = o - s;
      const l = [];
      for (let c = 0; c < i6; ++c)
        l.push(1);
      n = W(n, n.shape.concat(l));
    } else
      i6 = 0;
    let a;
    if (n.shape.length === 2 && t.shape.length === 2)
      r[0] === r[1] ? a = at(G(n, t), r[0]) : a = at(G(kt(n, [1, 0]), t), r[1]);
    else {
      const l = r[0] !== n.shape.length - 1, c = r[1] === t.shape.length - 1;
      a = Gt(n, t, l, c);
    }
    if (i6 > 0) {
      let l;
      s > o ? l = s + o - 3 : l = s - 1;
      const c = [];
      for (let u = l; u < l + i6; ++u)
        c.push(u);
      a = ka(a, c);
    }
    return a.shape.length === 1 && (a = Oe(a, 1)), a;
  });
}
var t1 = class extends Yo {
  constructor(t) {
    super(t), this.axes = t.axes, this.normalize = t.normalize == null ? false : t.normalize, this.supportsMasking = true, this.reshapeRequired = false;
  }
  build(t) {
    C(Array.isArray(t) && t.length === 2 && Array.isArray(t[0]) && Array.isArray(t[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    const e = t[0], s = t[1];
    if (e.length > 3 || s.length > 3)
      throw new yt("Dot layer does not support tensors of 4D or higher rank yet.");
    const o = this.interpretAxes(e, s);
    if (e[o[0]] !== s[o[1]])
      throw new E(`Dimension incompatibility: ${e[o[0]]} !== ${s[o[1]]}`);
  }
  mergeFunction(t) {
    if (t.length !== 2)
      throw new E(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);
    let e = t[0], s = t[1], o;
    return Array.isArray(this.axes) ? o = this.axes.map((r, i6) => Kr(r, t[i6].shape.length)) : o = [
      Kr(this.axes, e.shape.length),
      Kr(this.axes, s.shape.length)
    ], this.normalize && (e = Gl(e, o[0]), s = Gl(s, o[1])), y3(e, s, o);
  }
  interpretAxes(t, e) {
    let s;
    return Array.isArray(this.axes) ? s = this.axes : s = [
      Kr(this.axes, t.length),
      Kr(this.axes, e.length)
    ], s;
  }
  computeOutputShape(t) {
    C(Array.isArray(t) && t.length === 2 && Array.isArray(t[0]) && Array.isArray(t[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    const e = t[0].slice(), s = t[1].slice();
    if (e.length > 3 || s.length > 3)
      throw new yt("Dot layer does not support tensors of 4D or higher rank yet.");
    const o = this.interpretAxes(e, s);
    e.splice(o[0], 1), s.splice(o[1], 1), s.splice(0, 1);
    const r = e.concat(s);
    return r.length === 1 && r.push(1), r;
  }
  computeMask(t, e) {
    return null;
  }
  getConfig() {
    const t = {
      axes: this.axes,
      normalize: this.normalize
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
t1.className = "Dot";
_(t1);
var e1 = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.stddev = t.stddev;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { stddev: this.stddev };
    return Object.assign(e, t), e;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      return Ma(() => U(lu(s.shape, 0, this.stddev), s), () => s, e.training || false);
    });
  }
};
e1.className = "GaussianNoise";
_(e1);
var n1 = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.rate = t.rate;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { rate: this.rate };
    return Object.assign(e, t), e;
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e);
      const s = mt(t);
      return this.rate > 0 && this.rate < 1 ? Ma(() => {
        const r = Math.sqrt(this.rate / (1 - this.rate));
        return G(s, lu(s.shape, 1, r));
      }, () => s, e.training || false) : s;
    });
  }
};
n1.className = "GaussianDropout";
_(n1);
var s1 = class extends St {
  constructor(t) {
    super(t), this.supportsMasking = true, this.rate = t.rate, this.noiseShape = t.noiseShape;
  }
  _getNoiseShape(t) {
    return this.noiseShape || mt(t).shape;
  }
  computeOutputShape(t) {
    return t;
  }
  getConfig() {
    const t = super.getConfig(), e = { rate: this.rate };
    return Object.assign(e, t), e;
  }
  call(t, e) {
    return D(() => {
      if (this.rate < 1 && this.rate > 0) {
        const s = this._getNoiseShape(t);
        return Ma(() => {
          const r = mt(t), l = -1.6732632423543772 * 1.0507009873554805;
          let c = Bo(Sa(s), this.rate);
          c = es(c, "float32");
          const u = ((1 - this.rate) * (1 + this.rate * l ** 2)) ** -0.5, d = -u * l * this.rate, h = U(G(r, c), G(U(c, -1), l));
          return U(G(h, u), d);
        }, () => mt(t), e.training || false);
      }
      return t;
    });
  }
};
s1.className = "AlphaDropout";
_(s1);
function gi(n, t, e, s, o, r = 1e-3) {
  let i6;
  if (n.rank === 2)
    i6 = Jv(n, t, e, s, o, r);
  else if (n.rank === 3)
    i6 = qv(n, t, e, s, o, r);
  else if (n.rank === 4)
    i6 = eS(n, t, e, s, o, r);
  else
    throw new yt(`batchNormalization is not implemented for array of rank ${n.rank} yet`);
  return i6;
}
function w3(n, t, e, s, o = 1e-3) {
  return D(() => {
    const r = gp(n, s), i6 = r.mean, a = r.variance;
    return [gi(n, i6, a, e, t, o), i6, a];
  });
}
function I3(n, t, e, s, o = 1e-3) {
  return D(() => {
    const r = gp(n, s), i6 = r.mean, a = r.variance, l = [];
    for (const f of Kn(0, n.rank))
      s.indexOf(f) !== -1 ? l.push(1) : l.push(n.shape[f]);
    const c = W(i6, l), u = W(a, l), d = t == null ? null : W(t, l), h = e == null ? null : W(e, l);
    return [gi(n, c, u, h, d, o), i6, a];
  });
}
function C3(n, t, e, s, o = 1e-3) {
  return $t(s.slice().sort(), Kn(0, n.rank - 1)) ? w3(n, t, e, s, o) : I3(n, t, e, s, o);
}
var o1 = class extends St {
  constructor(t) {
    t == null && (t = {}), super(t), this.supportsMasking = true, this.axis = t.axis == null ? -1 : t.axis, this.momentum = t.momentum == null ? 0.99 : t.momentum, this.epsilon = t.epsilon == null ? 1e-3 : t.epsilon, this.center = t.center == null ? true : t.center, this.scale = t.scale == null ? true : t.scale, this.betaInitializer = Ut(t.betaInitializer || "zeros"), this.gammaInitializer = Ut(t.gammaInitializer || "ones"), this.movingMeanInitializer = Ut(t.movingMeanInitializer || "zeros"), this.movingVarianceInitializer = Ut(t.movingVarianceInitializer || "ones"), this.betaConstraint = pe(t.betaConstraint), this.gammaConstraint = pe(t.gammaConstraint), this.betaRegularizer = Qt(t.betaRegularizer), this.gammaRegularizer = Qt(t.gammaRegularizer);
  }
  build(t) {
    t = Rt(t);
    const e = this.axis >= 0 ? this.axis : this.axis + t.length, s = t[e];
    if (s == null)
      throw new E(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);
    this.inputSpec = [new de({ ndim: t.length, axes: { [e]: s } })];
    const o = [s];
    this.scale && (this.gamma = this.addWeight("gamma", o, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint)), this.center && (this.beta = this.addWeight("beta", o, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint)), this.movingMean = this.addWeight("moving_mean", o, null, this.movingMeanInitializer, null, false), this.movingVariance = this.addWeight("moving_variance", o, null, this.movingVarianceInitializer, null, false), this.built = true;
  }
  call(t, e) {
    return D(() => {
      const s = e.training == null ? false : e.training, o = mt(t), r = o.shape, i6 = r.length, a = Kn(0, i6), l = this.axis >= 0 ? this.axis : this.axis + i6;
      a.splice(l, 1);
      const c = Wo(1, i6);
      c[l] = r[l];
      const u = a.slice();
      u.sort();
      const d = !$t(u, Kn(0, i6).slice(0, i6 - 1)), h = () => {
        if (d) {
          const x6 = W(this.movingMean.read(), c), w = W(this.movingVariance.read(), c), y6 = this.center ? W(this.beta.read(), c) : null, I = this.scale ? W(this.gamma.read(), c) : null;
          return gi(o, x6, w, y6, I, this.epsilon);
        } else
          return gi(o, this.movingMean.read(), this.movingVariance.read(), this.beta == null ? null : this.beta.read(), this.gamma == null ? null : this.gamma.read(), this.epsilon);
      };
      if (!s)
        return h();
      const [p, f, m] = C3(o, this.gamma.read(), this.beta.read(), a, this.epsilon), g = (x6, w, y6) => {
        D(() => {
          const I = 1 - y6, v = x6.read(), k6 = G(it(v, w), I);
          x6.write(it(v, k6));
        });
      };
      return (() => {
        g(this.movingMean, f, this.momentum), g(this.movingVariance, m, this.momentum);
      })(), p;
    });
  }
  getConfig() {
    const t = {
      axis: this.axis,
      momentum: this.momentum,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: jt(this.betaInitializer),
      gammaInitializer: jt(this.gammaInitializer),
      movingMeanInitializer: jt(this.movingMeanInitializer),
      movingVarianceInitializer: jt(this.movingVarianceInitializer),
      betaRegularizer: zt(this.betaRegularizer),
      gammaRegularizer: zt(this.gammaRegularizer),
      betaConstraint: he(this.betaConstraint),
      gammaConstraint: he(this.gammaConstraint)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
o1.className = "BatchNormalization";
_(o1);
var r1 = class extends St {
  constructor(t) {
    if (t == null && (t = {}), super(t), this.axis = t.axis == null ? -1 : t.axis, typeof this.axis == "number") {
      if (!Number.isInteger(this.axis))
        throw new Error(`Expected axis to be an integer, but received ${this.axis}`);
    } else if (Array.isArray(this.axis)) {
      for (const e of this.axis)
        if (!Number.isInteger(e))
          throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`);
    } else
      throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);
    this.epsilon = t.epsilon == null ? 1e-3 : t.epsilon, this.center = t.center == null ? true : t.center, this.scale = t.scale == null ? true : t.scale, this.betaInitializer = Ut(t.betaInitializer || "zeros"), this.gammaInitializer = Ut(t.gammaInitializer || "ones"), this.betaRegularizer = Qt(t.betaRegularizer), this.gammaRegularizer = Qt(t.gammaRegularizer), this.supportsMasking = true;
  }
  build(t) {
    t = Rt(t);
    const e = t.length;
    typeof this.axis == "number" && (this.axis = [this.axis]);
    for (let r = 0; r < this.axis.length; ++r)
      this.axis[r] < 0 && (this.axis[r] += e);
    for (const r of this.axis)
      if (r < 0 || r >= e)
        throw new Error(`Invalid axis: ${r}`);
    if (this.axis.length !== Ps(this.axis).length)
      throw new Error(`Found duplicate axes in: ${this.axis}`);
    const s = this.axis.map((r) => t[r]), o = true;
    this.scale ? this.gamma = this.addWeight("gamma", s, "float32", this.gammaInitializer, this.gammaRegularizer, o) : this.gamma = null, this.center ? this.beta = this.addWeight("beta", s, "float32", this.betaInitializer, this.betaRegularizer, o) : this.beta = null, this.built = true;
  }
  call(t, e) {
    const s = mt(t), o = s.shape, r = o.length;
    return D(() => {
      let { mean: a, variance: l } = gp(s, this.axis, true);
      const c = Wo(1, r);
      for (const m of this.axis)
        c[m] = o[m];
      const u = (m) => m != null && m.shape.length !== r ? W(m, c) : m;
      let d = this.scale ? u(this.gamma.read()) : null, h = this.center ? u(this.beta.read()) : null;
      const p = [], f = [];
      for (let m = 0; m < r; ++m)
        this.axis.indexOf(m) !== -1 ? (p.push(o[m]), f.push(1)) : (p.push(1), f.push(o[m]));
      return a = Vn(a, p), l = Vn(l, p), d != null && (d = Vn(d, f)), h != null && (h = Vn(h, f)), gi(s, a, l, h, d, this.epsilon);
    });
  }
  getConfig() {
    const t = {
      axis: this.axis,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: jt(this.betaInitializer),
      gammaInitializer: jt(this.gammaInitializer),
      betaRegularizer: zt(this.betaRegularizer),
      gammaRegularizer: zt(this.gammaRegularizer)
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
r1.className = "LayerNormalization";
_(r1);
function v3(n, t, e) {
  return D(() => {
    if (n.rank !== 4)
      throw new E(`temporalPadding expects input tensor to be 4-D, but received a ${n.rank}-D tensor.`);
    if (t == null && (t = [[1, 1], [1, 1]]), t.length !== 2 || t[0].length !== 2 || t[1].length !== 2)
      throw new E("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
    if (e == null && (e = Zn()), e !== "channelsLast" && e !== "channelsFirst")
      throw new E(`Unknown data format: ${e}. Supported data formats are 'channelsLast' and 'channelsFirst.`);
    let s;
    return e === "channelsFirst" ? s = [[0, 0], [0, 0], t[0], t[1]] : s = [[0, 0], t[0], t[1], [0, 0]], bp(n, s);
  });
}
var i1 = class extends St {
  constructor(t) {
    if (t == null && (t = {}), super(t), this.dataFormat = t.dataFormat == null ? Zn() : t.dataFormat, t.padding == null)
      this.padding = [[1, 1], [1, 1]];
    else if (typeof t.padding == "number")
      this.padding = [[t.padding, t.padding], [t.padding, t.padding]];
    else {
      if (t.padding = t.padding, t.padding.length !== 2)
        throw new E(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);
      let e, s;
      if (typeof t.padding[0] == "number")
        e = [t.padding[0], t.padding[0]], s = [t.padding[1], t.padding[1]];
      else {
        if (t.padding = t.padding, t.padding[0].length !== 2)
          throw new E(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);
        if (e = t.padding[0], t.padding[1].length !== 2)
          throw new E(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);
        s = t.padding[1];
      }
      this.padding = [e, s];
    }
    this.inputSpec = [new de({ ndim: 4 })];
  }
  computeOutputShape(t) {
    t = Rt(t);
    let e, s;
    return this.dataFormat === "channelsFirst" ? (t[2] != null && t[2] >= 0 ? e = t[2] + this.padding[0][0] + this.padding[0][1] : e = null, t[3] != null && t[3] >= 0 ? s = t[3] + this.padding[1][0] + this.padding[1][1] : s = null, [t[0], t[1], e, s]) : (t[1] != null && t[1] >= 0 ? e = t[1] + this.padding[0][0] + this.padding[0][1] : e = null, t[2] != null && t[2] >= 0 ? s = t[2] + this.padding[1][0] + this.padding[1][1] : s = null, [t[0], e, s, t[3]]);
  }
  call(t, e) {
    return D(() => v3(mt(t), this.padding, this.dataFormat));
  }
  getConfig() {
    const t = {
      padding: this.padding,
      dataFormat: this.dataFormat
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
i1.className = "ZeroPadding2D";
_(i1);
function bu(n, t, e, s, o, r) {
  return D(() => {
    ae(o), Sx(r), gn(s), e == null && (e = [1, 1]), s == null && (s = "valid"), o == null && (o = Zn()), r == null && (r = "max"), n = Lf(n, o);
    let i6;
    const a = s === "same" ? "same" : "valid";
    return r === "max" ? i6 = mp(n, t, e, a) : i6 = np(
      // TODO(cais): Rank check?
      n,
      t,
      e,
      a
    ), o === "channelsFirst" && (i6 = kt(i6, [0, 3, 1, 2])), i6;
  });
}
function a1(n, t, e, s, o, r) {
  return D(() => {
    ae(o), Sx(r), gn(s), e == null && (e = [1, 1, 1]), s == null && (s = "valid"), o == null && (o = Zn()), r == null && (r = "max"), n = Sy(n, o);
    let i6;
    const a = s === "same" ? "same" : "valid";
    return r === "max" ? i6 = Ak(n, t, e, a) : i6 = Ov(n, t, e, a), o === "channelsFirst" && (i6 = kt(i6, [0, 4, 1, 2, 3])), i6;
  });
}
var l1 = class extends St {
  /**
   *
   * @param args Parameters for the Pooling layer.
   *
   * config.poolSize defaults to 2.
   */
  constructor(t) {
    if (t.poolSize == null && (t.poolSize = 2), super(t), typeof t.poolSize == "number")
      this.poolSize = [t.poolSize];
    else if (Array.isArray(t.poolSize) && t.poolSize.length === 1 && typeof t.poolSize[0] == "number")
      this.poolSize = t.poolSize;
    else
      throw new E(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.poolSize)}`);
    if (xe(this.poolSize, "poolSize"), t.strides == null)
      this.strides = this.poolSize;
    else if (typeof t.strides == "number")
      this.strides = [t.strides];
    else if (Array.isArray(t.strides) && t.strides.length === 1 && typeof t.strides[0] == "number")
      this.strides = t.strides;
    else
      throw new E(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.strides)}`);
    xe(this.strides, "strides"), this.padding = t.padding == null ? "valid" : t.padding, gn(this.padding), this.inputSpec = [new de({ ndim: 3 })];
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = On(t[1], this.poolSize[0], this.padding, this.strides[0]);
    return [t[0], e, t[2]];
  }
  call(t, e) {
    return D(() => {
      this.invokeCallHook(t, e), t = Ea(mt(t), 2);
      const s = this.poolingFunction(mt(t), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
      return ka(s, [2]);
    });
  }
  getConfig() {
    const t = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var c1 = class extends l1 {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), gn(o), bu(t, e, s, o, r, "max");
  }
};
c1.className = "MaxPooling1D";
_(c1);
var u1 = class extends l1 {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), gn(o), bu(t, e, s, o, r, "avg");
  }
};
u1.className = "AveragePooling1D";
_(u1);
var d1 = class extends St {
  constructor(t) {
    if (t.poolSize == null && (t.poolSize = [2, 2]), super(t), this.poolSize = Array.isArray(t.poolSize) ? t.poolSize : [t.poolSize, t.poolSize], t.strides == null)
      this.strides = this.poolSize;
    else if (Array.isArray(t.strides)) {
      if (t.strides.length !== 2)
        throw new E(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t.strides.length}.`);
      this.strides = t.strides;
    } else
      this.strides = [t.strides, t.strides];
    xe(this.poolSize, "poolSize"), xe(this.strides, "strides"), this.padding = t.padding == null ? "valid" : t.padding, this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), gn(this.padding), this.inputSpec = [new de({ ndim: 4 })];
  }
  computeOutputShape(t) {
    t = Rt(t);
    let e = this.dataFormat === "channelsFirst" ? t[2] : t[1], s = this.dataFormat === "channelsFirst" ? t[3] : t[2];
    return e = On(e, this.poolSize[0], this.padding, this.strides[0]), s = On(s, this.poolSize[1], this.padding, this.strides[1]), this.dataFormat === "channelsFirst" ? [t[0], t[1], e, s] : [t[0], e, s, t[3]];
  }
  call(t, e) {
    return D(() => (this.invokeCallHook(t, e), this.poolingFunction(mt(t), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }
  getConfig() {
    const t = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var h1 = class extends d1 {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), gn(o), bu(t, e, s, o, r, "max");
  }
};
h1.className = "MaxPooling2D";
_(h1);
var p1 = class extends d1 {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), gn(o), bu(t, e, s, o, r, "avg");
  }
};
p1.className = "AveragePooling2D";
_(p1);
var f1 = class extends St {
  constructor(t) {
    if (t.poolSize == null && (t.poolSize = [2, 2, 2]), super(t), this.poolSize = Array.isArray(t.poolSize) ? t.poolSize : [t.poolSize, t.poolSize, t.poolSize], t.strides == null)
      this.strides = this.poolSize;
    else if (Array.isArray(t.strides)) {
      if (t.strides.length !== 3)
        throw new E(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t.strides.length}.`);
      this.strides = t.strides;
    } else
      this.strides = [t.strides, t.strides, t.strides];
    xe(this.poolSize, "poolSize"), xe(this.strides, "strides"), this.padding = t.padding == null ? "valid" : t.padding, this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), gn(this.padding), this.inputSpec = [new de({ ndim: 5 })];
  }
  computeOutputShape(t) {
    t = Rt(t);
    let e = this.dataFormat === "channelsFirst" ? t[2] : t[1], s = this.dataFormat === "channelsFirst" ? t[3] : t[2], o = this.dataFormat === "channelsFirst" ? t[4] : t[3];
    return e = On(e, this.poolSize[0], this.padding, this.strides[0]), s = On(s, this.poolSize[1], this.padding, this.strides[1]), o = On(o, this.poolSize[2], this.padding, this.strides[2]), this.dataFormat === "channelsFirst" ? [t[0], t[1], e, s, o] : [t[0], e, s, o, t[4]];
  }
  call(t, e) {
    return D(() => (this.invokeCallHook(t, e), this.poolingFunction(mt(t), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }
  getConfig() {
    const t = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var m1 = class extends f1 {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), gn(o), a1(t, e, s, o, r, "max");
  }
};
m1.className = "MaxPooling3D";
_(m1);
var g1 = class extends f1 {
  constructor(t) {
    super(t);
  }
  poolingFunction(t, e, s, o, r) {
    return ae(r), gn(o), a1(t, e, s, o, r, "avg");
  }
};
g1.className = "AveragePooling3D";
_(g1);
var b1 = class extends St {
  constructor(t) {
    super(t), this.inputSpec = [new de({ ndim: 3 })];
  }
  computeOutputShape(t) {
    return [t[0], t[2]];
  }
  call(t, e) {
    throw new yt();
  }
};
var x1 = class extends b1 {
  constructor(t) {
    super(t || {});
  }
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return oe(s, 1);
    });
  }
};
x1.className = "GlobalAveragePooling1D";
_(x1);
var y1 = class extends b1 {
  constructor(t) {
    super(t || {});
  }
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return Pn(s, 1);
    });
  }
};
y1.className = "GlobalMaxPooling1D";
_(y1);
var w1 = class extends St {
  constructor(t) {
    super(t), this.dataFormat = t.dataFormat == null ? "channelsLast" : t.dataFormat, ae(this.dataFormat), this.inputSpec = [new de({ ndim: 4 })];
  }
  computeOutputShape(t) {
    return t = t, this.dataFormat === "channelsLast" ? [t[0], t[3]] : [t[0], t[1]];
  }
  call(t, e) {
    throw new yt();
  }
  getConfig() {
    const t = { dataFormat: this.dataFormat }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
var I1 = class extends w1 {
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return this.dataFormat === "channelsLast" ? oe(s, [1, 2]) : oe(s, [2, 3]);
    });
  }
};
I1.className = "GlobalAveragePooling2D";
_(I1);
var C1 = class extends w1 {
  call(t, e) {
    return D(() => {
      const s = mt(t);
      return this.dataFormat === "channelsLast" ? Pn(s, [1, 2]) : Pn(s, [2, 3]);
    });
  }
};
C1.className = "GlobalMaxPooling2D";
_(C1);
var v1 = class extends St {
  constructor(t) {
    super(t), this.layer = t.layer;
  }
  build(t) {
    this.built = true;
  }
  // TODO(cais): Implement activityRegularizer getter.
  get trainable() {
    return this.layer != null ? this.layer.trainable : false;
  }
  set trainable(t) {
    this.layer != null && (this.layer.trainable = t);
  }
  get trainableWeights() {
    return this.layer.trainableWeights;
  }
  // TODO(cais): Implement setter for trainableWeights.
  get nonTrainableWeights() {
    return this.layer.nonTrainableWeights;
  }
  // TODO(cais): Implement setter for nonTrainableWeights.
  get updates() {
    return this.layer._updates;
  }
  // TODO(cais): Implement getUpdatesFor().
  get losses() {
    return this.layer.losses;
  }
  // TODO(cais): Implement getLossesFor().
  getWeights() {
    return this.layer.getWeights();
  }
  setWeights(t) {
    this.layer.setWeights(t);
  }
  getConfig() {
    const t = {
      layer: {
        className: this.layer.getClassName(),
        config: this.layer.getConfig()
      }
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  setFastWeightInitDuringBuild(t) {
    super.setFastWeightInitDuringBuild(t), this.layer != null && this.layer.setFastWeightInitDuringBuild(t);
  }
  /** @nocollapse */
  static fromConfig(t, e, s = {}) {
    const o = e.layer, r = An(o, s);
    delete e.layer;
    const i6 = { layer: r };
    return Object.assign(i6, e), new t(i6);
  }
};
var S1 = class extends v1 {
  constructor(t) {
    super(t), this.supportsMasking = true;
  }
  build(t) {
    if (t = Rt(t), t.length < 3)
      throw new E(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t)}`);
    this.inputSpec = [{ shape: t }];
    const e = [t[0]].concat(t.slice(2));
    this.layer.built || (this.layer.build(e), this.layer.built = true), super.build(t);
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = [t[0]].concat(t.slice(2)), s = this.layer.computeOutputShape(e), o = t[1];
    return [s[0], o].concat(s.slice(1));
  }
  call(t, e) {
    return D(() => (t = mt(t), My(
      (i6, a) => [mt(this.layer.call(i6, e)), []],
      t,
      [],
      false,
      null,
      null,
      false,
      true
      /* needPerStepOutputs */
    )[1]));
  }
};
S1.className = "TimeDistributed";
_(S1);
function S3(n) {
  Uo(ZE, "BidirectionalMergeMode", n);
}
var k3 = "concat";
var k1 = class extends v1 {
  constructor(t) {
    super(t);
    const e = t.layer.getConfig(), s = {};
    s.className = t.layer.getClassName(), s.config = e, this.forwardLayer = An(s), e.goBackwards = e.goBackwards !== true;
    const o = {};
    if (o.className = t.layer.getClassName(), o.config = e, this.backwardLayer = An(o), this.forwardLayer.name = "forward_" + this.forwardLayer.name, this.backwardLayer.name = "backward_" + this.backwardLayer.name, this.mergeMode = t.mergeMode === void 0 ? k3 : t.mergeMode, S3(this.mergeMode), t.weights)
      throw new yt("weights support is not implemented for Bidirectional layer yet.");
    this._stateful = t.layer.stateful, this.returnSequences = t.layer.returnSequences, this.returnState = t.layer.returnState, this.supportsMasking = true, this._trainable = true, this.inputSpec = t.layer.inputSpec, this.numConstants = null;
  }
  get trainable() {
    return this._trainable;
  }
  set trainable(t) {
    this._trainable = t, this.forwardLayer != null && (this.forwardLayer.trainable = t), this.backwardLayer != null && (this.backwardLayer.trainable = t);
  }
  getWeights() {
    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
  }
  setWeights(t) {
    const e = t.length, s = Math.floor(e / 2);
    this.forwardLayer.setWeights(t.slice(0, s)), this.backwardLayer.setWeights(t.slice(s));
  }
  computeOutputShape(t) {
    let e = this.forwardLayer.computeOutputShape(t);
    Array.isArray(e) && Array.isArray(e[0]) || (e = [e]), e = e;
    let s, o, r;
    return this.returnState && (r = e.slice(1)), s = e[0], s = s, this.mergeMode === "concat" ? (s[s.length - 1] *= 2, o = [s]) : this.mergeMode == null ? o = [s, s.slice()] : o = [s], this.returnState ? this.mergeMode == null ? o.concat(r).concat(r.slice()) : [s].concat(r).concat(r.slice()) : Xe(o);
  }
  apply(t, e) {
    let s = e == null ? null : e.initialState, o = e == null ? null : e.constants;
    e == null && (e = {});
    const r = Ly(t, s, o, this.numConstants);
    if (t = r.inputs, s = r.initialState, o = r.constants, Array.isArray(t) && (s = t.slice(1), t = t[0]), (s == null || s.length === 0) && o == null)
      return super.apply(t, e);
    const i6 = [], a = [];
    if (s != null) {
      const c = s.length;
      if (c % 2 > 0)
        throw new E("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
      e.initialState = s, i6.push(...s);
      const u = s.map((d) => new de({ shape: d.shape }));
      this.forwardLayer.stateSpec = u.slice(0, c / 2), this.backwardLayer.stateSpec = u.slice(c / 2), a.push(...u);
    }
    if (o != null)
      throw new yt("Support for constants in Bidirectional layers is not implemented yet.");
    const l = i6[0] instanceof os;
    for (const c of i6)
      if (c instanceof os !== l)
        throw new E("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
    if (l) {
      const c = [t].concat(i6), u = this.inputSpec.concat(a), d = this.inputSpec;
      this.inputSpec = u;
      const h = super.apply(c, e);
      return this.inputSpec = d, h;
    } else
      return super.apply(t, e);
  }
  call(t, e) {
    return D(() => {
      const s = e.initialState;
      let o, r;
      if (s == null)
        o = this.forwardLayer.call(t, e), r = this.backwardLayer.call(t, e);
      else {
        const l = s.slice(0, s.length / 2), c = s.slice(s.length / 2);
        o = this.forwardLayer.call(t, Object.assign(e, { initialState: l })), r = this.backwardLayer.call(t, Object.assign(e, { initialState: c }));
      }
      let i6;
      this.returnState && (Array.isArray(o) && (i6 = o.slice(1).concat(r.slice(1))), o = o[0], r = r[0]), this.returnSequences && (r = Lo(r, 1));
      let a;
      return this.mergeMode === "concat" ? a = xf([o, r]) : this.mergeMode === "sum" ? a = U(o, r) : this.mergeMode === "ave" ? a = G(0.5, U(o, r)) : this.mergeMode === "mul" ? a = G(o, r) : this.mergeMode == null && (a = [o, r]), this.returnState ? this.mergeMode == null ? a.concat(i6) : [a].concat(i6) : a;
    });
  }
  resetStates(t) {
    this.forwardLayer.resetStates(), this.backwardLayer.resetStates();
  }
  build(t) {
    wo(this.forwardLayer.name, () => {
      this.forwardLayer.build(t);
    }), wo(this.backwardLayer.name, () => {
      this.backwardLayer.build(t);
    }), this.built = true;
  }
  computeMask(t, e) {
    Array.isArray(e) && (e = e[0]);
    let s;
    if (this.returnSequences ? this.mergeMode == null ? s = [e, e] : s = e : this.mergeMode == null ? s = [null, null] : s = null, this.returnState) {
      const r = this.forwardLayer.states.map((i6) => null);
      return Array.isArray(s) ? s.concat(r).concat(r) : [s].concat(r).concat(r);
    } else
      return s;
  }
  get trainableWeights() {
    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
  }
  get nonTrainableWeights() {
    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
  }
  // TODO(cais): Implement constraints().
  setFastWeightInitDuringBuild(t) {
    super.setFastWeightInitDuringBuild(t), this.forwardLayer != null && this.forwardLayer.setFastWeightInitDuringBuild(t), this.backwardLayer != null && this.backwardLayer.setFastWeightInitDuringBuild(t);
  }
  getConfig() {
    const t = {
      mergeMode: this.mergeMode
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  /** @nocollapse */
  static fromConfig(t, e) {
    const s = An(e.layer);
    if (delete e.layer, e.numConstants != null)
      throw new yt("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");
    const o = e;
    return o.layer = s, new t(o);
  }
};
k1.className = "Bidirectional";
_(k1);
var T1 = class extends St {
  constructor(t) {
    super(t), this.scale = t.scale, t.offset ? this.offset = t.offset : this.offset = 0;
  }
  getConfig() {
    const t = {
      scale: this.scale,
      offset: this.offset
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  call(t, e) {
    return D(() => (t = mt(t), t.dtype !== "float32" && (t = es(t, "float32")), U(G(t, this.scale), this.offset)));
  }
};
T1.className = "Rescaling";
_(T1);
var { resizeBilinear: T3, cropAndResize: N3 } = fs;
var N1 = class extends St {
  constructor(t) {
    super(t), this.height = t.height, this.width = t.width;
  }
  centerCrop(t, e, s, o, r, i6, a, l) {
    return D(() => {
      let c, u = false;
      const d = e / i6, h = s / a, p = (o + e) / i6, f = (r + s) / a, m = [d, h, p, f], g = [];
      t.rank === 3 ? (u = true, c = Xn([t])) : c = t;
      for (let I = 0; I < c.shape[0]; I++)
        g.push(m);
      const b = $e(g, [g.length, 4]), x6 = di(0, g.length, 1, "int32"), y6 = N3(c, b, x6, [o, r], "nearest");
      return es(u ? mt(Mo(y6)) : y6, l);
    });
  }
  upsize(t, e, s, o) {
    return D(() => {
      const r = T3(t, [e, s]);
      return es(r, o);
    });
  }
  call(t, e) {
    return D(() => {
      const s = mt(t), o = s.dtype, r = s.shape, i6 = r[r.length - 3], a = r[r.length - 2];
      let l = 0;
      i6 !== this.height && (l = Math.floor((i6 - this.height) / 2));
      let c = 0;
      return a !== this.width && (c = Math.floor((a - this.width) / 2), c === 0 && (c = 1)), l >= 0 && c >= 0 ? this.centerCrop(s, l, c, this.height, this.width, i6, a, o) : this.upsize(t, this.height, this.width, o);
    });
  }
  getConfig() {
    const t = {
      height: this.height,
      width: this.width
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = t.length - 3, s = t.length - 2;
    return t[e] = this.height, t[s] = this.width, t;
  }
};
N1.className = "CenterCrop";
_(N1);
function R3(n, t, e, s) {
  let o = mt(n);
  if (o.dtype !== "int32" && (o = es(o, "int32")), t === "int")
    return o;
  const r = o.shape;
  if (o.rank === 0 && (o = Oe(o, -1)), t === "oneHot" && o.shape[o.shape.length - 1] !== 1 && (o = Oe(o, -1)), o.rank > 2)
    throw new E(`When outputMode is not int, maximum output rank is 2 Received outputMode ${t} and input shape ${r} which would result in output rank ${o.rank}.`);
  const i6 = ["multiHot", "oneHot"].includes(t), a = o;
  let l;
  if (typeof s < "u" && t === "count" ? l = Tm(a, s, e, i6) : l = Tm(a, [], e, i6), t !== "tfIdf")
    return l;
  if (s)
    return G(l, s);
  throw new E("When outputMode is 'tfIdf', weights must be provided.");
}
var R1 = class extends St {
  constructor(t) {
    super(t), this.numTokens = t.numTokens, t.outputMode ? this.outputMode = t.outputMode : this.outputMode = "multiHot";
  }
  getConfig() {
    const t = {
      numTokens: this.numTokens,
      outputMode: this.outputMode
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  computeOutputShape(t) {
    return t = Rt(t), t == null ? [this.numTokens] : this.outputMode === "oneHot" && t[t.length - 1] !== 1 ? (t.push(this.numTokens), t) : (t[t.length - 1] = this.numTokens, t);
  }
  call(t, e) {
    return D(() => {
      t = mt(t), t.dtype !== "int32" && (t = es(t, "int32"));
      let s;
      if (typeof e.countWeights < "u") {
        if (this.outputMode !== "count")
          throw new E(`countWeights is not used when outputMode !== count.
              Received countWeights=${e.countWeights}`);
        s = mt(e.countWeights);
      }
      const o = Pn(t), r = Il(t), i6 = rn(this.numTokens, o).bufferSync().get(0), a = Bo(r, 0).bufferSync().get(0);
      if (!(i6 && a))
        throw new E(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);
      return R3(t, this.outputMode, this.numTokens, s);
    });
  }
};
R1.className = "CategoryEncoding";
_(R1);
var $3 = ["bilinear", "nearest"];
var lg = new Set($3);
var $1 = class extends St {
  constructor(t) {
    if (super(t), this.height = t.height, this.width = t.width, t.interpolation)
      if (lg.has(t.interpolation))
        this.interpolation = t.interpolation;
      else
        throw new E(`Invalid interpolation parameter: ${t.interpolation} is not implemented`);
    else
      this.interpolation = "bilinear";
    this.cropToAspectRatio = !!t.cropToAspectRatio;
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = t[2];
    return [this.height, this.width, e];
  }
  getConfig() {
    const t = {
      height: this.height,
      width: this.width,
      interpolation: this.interpolation,
      cropToAspectRatio: this.cropToAspectRatio
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  call(t, e) {
    return D(() => {
      const s = [this.height, this.width];
      if (this.interpolation === "bilinear")
        return fs.resizeBilinear(t, s, !this.cropToAspectRatio);
      if (this.interpolation === "nearest")
        return fs.resizeNearestNeighbor(t, s, !this.cropToAspectRatio);
      throw new Error(`Interpolation is ${this.interpolation} but only ${[...lg]} are supported`);
    });
  }
};
$1.className = "Resizing";
_($1);
var G1 = class {
  constructor(t) {
    this.seed = t;
  }
  next() {
    if (this.seed !== void 0)
      return this.seed++;
  }
};
G1.className = "RandomSeed";
var E1 = class extends St {
  constructor(t) {
    super(t), this.randomGenerator = new G1(t.seed);
  }
  getConfig() {
    const t = {
      seed: this.randomGenerator.seed
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
};
E1.className = "BaseRandomLayer";
var G3 = ["bilinear", "nearest"];
var cg = new Set(G3);
var L1 = class extends E1 {
  constructor(t) {
    super(t);
    const { factor: e, interpolation: s = "bilinear" } = t;
    if (this.factor = e, Array.isArray(this.factor) && this.factor.length === 2)
      this.widthLower = this.factor[0], this.widthUpper = this.factor[1];
    else if (!Array.isArray(this.factor) && this.factor > 0)
      this.widthLower = -this.factor, this.widthUpper = this.factor;
    else
      throw new E(`Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`);
    if (this.widthLower < -1 || this.widthUpper < -1)
      throw new E(`factor must have values larger than -1. Got: ${this.factor}`);
    if (this.widthUpper < this.widthLower)
      throw new E(`factor cannot have upper bound less than lower bound.
        Got upper bound: ${this.widthUpper}.
        Got lower bound: ${this.widthLower}
      `);
    if (s)
      if (cg.has(s))
        this.interpolation = s;
      else
        throw new E(`Invalid interpolation parameter: ${s} is not implemented`);
  }
  getConfig() {
    const t = {
      factor: this.factor,
      interpolation: this.interpolation
    }, e = super.getConfig();
    return Object.assign(t, e), t;
  }
  computeOutputShape(t) {
    t = Rt(t);
    const e = t[2];
    return [this.imgHeight, -1, e];
  }
  call(t, e) {
    return D(() => {
      const s = mt(t);
      this.imgHeight = s.shape[s.shape.length - 3];
      const o = s.shape[s.shape.length - 2];
      this.widthFactor = Sa([1], 1 + this.widthLower, 1 + this.widthUpper, "float32", this.randomGenerator.next());
      let r = this.widthFactor.dataSync()[0] * o;
      r = Math.round(r);
      const i6 = [this.imgHeight, r];
      switch (this.interpolation) {
        case "bilinear":
          return fs.resizeBilinear(t, i6);
        case "nearest":
          return fs.resizeNearestNeighbor(t, i6);
        default:
          throw new Error(`Interpolation is ${this.interpolation}
          but only ${[...cg]} are supported`);
      }
    });
  }
};
L1.className = "RandomWidth";
_(L1);
var E3 = F();
E3.registerFlag("KEEP_INTERMEDIATE_TENSORS", () => false, (n) => {
  n && console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
});
var ug;
(function(n) {
  n[n.DT_INVALID = 0] = "DT_INVALID", n[n.DT_FLOAT = 1] = "DT_FLOAT", n[n.DT_DOUBLE = 2] = "DT_DOUBLE", n[n.DT_INT32 = 3] = "DT_INT32", n[n.DT_UINT8 = 4] = "DT_UINT8", n[n.DT_INT16 = 5] = "DT_INT16", n[n.DT_INT8 = 6] = "DT_INT8", n[n.DT_STRING = 7] = "DT_STRING", n[n.DT_COMPLEX64 = 8] = "DT_COMPLEX64", n[n.DT_INT64 = 9] = "DT_INT64", n[n.DT_BOOL = 10] = "DT_BOOL", n[n.DT_QINT8 = 11] = "DT_QINT8", n[n.DT_QUINT8 = 12] = "DT_QUINT8", n[n.DT_QINT32 = 13] = "DT_QINT32", n[n.DT_BFLOAT16 = 14] = "DT_BFLOAT16", n[n.DT_QINT16 = 15] = "DT_QINT16", n[n.DT_QUINT16 = 16] = "DT_QUINT16", n[n.DT_UINT16 = 17] = "DT_UINT16", n[n.DT_COMPLEX128 = 18] = "DT_COMPLEX128", n[n.DT_HALF = 19] = "DT_HALF", n[n.DT_RESOURCE = 20] = "DT_RESOURCE", n[n.DT_VARIANT = 21] = "DT_VARIANT", n[n.DT_UINT32 = 22] = "DT_UINT32", n[n.DT_UINT64 = 23] = "DT_UINT64", n[n.DT_FLOAT_REF = 101] = "DT_FLOAT_REF", n[n.DT_DOUBLE_REF = 102] = "DT_DOUBLE_REF", n[n.DT_INT32_REF = 103] = "DT_INT32_REF", n[n.DT_UINT8_REF = 104] = "DT_UINT8_REF", n[n.DT_INT16_REF = 105] = "DT_INT16_REF", n[n.DT_INT8_REF = 106] = "DT_INT8_REF", n[n.DT_STRING_REF = 107] = "DT_STRING_REF", n[n.DT_COMPLEX64_REF = 108] = "DT_COMPLEX64_REF", n[n.DT_INT64_REF = 109] = "DT_INT64_REF", n[n.DT_BOOL_REF = 110] = "DT_BOOL_REF", n[n.DT_QINT8_REF = 111] = "DT_QINT8_REF", n[n.DT_QUINT8_REF = 112] = "DT_QUINT8_REF", n[n.DT_QINT32_REF = 113] = "DT_QINT32_REF", n[n.DT_BFLOAT16_REF = 114] = "DT_BFLOAT16_REF", n[n.DT_QINT16_REF = 115] = "DT_QINT16_REF", n[n.DT_QUINT16_REF = 116] = "DT_QUINT16_REF", n[n.DT_UINT16_REF = 117] = "DT_UINT16_REF", n[n.DT_COMPLEX128_REF = 118] = "DT_COMPLEX128_REF", n[n.DT_HALF_REF = 119] = "DT_HALF_REF", n[n.DT_RESOURCE_REF = 120] = "DT_RESOURCE_REF", n[n.DT_VARIANT_REF = 121] = "DT_VARIANT_REF", n[n.DT_UINT32_REF = 122] = "DT_UINT32_REF", n[n.DT_UINT64_REF = 123] = "DT_UINT64_REF";
})(ug || (ug = {}));
var dg;
(function(n) {
  (function(t) {
    t[t.LEGACY = 0] = "LEGACY", t[t.V1 = 1] = "V1", t[t.V2 = 2] = "V2";
  })(n.CheckpointFormatVersion || (n.CheckpointFormatVersion = {}));
})(dg || (dg = {}));
function L3(n, t) {
  return Dl(n, t);
}
function Dl(n, t, e = /* @__PURE__ */ new Map(), s = /* @__PURE__ */ new Set()) {
  if (n == null)
    return null;
  if (typeof Blob == "function" && n instanceof Blob)
    return n.slice();
  if (s.has(n))
    throw new Error("Circular references are not supported.");
  if (e.has(n))
    return e.get(n);
  const o = t(n);
  if (o.recurse && o.value !== null)
    throw new Error("A deep map function may not return both a value and recurse=true.");
  if (o.recurse)
    if (yr(n)) {
      const r = Array.isArray(n) ? [] : {};
      s.add(n);
      for (const i6 in n) {
        const a = n[i6], l = Dl(a, t, e, s);
        r[i6] = l;
      }
      return s.delete(n), n.__proto__ && (r.__proto__ = n.__proto__), r;
    } else
      throw new Error(`Can't recurse into non-iterable type: ${n}`);
  else
    return e.set(n, o.value), o.value;
}
function M3(n, t = W1) {
  return M1(n, t);
}
function M1(n, t, e = /* @__PURE__ */ new Set()) {
  const s = n[0];
  if (e.has(s))
    throw new Error("Circular references are not supported.");
  const o = t(n);
  if (o.recurse && o.value !== null)
    throw new Error("A deep zip function may not return both a value and recurse=true.");
  if (o.recurse)
    if (yr(s)) {
      const r = Array.isArray(s) ? [] : {};
      e.add(s);
      for (const i6 in s) {
        const a = n.map((c) => c[i6]), l = M1(a, t, e);
        r[i6] = l;
      }
      return e.delete(s), r;
    } else
      throw new Error(`Can't recurse into non-iterable type: ${s}`);
  else
    return o.value;
}
function W1(n) {
  return n === null ? null : yr(n[0]) ? { value: null, recurse: true } : { value: n, recurse: false };
}
async function D1(n, t) {
  const e = /* @__PURE__ */ new Map();
  Dl(n, t, e);
  for (const o of Array.from(e.keys())) {
    const r = e.get(o);
    if (Ci(r)) {
      const i6 = await r;
      e.set(o, i6);
    }
  }
  return Dl(n, t, e);
}
function yr(n) {
  let t = false;
  if (F().get("IS_BROWSER"))
    t = n instanceof TextDecoder;
  else {
    const { StringDecoder: e } = require_string_decoder();
    t = n instanceof e;
  }
  return n != null && !ArrayBuffer.isView(n) && (Array.isArray(n) || typeof n == "object" && !(n instanceof Mt) && !(n instanceof Promise) && !t);
}
function W3(n) {
  return n == null || D3(n) || Array.isArray(n) || typeof n == "object" && n instanceof Mt || qe(n);
}
function D3(n) {
  return n === null || typeof n != "object" && typeof n != "function";
}
function F3(n) {
  return L3(n, V3);
}
function V3(n) {
  return n instanceof Mt ? { value: n.clone(), recurse: false } : yr(n) ? { value: null, recurse: true } : { value: n, recurse: false };
}
var F1 = class {
  /**
   * Constructs a `RingBuffer`.
   * @param capacity The number of items that the buffer can accomodate.
   */
  constructor(t) {
    if (this.capacity = t, this.begin = 0, this.end = 0, t == null)
      throw new RangeError("Can't create a ring buffer of unknown capacity.");
    if (t < 1)
      throw new RangeError("Can't create ring buffer of capacity < 1.");
    this.data = new Array(t), this.doubledCapacity = 2 * t;
  }
  /**
   * Map any index into the range 0 <= index < 2*capacity.
   */
  wrap(t) {
    for (; t < 0; )
      t += this.doubledCapacity;
    return t % this.doubledCapacity;
  }
  get(t) {
    if (t < 0)
      throw new RangeError("Can't get item at a negative index.");
    return this.data[t % this.capacity];
  }
  set(t, e) {
    if (t < 0)
      throw new RangeError("Can't set item at a negative index.");
    this.data[t % this.capacity] = e;
  }
  /**
   * Returns the current number of items in the buffer.
   */
  length() {
    let t = this.end - this.begin;
    return t < 0 && (t = this.doubledCapacity + t), t;
  }
  /**
   * Reports whether the buffer is full.
   * @returns true if the number of items in the buffer equals its capacity, and
   *   false otherwise.
   */
  isFull() {
    return this.length() === this.capacity;
  }
  /**
   * Reports whether the buffer is empty.
   * @returns true if the number of items in the buffer equals zero, and
   *   false otherwise.
   */
  isEmpty() {
    return this.length() === 0;
  }
  /**
   * Adds an item to the end of the buffer.
   */
  push(t) {
    if (this.isFull())
      throw new RangeError("Ring buffer is full.");
    this.set(this.end, t), this.end = this.wrap(this.end + 1);
  }
  /**
   * Adds many items to the end of the buffer, in order.
   */
  pushAll(t) {
    for (const e of t)
      this.push(e);
  }
  /**
   * Removes and returns the last item in the buffer.
   */
  pop() {
    if (this.isEmpty())
      throw new RangeError("Ring buffer is empty.");
    this.end = this.wrap(this.end - 1);
    const t = this.get(this.end);
    return this.set(this.end, void 0), t;
  }
  /**
   * Adds an item to the beginning of the buffer.
   */
  unshift(t) {
    if (this.isFull())
      throw new RangeError("Ring buffer is full.");
    this.begin = this.wrap(this.begin - 1), this.set(this.begin, t);
  }
  /**
   * Removes and returns the first item in the buffer.
   */
  shift() {
    if (this.isEmpty())
      throw new RangeError("Ring buffer is empty.");
    const t = this.get(this.begin);
    return this.set(this.begin, void 0), this.begin = this.wrap(this.begin + 1), t;
  }
  /**
   * Removes and returns a specific item in the buffer, and moves the last item
   * to the vacated slot.  This is useful for implementing a shuffling stream.
   * Note that this operation necessarily scrambles the original order.
   *
   * @param relativeIndex: the index of the item to remove, relative to the
   *   first item in the buffer (e.g., hiding the ring nature of the underlying
   *   storage).
   */
  shuffleExcise(t) {
    if (this.isEmpty())
      throw new RangeError("Ring buffer is empty.");
    const e = this.wrap(this.begin + t), s = this.get(e);
    return this.set(e, this.pop()), s;
  }
};
var xu = class _xu extends F1 {
  /**
   * Constructs a `GrowingRingBuffer`.
   */
  constructor() {
    super(_xu.INITIAL_CAPACITY);
  }
  isFull() {
    return false;
  }
  push(t) {
    super.isFull() && this.expand(), super.push(t);
  }
  unshift(t) {
    super.isFull() && this.expand(), super.unshift(t);
  }
  /**
   * Doubles the capacity of the buffer.
   */
  expand() {
    const t = this.capacity * 2, e = new Array(t), s = this.length();
    for (let o = 0; o < s; o++)
      e[o] = this.get(this.wrap(this.begin + o));
    this.data = e, this.capacity = t, this.doubledCapacity = 2 * this.capacity, this.begin = 0, this.end = s;
  }
};
xu.INITIAL_CAPACITY = 32;
function V1(n) {
  return new O3(n);
}
function z3(n) {
  return new X3(n);
}
function P3(n, t) {
  return new z1(n, t);
}
function A3(n, t = Fs.FAIL) {
  return new j3(n, t);
}
var He = class {
  /**
   * Collect all remaining elements of a bounded stream into an array.
   * Obviously this will succeed only for small streams that fit in memory.
   * Useful for testing.
   *
   * @returns A Promise for an array of stream elements, which will resolve
   *   when the stream is exhausted.
   */
  async toArray() {
    const t = [];
    let e = await this.next();
    for (; !e.done; )
      t.push(e.value), e = await this.next();
    return t;
  }
  /**
   * Collect all elements of this dataset into an array with prefetching 100
   * elements. This is useful for testing, because the prefetch changes the
   * order in which the Promises are resolved along the processing pipeline.
   * This may help expose bugs where results are dependent on the order of
   * Promise resolution rather than on the logical order of the stream (i.e.,
   * due to hidden mutable state).
   *
   * @returns A Promise for an array of stream elements, which will resolve
   *   when the stream is exhausted.
   */
  async toArrayForTest() {
    const t = this.prefetch(100), e = [];
    let s = await t.next();
    for (; !s.done; )
      e.push(s.value), s = await t.next();
    return e;
  }
  /**
   * Draw items from the stream until it is exhausted.
   *
   * This can be useful when the stream has side effects but no output.  In
   * that case, calling this function guarantees that the stream will be
   * fully processed.
   */
  async resolveFully() {
    let t = await this.next();
    for (; !t.done; )
      t = await this.next();
  }
  /**
   * Draw items from the stream until it is exhausted, or a predicate fails.
   *
   * This can be useful when the stream has side effects but no output.  In
   * that case, calling this function guarantees that the stream will be
   * fully processed.
   */
  async resolveWhile(t) {
    let e = await this.next(), s = t(e.value);
    for (; !e.done && s; )
      e = await this.next(), s = t(e.value);
  }
  /**
   * Handles errors thrown on this stream using a provided handler function.
   *
   * @param handler A function that handles any `Error` thrown during a `next()`
   *   call and returns true if the stream should continue (dropping the failed
   *   call) or false if the stream should quietly terminate.  If the handler
   *   itself throws (or rethrows) an `Error`, that will be propagated.
   *
   * @returns A `LazyIterator` of elements passed through from upstream,
   *   possibly filtering or terminating on upstream `next()` calls that
   *   throw an `Error`.
   */
  handleErrors(t) {
    return new Y3(this, t);
  }
  // TODO(soergel): Implement reduce() etc.
  /**
   * Filters this stream according to `predicate`.
   *
   * @param predicate A function mapping a stream element to a boolean or a
   * `Promise` for one.
   *
   * @returns A `LazyIterator` of elements for which the predicate was true.
   */
  filter(t) {
    return new _3(this, t);
  }
  /**
   * Maps this stream through a 1-to-1 transform.
   *
   * @param transform A function mapping a stream element to a transformed
   *   element.
   *
   * @returns A `LazyIterator` of transformed elements.
   */
  map(t) {
    return new U3(this, t);
  }
  /**
   * Maps this stream through an async 1-to-1 transform.
   *
   * @param transform A function mapping a stream element to a `Promise` for a
   *   transformed stream element.
   *
   * @returns A `LazyIterator` of transformed elements.
   */
  mapAsync(t) {
    return new hg(this, t);
  }
  /**
   * Maps this stream through a 1-to-1 transform, forcing serial execution.
   *
   * @param transform A function mapping a stream element to a transformed
   *   element.
   *
   * @returns A `LazyIterator` of transformed elements.
   */
  serialMapAsync(t) {
    return new hg(this, t).serial();
  }
  /**
   * Maps this stream through a 1-to-many transform.
   *
   * @param transform A function mapping a stream element to an array of
   *   transformed elements.
   *
   * @returns A `DataStream` of transformed elements.
   */
  flatmap(t) {
    return new J3(this, t);
  }
  /**
   * Apply a function to every element of the stream.
   *
   * @param f A function to apply to each stream element.
   */
  async forEachAsync(t) {
    return this.map(t).resolveFully();
  }
  /**
   * Apply a function to every element of the stream, forcing serial execution.
   *
   * @param f A function to apply to each stream element.  Should return 'true'
   *   to indicate that the stream should continue, or 'false' to cause it to
   *   terminate.
   */
  async serialForEach(t) {
    return this.serialMapAsync(t).resolveWhile((e) => e === true);
  }
  /**
   * Groups elements into batches, represented as arrays of elements.
   *
   * We can think of the elements of this iterator as 'rows' (even if they are
   * nested structures).  By the same token, consecutive values for a given
   * key within the elements form a 'column'.  This matches the usual sense of
   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
   *
   * Thus, "Row-major" means that the resulting batch is simply a collection of
   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major
   * form, which is needed for vectorized computation.
   *
   * @param batchSize The number of elements desired per batch.
   * @param smallLastBatch Whether to emit the final batch when it has fewer
   *   than batchSize elements. Default true.
   * @returns A `LazyIterator` of batches of elements, represented as arrays
   *   of the original element type.
   */
  rowMajorBatch(t, e = true) {
    return new H3(this, t, e);
  }
  /**
   * Groups elements into batches, represented in column-major form.
   *
   * We can think of the elements of this iterator as 'rows' (even if they are
   * nested structures).  By the same token, consecutive values for a given
   * key within the elements form a 'column'.  This matches the usual sense of
   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
   *
   * Thus, "column-major" means that the resulting batch is a (potentially
   * nested) structure representing the columns.  Each column entry, then,
   * contains a collection of the values found in that column for a range of
   * input elements.  This representation allows for vectorized computation, in
   * contrast to the row-major form.
   *
   * The inputs should all have the same nested structure (i.e., of arrays and
   * dicts).  The result is a single object with the same nested structure,
   * where the leaves are arrays collecting the values of the inputs at that
   * location (or, optionally, the result of a custom function applied to those
   * arrays).
   *
   * @param batchSize The number of elements desired per batch.
   * @param smallLastBatch Whether to emit the final batch when it has fewer
   *   than batchSize elements. Default true.
   * @param zipFn: (optional) A function that expects an array of elements at a
   *   single node of the object tree, and returns a `DeepMapResult`.  The
   *   `DeepMapResult` either provides a result value for that node (i.e.,
   *   representing the subtree), or indicates that the node should be processed
   *   recursively.  The default zipFn recurses as far as possible and places
   *   arrays at the leaves.
   * @returns A `LazyIterator` of batches of elements, represented as an object
   *   with collections at the leaves.
   */
  columnMajorBatch(t, e = true, s = W1) {
    return this.rowMajorBatch(t, e).map((r) => M3(r, s));
  }
  /**
   * Concatenate this `LazyIterator` with another.
   *
   * @param iterator A `LazyIterator` to be concatenated onto this one.
   * @param baseErrorHandler An optional function that can intercept `Error`s
   *   raised during a `next()` call on the base stream.  This function can
   *   decide whether the error should be propagated, whether the error should
   *   be ignored, or whether the base stream should be terminated.
   * @returns A `LazyIterator`.
   */
  concatenate(t, e) {
    return new z1(V1([this, t]), e);
  }
  /**
   * Limits this stream to return at most `count` items.
   *
   * @param count The maximum number of items to provide from the stream. If
   * a negative or undefined value is given, the entire stream is returned
   *   unaltered.
   */
  take(t) {
    return t < 0 || t == null ? this : new B3(this, t);
  }
  /**
   * Skips the first `count` items in this stream.
   *
   * @param count The number of items to skip.  If a negative or undefined
   * value is given, the entire stream is returned unaltered.
   */
  skip(t) {
    return t < 0 || t == null ? this : new Z3(this, t);
  }
  /**
   * Prefetch the first `bufferSize` items in this stream.
   *
   * Note this prefetches Promises, but makes no guarantees about when those
   * Promises resolve.
   *
   * @param bufferSize: An integer specifying the number of elements to be
   *   prefetched.
   */
  prefetch(t) {
    return new P1(this, t);
  }
  // TODO(soergel): deep sharded shuffle, where supported
  /**
   * Randomly shuffles the elements of this stream.
   *
   * @param bufferSize: An integer specifying the number of elements from
   * this stream from which the new stream will sample.
   * @param seed: (Optional.) An integer specifying the random seed that
   * will be used to create the distribution.
   */
  shuffle(t, e) {
    return new q3(this, t, e);
  }
  /**
   * Force an iterator to execute serially: each next() call will await the
   * prior one, so that they cannot execute concurrently.
   */
  serial() {
    return new K3(this);
  }
};
var O3 = class extends He {
  constructor(t) {
    super(), this.items = t, this.trav = 0;
  }
  summary() {
    return `Array of ${this.items.length} items`;
  }
  async next() {
    if (this.trav >= this.items.length)
      return { value: null, done: true };
    const t = this.items[this.trav];
    return this.trav++, { value: F3(t), done: false };
  }
};
var X3 = class extends He {
  constructor(t) {
    super(), this.nextFn = t;
  }
  summary() {
    return "Function call";
  }
  async next() {
    try {
      return this.nextFn();
    } catch (t) {
      throw t.message = `Error thrown while iterating through a dataset: ${t.message}`, t;
    }
  }
};
var K3 = class extends He {
  constructor(t) {
    super(), this.upstream = t, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Serial`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    return this.upstream.next();
  }
};
var Z3 = class extends He {
  constructor(t, e) {
    super(), this.upstream = t, this.maxCount = e, this.count = 0, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Skip`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; this.count++ < this.maxCount; ) {
      const t = await this.upstream.next();
      if (t.done)
        return t;
      xt(t.value);
    }
    return this.upstream.next();
  }
};
var B3 = class extends He {
  constructor(t, e) {
    super(), this.upstream = t, this.maxCount = e, this.count = 0;
  }
  summary() {
    return `${this.upstream.summary()} -> Take`;
  }
  async next() {
    return this.count++ >= this.maxCount ? { value: null, done: true } : this.upstream.next();
  }
};
var H3 = class extends He {
  constructor(t, e, s = true) {
    super(), this.upstream = t, this.batchSize = e, this.enableSmallLastBatch = s, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> RowMajorBatch`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    const t = [];
    for (; t.length < this.batchSize; ) {
      const e = await this.upstream.next();
      if (e.done)
        return this.enableSmallLastBatch && t.length > 0 ? { value: t, done: false } : { value: null, done: true };
      t.push(e.value);
    }
    return { value: t, done: false };
  }
};
var _3 = class extends He {
  constructor(t, e) {
    super(), this.upstream = t, this.predicate = e, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Filter`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; ; ) {
      const t = await this.upstream.next();
      if (t.done || this.predicate(t.value))
        return t;
      xt(t.value);
    }
  }
};
var U3 = class extends He {
  constructor(t, e) {
    super(), this.upstream = t, this.transform = e;
  }
  summary() {
    return `${this.upstream.summary()} -> Map`;
  }
  async next() {
    const t = await this.upstream.next();
    if (t.done)
      return { value: null, done: true };
    const e = bs(t.value), s = this.transform(t.value), o = bs(s);
    for (const r of e)
      Yc(r, o) || r.dispose();
    return { value: s, done: false };
  }
};
var Y3 = class extends He {
  constructor(t, e) {
    super(), this.upstream = t, this.handler = e, this.count = 0, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> handleErrors`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; ; )
      try {
        return await this.upstream.next();
      } catch (t) {
        if (!this.handler(t))
          return { value: null, done: true };
      }
  }
};
var hg = class extends He {
  constructor(t, e) {
    super(), this.upstream = t, this.transform = e;
  }
  summary() {
    return `${this.upstream.summary()} -> AsyncMap`;
  }
  async next() {
    const t = await this.upstream.next();
    if (t.done)
      return { value: null, done: true };
    const e = bs(t.value), s = await this.transform(t.value), o = bs(s);
    for (const r of e)
      Yc(r, o) || r.dispose();
    return { value: s, done: false };
  }
};
var Q3 = class extends He {
  constructor() {
    super(), this.outputQueue = new xu(), this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; this.outputQueue.length() === 0; )
      if (!await this.pump())
        return { value: null, done: true };
    return { value: this.outputQueue.shift(), done: false };
  }
};
var J3 = class extends Q3 {
  constructor(t, e) {
    super(), this.upstream = t, this.transform = e;
  }
  summary() {
    return `${this.upstream.summary()} -> Flatmap`;
  }
  async pump() {
    const t = await this.upstream.next();
    if (t.done)
      return false;
    const e = bs(t.value), s = this.transform(t.value), o = bs(s);
    this.outputQueue.pushAll(s);
    for (const r of e)
      Yc(r, o) || r.dispose();
    return true;
  }
};
var z1 = class extends He {
  constructor(t, e) {
    super(), this.baseErrorHandler = e, this.lastRead = null, this.iterator = null, this.moreIterators = t;
  }
  summary() {
    return "TODO: fill in upstream of chained summaries -> Chained";
  }
  async next() {
    return this.lastRead = this.readFromChain(this.lastRead), this.lastRead;
  }
  async readFromChain(t) {
    if (await t, this.iterator == null) {
      const s = await this.moreIterators.next();
      if (s.done)
        return { value: null, done: true };
      this.iterator = s.value, this.baseErrorHandler != null && (this.iterator = this.iterator.handleErrors(this.baseErrorHandler));
    }
    const e = await this.iterator.next();
    return e.done ? (this.iterator = null, this.readFromChain(t)) : e;
  }
};
var Fs;
(function(n) {
  n[n.FAIL = 0] = "FAIL", n[n.SHORTEST = 1] = "SHORTEST", n[n.LONGEST = 2] = "LONGEST";
})(Fs || (Fs = {}));
var j3 = class extends He {
  constructor(t, e = Fs.FAIL) {
    super(), this.iterators = t, this.mismatchMode = e, this.count = 0, this.currentPromise = null;
  }
  summary() {
    return "{TODO: fill in upstream of zip summaries} -> Zip";
  }
  async nextState(t) {
    await t;
    let e = 0, s = 0;
    function o(i6) {
      return i6 instanceof He ? {
        value: i6.next().then((l) => (e++, l.done && s++, l.value)),
        recurse: false
      } : { value: null, recurse: true };
    }
    const r = await D1(this.iterators, o);
    if (e === s)
      return { value: null, done: true };
    if (s > 0)
      switch (this.mismatchMode) {
        case Fs.FAIL:
          throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);
        case Fs.SHORTEST:
          return { value: null, done: true };
        case Fs.LONGEST:
      }
    return this.count++, { value: r, done: false };
  }
  async next() {
    return this.currentPromise = this.nextState(this.currentPromise), this.currentPromise;
  }
};
var P1 = class extends He {
  constructor(t, e) {
    super(), this.upstream = t, this.bufferSize = e, this.buffer = new F1(e);
  }
  summary() {
    return `${this.upstream.summary()} -> Prefetch`;
  }
  /**
   * Refill the prefetch buffer.  Returns only after the buffer is full, or
   * the upstream source is exhausted.
   */
  refill() {
    for (; !this.buffer.isFull(); ) {
      const t = this.upstream.next();
      this.buffer.push(t);
    }
  }
  next() {
    return this.refill(), this.buffer.shift();
  }
};
var q3 = class extends P1 {
  constructor(t, e, s) {
    super(t, e), this.upstream = t, this.windowSize = e, this.upstreamExhausted = false, this.random = Nr.alea(s || Ie().toString()), this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  randomInt(t) {
    return Math.floor(this.random() * t);
  }
  chooseIndex() {
    return this.randomInt(this.buffer.length());
  }
  async serialNext() {
    for (this.upstreamExhausted || this.refill(); !this.buffer.isEmpty(); ) {
      const t = this.chooseIndex(), e = await this.buffer.shuffleExcise(t);
      if (e.done)
        this.upstreamExhausted = true;
      else
        return this.refill(), e;
    }
    return { value: null, done: true };
  }
};
var zf = class {
  constructor() {
    this.size = null;
  }
  // TODO(soergel): Make Datasets report whether repeated iterator() calls
  // produce the same result (e.g., reading from a file) or different results
  // (e.g., from the webcam).  Currently we don't make this distinction but it
  // could be important for the user to know.
  // abstract isDeterministic(): boolean;
  /**
   * Groups elements into batches.
   *
   * It is assumed that each of the incoming dataset elements has the same
   * structure -- i.e. the same set of keys at each location in an object
   * hierarchy.  For each key, the resulting `Dataset` provides a batched
   * element collecting all of the incoming values for that key.
   *
   *  * Incoming primitives are grouped into a 1-D Tensor.
   *  * Incoming Tensors are grouped into a new Tensor where the 0th axis is
   *    the batch dimension.
   *  * Incoming arrays are converted to Tensor and then batched.
   *  * A nested array is interpreted as an n-D Tensor, so the batched result
   *    has n+1 dimensions.
   *  * An array that cannot be converted to Tensor produces an error.
   *
   * If an array should not be batched as a unit, it should first be converted
   * to an object with integer keys.
   *
   * Here are a few examples:
   *
   * Batch a dataset of numbers:
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8]).batch(4);
   * await a.forEachAsync(e => e.print());
   * ```
   *
   * Batch a dataset of arrays:
   * ```js
   * const b = tf.data.array([[1], [2], [3], [4], [5], [6], [7], [8]]).batch(4);
   * await b.forEachAsync(e => e.print());
   * ```
   *
   * Batch a dataset of objects:
   * ```js
   * const c = tf.data.array([{a: 1, b: 11}, {a: 2, b: 12}, {a: 3, b: 13},
   *   {a: 4, b: 14}, {a: 5, b: 15}, {a: 6, b: 16}, {a: 7, b: 17},
   *   {a: 8, b: 18}]).batch(4);
   * await c.forEachAsync(e => {
   *   console.log('{');
   *   for(var key in e) {
   *     console.log(key+':');
   *     e[key].print();
   *   }
   *   console.log('}');
   * })
   * ```
   *
   * @param batchSize The number of elements desired per batch.
   * @param smallLastBatch Whether to emit the final batch when it has fewer
   *   than batchSize elements. Default true.
   * @returns A `Dataset`, from which a stream of batches can be obtained.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  batch(t, e = true) {
    const s = this;
    C(t > 0, () => `batchSize needs to be positive, but it is
      ${t}`);
    let o;
    return this.size === 1 / 0 || this.size == null ? o = this.size : e ? o = Math.ceil(this.size / t) : o = Math.floor(this.size / t), yn(async () => (await s.iterator()).columnMajorBatch(t, e, tM), o);
  }
  /**
   * Concatenates this `Dataset` with another.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]);
   * const b = tf.data.array([4, 5, 6]);
   * const c = a.concatenate(b);
   * await c.forEachAsync(e => console.log(e));
   * ```
   *
   * @param dataset A `Dataset` to be concatenated onto this one.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  concatenate(t) {
    const e = this;
    let s;
    return this.size === 1 / 0 || t.size === 1 / 0 ? s = 1 / 0 : this.size != null && t.size != null ? s = this.size + t.size : s = null, yn(async () => (await e.iterator()).concatenate(await t.iterator()), s);
  }
  /**
   * Filters this dataset according to `predicate`.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
   *   .filter(x => x%2 === 0);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param predicate A function mapping a dataset element to a boolean or a
   * `Promise` for one.
   *
   * @returns A `Dataset` of elements for which the predicate was true.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  filter(t) {
    const e = this;
    let s;
    return this.size === 1 / 0 ? s = 1 / 0 : s = null, yn(async () => (await e.iterator()).filter((o) => D(() => t(o))), s);
  }
  /**
   * Apply a function to every element of the dataset.
   *
   * After the function is applied to a dataset element, any Tensors contained
   * within that element are disposed.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param f A function to apply to each dataset element.
   * @returns A `Promise` that resolves after all elements have been processed.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  async forEachAsync(t) {
    return (await this.iterator()).forEachAsync(t);
  }
  /**
   * Maps this dataset through a 1-to-1 transform.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]).map(x => x*x);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param transform A function mapping a dataset element to a transformed
   *   dataset element.
   *
   * @returns A `Dataset` of transformed elements.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  map(t) {
    const e = this;
    return yn(async () => (await e.iterator()).map((s) => D(() => t(s))), this.size);
  }
  /**
   * Maps this dataset through an async 1-to-1 transform.
   *
   * ```js
   * const a =
   *  tf.data.array([1, 2, 3]).mapAsync(x => new Promise(function(resolve){
   *    setTimeout(() => {
   *      resolve(x * x);
   *    }, Math.random()*1000 + 500);
   *  }));
   * console.log(await a.toArray());
   * ```
   *
   * @param transform A function mapping a dataset element to a `Promise` for a
   *   transformed dataset element.  This transform is responsible for disposing
   *   any intermediate `Tensor`s, i.e. by wrapping its computation in
   *   `tf.tidy()`; that cannot be automated here (as it is in the synchronous
   *   `map()` case).
   *
   * @returns A `Dataset` of transformed elements.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  mapAsync(t) {
    const e = this;
    return yn(async () => (await e.iterator()).mapAsync(t), this.size);
  }
  /**
   *  Creates a `Dataset` that prefetches elements from this dataset.
   *
   * @param bufferSize: An integer specifying the number of elements to be
   *   prefetched.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  prefetch(t) {
    if (t == null)
      throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
    const e = this;
    return yn(async () => (await e.iterator()).prefetch(t), this.size);
  }
  /**
   * Repeats this dataset `count` times.
   *
   * NOTE: If this dataset is a function of global state (e.g. a random number
   * generator), then different repetitions may produce different elements.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3]).repeat(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param count: (Optional) An integer, representing the number of times
   *   the dataset should be repeated. The default behavior (if `count` is
   *   `undefined` or negative) is for the dataset be repeated indefinitely.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  repeat(t) {
    const e = this;
    let s;
    return this.size != null && t > 0 ? s = this.size * t : t === 0 ? s = 0 : this.size != null && (t === void 0 || t < 0) ? s = 1 / 0 : s = null, yn(async () => {
      const o = z3(async () => ({ value: await e.iterator(), done: false }));
      return P3(o.take(t));
    }, s);
  }
  /**
   * Creates a `Dataset` that skips `count` initial elements from this dataset.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).skip(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param count: The number of elements of this dataset that should be skipped
   *   to form the new dataset.  If `count` is greater than the size of this
   *   dataset, the new dataset will contain no elements.  If `count`
   *   is `undefined` or negative, skips the entire dataset.
   *
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  skip(t) {
    const e = this;
    let s;
    return this.size != null && t >= 0 && this.size >= t ? s = this.size - t : this.size != null && (this.size < t || t === void 0 || t < 0) ? s = 0 : s = null, yn(async () => (await e.iterator()).skip(t), s);
  }
  /**
   * Pseudorandomly shuffles the elements of this dataset. This is done in a
   * streaming manner, by sampling from a given number of prefetched elements.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).shuffle(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param bufferSize: An integer specifying the number of elements from this
   *   dataset from which the new dataset will sample.
   * @param seed: (Optional) An integer specifying the random seed that will
   *   be used to create the distribution.
   * @param reshuffleEachIteration: (Optional) A boolean, which if true
   *   indicates that the dataset should be pseudorandomly reshuffled each time
   *   it is iterated over. If false, elements will be returned in the same
   *   shuffled order on each iteration. (Defaults to `true`.)
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  shuffle(t, e, s = true) {
    if (t == null || t < 0)
      throw this.size == null ? new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.") : new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);
    const o = this, r = Nr.alea(e || Ie().toString());
    return yn(async () => {
      let i6 = r.int32();
      return s && (i6 += r.int32()), (await o.iterator()).shuffle(t, i6.toString());
    }, this.size);
  }
  /**
   * Creates a `Dataset` with at most `count` initial elements from this
   * dataset.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).take(3);
   * await a.forEachAsync(e => console.log(e));
   * ```
   *
   * @param count: The number of elements of this dataset that should be taken
   *   to form the new dataset.  If `count` is `undefined` or negative, or if
   *   `count` is greater than the size of this dataset, the new dataset will
   *   contain all elements of this dataset.
   * @returns A `Dataset`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  take(t) {
    const e = this;
    let s;
    return this.size != null && this.size > t ? s = t : this.size != null && this.size <= t ? s = this.size : s = null, yn(async () => (await e.iterator()).take(t), s);
  }
  /**
   * Collect all elements of this dataset into an array.
   *
   * Obviously this will succeed only for small datasets that fit in memory.
   * Useful for testing and generally should be avoided if possible.
   *
   * ```js
   * const a = tf.data.array([1, 2, 3, 4, 5, 6]);
   * console.log(await a.toArray());
   * ```
   *
   * @returns A Promise for an array of elements, which will resolve
   *   when a new stream has been obtained and fully consumed.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  async toArray() {
    if (this.size === 1 / 0)
      throw new Error("Can not convert infinite data stream to array.");
    return (await this.iterator()).toArray();
  }
  /**
   * Collect all elements of this dataset into an array with prefetching 100
   * elements. This is useful for testing, because the prefetch changes the
   * order in which the Promises are resolved along the processing pipeline.
   * This may help expose bugs where results are dependent on the order of
   * Promise resolution rather than on the logical order of the stream (i.e.,
   * due to hidden mutable state).
   *
   * @returns A Promise for an array of elements, which will resolve
   *   when a new stream has been obtained and fully consumed.
   */
  async toArrayForTest() {
    if (this.size === 1 / 0)
      throw new Error("Can not convert infinite data stream to array.");
    return (await this.iterator()).toArrayForTest();
  }
};
zf.MAX_BUFFER_SIZE = 1e4;
function yn(n, t = null) {
  return new class extends zf {
    constructor() {
      super(...arguments), this.size = t;
    }
    /*
     * Provide a new stream of elements.  Note this will also start new streams
     * from any underlying `Dataset`s.
     */
    async iterator() {
      return n();
    }
  }();
}
function BQ(n) {
  return yn(async () => V1(n), n.length);
}
function HQ(n) {
  if (!yr(n))
    throw new Error("The argument to zip() must be an object or array.");
  let t;
  if (Array.isArray(n))
    for (let e = 0; e < n.length; e++)
      t = t == null ? n[e].size : Math.min(t, n[e].size);
  else if (n instanceof Object)
    for (const e in n)
      t = t == null ? n[e].size : Math.min(t, n[e].size);
  return yn(async () => {
    const e = await D1(n, (s) => {
      if (s instanceof zf)
        return { value: s.iterator(), recurse: false };
      if (yr(s))
        return { value: null, recurse: true };
      throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.");
    });
    return A3(e, Fs.SHORTEST);
  }, t);
}
function tM(n) {
  if (n === null)
    return null;
  const t = n[0];
  return W3(t) ? { value: eM(n), recurse: false } : { value: null, recurse: true };
}
function eM(n) {
  if (n.length === 0)
    throw new Error("Can't make a batch of zero elements.");
  return n[0] instanceof Mt ? Xn(n) : $e(n);
}
function lt(n, t) {
  Array.isArray(n) || (n = [n]), n.forEach((e) => {
    e != null && C(e.dtype !== "complex64", () => `${t} does not support complex64 tensors in the CPU backend.`);
  });
}
var nM = C0;
var yu = class _yu extends _d {
  nextDataId() {
    return _yu.nextDataId++;
  }
  constructor() {
    super(), this.blockSize = 48, this.firstUse = true, this.data = new qg(this, Ot());
  }
  write(t, e, s) {
    this.firstUse && (this.firstUse = false, F().get("IS_NODE") && ln(`
============================
Hi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. 
============================`));
    const o = { id: this.nextDataId() };
    return this.data.set(o, { values: t, dtype: s, refCount: 1 }), o;
  }
  /**
   * Create a data bucket in cpu backend.
   * @param shape Shape of the `TensorInfo`.
   * @param dtype DType of the `TensorInfo`.
   * @param values The value of the `TensorInfo` stored as a flattened array.
   */
  makeTensorInfo(t, e, s) {
    let o;
    if (e === "string" && s != null && s.length > 0 && vr(s[0])) {
      const r = s.map((i6) => ms(i6));
      o = this.write(r, t, e);
    } else
      o = this.write(s, t, e);
    return { dataId: o, shape: t, dtype: e };
  }
  /** Return refCount of a `TensorData`. */
  refCount(t) {
    return this.data.has(t) ? this.data.get(t).refCount : 0;
  }
  /** Increase refCount of a `TensorData`. */
  incRef(t) {
    const e = this.data.get(t);
    e.refCount++;
  }
  /** Decrease refCount of a `TensorData`. */
  decRef(t) {
    if (this.data.has(t)) {
      const e = this.data.get(t);
      e.refCount--;
    }
  }
  move(t, e, s, o, r) {
    this.data.set(t, { values: e, dtype: o, refCount: r });
  }
  numDataIds() {
    return this.data.numDataIds();
  }
  async read(t) {
    return this.readSync(t);
  }
  readSync(t) {
    const { dtype: e, complexTensorInfos: s } = this.data.get(t);
    if (e === "complex64") {
      const o = this.readSync(s.real.dataId), r = this.readSync(s.imag.dataId);
      return xs(o, r);
    }
    return ib(this.data.get(t).values, e);
  }
  bufferSync(t) {
    const e = this.readSync(t.dataId);
    if (t.dtype === "string")
      try {
        const s = e.map((o) => gs(o));
        return vt(t.shape, t.dtype, s);
      } catch {
        throw new Error("Failed to decode encoded string bytes into utf-8");
      }
    return vt(t.shape, t.dtype, e);
  }
  makeOutput(t, e, s) {
    return Ot().makeTensorFromTensorInfo(this.makeTensorInfo(e, s, t), this);
  }
  /**
   * Dispose the memory if the dataId has 0 refCount. Return true if the memory
   * is released or memory is not managed in this backend, false if memory is
   * not cleared.
   * @param dataId
   * @oaram force Optional, remove the data regardless of refCount
   */
  disposeData(t, e = false) {
    if (this.data.has(t)) {
      if (this.data.get(t).refCount--, !e && this.data.get(t).refCount > 0)
        return false;
      const { complexTensorInfos: s } = this.data.get(t);
      s != null && (this.disposeData(s.real.dataId, true), this.disposeData(s.imag.dataId, true)), this.data.delete(t);
    }
    return true;
  }
  disposeIntermediateTensorInfo(t) {
    this.disposeData(t.dataId);
  }
  async time(t) {
    const e = Ie();
    return t(), { kernelMs: Ie() - e };
  }
  memory() {
    return {
      // Unreliable due to automatic gc. The numbers above are cumulative.
      unreliable: true,
      reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
    };
  }
  where(t) {
    lt([t], "where");
    const e = this.readSync(t.dataId);
    return nM(t.shape, e);
  }
  dispose() {
  }
  floatPrecision() {
    return 32;
  }
  /** Returns the smallest representable number.  */
  epsilon() {
    return super.epsilon();
  }
};
yu.nextDataId = 0;
function A1(n) {
  const t = new Float32Array(n.length);
  for (let e = 0; e < n.length; ++e)
    t[e] = Math.abs(n[e]);
  return t;
}
var sM = (n) => {
  const { x: t } = n.inputs, e = n.backend;
  lt(t, "abs");
  let s = new Float32Array(X(t.shape));
  const o = e.data.get(t.dataId).values;
  return s = A1(o), e.makeOutput(s, t.shape, t.dtype);
};
var oM = {
  kernelName: Ul,
  backendName: "cpu",
  kernelFunc: sM
};
function le(n) {
  return (t, e, s, o, r) => {
    const i6 = bt(t, e), a = i6.length, l = dt(i6), c = X(i6), u = Se(r, c), d = t.length, h = e.length, p = dt(t), f = dt(e), m = Go(t, i6), g = Go(e, i6);
    if (m.length + g.length === 0)
      for (let b = 0; b < u.length; ++b)
        u[b] = n(s[b % s.length], o[b % o.length]);
    else
      for (let b = 0; b < u.length; ++b) {
        const x6 = Xo(b, a, l), w = x6.slice(-d);
        m.forEach((k6) => w[k6] = 0);
        const y6 = zn(w, d, p), I = x6.slice(-h);
        g.forEach((k6) => I[k6] = 0);
        const v = zn(I, h, f);
        u[b] = n(s[y6], o[v]);
      }
    return [u, i6];
  };
}
function Je(n) {
  const { inputs: t, backend: e } = n, { real: s, imag: o } = t, r = e.data.get(s.dataId).values, i6 = e.data.get(o.dataId).values, a = e.makeTensorInfo(s.shape, "complex64"), l = e.data.get(a.dataId);
  return l.complexTensorInfos = {
    real: e.makeTensorInfo(s.shape, "float32", r),
    imag: e.makeTensorInfo(o.shape, "float32", i6)
  }, a;
}
var rM = {
  kernelName: ih,
  backendName: "cpu",
  kernelFunc: Je
};
function Fl(n, t, e = "float32") {
  if (e === "complex64") {
    const o = Fl(n, t, "float32"), r = Fl(n, t, "float32");
    return Je({ inputs: { real: o, imag: r }, backend: n });
  }
  const s = ke(X(t), e);
  return n.makeTensorInfo(t, e, s);
}
function rs(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  return e.incRef(s.dataId), { dataId: s.dataId, shape: s.shape, dtype: s.dtype };
}
var iM = {
  kernelName: Ki,
  backendName: "cpu",
  kernelFunc: rs
};
function Do(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.data.get(s.dataId).complexTensorInfos.real, r = e.data.get(o.dataId).values;
  return e.makeTensorInfo(o.shape, o.dtype, r);
}
var aM = {
  kernelName: Eh,
  backendName: "cpu",
  kernelFunc: Do
};
function O1(n, t, e, s) {
  if (s === "int32") {
    const o = Int32Array.from(n);
    return [t, "int32", o];
  }
  if (s === "bool") {
    const o = Qs([0], e), [r, i6] = le((a, l) => a !== l ? 1 : 0)(t, [], n, o, "bool");
    return [i6, "bool", r];
  }
  throw new Error(`Error in Cast: failed to cast ${e} to ${s}`);
}
function Ys(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dtype: r } = s;
  if (r === "complex64") {
    if (o.dtype === "complex64")
      return rs({ inputs: { x: o }, backend: e });
    const u = Fl(e, o.shape, o.dtype), d = Ys({ inputs: { x: o }, backend: e, attrs: { dtype: "float32" } }), h = Je({ inputs: { real: d, imag: u }, backend: e });
    return e.disposeIntermediateTensorInfo(u), e.disposeIntermediateTensorInfo(d), h;
  }
  if (o.dtype === "complex64") {
    const u = Do({ inputs: { input: o }, backend: e }), d = Ys({ inputs: { x: u }, backend: e, attrs: { dtype: r } });
    return e.disposeIntermediateTensorInfo(u), d;
  }
  if (!Qd(o.dtype, r)) {
    const u = rs({ inputs: { x: o }, backend: e });
    return { dataId: u.dataId, shape: u.shape, dtype: r };
  }
  const i6 = e.data.get(o.dataId).values, [a, l, c] = O1(i6, o.shape, o.dtype, r);
  return e.makeTensorInfo(a, l, c);
}
var lM = {
  kernelName: Gi,
  backendName: "cpu",
  kernelFunc: Ys
};
function fe(n, t, e, s) {
  return e == null ? ({ inputs: o, backend: r }) => {
    const { a: i6, b: a } = o, l = r;
    lt([i6, a], n);
    const c = l.data.get(i6.dataId).values, u = l.data.get(a.dataId).values, d = i6.dtype === "string" ? (
      // tslint:disable-next-line: no-any
      ys(c)
    ) : c, h = i6.dtype === "string" ? (
      // tslint:disable-next-line: no-any
      ys(u)
    ) : u, p = s || i6.dtype, [f, m] = t(i6.shape, a.shape, d, h, p);
    return l.makeTensorInfo(m, p, f);
  } : ({ inputs: o, backend: r }) => {
    const { a: i6, b: a } = o, l = r;
    if (i6.dtype === "complex64" || a.dtype === "complex64") {
      const c = Ys({ inputs: { x: i6 }, backend: l, attrs: { dtype: "complex64" } }), u = l.data.get(c.dataId), d = u.complexTensorInfos.real, h = u.complexTensorInfos.imag, p = l.data.get(d.dataId).values, f = l.data.get(h.dataId).values, m = Ys({ inputs: { x: a }, backend: l, attrs: { dtype: "complex64" } }), g = l.data.get(m.dataId), b = g.complexTensorInfos.real, x6 = g.complexTensorInfos.imag, w = l.data.get(b.dataId).values, y6 = l.data.get(x6.dataId).values, [I, v, k6] = e(i6.shape, a.shape, p, f, w, y6), S = l.makeTensorInfo(k6, "float32", I), N = l.makeTensorInfo(k6, "float32", v), R = Je({ inputs: { real: S, imag: N }, backend: l });
      return l.disposeIntermediateTensorInfo(c), l.disposeIntermediateTensorInfo(m), l.disposeIntermediateTensorInfo(S), l.disposeIntermediateTensorInfo(N), R;
    } else {
      const c = l.data.get(i6.dataId).values, u = l.data.get(a.dataId).values, d = s || i6.dtype, [h, p] = t(i6.shape, a.shape, c, u, d);
      return l.makeTensorInfo(p, d, h);
    }
  };
}
function Pf(n) {
  return (t, e, s, o, r, i6) => {
    const a = bt(t, e), l = X(a), c = a.length, u = dt(a), d = Se("float32", l), h = Se("float32", l), p = Go(t, a), f = Go(e, a), m = xs(s, o), g = xs(r, i6), b = t.length, x6 = dt(t), w = e.length, y6 = dt(e);
    if (p.length + f.length === 0)
      for (let I = 0; I < d.length; I++) {
        const v = I % m.length, k6 = I % g.length, S = n(m[v * 2], m[v * 2 + 1], g[k6 * 2], g[k6 * 2 + 1]);
        d[I] = S.real, h[I] = S.imag;
      }
    else
      for (let I = 0; I < d.length; I++) {
        const v = Xo(I, c, u), k6 = v.slice(-b);
        p.forEach((V) => k6[V] = 0);
        const S = zn(k6, b, x6), N = v.slice(-w);
        f.forEach((V) => N[V] = 0);
        const R = zn(N, w, y6), M6 = n(m[S * 2], m[S * 2 + 1], g[R * 2], g[R * 2 + 1]);
        d[I] = M6.real, h[I] = M6.imag;
      }
    return [d, h, a];
  };
}
var X1 = le((n, t) => n + t);
var cM = Pf((n, t, e, s) => ({ real: n + e, imag: t + s }));
var wr = fe(Sr, X1, cM);
var uM = {
  kernelName: Sr,
  backendName: "cpu",
  kernelFunc: wr
};
function Af(n, t, e, s, o) {
  const r = X(s), i6 = ke(o, e);
  for (let a = 0; a < n.length; a++) {
    const l = n[a];
    if (l < 0)
      throw new Error("Input x must be non-negative!");
    l >= o || (r > 0 ? i6[l] += t[a] : i6[l] += 1);
  }
  return i6;
}
function K1(n, t, e, s = false) {
  const o = n.shape[0], r = n.shape[1], i6 = vt([o, e], t.dtype);
  for (let a = 0; a < o; a++)
    for (let l = 0; l < r; l++) {
      const c = n.get(a, l);
      if (c < 0)
        throw new Error("Input x must be non-negative!");
      c >= e || (s ? i6.set(1, a, c) : t.size > 0 ? i6.set(i6.get(a, c) + t.get(a, l), a, c) : i6.set(i6.get(a, c) + 1, a, c));
    }
  return i6;
}
var Z1 = le((n, t) => n & t);
var dM = fe(rh, Z1);
var hM = {
  kernelName: rh,
  backendName: "cpu",
  kernelFunc: dM
};
function as(n) {
  return (t, e, s) => {
    const o = ne(e, t.length);
    for (let r = 0; r < t.length; ++r)
      o[r] = n(t[r], s);
    return o;
  };
}
function Wt(n, t, e) {
  const s = as(t);
  return so(n, s, e);
}
function so(n, t, e) {
  return ({ inputs: s, attrs: o, backend: r }) => {
    const { x: i6 } = s;
    lt(i6, n);
    const a = r, l = a.data.get(i6.dataId).values;
    let c;
    if (i6.dtype === "string") {
      if (!Array.isArray(l))
        throw new Error("String tensor's value was not an instance of Array");
      c = ys(l);
    } else
      c = l;
    const u = e || i6.dtype, d = t(c, u, o);
    return a.makeTensorInfo(i6.shape, u, d);
  };
}
var B1 = as((n) => Math.ceil(n));
var pM = so(Ei, B1);
var fM = {
  kernelName: Ei,
  backendName: "cpu",
  kernelFunc: pM
};
function H1(n, t, e, s) {
  const o = ne(e, X(t));
  if (s && e !== "string") {
    let r = 0;
    n.forEach((i6) => {
      const a = X(i6.shape);
      o.set(i6.vals, r), r += a;
    });
  } else {
    let r = 0;
    n.forEach((i6) => {
      const a = e === "string" ? ys(i6.vals) : i6.vals;
      let l = 0;
      for (let c = 0; c < i6.shape[0]; ++c) {
        const u = c * t[1] + r;
        for (let d = 0; d < i6.shape[1]; ++d)
          o[u + d] = a[l++];
      }
      r += i6.shape[1];
    });
  }
  return o;
}
var _1 = le((n, t) => n === t ? 1 : 0);
var U1 = fe(cc, _1, null, "bool");
var mM = {
  kernelName: cc,
  backendName: "cpu",
  kernelFunc: U1
};
var Y1 = as((n) => Math.exp(n));
var Q1 = so(zi, Y1, "float32");
var gM = {
  kernelName: zi,
  backendName: "cpu",
  kernelFunc: Q1
};
var J1 = as((n) => Math.expm1(n));
var bM = so(Pi, J1);
var xM = {
  kernelName: Pi,
  backendName: "cpu",
  kernelFunc: bM
};
var j1 = as((n) => Math.floor(n));
var yM = so(Ai, j1);
var wM = {
  kernelName: Ai,
  backendName: "cpu",
  kernelFunc: yM
};
var q1 = le((n, t) => Math.floor(n / t));
var IM = fe(Oi, q1, null, "int32");
var CM = {
  kernelName: Oi,
  backendName: "cpu",
  kernelFunc: IM
};
function tw(n, t, e, s, o, r, i6, a, l) {
  const c = vt([s, r], e);
  for (let u = 0; u < s; u++) {
    const d = [];
    let h = 0;
    for (let p = 0; p < o; p++) {
      const f = n[u * o + p];
      h += f * i6[p], d.push(f);
    }
    if (h < 0 || h >= l / r)
      throw new Error(`Invalid indices: ${d} does not index into ${a}`);
    for (let p = 0; p < r; p++)
      c.values[u * r + p] = t.get(...t.indexToLoc(h * r + p));
  }
  return c;
}
function ew(n, t, e) {
  const s = vt(e, n.dtype);
  for (let o = 0; o < s.size; ++o) {
    const i6 = s.indexToLoc(o).slice(), a = i6[0], l = i6[2], c = t.locToIndex([a, l]);
    i6[2] = t.values[c];
    const u = n.locToIndex(i6);
    0 <= u && u < n.values.length && (s.values[o] = n.values[u]);
  }
  return s;
}
var nw = le((n, t) => n > t ? 1 : 0);
var vM = fe(pc, nw, null, "bool");
var SM = {
  kernelName: pc,
  backendName: "cpu",
  kernelFunc: vM
};
var sw = le((n, t) => n >= t ? 1 : 0);
var kM = fe(Xi, sw, null, "bool");
var TM = {
  kernelName: Xi,
  backendName: "cpu",
  kernelFunc: kM
};
var ow = le((n, t) => n < t ? 1 : 0);
var NM = fe(mc, ow, null, "bool");
var RM = {
  kernelName: mc,
  backendName: "cpu",
  kernelFunc: NM
};
var rw = le((n, t) => n <= t ? 1 : 0);
var $M = fe(gc, rw, null, "bool");
var GM = {
  kernelName: gc,
  backendName: "cpu",
  kernelFunc: $M
};
function iw(n, t, e) {
  const s = (t - n) / (e - 1), o = ke(e, "float32");
  o[0] = n;
  for (let r = 1; r < o.length; r++)
    o[r] = o[r - 1] + s;
  return o;
}
var aw = as((n) => Math.log(n));
var EM = so(_i, aw);
var LM = {
  kernelName: _i,
  backendName: "cpu",
  kernelFunc: EM
};
function lw(n, t, e, s) {
  const o = Se(s, X(e));
  for (let r = 0; r < o.length; ++r) {
    const i6 = r * t;
    let a = n[i6];
    for (let l = 0; l < t; ++l) {
      const c = n[i6 + l];
      (Number.isNaN(c) || c > a) && (a = c);
    }
    o[r] = a;
  }
  return o;
}
var cw = le((n, t) => Math.max(n, t));
var MM = fe(Yi, cw);
var WM = {
  kernelName: Yi,
  backendName: "cpu",
  kernelFunc: MM
};
var uw = le((n, t) => Math.min(n, t));
var DM = fe(Qi, uw);
var FM = {
  kernelName: Qi,
  backendName: "cpu",
  kernelFunc: DM
};
var Of = le((n, t) => n * t);
var VM = Pf((n, t, e, s) => ({
  real: n * e - t * s,
  imag: n * s + t * e
}));
var wu = fe(ji, Of, VM);
var zM = {
  kernelName: ji,
  backendName: "cpu",
  kernelFunc: wu
};
function dw(n, t, e) {
  const s = Is(-1, e);
  return Of([], t, s, n, e);
}
function PM(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  lt(s, "neg");
  const o = e.data.get(s.dataId).values, [r, i6] = dw(o, s.shape, s.dtype);
  return e.makeTensorInfo(i6, s.dtype, r);
}
var AM = {
  kernelName: Nc,
  backendName: "cpu",
  kernelFunc: PM
};
var hw = le((n, t) => n !== t ? 1 : 0);
var OM = fe(Rc, hw, null, "bool");
var XM = {
  kernelName: Rc,
  backendName: "cpu",
  kernelFunc: OM
};
function Xf(n, t, e, s, o) {
  const r = t.length, i6 = X(t), a = dt(t), l = dt(o), c = Se(e, X(o));
  for (let u = 0; u < i6; ++u) {
    const d = Xo(u, r, a), h = new Array(d.length);
    for (let f = 0; f < h.length; f++)
      h[f] = d[s[f]];
    const p = zn(h, r, l);
    c[p] = n[u];
  }
  return c;
}
function _e(n) {
  const { inputs: t, attrs: e, backend: s } = n, { x: o } = t, { perm: r } = e;
  lt(o, "transpose");
  const i6 = o.shape.length, a = new Array(i6);
  for (let d = 0; d < a.length; d++)
    a[d] = o.shape[r[d]];
  const l = s.data.get(o.dataId).values, c = Xf(l, o.shape, o.dtype, r, a);
  return { dataId: s.write(c, a, o.dtype), shape: a, dtype: o.dtype };
}
var KM = {
  kernelName: ar,
  backendName: "cpu",
  kernelFunc: _e
};
function pw(n, t, e, s) {
  const [o, r] = ye(n, s), i6 = tn(t, "int32"), a = ke(X(o), i6), l = X(r);
  for (let c = 0; c < a.length; ++c) {
    const u = c * l;
    let d = 1;
    for (let h = 0; h < l; ++h)
      d *= e[u + h];
    a[c] = d;
  }
  return { outVals: a, outShape: o, outDtype: i6 };
}
function ZM(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  lt(o, "prod");
  const a = o.shape.length, l = Ct(r, o.shape), c = qt(l, a);
  let u = l, d = o;
  const h = [];
  c != null && (d = _e({ inputs: { x: o }, backend: e, attrs: { perm: c } }), h.push(d), u = ie(u.length, a));
  const p = e.data.get(d.dataId).values, { outVals: f, outShape: m, outDtype: g } = pw(d.shape, d.dtype, p, u);
  let b = m;
  return i6 && (b = re(m, l)), h.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), e.makeTensorInfo(b, g, f);
}
var BM = {
  kernelName: Wc,
  backendName: "cpu",
  kernelFunc: ZM
};
function HM(n, t, e) {
  n.forEach((s, o) => {
    if (s < 0 || s >= e) {
      const r = Xo(o, t.length, dt(t)).join(",");
      throw new Error(`indices[${r}] = ${s} is not in [0, ${e})`);
    }
  });
}
function _M(n, t) {
  for (let e = 0; e < n.length; ++e) {
    const s = n[e], o = e === n.length - 1 ? t : n[e + 1].length;
    if (s.length === 0)
      throw new Error("Ragged splits may not be empty");
    if (s[0] < 0)
      throw new Error("Ragged splits must be non-negative");
    if (s[s.length - 1] > o)
      throw new Error("Ragged splits must not point past values");
    for (let r = 1; r < s.length; ++r)
      if (s[r - 1] > s[r])
        throw new Error("Ragged splits must be sorted in ascending order");
  }
}
function UM(n, t, e, s) {
  const o = [];
  let r = 0;
  const i6 = t.length - 1 + e.length, a = new Array(i6).fill(null).map(() => [0]);
  _M(e, s);
  let l = 1;
  for (let c = 0; c < t.length - 1; ++c) {
    l *= t[c];
    const u = t[c + 1];
    for (let d = 1; d < l + 1; ++d)
      a[c].push(d * u);
  }
  for (let c = 0; c < n.length; ++c) {
    let u = n[c], d = n[c] + 1;
    for (let h = 0; h < e.length; ++h) {
      const p = e[h], f = h + t.length - 1;
      if (f >= 0) {
        const m = a[f], g = m[m.length - 1] - p[u];
        for (let b = u; b < d; ++b)
          a[f].push(p[b + 1] + g);
      }
      u = p[u], d = p[d];
    }
    d !== u && (o.push([u, d]), r += d - u);
  }
  return { outSplits: a, valueSlices: o, numValues: r };
}
function YM(n) {
  const t = [];
  for (let e = 0; e < n.length; ++e) {
    const s = n[e].length, o = ne("int32", s);
    t.push(o), n[e].forEach((r, i6) => o[i6] = r);
  }
  return t;
}
function pg(n, t) {
  const e = n.slice(0, t);
  for (; e.length < t; )
    e.push(1);
  for (let s = t; s < n.length; s++)
    e[t - 1] *= n[s];
  return e;
}
function QM(n, t, e, s, o, r) {
  const i6 = pg(t, 2)[1], a = pg(r, 2)[1];
  let l = 0;
  for (const c of e)
    for (let u = c[0]; u < c[1]; ++u) {
      for (let d = 0; d < s; ++d)
        o[l * a + d] = n[u * i6 + d];
      ++l;
    }
}
function JM(n, t, e, s, o) {
  const r = t.slice();
  r[0] = o;
  const i6 = ne(e, X(r)), a = n.length, l = a === 0 ? 0 : a / t[0];
  return QM(n, t, s, l, i6, r), [i6, r];
}
function fw(n, t, e, s, o, r, i6, a) {
  if (n.length === 0)
    throw new Error("paramsNestedSplits must be non empty");
  if (t[0].length === 0)
    throw new Error("Split tensors must not be scalars");
  const l = t[0][0] - 1;
  if (HM(r, i6, l), s.length === 0)
    throw new Error("params.rank must be nonzero");
  const c = s[0], { outSplits: u, valueSlices: d, numValues: h } = UM(r, i6, n, c), p = YM(u), f = JM(e, s, o, d, h);
  return [p, f[0], f[1]];
}
var fg = 2147483647;
function mw(n, t, e, s, o, r, i6) {
  if (t.length > 1)
    throw new Error("starts must be a scalar or vector");
  if (o.length > 1)
    throw new Error("limits must be a scalar or vector");
  if (i6.length > 1)
    throw new Error("deltas must be a scalar or vector");
  const a = t.length === 0, l = o.length === 0, c = i6.length === 0, u = [];
  a || u.push(t[0]), l || u.push(o[0]), c || u.push(i6[0]);
  for (let g = 1; g < u.length; ++g)
    if (u[g] !== u[g - 1])
      throw new Error("starts, limits, and deltas must have the same shape");
  const d = u.length === 0 ? 1 : u[0], h = ne("int32", d + 1);
  h[0] = 0;
  for (let g = 0; g < d; ++g) {
    const b = a ? n[0] : n[g], x6 = l ? s[0] : s[g], w = c ? r[0] : r[g];
    if (w === 0)
      throw new Error("Requires delta != 0");
    let y6;
    if (w > 0 && x6 < b || w < 0 && x6 > b)
      y6 = 0;
    else if (y6 = Math.ceil(Math.abs((x6 - b) / w)), y6 > fg)
      throw new Error(`Requires ((limit - start) / delta) <= ${fg}`);
    h[g + 1] = h[g] + y6;
  }
  const p = h[d], f = ne(e, p);
  let m = 0;
  for (let g = 0; g < d; ++g) {
    const b = h[g + 1] - h[g];
    let x6 = a ? n[0] : n[g];
    const w = c ? r[0] : r[g];
    for (let y6 = 0; y6 < b; ++y6)
      f[m++] = x6, x6 += w;
  }
  return [h, f];
}
var xn = Fn;
var Vl = class _Vl {
  constructor(t, e, s, o, r, i6, a, l, c, u) {
    this.shape = t, this.shapeShape = e, this.values = s, this.valuesShape = o, this.valuesDType = r, this.defaultValue = i6, this.defaultValueShape = a, this.rowPartitionValues = l, this.rowPartitionValuesShapes = c, this.rowPartitionTypes = Y0(u), this.raggedRank = Q0(this.rowPartitionTypes);
  }
  getRowPartitionTypeByDimension(t) {
    return this.rowPartitionTypes[0] === xn.FIRST_DIM_SIZE ? this.rowPartitionTypes[t + 1] : this.rowPartitionTypes[t];
  }
  // Returns the relationship between dimension and dimension + 1.
  getRowPartitionTensor(t) {
    return this.rowPartitionTypes[0] === xn.FIRST_DIM_SIZE ? this.rowPartitionValues[t + 1] : this.rowPartitionValues[t];
  }
  getMaxWidth(t) {
    const e = this.getRowPartitionTensor(t - 1);
    switch (this.getRowPartitionTypeByDimension(t - 1)) {
      case xn.VALUE_ROWIDS:
        return _Vl.getMaxWidthValueRowID(e);
      case xn.ROW_SPLITS:
        return _Vl.getMaxWidthRowSplit(e);
      default:
        throw new Error(`Cannot handle partition type ${xn[this.getRowPartitionTypeByDimension(t - 1)]}`);
    }
  }
  static getMaxWidthRowSplit(t) {
    const e = t.length;
    if (e === 0 || e === 1)
      return 0;
    let s = 0;
    for (let o = 0; o < e - 1; ++o) {
      const r = t[o + 1] - t[o];
      r > s && (s = r);
    }
    return s;
  }
  static getMaxWidthValueRowID(t) {
    const e = t.length;
    if (e === 0)
      return 0;
    let s = 0, o = t[0], r = 0;
    for (let i6 = 1; i6 < e; ++i6) {
      const a = t[i6];
      a !== o && (o = a, r = Math.max(i6 - s, r), s = i6);
    }
    return Math.max(e - s, r);
  }
  tensorShapeFromTensor(t, e, s = true) {
    if (e.length === 0) {
      if (t[0] === -1)
        return [];
      throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.");
    }
    return gg(t, s);
  }
  calculateOutputSize(t) {
    const e = this.valuesShape, s = this.defaultValueShape;
    J0(s, e);
    const o = this.tensorShapeFromTensor(this.shape, this.shapeShape), i6 = U0(this.raggedRank, o, e);
    i6[0] < 0 && (i6[0] = t);
    for (let a = 1; a <= this.raggedRank; ++a)
      i6[a] < 0 && (i6[a] = this.getMaxWidth(a));
    return i6;
  }
  /**
   * The outputIndex represents the index in the output tensor
   * where the first element of a particular dimension would be written.
   * If it is -1, it indicates that the index is out of scope.
   * Example, given firstDimension = 10, firstDimensionOutput = 6,
   * and outputIndexMultiplier = 100:
   * result = [0 100 200 300 400 500 -1 -1 -1 -1]
   * If firstDimensionOutput = 11 instead, then:
   * result = [0 100 200 300 400 500 600 700 800 900]
   */
  calculateFirstParentOutputIndex(t, e, s) {
    const o = Math.min(t, s), r = [];
    let i6 = 0;
    for (let a = 0; a < o; ++a, i6 += e)
      r.push(i6);
    for (let a = o; a < t; ++a)
      r.push(-1);
    return C(r.length === t, () => "Final length of result must be equal to firstDimension."), r;
  }
  calculateOutputIndexRowSplit(t, e, s, o) {
    const r = t.length, i6 = [];
    for (let a = 0; a < r - 1; ++a) {
      const l = t[a + 1] - t[a];
      let c = Math.min(o, l), u = e[a];
      u === -1 && (c = 0);
      for (let d = 0; d < c; ++d)
        i6.push(u), u += s;
      for (let d = 0; d < l - c; ++d)
        i6.push(-1);
    }
    if (r > 0 && i6.length !== t[r - 1])
      throw new Error("Invalid row split size.");
    return i6;
  }
  // Calculate the output index of the first element of a list.
  // The parentOutputIndex is the same computation for the previous list.
  // -1 indicates an element or list that is out of range.
  // The outputIndexMultiplier is the number of output indices one moves
  // forward for each column.
  // E.g., given:
  // valueRowIds:[0 1 2 2 2 3 5 5 6]
  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]
  // outputIndexMultiplier: 10
  // outputSize: 2
  // You get:
  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]
  // result[0] = parentOutputIndex[valueRowIds[0]]
  // result[1] = parentOutputIndex[valueRowIds[1]]
  // result[2] = parentOutputIndex[valueRowIds[2]]
  // result[3] = parentOutputIndex[valueRowIds[2] + 10]
  // result[4] = -1 because it is the third element the size is 2.
  // result[5] = parentOutputIndex[valueRowIds[3]]
  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1
  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1
  // result[8] = parentOutputIndex[valueRowIds[7]]
  calculateOutputIndexValueRowID(t, e, s, o) {
    const r = t.length, i6 = [];
    if (r === 0)
      return [];
    let a = 0, l = t[0];
    if (l >= e.length)
      throw new Error(`Got currentValueRowId=${l}, which is not less than ${e.length}`);
    let c = e[l];
    i6.push(c);
    for (let u = 1; u < r; ++u) {
      const d = t[u];
      if (d === l)
        c >= 0 && (++a, a < o ? c += s : c = -1);
      else {
        if (a = 0, l = d, d >= e.length)
          throw new Error(`Got nextValueRowId=${d} which is not less than ${e.length}`);
        c = e[d];
      }
      i6.push(c);
    }
    if (i6.length !== t.length)
      throw new Error("Invalid row ids.");
    return i6;
  }
  calculateOutputIndex(t, e, s, o) {
    const r = this.getRowPartitionTensor(t), i6 = this.getRowPartitionTypeByDimension(t);
    switch (i6) {
      case xn.VALUE_ROWIDS:
        return this.calculateOutputIndexValueRowID(r, e, s, o);
      case xn.ROW_SPLITS:
        if (r.length - 1 > e.length)
          throw new Error(`Row partition size is greater than output size: ${r.length - 1} > ${e.length}`);
        return this.calculateOutputIndexRowSplit(r, e, s, o);
      default:
        throw new Error(`Unsupported partition type: ${xn[i6]}`);
    }
  }
  getFirstDimensionSize() {
    const t = this.rowPartitionValues[0];
    if (this.rowPartitionTypes.length === 0)
      throw new Error("No row_partition_types given.");
    const e = this.rowPartitionTypes[0];
    switch (e) {
      case xn.FIRST_DIM_SIZE:
        return t[0];
      case xn.VALUE_ROWIDS:
        throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
      case xn.ROW_SPLITS:
        return this.rowPartitionValuesShapes[0][0] - 1;
      default:
        throw new Error(`Cannot handle type ${xn[e]}`);
    }
  }
  compute() {
    if (this.rowPartitionValues[0].length <= 0)
      throw new Error("Invalid first partition input. Tensor requires at least one element.");
    const e = this.getFirstDimensionSize(), s = this.calculateOutputSize(e), o = new Array(this.raggedRank + 1);
    o[o.length - 1] = 1;
    for (let l = o.length - 2; l >= 0; --l)
      o[l] = o[l + 1] * s[l + 1];
    const r = gg(s, false), i6 = ne(this.valuesDType, X(r));
    if (o[0] * s[0] > 0) {
      let l = this.calculateFirstParentOutputIndex(e, o[0], s[0]);
      for (let c = 1; c <= this.raggedRank; ++c)
        l = this.calculateOutputIndex(c - 1, l, o[c], s[c]);
      this.setOutput(this.raggedRank, l, i6, r);
    }
    return [r, i6];
  }
  setOutput(t, e, s, o) {
    if (s.length === 0)
      return;
    const r = this.values, i6 = s;
    let a = o.slice();
    a = a.slice(t + 1);
    const l = X(a), c = e.length;
    let u = this.defaultValue;
    if (u.length !== l && u.length !== 1) {
      const f = this.defaultValueShape;
      D(() => {
        const m = W(u, f);
        u = ni(m, a).dataSync();
      });
    }
    let d = 0, h = 0, p = 0;
    for (let f = 0; f <= c; ++f) {
      let m = f < c ? e[f] : -1;
      if (m === p) {
        ++p;
        continue;
      }
      if (h < p) {
        const g = r.subarray(d * l), b = i6.subarray(h * l), x6 = (p - h) * l;
        mg(b, g, x6);
      }
      if (f >= c) {
        const g = s.length;
        m = Math.floor(g / l);
      }
      if (m > p)
        if (this.defaultValue.length === 1)
          i6.subarray(p * l, m * l).fill(this.defaultValue[0]), p = m;
        else
          for (; m > p; ) {
            const g = i6.slice(p * l);
            mg(g, u, l), ++p;
          }
      m < 0 ? (d = f + 1, h = p) : (d = f, h = p, p = h + 1);
    }
  }
};
function mg(n, t, e) {
  for (let s = 0; s < e; s++)
    n[s] = t[s];
}
function gg(n, t) {
  const e = [];
  for (let s of n) {
    if (s < 0) {
      if (!t)
        throw new Error(`Dimension ${s} must be >= 0`);
      if (s < -1)
        throw new Error(`Dimension ${s} must be >= -1`);
      s = -1;
    }
    e.push(s);
  }
  return e;
}
function gw(n, t, e, s, o, r, i6, a, l, c) {
  return new Vl(n, t, e, s, o, r, i6, a, l, c).compute();
}
function bw(n, t, e, s) {
  const o = n === t, r = n < t && e < 0, i6 = t < n && e > 1;
  if (o || r || i6)
    return ke(0, s);
  const a = Math.abs(Math.ceil((t - n) / e)), l = ke(a, s);
  t < n && e === 1 && (e = -1), l[0] = n;
  for (let c = 1; c < l.length; c++)
    l[c] = l[c - 1] + e;
  return l;
}
var xw = as((n) => 1 / Math.sqrt(n));
var jM = so(oa, xw);
var qM = {
  kernelName: oa,
  backendName: "cpu",
  kernelFunc: jM
};
function bo(n, t, e, s, o, r, i6, a, l, c) {
  const u = [s / o, o], d = n.values, h = t.values;
  if (s === 0)
    return vt(e, t.dtype);
  const p = l instanceof ve ? l : vt(u, t.dtype);
  typeof l == "string" || typeof l == "number" ? p.values.fill(l) : typeof l == "boolean" && p.values.fill(+l);
  for (let f = 0; f < r; f++) {
    const m = [];
    let g = 0;
    for (let b = 0; b < i6; b++) {
      const x6 = d[f * i6 + b];
      m.push(x6), g += x6 * a[b];
    }
    if (g < 0 || g >= s / o)
      throw new Error(`Invalid indices: ${m} does not index into ${e}`);
    for (let b = 0; b < o; b++)
      c ? p.values[g * o + b] += h[f * o + b] : p.values[g * o + b] = t.rank === 0 ? h[0] : h[f * o + b];
  }
  return p;
}
var tW = as((n) => 1 / (1 + Math.exp(-n)));
var yw = Wt(ca, (n) => 1 / (1 + Math.exp(-n)));
var eW = {
  kernelName: ca,
  backendName: "cpu",
  kernelFunc: yw
};
function ww(n, t, e, s, o) {
  const r = Hp(s, t, e), i6 = X(e), a = dt(s);
  if (r) {
    const d = _p(t, a);
    return o === "string" ? n.slice(d, d + i6) : n.subarray(d, d + i6);
  }
  const l = o === "string" ? ys(n) : n, c = vt(s, o, l), u = vt(e, o);
  for (let d = 0; d < u.size; ++d) {
    const h = u.indexToLoc(d), p = h.map((f, m) => f + t[m]);
    u.set(c.get(...p), ...h);
  }
  return o === "string" ? bx(u.values) : u.values;
}
function Fo(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, size: i6 } = s;
  lt(o, "slice");
  const [a, l] = nu(o, r, i6);
  Zp(o, a, l);
  const c = e.data.get(o.dataId).values, u = ww(c, a, l, o.shape, o.dtype);
  return e.makeTensorInfo(l, o.dtype, u);
}
var nW = {
  kernelName: Ac,
  backendName: "cpu",
  kernelFunc: Fo
};
function Iw(n, t, e, s, o, r, i6) {
  const a = t[0], l = r[0], c = new Array(l), u = new Array(a), d = t[1];
  if (l === 0) {
    if (a !== 0)
      throw new Error(ox(a));
    const g = ne(e, 0), b = ne(o, 0);
    return [
      g,
      [0, d],
      b,
      c,
      u
    ];
  }
  let h = true, p = 0;
  const f = new Array(l).fill(0);
  for (let g = 0; g < a; ++g) {
    const b = n[g * d];
    if (b < 0)
      throw new Error(rx(g, b));
    if (b >= l)
      throw new Error(ix(g, b, l));
    ++f[b], h = h && b >= p, p = b;
  }
  let m = true;
  for (let g = 0; g < l; ++g) {
    const b = f[g] === 0;
    c[g] = b, m = m && !b, f[g] = Math.max(f[g], 1), g > 0 && (f[g] += f[g - 1]);
  }
  if (m && h) {
    const g = n, b = s;
    for (let x6 = 0; x6 < a; ++x6)
      u[x6] = x6;
    return [
      g,
      [a, d],
      b,
      c,
      u
    ];
  } else {
    const g = f[l - 1], b = ne(e, g * d), x6 = ne(o, g), w = new Array(l).fill(0);
    for (let y6 = 0; y6 < a; ++y6) {
      const I = n[y6 * d], v = w[I], k6 = (I === 0 ? 0 : f[I - 1]) + v;
      w[I]++;
      for (let S = 0; S < d; ++S)
        b[k6 * d + S] = n[y6 * d + S];
      x6[k6] = s[y6], u[y6] = k6;
    }
    for (let y6 = 0; y6 < l; ++y6)
      if (w[y6] === 0) {
        const v = y6 === 0 ? 0 : f[y6 - 1];
        b[v * d + 0] = y6;
        for (let k6 = 1; k6 < d; ++k6)
          b[v * d + k6] = 0;
        x6[v] = i6;
      }
    return [
      b,
      [g, d],
      x6,
      c,
      u
    ];
  }
}
function Cw(n, t, e, s, o) {
  const r = X(s), i6 = t[0], a = o.length, l = [];
  let c = 1, u = -1;
  for (let g = 0; g < a; ++g) {
    const b = o[g];
    if (b === -1) {
      if (u !== -1)
        throw new Error(ax(u, g));
      u = g, l.push(1);
    } else {
      if (b < 0)
        throw new Error(lx(g, b));
      c *= b, l.push(b);
    }
  }
  if (u !== -1) {
    if (c <= 0)
      throw new Error(cx());
    const g = Math.trunc(r / c);
    if (c * g !== r)
      throw new Error(ux(s, l));
    l[u] = g;
  }
  if (X(l) !== r)
    throw new Error(dx(s, l));
  const h = s.length, p = [];
  if (h > 0) {
    p[h - 1] = 1;
    for (let g = h - 2; g >= 0; --g)
      p[g] = p[g + 1] * s[g + 1];
  }
  const f = [];
  if (a > 0) {
    f[a - 1] = 1;
    for (let g = a - 2; g >= 0; --g)
      f[g] = f[g + 1] * l[g + 1];
  }
  const m = ne(e, i6 * a);
  for (let g = 0; g < i6; ++g) {
    let b = 0;
    for (let x6 = 0; x6 < h; ++x6)
      b += n[g * h + x6] * p[x6];
    for (let x6 = 0; x6 < a; ++x6)
      m[g * a + x6] = Math.trunc(b / f[x6]), b %= f[x6];
  }
  return [m, [i6, a], l];
}
function Kf(n, t, e, s, o, r = false, i6 = 0) {
  const a = s.length, l = [t[0], n.length / t[0]], c = l[1], d = a > 0 ? o[a - 1] + 1 : 0;
  if (d < 0)
    throw new Error(Td());
  const h = t.slice();
  h[0] = d;
  const p = h.reduce((w, y6) => w * y6, 1), f = ne(e, p);
  if (a === 0)
    return d > 0 && f.fill(i6), [f, h];
  if (d <= 0)
    throw new Error(Td());
  let m = 0, g = 1, b = 0, x6 = o[m];
  for (; ; ) {
    let w = 0;
    if (g < a) {
      if (w = o[g], x6 === w) {
        ++g;
        continue;
      }
      if (x6 >= w)
        throw new Error(hx());
    }
    if (x6 < 0 || x6 >= d)
      throw new Error(px(x6, d));
    x6 > b && f.fill(i6, b * c, x6 * c);
    for (let y6 = m; y6 < g; ++y6) {
      const I = s[y6];
      if (I < 0 || I >= l[0])
        throw new Error(fx(y6, s[y6], l[0]));
      for (let v = 0; v < c; v++)
        f[x6 * c + v] += n[I * c + v];
    }
    if (r)
      for (let y6 = 0; y6 < c; y6++)
        f[x6 * c + y6] /= g - m;
    if (m = g, ++g, b = x6 + 1, x6 = w, g > a)
      break;
  }
  return b < d && f.fill(i6, b * c, d * c), [f, h];
}
var sW = as((n) => Math.sqrt(n));
var oW = Wt(da, (n) => Math.sqrt(n));
var rW = {
  kernelName: da,
  backendName: "cpu",
  kernelFunc: oW
};
var vw = le((n, t) => {
  const e = n - t;
  return e * e;
});
var iW = fe(ha, vw);
var aW = {
  kernelName: ha,
  backendName: "cpu",
  kernelFunc: iW
};
var Sw = as((n, t) => {
  const { pattern: e, replaceGlobal: s, rewrite: o } = t;
  return n.replace(new RegExp(e, s ? "g" : ""), o);
});
var lW = so(Bc, Sw);
var cW = {
  kernelName: Bc,
  backendName: "cpu",
  kernelFunc: lW
};
function kw(n, t, e, s) {
  const o = vt(n, t.dtype);
  for (let r = 0; r < o.size; r++) {
    const i6 = o.indexToLoc(r), a = new Array(i6.length);
    for (let l = 0; l < a.length; l++)
      a[l] = i6[l] * e[l] + s[l];
    o.set(t.get(...a), ...i6);
  }
  return o;
}
var uW = class {
  constructor(t, e, s, o, r, i6) {
    this.separator = ms(t), this.nGramWidths = e, this.leftPad = ms(s), this.rightPad = ms(o), this.padWidth = r, this.preserveShort = i6;
  }
  getPadWidth(t) {
    return Math.min(this.padWidth < 0 ? t - 1 : this.padWidth, t - 1);
  }
  getNumNGrams(t, e) {
    const s = this.getPadWidth(e);
    return Math.max(0, t + 2 * s - e + 1);
  }
  createNGrams(t, e, s, o, r, i6) {
    for (let a = 0; a < r; ++a) {
      const l = this.getPadWidth(i6), c = Math.max(0, l - a), u = Math.max(0, l - (r - (a + 1))), d = i6 - (c + u), h = e + (c > 0 ? 0 : a - l);
      let p = 0;
      p += c * this.leftPad.length;
      for (let x6 = 0; x6 < d; ++x6)
        p += t[h + x6].length;
      p += u * this.rightPad.length;
      const f = c + u + d - 1;
      p += f * this.separator.length, s[o + a] = new Uint8Array(p);
      const m = s[o + a];
      let g = 0;
      const b = (x6) => x6.forEach((w) => m[g++] = w);
      for (let x6 = 0; x6 < c; ++x6)
        b(this.leftPad), b(this.separator);
      for (let x6 = 0; x6 < d - 1; ++x6)
        b(t[h + x6]), b(this.separator);
      if (d > 0) {
        b(t[h + d - 1]);
        for (let x6 = 0; x6 < u; ++x6)
          b(this.separator), b(this.rightPad);
      } else {
        for (let x6 = 0; x6 < u - 1; ++x6)
          b(this.rightPad), b(this.separator);
        b(this.rightPad);
      }
    }
  }
  // Data and splits together form the definition of the ragged tensor,
  // where data is 1 dimensional and contains the values of the tensor
  // and splits denotes the indices at which each row starts.
  compute(t, e) {
    const s = t.length, o = e.length;
    if (o > 0) {
      let l = e[0];
      if (l !== 0)
        throw new Error(`First split value must be 0, got ${l}`);
      for (let c = 1; c < o; ++c) {
        let u = e[c] >= l;
        if (u = u && e[c] <= s, !u)
          throw new Error(`Invalid split value ${e[c]}, must be in [${l}, ${s}]`);
        l = e[c];
      }
      if (l !== s)
        throw new Error(`Last split value must be data size. Expected ${s}, got ${l}`);
    }
    const r = o - 1, i6 = ne("int32", o);
    if (s === 0 || o === 0) {
      const l = new Array(s);
      for (let c = 0; c <= r; ++c)
        i6[c] = 0;
      return [l, i6];
    }
    i6[0] = 0;
    for (let l = 1; l <= r; ++l) {
      const c = e[l] - e[l - 1];
      let u = 0;
      this.nGramWidths.forEach((d) => {
        u += this.getNumNGrams(c, d);
      }), this.preserveShort && c > 0 && u === 0 && (u = 1), i6[l] = i6[l - 1] + u;
    }
    const a = new Array(i6[r]);
    for (let l = 0; l < r; ++l) {
      const c = e[l];
      let u = i6[l];
      if (this.nGramWidths.forEach((d) => {
        const h = e[l + 1] - e[l], p = this.getNumNGrams(h, d);
        this.createNGrams(t, c, a, u, p, d), u += p;
      }), this.preserveShort && u === i6[l]) {
        const d = e[l + 1] - e[l];
        if (d === 0)
          continue;
        const h = d + 2 * this.padWidth;
        this.createNGrams(t, c, a, u, 1, h);
      }
    }
    return [a, i6];
  }
};
function Tw(n, t, e, s, o, r, i6, a) {
  return new uW(e, s, o, r, i6, a).compute(n, t);
}
function dW(n, t, e, s) {
  if (!n.length)
    return;
  if (t.length === 0) {
    for (let r = 0; r < n.length; ++r)
      s.push(n.subarray(r, r + 1));
    return;
  }
  if (t.length === 1) {
    const r = t[0];
    let i6 = n.indexOf(r);
    for (; i6 !== -1; ) {
      const a = n.subarray(0, i6);
      (!e || a.length !== 0) && s.push(a), n = n.subarray(i6 + 1), i6 = n.indexOf(r);
    }
    (!e || n.length !== 0) && s.push(n);
    return;
  }
  let o = 0;
  for (let r = 0; r < n.length + 1; r++)
    if (r === n.length || t.indexOf(n[r]) !== -1) {
      const i6 = n.subarray(o, r);
      (!e || i6.length !== 0) && s.push(i6), o = r + 1;
    }
}
function Nw(n, t, e) {
  const s = n.length, o = [];
  let r = 0, i6 = 0;
  const a = new Array(s);
  for (let h = 0; h < s; ++h) {
    const p = o.length;
    dW(n[h], t, e, o);
    const f = o.length - p;
    a[h] = f, r += f, i6 = Math.max(i6, f);
  }
  const l = ne("int32", r * 2), c = new Array(r), u = [s, i6];
  let d = 0;
  for (let h = 0; h < s; ++h)
    for (let p = 0; p < a[h]; ++p)
      l[d * 2] = h, l[d * 2 + 1] = p, c[d] = o[d], ++d;
  return [l, c, u];
}
function Rw(n, t) {
  const e = ne("int32", n.length);
  for (let s = 0; s < n.length; ++s)
    e[s] = Lb(n[s]).modulo(t).getLowBitsUnsigned();
  return e;
}
var $w = le((n, t) => n - t);
var hW = Pf((n, t, e, s) => ({ real: n - e, imag: t - s }));
var Zf = fe(pa, $w, hW);
var pW = {
  kernelName: pa,
  backendName: "cpu",
  kernelFunc: Zf
};
function Gw(n, t) {
  const e = new Array(n.rank);
  for (let o = 0; o < e.length; o++)
    e[o] = n.shape[o] * t[o];
  const s = vt(e, n.dtype);
  for (let o = 0; o < s.values.length; ++o) {
    const r = s.indexToLoc(o), i6 = new Array(n.rank);
    for (let l = 0; l < i6.length; l++)
      i6[l] = r[l] % n.shape[l];
    const a = n.locToIndex(i6);
    s.values[o] = n.values[a];
  }
  return s;
}
var Qr = (n, t) => {
  const e = t.value - n.value;
  return e === 0 ? n.index - t.index : e;
};
function Ew(n, t, e = 0, s = n.length - 1) {
  for (; s > e; ) {
    if (s - e > 600) {
      const a = s - e + 1, l = t - e + 1, c = Math.log(a), u = 0.5 * Math.exp(2 * c / 3), d = 0.5 * Math.sqrt(c * u * (a - u) / a) * Math.sign(l - a / 2), h = Math.max(e, Math.floor(t - l * u / a + d)), p = Math.min(s, Math.floor(t + (a - l) * u / a + d));
      Ew(n, t, h, p);
    }
    const o = n[t];
    let r = e, i6 = s;
    for (ds(n, e, t), Qr(n[s], o) > 0 && ds(n, e, s); r < i6; ) {
      for (ds(n, r, i6), r++, i6--; Qr(n[r], o) < 0; )
        r = r + 1;
      for (; Qr(n[i6], o) > 0; )
        i6 = i6 - 1;
    }
    Qr(n[e], o) === 0 ? ds(n, e, i6) : (i6 = i6 + 1, ds(n, i6, s)), i6 <= t && (e = i6 + 1), t <= i6 && (s = i6 - 1);
  }
}
function Lw(n, t, e, s, o) {
  const r = t[t.length - 1], [i6, a] = [n.length / r, r], l = Se(e, i6 * s), c = Se("int32", i6 * s);
  for (let d = 0; d < i6; d++) {
    const h = d * a, p = n.subarray(h, h + a);
    let f = new Array(p.length);
    p.forEach((x6, w) => f[w] = { value: x6, index: w }), s < f.length && (Ew(f, s), f = f.slice(0, s)), o && f.sort(Qr);
    const m = d * s, g = l.subarray(m, m + s), b = c.subarray(m, m + s);
    for (let x6 = 0; x6 < s; x6++)
      g[x6] = f[x6].value, b[x6] = f[x6].index;
  }
  const u = t.slice();
  return u[u.length - 1] = s, [
    vt(u, e, l),
    vt(u, "int32", c)
  ];
}
function Mw(n, t, e, s) {
  const o = Ct(t, e)[0], r = [1, e[0], 1];
  for (let f = 0; f < o; f++)
    r[0] *= e[f];
  r[1] = e[o];
  for (let f = o + 1; f < e.length; f++)
    r[2] *= e[f];
  const i6 = /* @__PURE__ */ new Map(), a = new Int32Array(e[o]), l = new ve(r, s, n), c = [], u = r[0] === 1 && r[2] === 1;
  for (let f = 0; f < e[o]; f++) {
    let m;
    if (u)
      m = n[f].toString();
    else {
      const b = [];
      for (let x6 = 0; x6 < r[0]; x6++)
        for (let w = 0; w < r[2]; w++)
          b.push(l.get(x6, f, w));
      m = b.join(",");
    }
    const g = i6.get(m);
    if (g != null)
      a[f] = g;
    else {
      const b = i6.size;
      i6.set(m, b), a[f] = b, c.push(f);
    }
  }
  const d = r.slice();
  d[1] = i6.size;
  const h = new ve(d, s);
  c.forEach((f, m) => {
    for (let g = 0; g < r[0]; g++)
      for (let b = 0; b < r[2]; b++)
        h.set(l.get(g, f, b), g, m, b);
  });
  const p = e.slice();
  return p[o] = d[1], {
    outputValues: h.values,
    outputShape: p,
    indices: a
  };
}
var fW = Object.freeze(Object.defineProperty({
  __proto__: null,
  addImpl: X1,
  bincountImpl: Af,
  bincountReduceImpl: K1,
  bitwiseAndImpl: Z1,
  castImpl: O1,
  ceilImpl: B1,
  concatImpl: H1,
  equalImpl: _1,
  expImpl: Y1,
  expm1Impl: J1,
  floorDivImpl: q1,
  floorImpl: j1,
  gatherNdImpl: tw,
  gatherV2Impl: ew,
  greaterEqualImpl: sw,
  greaterImpl: nw,
  lessEqualImpl: rw,
  lessImpl: ow,
  linSpaceImpl: iw,
  logImpl: aw,
  maxImpl: lw,
  maximumImpl: cw,
  minimumImpl: uw,
  multiplyImpl: Of,
  negImpl: dw,
  notEqualImpl: hw,
  prodImpl: pw,
  raggedGatherImpl: fw,
  raggedRangeImpl: mw,
  raggedTensorToTensorImpl: gw,
  rangeImpl: bw,
  rsqrtImpl: xw,
  scatterImpl: bo,
  sigmoidImpl: tW,
  simpleAbsImpl: A1,
  sliceImpl: ww,
  sparseFillEmptyRowsImpl: Iw,
  sparseReshapeImpl: Cw,
  sparseSegmentReductionImpl: Kf,
  sqrtImpl: sW,
  squaredDifferenceImpl: vw,
  staticRegexReplaceImpl: Sw,
  stridedSliceImpl: kw,
  stringNGramsImpl: Tw,
  stringSplitImpl: Nw,
  stringToHashBucketFastImpl: Rw,
  subImpl: $w,
  tileImpl: Gw,
  topKImpl: Lw,
  transposeImpl: Xf,
  uniqueImpl: Mw
}, Symbol.toStringTag, { value: "Module" }));
Pb(
  "cpu",
  () => new yu(),
  1
  /* priority */
);
var Ww = Wt(Fi, (n) => n >= 0 ? n : Math.exp(n) - 1);
var mW = {
  kernelName: Fi,
  backendName: "cpu",
  kernelFunc: Ww
};
function Dw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { alpha: r } = s;
  lt([o], "leakyRelu");
  const i6 = X(o.shape), a = e.data.get(o.dataId).values, l = Se("float32", i6);
  for (let c = 0; c < a.length; c++)
    l[c] = a[c] < 0 ? r * a[c] : a[c];
  return e.makeTensorInfo(o.shape, "float32", l);
}
var gW = {
  kernelName: fc,
  backendName: "cpu",
  kernelFunc: Dw
};
var bW = le((n, t) => n < 0 ? t * n : n);
function Fw(n) {
  const { inputs: t, backend: e } = n, { x: s, alpha: o } = t;
  lt([s, o], "prelu");
  const r = e.data.get(s.dataId).values, i6 = e.data.get(o.dataId).values, [a, l] = bW(s.shape, o.shape, r, i6, "float32");
  return e.makeTensorInfo(l, "float32", a);
}
var xW = {
  kernelName: Mc,
  backendName: "cpu",
  kernelFunc: Fw
};
var Vw = Wt(ea, (n) => Math.max(0, n));
var yW = {
  kernelName: ea,
  backendName: "cpu",
  kernelFunc: Vw
};
var zw = Wt(na, (n) => Math.min(Math.max(0, n), 6));
var wW = {
  kernelName: na,
  backendName: "cpu",
  kernelFunc: zw
};
function zl(n, t, e, s, o) {
  if (e === "linear")
    return rs({ inputs: { x: t }, backend: n });
  if (e === "relu")
    return Vw({ inputs: { x: t }, backend: n });
  if (e === "elu")
    return Ww({ inputs: { x: t }, backend: n });
  if (e === "relu6")
    return zw({ inputs: { x: t }, backend: n });
  if (e === "prelu")
    return Fw({ inputs: { x: t, alpha: s }, backend: n });
  if (e === "leakyrelu")
    return Dw({ inputs: { x: t }, backend: n, attrs: { alpha: o } });
  if (e === "sigmoid")
    return yw({ inputs: { x: t }, backend: n });
  throw new Error(`Activation ${e} has not been implemented for the CPU backend.`);
}
function Zt(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { shape: r } = s, i6 = X(o.shape), a = Yd(r, i6), l = X(a);
  C(i6 === l, () => `The new shape (${a}) has ${l} elements and the old shape (${o.shape}) has ${i6} elements. The new shape and old shape must have the same number of elements.`), e.incRef(o.dataId);
  const c = e.data.get(o.dataId);
  if (c.complexTensorInfos != null) {
    const u = c.complexTensorInfos.real, d = c.complexTensorInfos.imag;
    u.shape = a, d.shape = a;
  }
  return { dataId: o.dataId, shape: a, dtype: o.dtype };
}
var IW = {
  kernelName: Dc,
  backendName: "cpu",
  kernelFunc: Zt
};
function Pw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r } = t, { transposeA: i6, transposeB: a } = s;
  lt([o, r], "matMul");
  const l = o.shape.length, c = r.shape.length, u = i6 ? o.shape[l - 2] : o.shape[l - 1], d = a ? r.shape[c - 1] : r.shape[c - 2], h = i6 ? o.shape[l - 1] : o.shape[l - 2], p = a ? r.shape[c - 2] : r.shape[c - 1], f = o.shape.slice(0, -2), m = r.shape.slice(0, -2), g = X(f), b = X(m), w = bt(o.shape.slice(0, -2), r.shape.slice(0, -2)).concat([h, p]);
  C(u === d, () => `Error in matMul: inner shapes (${u}) and (${d}) of Tensors with shapes ${o.shape} and ${r.shape} and transposeA=${i6} and transposeB=${a} must match.`);
  const y6 = i6 ? [g, u, h] : [g, h, u], I = a ? [b, p, d] : [b, d, p], v = Zt({ inputs: { x: o }, backend: e, attrs: { shape: y6 } }), k6 = Zt({ inputs: { x: r }, backend: e, attrs: { shape: I } }), S = i6 ? v.shape[1] : v.shape[2], N = i6 ? v.shape[2] : v.shape[1], R = a ? k6.shape[1] : k6.shape[2], M6 = Math.max(g, b), V = e.data.get(v.dataId).values, z = e.data.get(k6.dataId).values, P = dt(v.shape), A = dt(k6.shape), [O, B6, Z] = i6 ? [P[0], 1, P[1]] : [P[0], P[1], 1], [H6, Y, Q6] = a ? [1, A[1], A[0]] : [A[1], 1, A[0]], j = N * R, J6 = vt([M6, N, R], v.dtype), ot = J6.values, q = e.blockSize;
  for (let rt = 0; rt < M6; rt++) {
    const ht = rt % g, ft = rt % b;
    for (let pt = 0; pt < N; pt += q) {
      const wt2 = Math.min(pt + q, N);
      for (let It2 = 0; It2 < R; It2 += q) {
        const Et2 = Math.min(It2 + q, R);
        for (let Pt = 0; Pt < S; Pt += q) {
          const te = Math.min(Pt + q, S);
          for (let At2 = pt; At2 < wt2; At2++)
            for (let Dt = It2; Dt < Et2; Dt++) {
              let Jt2 = 0;
              for (let _t2 = Pt; _t2 < te; _t2++) {
                const ls = (
                  // tslint:disable-next-line: max-line-length
                  V[ht * O + At2 * B6 + _t2 * Z]
                ), we2 = (
                  // tslint:disable-next-line: max-line-length
                  z[_t2 * H6 + Dt * Y + ft * Q6]
                );
                Jt2 += ls * we2;
              }
              ot[rt * j + (At2 * R + Dt)] += Jt2;
            }
        }
      }
    }
  }
  return e.disposeIntermediateTensorInfo(v), e.disposeIntermediateTensorInfo(k6), e.makeTensorInfo(w, J6.dtype, J6.values);
}
var CW = {
  kernelName: ql,
  backendName: "cpu",
  kernelFunc: Pw
};
function vW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r, bias: i6, preluActivationWeights: a } = t, { transposeA: l, transposeB: c, activation: u, leakyreluAlpha: d } = s;
  let h, p, f;
  const m = [];
  h = Pw({ inputs: { a: o, b: r }, attrs: { transposeA: l, transposeB: c }, backend: e }), i6 && (p = wr({ inputs: { a: h, b: i6 }, backend: e }), m.push(h), h = p), u && (f = zl(e, h, u, a, d), m.push(h), h = f);
  for (const b of m)
    e.disposeIntermediateTensorInfo(b);
  return h;
}
var SW = {
  kernelName: ml,
  backendName: "cpu",
  kernelFunc: vW
};
var kW = Wt(vi, (n) => Math.acos(n));
var TW = {
  kernelName: vi,
  backendName: "cpu",
  kernelFunc: kW
};
var NW = Wt(Si, (n) => Math.acosh(n));
var RW = {
  kernelName: Si,
  backendName: "cpu",
  kernelFunc: NW
};
function $W(n) {
  const { inputs: t, backend: e } = n, s = t;
  lt(t, "addN");
  const o = s.map((a) => e.data.get(a.dataId).values), r = vt(s[0].shape, s[0].dtype), i6 = r.values;
  for (let a = 0; a < s.length; a++) {
    const l = o[a];
    for (let c = 0; c < i6.length; c++)
      i6[c] += l[c];
  }
  return e.makeTensorInfo(r.shape, r.dtype, r.values);
}
var GW = {
  kernelName: qd,
  backendName: "cpu",
  kernelFunc: $W
};
function EW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  lt(o, "all");
  const a = Ct(r, o.shape);
  let l = a;
  const c = qt(l, o.shape.length);
  let u = o;
  c != null && (u = _e({ inputs: { x: o }, backend: e, attrs: { perm: c } }), l = ie(l.length, o.shape.length)), Ne("all", l, u.shape.length);
  const [d, h] = ye(u.shape, l), p = X(h), f = ke(X(d), u.dtype), m = e.data.get(u.dataId).values;
  for (let b = 0; b < f.length; ++b) {
    const x6 = b * p;
    let w = m[x6];
    for (let y6 = 0; y6 < p; ++y6) {
      const I = m[x6 + y6];
      w = w && I;
    }
    f[b] = w;
  }
  c != null && e.disposeIntermediateTensorInfo(u);
  const g = e.makeTensorInfo(d, u.dtype, f);
  if (i6) {
    const b = re(d, a), x6 = Zt({ inputs: { x: g }, backend: e, attrs: { shape: b } });
    return e.disposeIntermediateTensorInfo(g), x6;
  }
  return g;
}
var LW = {
  kernelName: th,
  backendName: "cpu",
  kernelFunc: EW
};
function MW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  lt(o, "any");
  const a = Ct(r, o.shape);
  let l = a;
  const c = qt(l, o.shape.length);
  let u = o;
  c != null && (u = _e({ inputs: { x: o }, backend: e, attrs: { perm: c } }), l = ie(l.length, o.shape.length)), Ne("any", l, u.shape.length);
  const [d, h] = ye(u.shape, l), p = X(h), f = ke(X(d), u.dtype), m = e.data.get(u.dataId).values;
  for (let b = 0; b < f.length; ++b) {
    const x6 = b * p;
    let w = m[x6];
    for (let y6 = 0; y6 < p; ++y6) {
      const I = m[x6 + y6];
      w = w || I;
    }
    f[b] = w;
  }
  c != null && e.disposeIntermediateTensorInfo(u);
  const g = e.makeTensorInfo(d, u.dtype, f);
  if (i6) {
    const b = re(d, a), x6 = Zt({ inputs: { x: g }, backend: e, attrs: { shape: b } });
    return e.disposeIntermediateTensorInfo(g), x6;
  }
  return g;
}
var WW = {
  kernelName: eh,
  backendName: "cpu",
  kernelFunc: MW
};
function DW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  lt(o, "argMax");
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = _e({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), i6 = [i6[0]], Ne("argMax", i6, l.shape.length);
  const [u, d] = ye(l.shape, i6), h = X(u), p = ke(h, "int32"), f = X(d), m = e.data.get(l.dataId).values;
  for (let g = 0; g < p.length; ++g) {
    const b = g * f;
    let x6 = m[b], w = 0;
    for (let y6 = 0; y6 < f; ++y6) {
      const I = m[b + y6];
      I > x6 && (x6 = I, w = y6);
    }
    p[g] = w;
  }
  return c.forEach((g) => e.disposeIntermediateTensorInfo(g)), e.makeTensorInfo(u, "int32", p);
}
var FW = {
  kernelName: Yl,
  backendName: "cpu",
  kernelFunc: DW
};
function VW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  lt(o, "argMin");
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = _e({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), i6 = [i6[0]], Ne("argMin", i6, l.shape.length);
  const [u, d] = ye(l.shape, i6), h = X(u), p = ke(h, "int32"), f = X(d), m = e.data.get(l.dataId).values;
  for (let g = 0; g < p.length; ++g) {
    const b = g * f;
    let x6 = m[b], w = 0;
    for (let y6 = 0; y6 < f; ++y6) {
      const I = m[b + y6];
      I < x6 && (x6 = I, w = y6);
    }
    p[g] = w;
  }
  return c.forEach((g) => e.disposeIntermediateTensorInfo(g)), e.makeTensorInfo(u, "int32", p);
}
var zW = {
  kernelName: Ql,
  backendName: "cpu",
  kernelFunc: VW
};
var PW = Wt(ki, (n) => Math.asin(n));
var AW = {
  kernelName: ki,
  backendName: "cpu",
  kernelFunc: PW
};
var OW = Wt(Ti, (n) => Math.asinh(n));
var XW = {
  kernelName: Ti,
  backendName: "cpu",
  kernelFunc: OW
};
var KW = Wt(Ni, (n) => Math.atan(n));
var ZW = {
  kernelName: Ni,
  backendName: "cpu",
  kernelFunc: KW
};
var BW = le((n, t) => Math.atan2(n, t));
var HW = fe($i, BW);
var _W = {
  kernelName: $i,
  backendName: "cpu",
  kernelFunc: HW
};
var UW = Wt(Ri, (n) => Math.atanh(n));
var YW = {
  kernelName: Ri,
  backendName: "cpu",
  kernelFunc: UW
};
function Bf(n, t, e, s, o, r) {
  const i6 = o.strideHeight, a = o.strideWidth, l = o.dilationHeight, c = o.dilationWidth, u = o.effectiveFilterHeight, d = o.effectiveFilterWidth, h = o.padInfo.top, p = o.padInfo.left, f = r === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY, m = vt(o.outShape, e), g = m.values, b = o.outShape[1] * o.outShape[2] * o.outShape[3], x6 = o.outShape[2] * o.outShape[3], w = o.outShape[3];
  for (let y6 = 0; y6 < o.batchSize; ++y6) {
    const I = y6 * b, v = y6 * s[0];
    for (let k6 = 0; k6 < o.inChannels; ++k6)
      for (let S = 0; S < o.outHeight; ++S) {
        const N = S * i6 - h, R = Math.max(0, N), M6 = Math.min(o.inHeight, u + N), V = I + S * x6;
        for (let z = 0; z < o.outWidth; ++z) {
          const P = z * a - p, A = Math.max(0, P), O = Math.min(o.inWidth, d + P);
          let B6 = f, Z = 0, H6 = 0;
          for (let Q6 = R; Q6 < M6; Q6 += l) {
            const j = v + Q6 * s[1];
            for (let J6 = A; J6 < O; J6 += c) {
              const ot = j + J6 * s[2], q = n[ot + k6];
              r === "max" && q > B6 ? B6 = q : r === "avg" && (Z += q, H6++);
            }
            if (isNaN(B6))
              break;
          }
          const Y = V + z * w + k6;
          g[Y] = r === "avg" ? Z / H6 : B6;
        }
      }
  }
  return m;
}
function Aw(n, t, e, s, o = false, r = false) {
  const i6 = vt(s.outShape, "int32"), a = s.strideHeight, l = s.strideWidth, c = s.dilationHeight, u = s.dilationWidth, d = s.effectiveFilterHeight, h = s.effectiveFilterWidth, p = s.padInfo.top, f = s.padInfo.left, m = vt(t, e, n);
  for (let g = 0; g < s.batchSize; ++g)
    for (let b = 0; b < s.inChannels; ++b)
      for (let x6 = 0; x6 < s.outHeight; ++x6) {
        const w = x6 * a - p;
        let y6 = w;
        for (; y6 < 0; )
          y6 += c;
        const I = Math.min(s.inHeight, d + w);
        for (let v = 0; v < s.outWidth; ++v) {
          const k6 = v * l - f;
          let S = k6;
          for (; S < 0; )
            S += u;
          const N = Math.min(s.inWidth, h + k6);
          let R = Number.NEGATIVE_INFINITY, M6 = -1;
          for (let V = y6; V < I; V += c) {
            const z = V - w;
            for (let P = S; P < N; P += u) {
              const A = P - k6, O = m.get(g, V, P, b);
              O > R && (R = O, o ? M6 = r ? ((g * s.inHeight + V) * s.inWidth + P) * s.inChannels + b : (V * s.inWidth + P) * s.inChannels + b : M6 = z * h + A);
            }
          }
          i6.set(M6, g, x6, v, b);
        }
      }
  return i6;
}
function Ow(n, t, e, s, o, r) {
  const i6 = o.strideDepth, a = o.strideHeight, l = o.strideWidth, c = o.dilationDepth, u = o.dilationHeight, d = o.dilationWidth, h = o.effectiveFilterDepth, p = o.effectiveFilterHeight, f = o.effectiveFilterWidth, m = o.padInfo.front, g = o.padInfo.top, b = o.padInfo.left, x6 = r === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY, w = vt(o.outShape, e), y6 = w.values, I = o.outShape[1] * o.outShape[2] * o.outShape[3] * o.outShape[4], v = o.outShape[2] * o.outShape[3] * o.outShape[4], k6 = o.outShape[3] * o.outShape[4], S = o.outShape[4];
  for (let N = 0; N < o.batchSize; ++N) {
    const R = N * I, M6 = N * s[0];
    for (let V = 0; V < o.inChannels; ++V)
      for (let z = 0; z < o.outDepth; ++z) {
        const P = z * i6 - m;
        let A = P;
        for (; A < 0; )
          A += c;
        const O = Math.min(o.inDepth, h + P), B6 = R + z * v;
        for (let Z = 0; Z < o.outHeight; ++Z) {
          const H6 = Z * a - g;
          let Y = H6;
          for (; Y < 0; )
            Y += u;
          const Q6 = Math.min(o.inHeight, p + H6), j = B6 + Z * k6;
          for (let J6 = 0; J6 < o.outWidth; ++J6) {
            const ot = J6 * l - b;
            let q = ot;
            for (; q < 0; )
              q += d;
            const rt = Math.min(o.inWidth, f + ot), ht = j + J6 * S;
            let ft = x6, pt = 0, wt2 = 0;
            for (let Et2 = A; Et2 < O; Et2 += c) {
              const Pt = M6 + Et2 * s[1];
              for (let te = Y; te < Q6; te += u) {
                const At2 = Pt + te * s[2];
                for (let Dt = q; Dt < rt; Dt += d) {
                  const Jt2 = At2 + Dt * s[3], _t2 = n[Jt2 + V];
                  if (r === "max" && _t2 > ft ? ft = _t2 : r === "avg" && (pt += _t2, wt2++), isNaN(ft))
                    break;
                }
                if (isNaN(ft))
                  break;
              }
              if (isNaN(ft))
                break;
            }
            const It2 = ht + V;
            y6[It2] = r === "avg" ? pt / Math.max(wt2, 1) : ft;
          }
        }
      }
  }
  return w;
}
function QW(n, t) {
  const e = vt(t.outShape, "int32"), s = t.strideDepth, o = t.strideHeight, r = t.strideWidth, i6 = t.dilationDepth, a = t.dilationHeight, l = t.dilationWidth, c = t.effectiveFilterDepth, u = t.effectiveFilterHeight, d = t.effectiveFilterWidth, h = t.padInfo.front, p = t.padInfo.top, f = t.padInfo.left;
  for (let m = 0; m < t.batchSize; ++m)
    for (let g = 0; g < t.inChannels; ++g)
      for (let b = 0; b < t.outDepth; ++b) {
        const x6 = b * s - h;
        let w = x6;
        for (; w < 0; )
          w += i6;
        const y6 = Math.min(t.inDepth, c + x6);
        for (let I = 0; I < t.outHeight; ++I) {
          const v = I * o - p;
          let k6 = v;
          for (; k6 < 0; )
            k6 += a;
          const S = Math.min(t.inHeight, u + v);
          for (let N = 0; N < t.outWidth; ++N) {
            const R = N * r - f;
            let M6 = R;
            for (; M6 < 0; )
              M6 += l;
            const V = Math.min(t.inWidth, d + R);
            let z = Number.NEGATIVE_INFINITY, P = -1;
            for (let A = w; A < y6; A += i6) {
              const O = A - x6;
              for (let B6 = k6; B6 < S; B6 += a) {
                const Z = B6 - v;
                for (let H6 = M6; H6 < V; H6 += l) {
                  const Y = H6 - R, Q6 = n.get(m, A, B6, H6, g);
                  Q6 >= z && (z = Q6, P = O * u * d + Z * u + Y);
                }
              }
            }
            e.set(P, m, b, I, N, g);
          }
        }
      }
  return e;
}
function JW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  lt(o, "avgPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  C(Le(i6, c), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  let d;
  if (u.filterWidth === 1 && u.filterHeight === 1 && $t(u.inShape, u.outShape))
    d = rs({ inputs: { x: o }, backend: e });
  else {
    const h = e.data.get(o.dataId).values, p = dt(o.shape), f = Bf(h, o.shape, o.dtype, p, u, "avg");
    d = e.makeTensorInfo(u.outShape, o.dtype, f.values);
  }
  return d;
}
var jW = {
  kernelName: Jl,
  backendName: "cpu",
  kernelFunc: JW
};
function qW(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l, dataFormat: c } = s;
  lt(o, "avgPool3d");
  const u = vs(o.shape, r, i6, 1, a, l, c), d = e.data.get(o.dataId).values, h = Ow(d, o.shape, o.dtype, dt(o.shape), u, "avg");
  return e.makeTensorInfo(h.shape, "float32", h.values);
}
var tD = {
  kernelName: jl,
  backendName: "cpu",
  kernelFunc: qW
};
function eD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, { filterSize: i6, strides: a, pad: l, dimRoundingMode: c } = s;
  lt([o, r], "avgPool3DGrad");
  const u = vs(r.shape, i6, a, 1, l, c), d = u.strideDepth, h = u.strideHeight, p = u.strideWidth, f = u.filterDepth, m = u.filterHeight, g = u.filterWidth, b = u.dilationDepth, x6 = u.dilationHeight, w = u.dilationWidth, y6 = u.effectiveFilterDepth, I = u.effectiveFilterHeight, v = u.effectiveFilterWidth, k6 = y6 - 1 - u.padInfo.front, S = v - 1 - u.padInfo.left, N = I - 1 - u.padInfo.top, R = vt(r.shape, "float32"), M6 = 1 / (f * m * g), V = e.bufferSync(o);
  for (let z = 0; z < u.batchSize; ++z)
    for (let P = 0; P < u.inChannels; ++P)
      for (let A = 0; A < u.inDepth; ++A)
        for (let O = 0; O < u.inHeight; ++O)
          for (let B6 = 0; B6 < u.inWidth; ++B6) {
            const Z = A - k6, H6 = O - N, Y = B6 - S;
            let Q6 = 0;
            for (let j = 0; j < y6; j += b) {
              const J6 = (Z + j) / d;
              if (!(J6 < 0 || J6 >= u.outDepth || Math.floor(J6) !== J6))
                for (let ot = 0; ot < I; ot += x6) {
                  const q = (H6 + ot) / h;
                  if (!(q < 0 || q >= u.outHeight || Math.floor(q) !== q))
                    for (let rt = 0; rt < v; rt += w) {
                      const ht = (Y + rt) / p;
                      if (ht < 0 || ht >= u.outWidth || Math.floor(ht) !== ht)
                        continue;
                      const ft = V.get(z, J6, q, ht, P);
                      Q6 += ft;
                    }
                }
            }
            R.set(Q6 * M6, z, A, O, B6, P);
          }
  return e.makeTensorInfo(R.shape, R.dtype, R.values);
}
var nD = {
  kernelName: sh,
  backendName: "cpu",
  kernelFunc: eD
};
function sD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r;
  lt([o, r], "avgPoolGrad");
  const { filterSize: a, strides: l, pad: c } = s, u = $n(i6.shape, a, l, 1, c), d = u.strideHeight, h = u.strideWidth, p = u.filterHeight, f = u.filterWidth, m = u.dilationHeight, g = u.dilationWidth, b = u.effectiveFilterHeight, x6 = u.effectiveFilterWidth, w = x6 - 1 - u.padInfo.left, y6 = b - 1 - u.padInfo.top, I = vt(i6.shape, "float32"), v = 1 / (p * f), k6 = e.data.get(o.dataId).values, S = vt(o.shape, "float32", k6);
  for (let N = 0; N < u.batchSize; ++N)
    for (let R = 0; R < u.inChannels; ++R)
      for (let M6 = 0; M6 < u.inHeight; ++M6)
        for (let V = 0; V < u.inWidth; ++V) {
          const z = M6 - y6, P = V - w;
          let A = 0;
          for (let O = 0; O < b; O += m) {
            const B6 = (z + O) / d;
            if (!(B6 < 0 || B6 >= u.outHeight || Math.floor(B6) !== B6))
              for (let Z = 0; Z < x6; Z += g) {
                const H6 = (P + Z) / h;
                if (H6 < 0 || H6 >= u.outWidth || Math.floor(H6) !== H6)
                  continue;
                const Y = S.get(N, B6, H6, R);
                A += Y;
              }
          }
          I.set(A * v, N, M6, V, R);
        }
  return e.makeTensorInfo(I.shape, I.dtype, I.values);
}
var oD = {
  kernelName: nh,
  backendName: "cpu",
  kernelFunc: sD
};
function rD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, scale: r, offset: i6, mean: a, variance: l } = t;
  C(a.shape.length === l.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), C(i6 == null || a.shape.length === i6.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), C(r == null || a.shape.length === r.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks."), lt([o, a, l, r, i6], "batchNorm");
  let { varianceEpsilon: c } = s;
  c == null && (c = 1e-3);
  const u = e.data.get(o.dataId).values, d = e.data.get(a.dataId).values, h = e.data.get(l.dataId).values, p = r ? e.data.get(r.dataId).values : new Float32Array([1]), f = i6 ? e.data.get(i6.dataId).values : new Float32Array([0]), m = new Float32Array(u.length), g = f.length, b = p.length, x6 = h.length, w = d.length;
  let y6 = 0, I = 0, v = 0, k6 = 0;
  for (let S = 0; S < u.length; ++S)
    m[S] = f[y6++] + (u[S] - d[I++]) * p[v++] / Math.sqrt(h[k6++] + c), y6 >= g && (y6 = 0), I >= w && (I = 0), v >= b && (v = 0), k6 >= x6 && (k6 = 0);
  return e.makeTensorInfo(o.shape, o.dtype, m);
}
var iD = {
  kernelName: dc,
  backendName: "cpu",
  kernelFunc: rD
};
function aD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, crops: i6 } = s;
  lt([o], "batchToSpaceND");
  const a = r.reduce((b, x6) => b * x6), l = Na(o.shape, r, a), c = Ra(l.length, r.length), u = $a(o.shape, r, a), d = jp(i6, r.length), h = qp(u, i6, r.length), p = Zt({ inputs: { x: o }, backend: e, attrs: { shape: l } }), f = _e({ inputs: { x: p }, backend: e, attrs: { perm: c } }), m = Zt({ inputs: { x: f }, backend: e, attrs: { shape: u } }), g = Fo({
    inputs: { x: m },
    backend: e,
    attrs: { begin: d, size: h }
  });
  return e.disposeIntermediateTensorInfo(p), e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(m), g;
}
var lD = {
  kernelName: tc,
  backendName: "cpu",
  kernelFunc: aD
};
function cD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6 } = s, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, c = Af(a, l, r.dtype, r.shape, i6);
  return e.makeTensorInfo([i6], r.dtype, c);
}
var uD = {
  kernelName: oh,
  backendName: "cpu",
  kernelFunc: cD
};
function dD(n) {
  const { inputs: t, backend: e } = n, { s0: s, s1: o } = t, r = e.data.get(s.dataId).values, i6 = e.data.get(o.dataId).values, a = bt(Array.from(r), Array.from(i6));
  return e.makeTensorInfo([a.length], "int32", Int32Array.from(a));
}
var hD = {
  kernelName: cb,
  backendName: "cpu",
  kernelFunc: dD
};
var pD = Wt(Li, (n, t) => {
  const e = t;
  return n > e.clipValueMax ? e.clipValueMax : n < e.clipValueMin ? e.clipValueMin : n;
});
var fD = {
  kernelName: Li,
  backendName: "cpu",
  kernelFunc: pD
};
var mD = (n) => {
  const { x: t } = n.inputs, e = n.backend, s = new Float32Array(X(t.shape)), o = e.data.get(t.dataId), r = o.complexTensorInfos.real, i6 = o.complexTensorInfos.imag, a = e.data.get(r.dataId).values, l = e.data.get(i6.dataId).values;
  for (let c = 0; c < a.length; c++) {
    const u = a[c], d = l[c];
    s[c] = Math.hypot(u, d);
  }
  return e.makeOutput(s, t.shape, "float32");
};
var gD = {
  kernelName: ec,
  backendName: "cpu",
  kernelFunc: mD
};
function Ir(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.data.get(s.dataId).complexTensorInfos.imag, r = e.data.get(o.dataId).values;
  return e.makeTensorInfo(o.shape, o.dtype, r);
}
var bD = {
  kernelName: vh,
  backendName: "cpu",
  kernelFunc: Ir
};
function Cr(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s, r = Ct(o, t[0].shape)[0], i6 = t.map((m) => m.shape);
  Yp(i6, r);
  let a = ts(t.map((m) => m.shape), r);
  if (X(a) === 0)
    return e.makeTensorInfo(a, t[0].dtype, []);
  const l = t.filter((m) => X(m.shape) > 0);
  if (l.length === 1)
    return rs({ inputs: { x: l[0] }, backend: e });
  if (l[0].dtype === "complex64") {
    const m = l.map((y6) => Do({ inputs: { input: y6 }, backend: e })), g = l.map((y6) => Ir({ inputs: { input: y6 }, backend: e })), b = Cr({ inputs: m, backend: e, attrs: { axis: r } }), x6 = Cr({ inputs: g, backend: e, attrs: { axis: r } }), w = Je({ inputs: { real: b, imag: x6 }, backend: e });
    return m.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), g.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), e.disposeIntermediateTensorInfo(b), e.disposeIntermediateTensorInfo(x6), w;
  }
  const c = l.map((m) => {
    const b = [-1, X(m.shape.slice(r))];
    return Zt({ inputs: { x: m }, backend: e, attrs: { shape: b } });
  }), u = c.map((m) => ({ vals: e.data.get(m.dataId).values, shape: m.shape }));
  a = ts(
    c.map((m) => m.shape),
    1
    /* axis */
  );
  const d = c[0].shape[0] === 1, h = H1(u, a, t[0].dtype, d), p = ts(l.map((m) => m.shape), r), f = e.makeTensorInfo(p, t[0].dtype, h);
  return c.forEach((m) => e.disposeIntermediateTensorInfo(m)), f;
}
var xD = {
  kernelName: nc,
  backendName: "cpu",
  kernelFunc: Cr
};
function Xw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dataFormat: l, dilations: c, dimRoundingMode: u } = s;
  lt([o, r], "conv2d");
  const d = Ss(l), h = Te(o.shape, r.shape, i6, c, a, u, false, d), p = h.filterHeight, f = h.filterWidth, m = h.dilationHeight, g = h.dilationWidth, b = h.padInfo.left, x6 = h.padInfo.top, w = h.dataFormat === "channelsLast", y6 = new ve(h.outShape, o.dtype), I = dt(o.shape), v = dt(r.shape), k6 = I[0], S = w ? I[1] : I[2], N = w ? I[2] : 1, R = w ? 1 : I[1], M6 = y6.strides[0], V = w ? y6.strides[1] : y6.strides[2], z = w ? y6.strides[2] : 1, P = w ? 1 : y6.strides[1], A = e.data.get(o.dataId).values, O = e.data.get(r.dataId).values, B6 = y6.values;
  for (let Z = 0; Z < h.batchSize; ++Z) {
    const H6 = Z * k6, Y = Z * M6;
    for (let Q6 = 0; Q6 < h.outHeight; ++Q6) {
      const j = Y + Q6 * V, J6 = Q6 * h.strideHeight - x6;
      for (let ot = 0; ot < p; ++ot) {
        const q = J6 + ot * m;
        if (q < 0 || q >= h.inHeight)
          continue;
        const rt = ot * v[0], ht = H6 + q * S;
        for (let ft = 0; ft < h.outWidth; ++ft) {
          const pt = j + ft * z, wt2 = ft * h.strideWidth - b;
          for (let It2 = 0; It2 < f; ++It2) {
            const Et2 = wt2 + It2 * g;
            if (Et2 < 0 || Et2 >= h.inWidth)
              continue;
            const Pt = rt + It2 * v[1], te = ht + Et2 * N;
            let At2 = Pt;
            for (let Dt = 0; Dt < h.inChannels; ++Dt) {
              const Jt2 = A[te + Dt * R];
              for (let _t2 = 0; _t2 < h.outChannels; ++_t2)
                B6[pt + _t2 * P] += Jt2 * O[At2 + _t2];
              At2 += h.outChannels;
            }
          }
        }
      }
    }
  }
  return e.makeTensorInfo(y6.shape, y6.dtype, B6);
}
var yD = {
  kernelName: sc,
  backendName: "cpu",
  kernelFunc: Xw
};
function wD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, dataFormat: l, dimRoundingMode: c, filterShape: u } = s;
  lt([o, r], "conv2dBackpropFilter");
  const d = Ss(l), h = Te(o.shape, u, i6, 1, a, c, false, d), { strideHeight: p, strideWidth: f, filterHeight: m, filterWidth: g } = h, b = h.dataFormat === "channelsLast", x6 = new ve(h.filterShape, "float32"), w = h.padInfo.left, y6 = h.padInfo.top, I = e.data.get(o.dataId).values, v = e.data.get(r.dataId).values, k6 = new ve(o.shape, o.dtype, I), S = new ve(r.shape, r.dtype, v);
  for (let N = 0; N < m; ++N) {
    const R = Math.max(0, Math.ceil((y6 - N) / p)), M6 = Math.min(h.outHeight, (h.inHeight + y6 - N) / p);
    for (let V = 0; V < g; ++V) {
      const z = Math.max(0, Math.ceil((w - V) / f)), P = Math.min(h.outWidth, (h.inWidth + w - V) / f);
      for (let A = 0; A < h.inChannels; ++A)
        for (let O = 0; O < h.outChannels; ++O) {
          let B6 = 0;
          for (let Z = 0; Z < h.batchSize; ++Z)
            for (let H6 = R; H6 < M6; ++H6) {
              const Y = N + H6 * p - y6;
              for (let Q6 = z; Q6 < P; ++Q6) {
                const j = V + Q6 * f - w;
                b ? B6 += k6.get(Z, Y, j, A) * S.get(Z, H6, Q6, O) : B6 += k6.get(Z, A, Y, j) * S.get(Z, O, H6, Q6);
              }
            }
          x6.set(B6, N, V, A, O);
        }
    }
  }
  return e.makeTensorInfo(x6.shape, x6.dtype, x6.values);
}
var ID = {
  kernelName: ah,
  backendName: "cpu",
  kernelFunc: wD
};
function CD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { inputShape: i6, strides: a, pad: l, dataFormat: c, dimRoundingMode: u } = s;
  lt([o, r], "conv2dBackpropInput");
  const d = dt(r.shape), h = dt(o.shape);
  let p = Ss(c);
  const f = Te(i6, r.shape, a, 1, l, u, false, p), m = new ve(f.inShape, "float32"), g = m.values, b = e.data.get(o.dataId).values, x6 = e.data.get(r.dataId).values, [w, y6, I] = d, { batchSize: v, filterHeight: k6, filterWidth: S, inChannels: N, inHeight: R, inWidth: M6, outChannels: V, outHeight: z, outWidth: P, strideHeight: A, strideWidth: O } = f;
  p = f.dataFormat;
  const B6 = k6 - 1 - f.padInfo.top, Z = S - 1 - f.padInfo.left, H6 = p === "channelsLast", Y = m.strides[0], Q6 = H6 ? m.strides[1] : m.strides[2], j = H6 ? m.strides[2] : 1, J6 = H6 ? 1 : m.strides[1], ot = h[0], q = H6 ? h[1] : h[2], rt = H6 ? h[2] : 1, ht = H6 ? 1 : h[1];
  for (let ft = 0; ft < v; ++ft)
    for (let pt = 0; pt < N; ++pt)
      for (let wt2 = 0; wt2 < R; ++wt2) {
        const It2 = wt2 - B6, Et2 = Math.max(0, Math.ceil(It2 / A)), Pt = Math.min(z, (k6 + It2) / A);
        for (let te = 0; te < M6; ++te) {
          const At2 = te - Z, Dt = Math.max(0, Math.ceil(At2 / O)), Jt2 = Math.min(P, (S + At2) / O);
          let _t2 = 0;
          for (let we2 = Et2; we2 < Pt; ++we2) {
            const $s = we2 * A - It2;
            for (let an = Dt; an < Jt2; ++an) {
              const ro = an * O - At2, Ln2 = ot * ft + q * we2 + rt * an, cs = w * (k6 - 1 - $s) + y6 * (S - 1 - ro) + I * pt;
              for (let Gs = 0; Gs < V; ++Gs) {
                const Es = b[Ln2 + ht * Gs], Ls = x6[cs + Gs];
                _t2 += Es * Ls;
              }
            }
          }
          const ls = Y * ft + Q6 * wt2 + j * te + J6 * pt;
          g[ls] = _t2;
        }
      }
  return e.makeTensorInfo(m.shape, m.dtype, m.values);
}
var vD = {
  kernelName: oc,
  backendName: "cpu",
  kernelFunc: CD
};
function SD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l } = s;
  lt([o, r], "conv3d");
  const c = Js(o.shape, r.shape, i6, l, a), { filterDepth: u, filterHeight: d, filterWidth: h, dilationDepth: p, dilationHeight: f, dilationWidth: m, padInfo: g } = c, b = g.front, x6 = g.left, w = g.top, y6 = new ve(c.outShape, o.dtype), I = e.data.get(o.dataId).values, v = e.data.get(r.dataId).values, k6 = y6.values, S = dt(o.shape), N = dt(r.shape);
  for (let R = 0; R < c.batchSize; ++R) {
    const M6 = R * S[0], V = R * y6.strides[0];
    for (let z = 0; z < c.outDepth; ++z) {
      const P = V + z * y6.strides[1], A = z * c.strideDepth - b;
      for (let O = 0; O < u; ++O) {
        const B6 = A + O * p;
        if (B6 < 0 || B6 >= c.inDepth)
          continue;
        const Z = O * N[0], H6 = M6 + B6 * S[1];
        for (let Y = 0; Y < c.outHeight; ++Y) {
          const Q6 = P + Y * y6.strides[2], j = Y * c.strideHeight - w;
          for (let J6 = 0; J6 < d; ++J6) {
            const ot = j + J6 * f;
            if (ot < 0 || ot >= c.inHeight)
              continue;
            const q = Z + J6 * N[1], rt = H6 + ot * S[2];
            for (let ht = 0; ht < c.outWidth; ++ht) {
              const ft = Q6 + ht * c.outChannels, pt = ht * c.strideWidth - x6;
              for (let wt2 = 0; wt2 < h; ++wt2) {
                const It2 = pt + wt2 * m;
                if (It2 < 0 || It2 >= c.inWidth)
                  continue;
                const Et2 = q + wt2 * N[2], Pt = rt + It2 * c.inChannels;
                let te = Et2;
                for (let At2 = 0; At2 < c.inChannels; ++At2) {
                  const Dt = I[Pt + At2];
                  for (let Jt2 = 0; Jt2 < c.outChannels; ++Jt2)
                    k6[ft + Jt2] += Dt * v[te + Jt2];
                  te += c.outChannels;
                }
              }
            }
          }
        }
      }
    }
  }
  return e.makeTensorInfo(y6.shape, y6.dtype, y6.values);
}
var kD = {
  kernelName: rc,
  backendName: "cpu",
  kernelFunc: SD
};
function TD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, filterShape: l } = s;
  lt([o, r], "conv3dBackpropFilterV2");
  const c = dt(o.shape), u = dt(r.shape), d = Js(o.shape, l, i6, 1, a), h = d.strideDepth, p = d.strideHeight, f = d.strideWidth, m = d.filterDepth, g = d.filterHeight, b = d.filterWidth, x6 = new ve(d.filterShape, "float32"), w = x6.values, [y6, I, v, k6] = x6.strides, S = e.data.get(r.dataId).values, [N, R, M6, V] = u, z = e.data.get(o.dataId).values, [P, A, O, B6] = c, Z = d.padInfo.front, H6 = d.padInfo.left, Y = d.padInfo.top;
  for (let Q6 = 0; Q6 < m; ++Q6) {
    const j = Math.max(0, Math.ceil((Z - Q6) / h)), J6 = Math.min(d.outDepth, (d.inDepth + Z - Q6) / h), ot = Q6 * y6;
    for (let q = 0; q < g; ++q) {
      const rt = Math.max(0, Math.ceil((Y - q) / p)), ht = Math.min(d.outHeight, (d.inHeight + Y - q) / p), ft = q * I + ot;
      for (let pt = 0; pt < b; ++pt) {
        const wt2 = Math.max(0, Math.ceil((H6 - pt) / f)), It2 = Math.min(d.outWidth, (d.inWidth + H6 - pt) / f), Et2 = pt * v + ft;
        for (let Pt = 0; Pt < d.inChannels; ++Pt) {
          const te = Pt * k6 + Et2;
          for (let At2 = 0; At2 < d.outChannels; ++At2) {
            let Dt = 0;
            for (let Jt2 = 0; Jt2 < d.batchSize; ++Jt2) {
              const _t2 = Jt2 * P, ls = Jt2 * N;
              for (let we2 = j; we2 < J6; ++we2) {
                const an = (Q6 + we2 * h - Z) * A + _t2, ro = we2 * R + ls;
                for (let Ln2 = rt; Ln2 < ht; ++Ln2) {
                  const Gs = (q + Ln2 * p - Y) * O + an, Es = Ln2 * M6 + ro;
                  for (let Ls = wt2; Ls < It2; ++Ls) {
                    const Nu = (pt + Ls * f - H6) * B6 + Gs, Ru = Ls * V + Es;
                    Dt += z[Nu + Pt] * S[Ru + At2];
                  }
                }
              }
            }
            w[te + At2] = Dt;
          }
        }
      }
    }
  }
  return e.makeTensorInfo(x6.shape, x6.dtype, x6.values);
}
var ND = {
  kernelName: lh,
  backendName: "cpu",
  kernelFunc: TD
};
function RD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { pad: i6, strides: a, inputShape: l } = s;
  lt([o], "conv3dBackpropInputV2");
  const c = dt(o.shape), u = dt(r.shape), d = Js(l, r.shape, a, 1, i6), h = new ve(d.inShape, "float32"), p = h.values, [f, m, g, b] = h.strides, x6 = e.data.get(o.dataId).values, [w, y6, I, v] = c, k6 = e.data.get(r.dataId).values, [S, N, R, M6] = u, { batchSize: V, filterDepth: z, filterHeight: P, filterWidth: A, inChannels: O, inDepth: B6, inHeight: Z, inWidth: H6, outChannels: Y, outDepth: Q6, outHeight: j, outWidth: J6, strideDepth: ot, strideHeight: q, strideWidth: rt } = d, ht = z - 1 - d.padInfo.front, ft = P - 1 - d.padInfo.top, pt = A - 1 - d.padInfo.left;
  for (let wt2 = 0; wt2 < V; ++wt2)
    for (let It2 = 0; It2 < O; ++It2)
      for (let Et2 = 0; Et2 < B6; ++Et2) {
        const Pt = Et2 - ht, te = Math.max(0, Math.ceil(Pt / ot)), At2 = Math.min(Q6, (z + Pt) / ot);
        for (let Dt = 0; Dt < Z; ++Dt) {
          const Jt2 = Dt - ft, _t2 = Math.max(0, Math.ceil(Jt2 / q)), ls = Math.min(j, (P + Jt2) / q);
          for (let we2 = 0; we2 < H6; ++we2) {
            const $s = we2 - pt, an = Math.max(0, Math.ceil($s / rt)), ro = Math.min(J6, (A + $s) / rt);
            let Ln2 = 0;
            for (let cs = te; cs < At2; ++cs) {
              const Gs = cs * ot - Pt;
              for (let Es = _t2; Es < ls; ++Es) {
                const Ls = Es * q - Jt2;
                for (let Pr = an; Pr < ro; ++Pr) {
                  const Nu = Pr * rt - $s, Ru = w * wt2 + y6 * cs + I * Es + v * Pr, EC = S * (z - 1 - Gs) + N * (P - 1 - Ls) + R * (A - 1 - Nu) + M6 * It2;
                  for (let Ka = 0; Ka < Y; ++Ka) {
                    const LC = x6[Ru + Ka], MC = k6[EC + Ka];
                    Ln2 += LC * MC;
                  }
                }
              }
            }
            p[f * wt2 + m * Et2 + g * Dt + b * we2 + It2] = Ln2;
          }
        }
      }
  return e.makeTensorInfo(h.shape, h.dtype, h.values);
}
var $D = {
  kernelName: ch,
  backendName: "cpu",
  kernelFunc: RD
};
var GD = Wt(Mi, (n) => Math.cos(n));
var ED = {
  kernelName: Mi,
  backendName: "cpu",
  kernelFunc: GD
};
var LD = Wt(Wi, (n) => Math.cosh(n));
var MD = {
  kernelName: Wi,
  backendName: "cpu",
  kernelFunc: LD
};
function WD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { image: o, boxes: r, boxInd: i6 } = t, { cropSize: a, method: l, extrapolationValue: c } = s, [u, d, h, p] = o.shape, f = r.shape[0], [m, g] = a, b = vt([f, m, g, p], "float32"), x6 = e.data.get(r.dataId).values, w = e.data.get(i6.dataId).values, y6 = e.data.get(o.dataId).values, I = dt(o.shape), v = dt(b.shape);
  for (let k6 = 0; k6 < f; k6++) {
    const S = k6 * 4, N = x6[S], R = x6[S + 1], M6 = x6[S + 2], V = x6[S + 3], z = w[k6];
    if (z >= u)
      continue;
    const P = m > 1 ? (M6 - N) * (d - 1) / (m - 1) : 0, A = g > 1 ? (V - R) * (h - 1) / (g - 1) : 0;
    for (let O = 0; O < m; O++) {
      const B6 = m > 1 ? N * (d - 1) + O * P : 0.5 * (N + M6) * (d - 1);
      if (B6 < 0 || B6 > d - 1) {
        for (let Z = 0; Z < g; Z++)
          for (let H6 = 0; H6 < p; H6++) {
            const Y = H6 + Z * v[2] + O * v[1] + k6 * v[0];
            b.values[Y] = c;
          }
        continue;
      }
      if (l === "bilinear") {
        const Z = Math.floor(B6), H6 = Math.ceil(B6), Y = B6 - Z;
        for (let Q6 = 0; Q6 < g; Q6++) {
          const j = g > 1 ? R * (h - 1) + Q6 * A : 0.5 * (R + V) * (h - 1);
          if (j < 0 || j > h - 1) {
            for (let rt = 0; rt < p; rt++) {
              const ht = rt + Q6 * v[2] + O * v[1] + k6 * v[0];
              b.values[ht] = c;
            }
            continue;
          }
          const J6 = Math.floor(j), ot = Math.ceil(j), q = j - J6;
          for (let rt = 0; rt < p; rt++) {
            let ht = rt + J6 * I[2] + Z * I[1] + z * I[0];
            const ft = y6[ht];
            ht = rt + ot * I[2] + Z * I[1] + z * I[0];
            const pt = y6[ht];
            ht = rt + J6 * I[2] + H6 * I[1] + z * I[0];
            const wt2 = y6[ht];
            ht = rt + ot * I[2] + H6 * I[1] + z * I[0];
            const It2 = y6[ht], Et2 = ft + (pt - ft) * q, Pt = wt2 + (It2 - wt2) * q;
            ht = rt + Q6 * v[2] + O * v[1] + k6 * v[0], b.values[ht] = Et2 + (Pt - Et2) * Y;
          }
        }
      } else
        for (let Z = 0; Z < g; ++Z) {
          const H6 = g > 1 ? R * (h - 1) + Z * A : 0.5 * (R + V) * (h - 1);
          if (H6 < 0 || H6 > h - 1) {
            for (let j = 0; j < p; j++) {
              const J6 = j + Z * v[2] + O * v[1] + k6 * v[0];
              b.values[J6] = c;
            }
            continue;
          }
          const Y = Math.round(H6), Q6 = Math.round(B6);
          for (let j = 0; j < p; j++) {
            const J6 = j + Y * I[2] + Q6 * I[1] + z * I[0], ot = j + Z * v[2] + O * v[1] + k6 * v[0];
            b.values[ot] = y6[J6];
          }
        }
    }
  }
  return e.makeTensorInfo(b.shape, b.dtype, b.values);
}
var DD = {
  kernelName: dh,
  backendName: "cpu",
  kernelFunc: WD
};
function FD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  lt(o, "cumprod");
  const l = qt([r], o.shape.length);
  let c = o;
  l != null && (c = _e({ inputs: { x: o }, backend: e, attrs: { perm: l } }));
  const u = ie(1, o.shape.length)[0];
  if (u !== c.shape.length - 1)
    throw new Error(`backend.cumprod in CPU expects an inner-most axis=${c.shape.length - 1} but got axis=${u}`);
  const d = tn(c.dtype, "int32"), h = _l(X(c.shape), d), p = e.data.get(c.dataId).values, f = c.shape[c.shape.length - 1], m = a ? (b, x6) => b + f - x6 - 1 : (b, x6) => b + x6;
  for (let b = 0; b < p.length; b += f)
    for (let x6 = 0; x6 < f; x6++) {
      const w = m(b, x6);
      if (x6 === 0)
        h[w] = i6 ? 1 : p[w];
      else {
        const y6 = m(b, x6 - 1);
        h[w] = i6 ? p[y6] * h[y6] : p[w] * h[y6];
      }
    }
  const g = e.makeTensorInfo(c.shape, d, h);
  if (l != null) {
    const b = js(l), x6 = _e({ inputs: { x: g }, backend: e, attrs: { perm: b } });
    return e.disposeIntermediateTensorInfo(g), e.disposeIntermediateTensorInfo(c), x6;
  }
  return g;
}
var VD = {
  kernelName: uh,
  backendName: "cpu",
  kernelFunc: FD
};
function zD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  lt(o, "cumsum");
  const l = qt([r], o.shape.length);
  let c = o;
  l != null && (c = _e({ inputs: { x: o }, backend: e, attrs: { perm: l } }));
  const u = ie(1, o.shape.length)[0];
  if (u !== c.shape.length - 1)
    throw new Error(`backend.cumsum in CPU expects an inner-most axis=${c.shape.length - 1} but got axis=${u}`);
  const d = tn(c.dtype, "int32"), h = ke(X(c.shape), d), p = e.data.get(c.dataId).values, f = c.shape[c.shape.length - 1], m = a ? (b, x6) => b + f - x6 - 1 : (b, x6) => b + x6;
  for (let b = 0; b < p.length; b += f)
    for (let x6 = 0; x6 < f; x6++) {
      const w = m(b, x6);
      if (x6 === 0)
        h[w] = i6 ? 0 : p[w];
      else {
        const y6 = m(b, x6 - 1);
        h[w] = i6 ? p[y6] + h[y6] : p[w] + h[y6];
      }
    }
  const g = e.makeTensorInfo(c.shape, d, h);
  if (l != null) {
    const b = js(l), x6 = _e({ inputs: { x: g }, backend: e, attrs: { perm: b } });
    return e.disposeIntermediateTensorInfo(g), e.disposeIntermediateTensorInfo(c), x6;
  }
  return g;
}
var PD = {
  kernelName: ic,
  backendName: "cpu",
  kernelFunc: zD
};
function AD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6, binaryOutput: a } = s;
  if (o.shape.length === 1) {
    const l = e.data.get(o.dataId).values, c = e.data.get(r.dataId).values, u = Af(l, c, r.dtype, r.shape, i6);
    return e.makeTensorInfo([i6], r.dtype, u);
  } else if (o.shape.length === 2) {
    const l = e.bufferSync(o), c = e.bufferSync(r), u = K1(l, c, i6, a);
    return e.makeTensorInfo(u.shape, r.dtype, u.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${o.shape.length}.`);
}
var OD = {
  kernelName: hh,
  backendName: "cpu",
  kernelFunc: AD
};
function XD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockSize: r, dataFormat: i6 } = s;
  C(i6 === "NHWC", () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${i6}`);
  const a = o.shape[0], l = o.shape[1], c = o.shape[2], u = o.shape[3], d = l * r, h = c * r, p = u / (r * r), f = e.data.get(o.dataId).values, m = new Float32Array(a * d * h * p);
  let g = 0;
  for (let b = 0; b < a; ++b)
    for (let x6 = 0; x6 < d; ++x6) {
      const w = Math.floor(x6 / r), y6 = x6 % r;
      for (let I = 0; I < h; ++I) {
        const v = Math.floor(I / r), k6 = I % r, S = (y6 * r + k6) * p;
        for (let N = 0; N < p; ++N) {
          const M6 = N + S + u * (v + c * (w + l * b));
          m[g++] = f[M6];
        }
      }
    }
  return e.makeTensorInfo([a, d, h, p], o.dtype, m);
}
var KD = {
  kernelName: ph,
  backendName: "cpu",
  kernelFunc: XD
};
function Kw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l, dimRoundingMode: c } = s;
  lt([o, r], "depthwiseConv2DNative");
  const u = dt(o.shape), d = dt(r.shape);
  let h = l;
  h == null && (h = [1, 1]), C(Le(i6, h), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i6} and dilations '${h}'`);
  const p = Te(
    o.shape,
    r.shape,
    i6,
    h,
    a,
    c,
    true
    /* depthwise */
  ), { filterHeight: f, filterWidth: m, dilationHeight: g, dilationWidth: b, padInfo: x6 } = p, w = x6.left, y6 = x6.top, I = p.outChannels / p.inChannels, v = new ve(p.outShape, o.dtype), k6 = e.data.get(o.dataId).values, S = e.data.get(r.dataId).values, N = v.values;
  for (let R = 0; R < p.batchSize; ++R) {
    const M6 = R * u[0], V = R * v.strides[0];
    for (let z = 0; z < p.outHeight; ++z) {
      const P = V + z * v.strides[1], A = z * p.strideHeight - y6;
      for (let O = 0; O < f; ++O) {
        const B6 = A + O * g;
        if (B6 < 0 || B6 >= p.inHeight)
          continue;
        const Z = O * d[0], H6 = M6 + B6 * u[1];
        for (let Y = 0; Y < p.outWidth; ++Y) {
          const Q6 = P + Y * v.strides[2], j = Y * p.strideWidth - w;
          for (let J6 = 0; J6 < m; ++J6) {
            const ot = j + J6 * b;
            if (ot < 0 || ot >= p.inWidth)
              continue;
            const q = Z + J6 * d[1], rt = H6 + ot * p.inChannels;
            let ht = Q6, ft = q;
            for (let pt = 0; pt < p.inChannels; ++pt) {
              const wt2 = k6[rt + pt];
              for (let It2 = 0; It2 < I; ++It2)
                N[ht + It2] += wt2 * S[ft + It2];
              ht += I, ft += I;
            }
          }
        }
      }
    }
  }
  return e.makeTensorInfo(v.shape, v.dtype, v.values);
}
var ZD = {
  kernelName: ac,
  backendName: "cpu",
  kernelFunc: Kw
};
function BD(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, filterShape: u } = s;
  lt([o, r], "depthwiseConv2dNativeBackpropFilter");
  const d = Te(
    o.shape,
    u,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), { strideHeight: h, strideWidth: p, filterHeight: f, filterWidth: m } = d, g = new ve(d.filterShape, "float32"), b = d.padInfo.left, x6 = d.padInfo.top, w = d.outChannels / d.inChannels, y6 = e.data.get(o.dataId).values, I = new ve(o.shape, o.dtype, y6), v = e.data.get(r.dataId).values, k6 = new ve(r.shape, r.dtype, v);
  for (let S = 0; S < f; ++S) {
    const N = Math.max(0, Math.ceil((x6 - S) / h)), R = Math.min(d.outHeight, (d.inHeight + x6 - S) / h);
    for (let M6 = 0; M6 < m; ++M6) {
      const V = Math.max(0, Math.ceil((b - M6) / p)), z = Math.min(d.outWidth, (d.inWidth + b - M6) / p);
      for (let P = 0; P < d.outChannels; ++P) {
        const A = Math.trunc(P / w), O = P % w;
        let B6 = 0;
        for (let Z = 0; Z < d.batchSize; ++Z)
          for (let H6 = N; H6 < R; ++H6) {
            const Y = S + H6 * h - x6;
            for (let Q6 = V; Q6 < z; ++Q6) {
              const j = M6 + Q6 * p - b;
              B6 += I.get(Z, Y, j, A) * k6.get(Z, H6, Q6, P);
            }
          }
        g.set(B6, S, M6, A, O);
      }
    }
  }
  return e.makeTensorInfo(g.shape, g.dtype, g.values);
}
var HD = {
  kernelName: fh,
  backendName: "cpu",
  kernelFunc: BD
};
function _D(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, inputShape: u } = s;
  lt([o, r], "depthwiseConv2DNativeBackpropInput");
  const d = dt(o.shape), h = dt(r.shape), p = Te(
    u,
    r.shape,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), f = new ve(p.inShape, "float32"), m = f.values, [g, b, x6] = f.strides, w = e.data.get(o.dataId).values, [y6, I, v] = d, k6 = e.data.get(r.dataId).values, [S, N, R] = h, { batchSize: M6, filterHeight: V, filterWidth: z, inChannels: P, inHeight: A, inWidth: O, outChannels: B6, outHeight: Z, outWidth: H6, strideHeight: Y, strideWidth: Q6 } = p, j = V - 1 - p.padInfo.top, J6 = z - 1 - p.padInfo.left, ot = B6 / P;
  for (let q = 0; q < M6; ++q)
    for (let rt = 0; rt < P; ++rt)
      for (let ht = 0; ht < A; ++ht) {
        const ft = ht - j, pt = Math.max(0, Math.ceil(ft / Y)), wt2 = Math.min(Z, (V + ft) / Y);
        for (let It2 = 0; It2 < O; ++It2) {
          const Et2 = It2 - J6, Pt = Math.max(0, Math.ceil(Et2 / Q6)), te = Math.min(H6, (z + Et2) / Q6);
          let At2 = 0;
          for (let Dt = pt; Dt < wt2; ++Dt) {
            const Jt2 = Dt * Y - ft;
            for (let _t2 = Pt; _t2 < te; ++_t2) {
              const ls = _t2 * Q6 - Et2, we2 = y6 * q + I * Dt + v * _t2, $s = S * (V - 1 - Jt2) + N * (z - 1 - ls) + R * rt;
              for (let an = 0; an < ot; ++an) {
                const ro = rt * ot + an, Ln2 = w[we2 + ro], cs = k6[$s + an];
                At2 += Ln2 * cs;
              }
            }
          }
          m[g * q + b * ht + x6 * It2 + rt] = At2;
        }
      }
  return e.makeTensorInfo(f.shape, f.dtype, f.values);
}
var UD = {
  kernelName: mh,
  backendName: "cpu",
  kernelFunc: _D
};
function YD(n) {
  const { inputs: t, backend: e } = n, { x: s } = t, o = X(s.shape), r = e.data.get(s.dataId).values, i6 = vt([o, o], s.dtype), a = i6.values;
  for (let c = 0; c < r.length; c++)
    a[c * o + c] = r[c];
  const l = [...s.shape, ...s.shape];
  return e.makeTensorInfo(l, i6.dtype, i6.values);
}
var QD = {
  kernelName: ub,
  backendName: "cpu",
  kernelFunc: YD
};
var JD = {
  kernelName: lc,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t, attrs: e }) => {
    const { x: s, filter: o } = n, { strides: r, pad: i6, dilations: a } = e, l = t, c = l.data.get(s.dataId).values, u = s.shape.length, d = l.data.get(o.dataId).values, h = o.shape.length, { batchSize: p, inHeight: f, inWidth: m, inChannels: g, outHeight: b, outWidth: x6, padInfo: w, strideHeight: y6, strideWidth: I, filterHeight: v, filterWidth: k6, dilationHeight: S, dilationWidth: N, outShape: R } = Ia(s.shape, o.shape, r, i6, "NHWC", a), M6 = X(R), V = R.length, z = ne(s.dtype, M6);
    for (let A = 0; A < p; ++A)
      for (let O = 0; O < b; ++O) {
        const B6 = O * y6 - w.top;
        for (let Z = 0; Z < x6; ++Z) {
          const H6 = Z * I - w.left;
          for (let Y = 0; Y < g; ++Y) {
            let Q6 = Number.MIN_SAFE_INTEGER;
            for (let J6 = 0; J6 < v; ++J6) {
              const ot = B6 + J6 * S;
              if (ot >= 0 && ot < f)
                for (let q = 0; q < k6; ++q) {
                  const rt = H6 + q * N;
                  if (rt >= 0 && rt < m) {
                    const ht = zn([A, ot, rt, Y], u, dt(s.shape)), ft = zn([J6, q, Y], h, dt(o.shape)), pt = c[ht] + d[ft];
                    pt > Q6 && (Q6 = pt);
                  }
                }
            }
            const j = zn([A, O, Z, Y], V, dt(R));
            z[j] = Q6;
          }
        }
      }
    return { dataId: l.write(Qs(z, s.dtype), R, s.dtype), shape: R, dtype: s.dtype };
  }
};
var jD = {
  kernelName: ld,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t, attrs: e }) => {
    const { x: s, filter: o, dy: r } = n, { strides: i6, pad: a, dilations: l } = e, c = t, u = kn(s.shape, c.data.get(s.dataId).values), d = kn(o.shape, c.data.get(o.dataId).values), { batchSize: h, inHeight: p, inWidth: f, inChannels: m, outHeight: g, outWidth: b, padInfo: x6, strideHeight: w, strideWidth: y6, filterHeight: I, filterWidth: v, dilationHeight: k6, dilationWidth: S, outShape: N } = Ia(s.shape, o.shape, i6, a, "NHWC", l);
    C(r.rank === N.length, () => `Error in ${ld}, dy must have the same rank as output ${N.length}, but got ${r.rank}`);
    const R = kn(N, c.data.get(r.dataId).values), M6 = Jd(o.shape, o.dtype);
    for (let z = 0; z < h; ++z)
      for (let P = 0; P < g; ++P) {
        const A = P * w - x6.top;
        for (let O = 0; O < b; ++O) {
          const B6 = O * y6 - x6.left;
          for (let Z = 0; Z < m; ++Z) {
            let H6 = Number.MIN_SAFE_INTEGER, Y = 0, Q6 = 0;
            for (let j = 0; j < I; ++j) {
              const J6 = A + j * k6;
              if (J6 >= 0 && J6 < p)
                for (let ot = 0; ot < v; ++ot) {
                  const q = B6 + ot * S;
                  if (q >= 0 && q < f) {
                    const rt = u[z][J6][q][Z] + d[j][ot][Z];
                    rt > H6 && (H6 = rt, Y = j, Q6 = ot);
                  }
                }
            }
            M6[Y][Q6][Z] += R[z][P][O][Z];
          }
        }
      }
    return { dataId: c.write(Qs(M6, s.dtype), o.shape, o.dtype), shape: o.shape, dtype: o.dtype };
  }
};
var qD = {
  kernelName: ad,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t, attrs: e }) => {
    const { x: s, filter: o, dy: r } = n, { strides: i6, pad: a, dilations: l } = e, c = t, u = kn(s.shape, c.data.get(s.dataId).values), d = kn(o.shape, c.data.get(o.dataId).values), { batchSize: h, inHeight: p, inWidth: f, inChannels: m, outHeight: g, outWidth: b, padInfo: x6, strideHeight: w, strideWidth: y6, filterHeight: I, filterWidth: v, dilationHeight: k6, dilationWidth: S, outShape: N } = Ia(s.shape, o.shape, i6, a, "NHWC", l);
    C(r.rank === N.length, () => `Error in ${ad}, dy must have the same rank as output ${N.length}, but got ${r.rank}`);
    const R = kn(N, c.data.get(r.dataId).values), M6 = Jd(s.shape, s.dtype);
    for (let z = 0; z < h; ++z)
      for (let P = 0; P < g; ++P) {
        const A = P * w - x6.top;
        for (let O = 0; O < b; ++O) {
          const B6 = O * y6 - x6.left;
          for (let Z = 0; Z < m; ++Z) {
            let H6 = Number.MIN_SAFE_INTEGER, Y = A < 0 ? 0 : A, Q6 = B6 < 0 ? 0 : B6;
            for (let j = 0; j < I; ++j) {
              const J6 = A + j * k6;
              if (J6 >= 0 && J6 < p)
                for (let ot = 0; ot < v; ++ot) {
                  const q = B6 + ot * S;
                  if (q >= 0 && q < f) {
                    const rt = u[z][J6][q][Z] + d[j][ot][Z];
                    rt > H6 && (H6 = rt, Y = J6, Q6 = q);
                  }
                }
            }
            M6[z][Y][Q6][Z] += R[z][P][O][Z];
          }
        }
      }
    return { dataId: c.write(Qs(M6, s.dtype), s.shape, s.dtype), shape: s.shape, dtype: s.dtype };
  }
};
function tF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { image: o } = t, { canvas: r, options: i6 } = s, { contextOptions: a, imageOptions: l } = i6 || {}, c = (l == null ? void 0 : l.alpha) || 1, u = (a == null ? void 0 : a.contextType) || "2d";
  if (u !== "2d")
    throw new Error(`Context type ${a.contextType} is not supported by the CPU backend.`);
  const d = r.getContext(u, (a == null ? void 0 : a.contextAttributes) || {});
  if (d == null)
    throw new Error(`Could not get the context with ${u} type.`);
  const [h, p] = o.shape.slice(0, 2), f = o.shape.length === 2 ? 1 : o.shape[2], m = e.data.get(o.dataId).values, g = o.dtype === "float32" ? 255 : 1, b = new Uint8ClampedArray(p * h * 4);
  for (let w = 0; w < h * p; ++w) {
    const y6 = [0, 0, 0, 255 * c];
    for (let v = 0; v < f; v++) {
      const k6 = m[w * f + v];
      if (o.dtype === "float32") {
        if (k6 < 0 || k6 > 1)
          throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${k6}.`);
      } else if (o.dtype === "int32" && (k6 < 0 || k6 > 255))
        throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${k6}.`);
      f === 1 ? (y6[0] = k6 * g, y6[1] = k6 * g, y6[2] = k6 * g) : y6[v] = k6 * g;
    }
    const I = w * 4;
    b[I + 0] = Math.round(y6[0]), b[I + 1] = Math.round(y6[1]), b[I + 2] = Math.round(y6[2]), b[I + 3] = Math.round(y6[3]);
  }
  r.width = p, r.height = h;
  const x6 = new ImageData(b, p, h);
  return d.putImageData(x6, 0, 0), o;
}
var eF = {
  kernelName: gh,
  backendName: "cpu",
  kernelFunc: tF
};
function za(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  lt(o, "sum");
  let a;
  o.dtype === "bool" ? a = Ys({ inputs: { x: o }, backend: e, attrs: { dtype: "int32" } }) : a = rs({ inputs: { x: o }, backend: e });
  const l = a.shape.length, c = Ct(r, a.shape), u = qt(c, l);
  let d = c, h = a;
  u != null && (h = _e({ inputs: { x: a }, backend: e, attrs: { perm: u } }), d = ie(d.length, l)), Ne("sum", d, h.shape.length);
  const [p, f] = ye(h.shape, d), m = tn(h.dtype, "int32");
  let g = Fl(e, p, m);
  const b = X(f), x6 = e.data.get(g.dataId).values, w = e.data.get(h.dataId).values;
  for (let y6 = 0; y6 < x6.length; ++y6) {
    const I = y6 * b;
    let v = 0;
    for (let k6 = 0; k6 < b; ++k6)
      v += w[I + k6];
    x6[y6] = v;
  }
  if (i6) {
    const y6 = re(g.shape, c), I = g;
    g = Zt({ inputs: { x: g }, backend: e, attrs: { shape: y6 } }), e.disposeIntermediateTensorInfo(I);
  }
  return e.disposeIntermediateTensorInfo(a), u != null && e.disposeIntermediateTensorInfo(h), g;
}
var nF = {
  kernelName: Oc,
  backendName: "cpu",
  kernelFunc: za
};
function sF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { equation: o } = s, r = t, { allDims: i6, summedDims: a, idDims: l } = lf(o, r.length);
  uf(i6.length, l, r);
  const { path: c, steps: u } = df(a, l), d = u.length;
  let h = null, p = i6.length;
  const f = [];
  for (let m = 0; m < d; ++m) {
    for (const g of u[m]) {
      const { permutationIndices: b, expandDims: x6 } = cf(p, l[g]);
      let w;
      hf(b) ? w = r[g] : (w = _e({ inputs: { x: r[g] }, backend: e, attrs: { perm: b } }), f.push(w));
      const y6 = w.shape.slice();
      for (let I = 0; I < x6.length; ++I)
        y6.splice(x6[I], 0, 1);
      $t(w.shape, y6) || (w = Zt({ inputs: { x: w }, backend: e, attrs: { shape: y6 } }), f.push(w)), h === null ? h = w : (h = wu({ inputs: { a: w, b: h }, backend: e }), f.push(h));
    }
    m < d - 1 && (c[m] >= 0 && (h = za({
      inputs: { x: h },
      backend: e,
      attrs: {
        axis: c[m] - (i6.length - p),
        keepDims: false
      }
    }), f.push(h)), p--);
  }
  for (const m of f)
    m !== h && e.disposeIntermediateTensorInfo(m);
  return h;
}
var oF = {
  kernelName: bh,
  backendName: "cpu",
  kernelFunc: sF
};
function rF(n) {
  const { inputs: t, backend: e } = n, { dy: s, y: o } = t;
  lt([s, o], "eluGrad");
  const r = new Float32Array(X(o.shape)), i6 = e.data.get(o.dataId).values, a = e.data.get(s.dataId).values;
  for (let l = 0; l < i6.length; ++l) {
    const c = i6[l];
    c >= 0 ? r[l] = a[l] : r[l] = a[l] * (c + 1);
  }
  return e.makeTensorInfo(o.shape, "float32", r);
}
var iF = {
  kernelName: xh,
  backendName: "cpu",
  kernelFunc: rF
};
var aF = tf;
var lF = ef;
var cF = nf;
var uF = sf;
var dF = of;
var hF = rf;
var pF = Wt(Vi, (n) => {
  const t = Math.sign(n), e = Math.abs(n), s = 1 / (1 + aF * e);
  return t * (1 - ((((hF * s + dF) * s + uF) * s + cF) * s + lF) * s * Math.exp(-e * e));
});
var fF = {
  kernelName: Vi,
  backendName: "cpu",
  kernelFunc: pF
};
function Pl(n) {
  const { inputs: t, backend: e, attrs: s } = n, { input: o } = t, { dim: r } = s, i6 = o.shape.length, a = o.shape.slice();
  let l = r;
  return r < 0 && (C(-(i6 + 1) <= r, () => `Axis must be in the interval [${-(i6 + 1)}, ${i6}]`), l = i6 + r + 1), a.splice(l, 0, 1), Zt({ inputs: { x: o }, backend: e, attrs: { shape: a } });
}
var mF = {
  kernelName: uc,
  backendName: "cpu",
  kernelFunc: Pl
};
var gF = le((n, t) => n / t);
var Hf = fe(Di, gF);
var Fd = {
  kernelName: Di,
  backendName: "cpu",
  kernelFunc: Hf
};
function Zw(n, t, e) {
  const s = n.shape, o = s[0], r = s[1], i6 = e.data.get(n.dataId), a = i6.complexTensorInfos.real, l = i6.complexTensorInfos.imag, c = [o, r], u = X(c), d = Se("float32", u), h = Se("float32", u);
  for (let g = 0; g < o; g++) {
    const b = Fo({
      inputs: { x: a },
      backend: e,
      attrs: { begin: [g, 0], size: [1, r] }
    }), x6 = Fo({
      inputs: { x: l },
      backend: e,
      attrs: { begin: [g, 0], size: [1, r] }
    }), w = Je({ inputs: { real: b, imag: x6 }, backend: e }), { real: y6, imag: I } = bF(w, t, e), v = xs(y6, I);
    for (let k6 = 0; k6 < r; k6++) {
      const S = af(v, k6);
      d[g * r + k6] = S.real, h[g * r + k6] = S.imag;
    }
    e.disposeIntermediateTensorInfo(b), e.disposeIntermediateTensorInfo(x6), e.disposeIntermediateTensorInfo(w);
  }
  const p = e.makeTensorInfo(c, "float32", d), f = e.makeTensorInfo(c, "float32", h), m = Je({ inputs: { real: p, imag: f }, backend: e });
  return e.disposeIntermediateTensorInfo(p), e.disposeIntermediateTensorInfo(f), m;
}
function bF(n, t, e) {
  const s = X(n.shape), o = e.data.get(n.dataId), r = e.data.get(o.complexTensorInfos.real.dataId).values, i6 = e.data.get(o.complexTensorInfos.imag.dataId).values;
  if (xF(s)) {
    const a = Vd(r, i6, s, t, e), l = [n.shape[0], n.shape[1]];
    if (t) {
      const c = e.makeTensorInfo(l, "float32", a.real), u = e.makeTensorInfo(l, "float32", a.imag), d = e.makeTensorInfo([], "float32", Is(s, "float32")), h = rs({ inputs: { x: d }, backend: e }), p = Fd.kernelFunc({ inputs: { a: c, b: d }, backend: e }), f = Fd.kernelFunc({ inputs: { a: u, b: h }, backend: e }), m = e.data.get(p.dataId).values, g = e.data.get(f.dataId).values;
      return e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(u), e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(h), e.disposeIntermediateTensorInfo(p), e.disposeIntermediateTensorInfo(f), { real: m, imag: g };
    }
    return a;
  } else {
    const a = xs(r, i6), l = yF(a, s, t);
    return j0(l);
  }
}
function xF(n) {
  return (n & n - 1) === 0;
}
function Vd(n, t, e, s, o) {
  if (e === 1)
    return { real: n, imag: t };
  const r = xs(n, t), i6 = e / 2, a = q0(r), l = a.real, c = a.imag, u = [l.length], d = o.makeTensorInfo(u, "float32", l), h = o.makeTensorInfo(u, "float32", c), p = Je({ inputs: { real: d, imag: h }, backend: o }), f = tx(r), m = f.real, g = f.imag, b = [m.length], x6 = o.makeTensorInfo(b, "float32", m), w = o.makeTensorInfo(b, "float32", g), y6 = Je({ inputs: { real: x6, imag: w }, backend: o }), I = Vd(l, c, i6, s, o), v = I.real, k6 = I.imag, S = [v.length], N = o.makeTensorInfo(S, "float32", v), R = o.makeTensorInfo(S, "float32", k6), M6 = Je({
    inputs: { real: N, imag: R },
    backend: o
  }), V = Vd(m, g, i6, s, o), z = V.real, P = V.imag, A = [z.length], O = o.makeTensorInfo(A, "float32", z), B6 = o.makeTensorInfo(A, "float32", P), Z = Je({ inputs: { real: O, imag: B6 }, backend: o }), H6 = nx(e, s), Y = [H6.real.length], Q6 = o.makeTensorInfo(Y, "float32", H6.real), j = o.makeTensorInfo(Y, "float32", H6.imag), J6 = Je({ inputs: { real: Q6, imag: j }, backend: o }), ot = wu({ inputs: { a: J6, b: Z }, backend: o }), q = wr({
    inputs: { a: M6, b: ot },
    backend: o
  }), rt = Zf({
    inputs: { a: M6, b: ot },
    backend: o
  }), ht = Do({ inputs: { input: q }, backend: o }), ft = Do({ inputs: { input: rt }, backend: o }), pt = Ir({ inputs: { input: q }, backend: o }), wt2 = Ir({ inputs: { input: rt }, backend: o }), It2 = Cr({
    inputs: [ht, ft],
    backend: o,
    attrs: { axis: 0 }
  }), Et2 = Cr({
    inputs: [pt, wt2],
    backend: o,
    attrs: { axis: 0 }
  }), Pt = o.data.get(It2.dataId).values, te = o.data.get(Et2.dataId).values;
  return o.disposeIntermediateTensorInfo(d), o.disposeIntermediateTensorInfo(h), o.disposeIntermediateTensorInfo(p), o.disposeIntermediateTensorInfo(x6), o.disposeIntermediateTensorInfo(w), o.disposeIntermediateTensorInfo(y6), o.disposeIntermediateTensorInfo(N), o.disposeIntermediateTensorInfo(R), o.disposeIntermediateTensorInfo(M6), o.disposeIntermediateTensorInfo(O), o.disposeIntermediateTensorInfo(B6), o.disposeIntermediateTensorInfo(Z), o.disposeIntermediateTensorInfo(Q6), o.disposeIntermediateTensorInfo(j), o.disposeIntermediateTensorInfo(J6), o.disposeIntermediateTensorInfo(ot), o.disposeIntermediateTensorInfo(q), o.disposeIntermediateTensorInfo(rt), o.disposeIntermediateTensorInfo(ht), o.disposeIntermediateTensorInfo(pt), o.disposeIntermediateTensorInfo(ft), o.disposeIntermediateTensorInfo(wt2), o.disposeIntermediateTensorInfo(It2), o.disposeIntermediateTensorInfo(Et2), { real: Pt, imag: te };
}
function yF(n, t, e) {
  const s = new Float32Array(t * 2);
  for (let o = 0; o < t; o++) {
    let r = 0, i6 = 0;
    for (let a = 0; a < t; a++) {
      const l = sx(o * a, t, e), c = af(n, a);
      r += c.real * l.real - c.imag * l.imag, i6 += c.real * l.imag + c.imag * l.real;
    }
    e && (r /= t, i6 /= t), ex(s, r, i6, o);
  }
  return s;
}
function wF(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = X(s.shape), r = s.shape[s.shape.length - 1], i6 = o / r, a = Zt({
    inputs: { x: s },
    backend: e,
    attrs: { shape: [i6, r] }
  }), l = Zw(a, false, e), c = Zt({ inputs: { x: l }, backend: e, attrs: { shape: s.shape } });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(l), c;
}
var IF = {
  kernelName: yh,
  backendName: "cpu",
  kernelFunc: wF
};
function _f(n) {
  const { backend: t, attrs: e } = n, { shape: s, value: o, dtype: r } = e, i6 = r || Oo(o), a = ne(i6, X(s));
  return vF(a, o, i6), t.makeTensorInfo(s, i6, a);
}
var CF = {
  kernelName: wh,
  backendName: "cpu",
  kernelFunc: _f
};
function vF(n, t, e) {
  n.fill(t);
}
var SF = {
  kernelName: Ih,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { image: s } = n, o = e, r = Se(s.dtype, X(s.shape)), [i6, a, l, c] = s.shape, u = o.data.get(s.dataId).values;
    for (let h = 0; h < i6; h++) {
      const p = h * l * a * c;
      for (let f = 0; f < a; f++) {
        const m = f * (l * c);
        for (let g = 0; g < l; g++) {
          const b = g * c;
          for (let x6 = 0; x6 < c; x6++) {
            const w = Math.round(l - g - 1), y6 = p + m + b + x6;
            let I = u[y6];
            if (w >= 0 && w < l) {
              const v = w * c, k6 = p + m + v + x6;
              I = u[k6];
            }
            r[y6] = I;
          }
        }
      }
    }
    return { dataId: o.write(r, s.shape, s.dtype), shape: s.shape, dtype: s.dtype };
  }
};
function kF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h, activation: p, leakyreluAlpha: f } = s;
  let m = Xw({
    inputs: { x: o, filter: r },
    backend: e,
    attrs: { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h }
  });
  if (i6) {
    const g = m;
    if (u === "NCHW" && i6.shape.length === 1 && i6.shape[0] !== 1) {
      const b = Zt({ inputs: { x: i6 }, backend: e, attrs: { shape: [i6.shape[0], 1, 1] } });
      m = wr({ inputs: { a: m, b }, backend: e }), e.disposeIntermediateTensorInfo(b);
    } else
      m = wr({ inputs: { a: m, b: i6 }, backend: e });
    e.disposeIntermediateTensorInfo(g);
  }
  if (p) {
    const g = m;
    if (u === "NCHW" && p === "prelu" && a.shape.length === 1 && a.shape[0] !== 1) {
      const b = Zt({
        inputs: { x: a },
        backend: e,
        attrs: { shape: [a.shape[0], 1, 1] }
      });
      m = zl(e, m, p, b, f), e.disposeIntermediateTensorInfo(b);
    } else
      m = zl(e, m, p, a, f);
    e.disposeIntermediateTensorInfo(g);
  }
  return m;
}
var TF = {
  kernelName: gl,
  backendName: "cpu",
  kernelFunc: kF
};
function NF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h, activation: p, leakyreluAlpha: f } = s;
  let m = Kw({
    inputs: { x: o, filter: r },
    backend: e,
    attrs: { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h }
  });
  if (i6) {
    const g = m;
    m = wr({ inputs: { a: m, b: i6 }, backend: e }), e.disposeIntermediateTensorInfo(g);
  }
  if (p) {
    const g = m;
    m = zl(e, m, p, a, f), e.disposeIntermediateTensorInfo(g);
  }
  return m;
}
var RF = {
  kernelName: Cb,
  backendName: "cpu",
  kernelFunc: NF
};
function $F(n) {
  const { inputs: t, backend: e } = n, { params: s, indices: o } = t, r = X(s.shape), i6 = o.shape, a = i6[i6.length - 1], [l, c, u, d] = eu(s, o);
  if (c === 0)
    return e.makeTensorInfo(l, s.dtype, []);
  const h = e.data.get(o.dataId).values, p = e.bufferSync(s), f = tw(h, p, s.dtype, c, a, u, d, s.shape, r);
  return e.makeTensorInfo(l, s.dtype, f.values);
}
var GF = {
  kernelName: db,
  backendName: "cpu",
  kernelFunc: $F
};
function EF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, indices: r } = t, { axis: i6, batchDims: a } = s;
  lt([o, r], "gatherV2");
  const l = Ct(i6, o.shape)[0], c = e.data.get(r.dataId).values, u = o.shape[l];
  for (let y6 = 0; y6 < c.length; ++y6) {
    const I = c[y6];
    C(I <= u - 1 && I >= 0, () => `GatherV2: the index value ${I} is not in [0, ${u - 1}]`);
  }
  let d = a;
  a == null && (d = 0);
  const h = X(r.shape), p = ff(o, r, l, d), f = Zt({
    inputs: { x: o },
    backend: e,
    attrs: {
      shape: [
        p.batchSize,
        p.outerSize,
        p.dimSize,
        p.sliceSize
      ]
    }
  }), m = Zt({
    inputs: { x: r },
    backend: e,
    attrs: { shape: [p.batchSize, h / p.batchSize] }
  }), g = [
    p.batchSize,
    p.outerSize,
    h / p.batchSize,
    p.sliceSize
  ], b = e.bufferSync(m), x6 = e.bufferSync(f), w = ew(x6, b, g);
  return e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(m), e.makeTensorInfo(p.outputShape, w.dtype, w.values);
}
var LF = {
  kernelName: hc,
  backendName: "cpu",
  kernelFunc: EF
};
function MF(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = X(s.shape), r = s.shape[s.shape.length - 1], i6 = o / r, a = Zt({
    inputs: { x: s },
    backend: e,
    attrs: { shape: [i6, r] }
  }), l = Zw(a, true, e), c = Zt({ inputs: { x: l }, backend: e, attrs: { shape: s.shape } });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(l), c;
}
var WF = {
  kernelName: Ch,
  backendName: "cpu",
  kernelFunc: MF
};
var DF = Wt(Zi, (n) => Number.isFinite(n) ? 1 : 0, "bool");
var FF = {
  kernelName: Zi,
  backendName: "cpu",
  kernelFunc: DF
};
var VF = Wt(Bi, (n) => Math.abs(n) === 1 / 0 ? 1 : 0, "bool");
var zF = {
  kernelName: Bi,
  backendName: "cpu",
  kernelFunc: VF
};
var PF = Wt(Hi, (n) => Number.isNaN(n) ? 1 : 0, "bool");
var AF = {
  kernelName: Hi,
  backendName: "cpu",
  kernelFunc: PF
};
function OF(n) {
  const { backend: t, attrs: e } = n, { start: s, stop: o, num: r } = e, i6 = iw(s, o, r);
  return t.makeTensorInfo([i6.length], "float32", i6);
}
var XF = {
  kernelName: hb,
  backendName: "cpu",
  kernelFunc: OF
};
var KF = Wt(Ui, (n) => Math.log1p(n));
var ZF = {
  kernelName: Ui,
  backendName: "cpu",
  kernelFunc: KF
};
var BF = le((n, t) => n && t);
var HF = fe(bc, BF, null, "bool");
var _F = {
  kernelName: bc,
  backendName: "cpu",
  kernelFunc: HF
};
var UF = Wt(xc, (n) => n ? 0 : 1, "bool");
var YF = {
  kernelName: xc,
  backendName: "cpu",
  kernelFunc: UF
};
var QF = le((n, t) => n || t);
var JF = fe(yc, QF, null, "bool");
var jF = {
  kernelName: yc,
  backendName: "cpu",
  kernelFunc: JF
};
function qF(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { depthRadius: r, bias: i6, alpha: a, beta: l } = s;
  lt(o, "LRN");
  const c = o.shape[3], u = c - 1, d = e.data.get(o.dataId).values, h = X(o.shape), p = new Float32Array(h);
  function f(m) {
    const g = m % c;
    let b = m - g + Math.max(0, g - r);
    const x6 = m - g + Math.min(g + r, u);
    let w = 0;
    for (; b <= x6; b++) {
      const y6 = d[b];
      w += y6 * y6;
    }
    return w;
  }
  for (let m = 0; m < h; m++) {
    const g = f(m), b = d[m] * Math.pow(i6 + a * g, -l);
    p[m] = b;
  }
  return e.makeTensorInfo(o.shape, o.dtype, p);
}
var tV = {
  kernelName: wc,
  backendName: "cpu",
  kernelFunc: qF
};
function eV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, y: r, dy: i6 } = t, { depthRadius: a, bias: l, alpha: c, beta: u } = s;
  lt(i6, "LRNGrad");
  const d = X(i6.shape), h = i6.shape[3], p = e.data.get(i6.dataId).values, f = e.data.get(o.dataId).values, m = e.data.get(r.dataId).values, g = new Float32Array(d), b = d;
  for (let x6 = 0; x6 < b; x6++) {
    const w = x6 % h, y6 = x6 - w + Math.max(0, w - a), I = x6 - w + Math.min(h, w + a + 1);
    let v = 0;
    for (let k6 = y6; k6 < I; k6++)
      v += Math.pow(f[k6], 2);
    v = c * v + l;
    for (let k6 = y6; k6 < I; k6++) {
      let S = -2 * c * u * f[k6] * m[x6] / v;
      x6 === k6 && (S += Math.pow(v, -u)), S *= p[x6], g[k6] += S;
    }
  }
  return e.makeTensorInfo(i6.shape, o.dtype, g);
}
var nV = {
  kernelName: Sh,
  backendName: "cpu",
  kernelFunc: eV
};
function Bw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reductionIndices: r, keepDims: i6 } = s, a = e;
  let l = o.shape;
  const c = l.length, u = Ct(r, l);
  let d = u;
  const h = qt(d, c);
  let p = a.data.get(o.dataId).values;
  if (h != null) {
    const y6 = new Array(c);
    for (let I = 0; I < y6.length; I++)
      y6[I] = l[h[I]];
    p = Xf(p, l, o.dtype, h, y6), d = ie(d.length, c), l = y6;
  }
  lt(o, "max"), Ne("max", d, c);
  const [f, m] = ye(l, d), g = X(m), b = lw(p, g, f, o.dtype), x6 = a.write(b, f, o.dtype);
  let w = f;
  return i6 && (w = re(f, u)), { dataId: x6, shape: w, dtype: o.dtype };
}
var sV = {
  kernelName: Ic,
  backendName: "cpu",
  kernelFunc: Bw
};
function oV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  lt(o, "maxPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  C(Le(i6, c), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  let d;
  if (u.filterWidth === 1 && u.filterHeight === 1 && $t(u.inShape, u.outShape))
    d = rs({ inputs: { x: o }, backend: e });
  else {
    const h = e.data.get(o.dataId).values, p = dt(o.shape), f = Bf(h, o.shape, o.dtype, p, u, "max");
    d = e.makeTensorInfo(u.outShape, o.dtype, f.values);
  }
  return d;
}
var rV = {
  kernelName: Cc,
  backendName: "cpu",
  kernelFunc: oV
};
function iV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l, dataFormat: c } = s;
  lt(o, "maxPool3d");
  const u = vs(o.shape, r, i6, 1, a, l, c), d = e.data.get(o.dataId).values, h = Ow(d, o.shape, o.dtype, dt(o.shape), u, "max");
  return e.makeTensorInfo(h.shape, "float32", h.values);
}
var aV = {
  kernelName: vc,
  backendName: "cpu",
  kernelFunc: iV
};
function lV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, { filterSize: i6, strides: a, pad: l, dimRoundingMode: c } = s;
  lt([o, r], "maxPool3DGrad");
  const u = vs(r.shape, i6, a, 1, l, c), d = e.bufferSync(r), h = QW(d, u), p = u.strideDepth, f = u.strideHeight, m = u.strideWidth, g = u.dilationDepth, b = u.dilationHeight, x6 = u.dilationWidth, w = u.effectiveFilterDepth, y6 = u.effectiveFilterHeight, I = u.effectiveFilterWidth, v = w - 1 - u.padInfo.front, k6 = I - 1 - u.padInfo.left, S = y6 - 1 - u.padInfo.top, N = vt(r.shape, "float32"), R = e.bufferSync(o);
  for (let M6 = 0; M6 < u.batchSize; ++M6)
    for (let V = 0; V < u.inChannels; ++V)
      for (let z = 0; z < u.inDepth; ++z)
        for (let P = 0; P < u.inHeight; ++P)
          for (let A = 0; A < u.inWidth; ++A) {
            const O = z - v, B6 = P - S, Z = A - k6;
            let H6 = 0;
            for (let Y = 0; Y < w; Y += g) {
              const Q6 = (O + Y) / p;
              if (!(Q6 < 0 || Q6 >= u.outDepth || Math.floor(Q6) !== Q6))
                for (let j = 0; j < y6; j += b) {
                  const J6 = (B6 + j) / f;
                  if (!(J6 < 0 || J6 >= u.outHeight || Math.floor(J6) !== J6))
                    for (let ot = 0; ot < I; ot += x6) {
                      const q = (Z + ot) / m;
                      if (q < 0 || q >= u.outWidth || Math.floor(q) !== q)
                        continue;
                      const rt = w * y6 * I - 1 - h.get(M6, Q6, J6, q, V), ht = Y * y6 * I + j * I + ot, ft = rt === ht ? 1 : 0;
                      if (ft === 0)
                        continue;
                      const pt = R.get(M6, Q6, J6, q, V);
                      H6 += pt * ft;
                    }
                }
            }
            N.set(H6, M6, z, P, A, V);
          }
  return e.makeTensorInfo(N.shape, N.dtype, N.values);
}
var cV = {
  kernelName: Th,
  backendName: "cpu",
  kernelFunc: lV
};
function uV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r, output: i6 } = t, a = r;
  lt([r, i6], "maxPoolGrad");
  const { filterSize: l, strides: c, pad: u, dimRoundingMode: d } = s, h = $n(a.shape, l, c, 1, u, d), p = e.data.get(a.dataId).values, f = vt(h.outShape, a.dtype, Aw(p, a.shape, a.dtype, h).values), m = h.strideHeight, g = h.strideWidth, b = h.dilationHeight, x6 = h.dilationWidth, w = h.effectiveFilterHeight, y6 = h.effectiveFilterWidth, I = y6 - 1 - h.padInfo.left, v = w - 1 - h.padInfo.top, k6 = vt(a.shape, "float32"), S = e.data.get(o.dataId).values, N = vt(o.shape, "float32", S);
  for (let R = 0; R < h.batchSize; ++R)
    for (let M6 = 0; M6 < h.inChannels; ++M6)
      for (let V = 0; V < h.inHeight; ++V)
        for (let z = 0; z < h.inWidth; ++z) {
          const P = V - v, A = z - I;
          let O = 0;
          for (let B6 = 0; B6 < w; B6 += b) {
            const Z = (P + B6) / m;
            if (!(Z < 0 || Z >= h.outHeight || Math.floor(Z) !== Z))
              for (let H6 = 0; H6 < y6; H6 += x6) {
                const Y = (A + H6) / g;
                if (Y < 0 || Y >= h.outWidth || Math.floor(Y) !== Y)
                  continue;
                const Q6 = w * y6 - 1 - f.get(R, Z, Y, M6), j = B6 * y6 + H6, J6 = Q6 === j ? 1 : 0;
                if (J6 === 0)
                  continue;
                const ot = N.get(R, Z, Y, M6);
                O += ot * J6;
              }
          }
          k6.set(O, R, V, z, M6);
        }
  return e.makeTensorInfo(k6.shape, k6.dtype, k6.values);
}
var dV = {
  kernelName: kh,
  backendName: "cpu",
  kernelFunc: uV
};
function hV(n, t, e, s, o) {
  const r = dt(t), i6 = Bf(n, t, e, r, o, "max"), a = Aw(n, t, e, o, true, s);
  return [i6.values, a.values];
}
var pV = {
  kernelName: pb,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { x: s } = n, { filterSize: o, strides: r, pad: i6, includeBatchInIndex: a } = t, l = e;
    lt(s, "MaxPoolWithArgmax");
    const c = l.data.get(s.dataId).values, u = $n(s.shape, o, r, [1, 1], i6), [d, h] = hV(c, s.shape, s.dtype, a, u), p = l.write(d, u.outShape, s.dtype), f = l.write(h, u.outShape, s.dtype);
    return [
      { dataId: p, shape: u.outShape, dtype: s.dtype },
      { dataId: f, shape: u.outShape, dtype: "int32" }
    ];
  }
};
function fV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = Ct(r, o.shape), c = ye(o.shape, a)[1], u = X(c), d = [], h = e.makeTensorInfo([], "float32", new Float32Array([u]));
  d.push(h);
  const p = Ys({ inputs: { x: o }, backend: e, attrs: { dtype: "float32" } });
  d.push(p);
  const f = Hf({ inputs: { a: p, b: h }, backend: e });
  d.push(f);
  const m = za({ inputs: { x: f }, backend: e, attrs: { axis: r, keepDims: i6 } });
  return d.forEach((g) => e.disposeIntermediateTensorInfo(g)), m;
}
var mV = {
  kernelName: Sc,
  backendName: "cpu",
  kernelFunc: fV
};
function gV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  lt(o, "min");
  const a = Ct(r, o.shape);
  let l = a;
  const c = qt(l, o.shape.length);
  let u = o;
  c != null && (u = _e({ inputs: { x: o }, backend: e, attrs: { perm: c } }), l = ie(l.length, o.shape.length)), Ne("min", l, u.shape.length);
  const [d, h] = ye(u.shape, l), p = X(h), f = ke(X(d), u.dtype), m = e.data.get(u.dataId).values;
  for (let b = 0; b < f.length; ++b) {
    const x6 = b * p;
    let w = m[x6];
    for (let y6 = 0; y6 < p; ++y6) {
      const I = m[x6 + y6];
      (Number.isNaN(I) || I < w) && (w = I);
    }
    f[b] = w;
  }
  c != null && e.disposeIntermediateTensorInfo(u);
  const g = e.makeTensorInfo(d, u.dtype, f);
  if (i6) {
    const b = re(d, a), x6 = Zt({ inputs: { x: g }, backend: e, attrs: { shape: b } });
    return e.disposeIntermediateTensorInfo(g), x6;
  }
  return g;
}
var bV = {
  kernelName: kc,
  backendName: "cpu",
  kernelFunc: gV
};
function xV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { paddings: r, mode: i6 } = s;
  lt(o, "mirrorPad");
  const a = r.map(
    (w, y6) => w[0] + o.shape[y6] + w[1]
    /* afterPad */
  ), l = r.map((w) => w[0]), c = r.map((w, y6) => w[0] + o.shape[y6]), u = i6 === "reflect" ? 0 : 1, d = e.data.get(o.dataId).values, h = o.shape.length, p = dt(o.shape), f = X(a), m = a.length, g = dt(a), b = Se(o.dtype, f);
  for (let w = 0; w < f; w++) {
    let y6 = Xo(w, m, g);
    for (let v = 0; v < m; v++)
      y6[v] < l[v] ? y6[v] = l[v] * 2 - y6[v] - u : y6[v] >= c[v] && (y6[v] = (c[v] - 1) * 2 - y6[v] + u);
    y6 = y6.map((v, k6) => v - l[k6]);
    const I = zn(y6, h, p);
    b[w] = d[I];
  }
  return { dataId: e.write(b, a, o.dtype), shape: a, dtype: o.dtype };
}
var yV = {
  kernelName: Tc,
  backendName: "cpu",
  kernelFunc: xV
};
var wV = le((n, t) => {
  const e = n % t;
  return n < 0 && t < 0 || n >= 0 && t >= 0 ? e : (e + t) % t;
});
var IV = fe(Ji, wV);
var CV = {
  kernelName: Ji,
  backendName: "cpu",
  kernelFunc: IV
};
function Hw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { dim: r } = s, i6 = o.shape.length;
  let a = r;
  if (a === -1 && (a = i6 - 1), a !== i6 - 1)
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${i6} and dim was ${a}`);
  const l = Ct([a], o.shape), c = Bw({
    inputs: { x: o },
    backend: e,
    attrs: { reductionIndices: l, keepDims: false }
  }), u = re(c.shape, l), d = Zt({ inputs: { x: c }, backend: e, attrs: { shape: u } }), h = Zf({ inputs: { a: o, b: d }, backend: e }), p = Q1({ inputs: { x: h }, backend: e }), f = za({ inputs: { x: p }, backend: e, attrs: { axis: l, keepDims: false } }), m = Zt({ inputs: { x: f }, backend: e, attrs: { shape: u } }), g = Hf({ inputs: { a: p, b: m }, backend: e });
  return e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(h), e.disposeIntermediateTensorInfo(p), e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(m), g;
}
var vV = {
  kernelName: Zc,
  backendName: "cpu",
  kernelFunc: Hw
};
function SV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { numSamples: r, seed: i6, normalized: a } = s;
  lt(o, "multinomial");
  const l = a ? o : Hw({ inputs: { logits: o }, backend: e, attrs: { dim: -1 } }), c = l.shape[0], u = l.shape[1], d = e.data.get(l.dataId).values, h = [c, r], p = ke(X(h), "int32");
  for (let f = 0; f < c; ++f) {
    const m = f * u, g = new Float32Array(u - 1);
    g[0] = d[m];
    for (let w = 1; w < g.length; ++w)
      g[w] = g[w - 1] + d[m + w];
    const b = Nr.alea(i6.toString()), x6 = f * r;
    for (let w = 0; w < r; ++w) {
      const y6 = b();
      p[x6 + w] = g.length;
      for (let I = 0; I < g.length; I++)
        if (y6 < g[I]) {
          p[x6 + w] = I;
          break;
        }
    }
  }
  return a || e.disposeIntermediateTensorInfo(l), e.makeTensorInfo(h, "int32", p);
}
var kV = {
  kernelName: fb,
  backendName: "cpu",
  kernelFunc: SV
};
var TV = zp;
function NV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l } = s;
  lt(o, "NonMaxSuppression");
  const c = e.data.get(o.dataId).values, u = e.data.get(r.dataId).values, { selectedIndices: d } = TV(c, u, i6, a, l);
  return e.makeTensorInfo([d.length], "int32", new Int32Array(d));
}
var RV = {
  kernelName: Nh,
  backendName: "cpu",
  kernelFunc: NV
};
var $V = Pp;
function GV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, padToMaxOutputSize: c } = s;
  lt(o, "NonMaxSuppressionPadded");
  const u = e.data.get(o.dataId).values, d = e.data.get(r.dataId).values, { selectedIndices: h, validOutputs: p } = $V(u, d, i6, a, l, c);
  return [
    e.makeTensorInfo([h.length], "int32", new Int32Array(h)),
    e.makeTensorInfo([], "int32", new Int32Array([p]))
  ];
}
var EV = {
  kernelName: Rh,
  backendName: "cpu",
  kernelFunc: GV
};
var LV = Ap;
function MV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, softNmsSigma: c } = s;
  lt(o, "NonMaxSuppressionWithScore");
  const u = e.data.get(o.dataId).values, d = e.data.get(r.dataId).values, h = i6, p = a, f = l, m = c, { selectedIndices: g, selectedScores: b } = LV(u, d, h, p, f, m);
  return [
    e.makeTensorInfo([g.length], "int32", new Int32Array(g)),
    e.makeTensorInfo([b.length], "float32", new Float32Array(b))
  ];
}
var WV = {
  kernelName: $h,
  backendName: "cpu",
  kernelFunc: MV
};
function DV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o } = t, { dtype: r, depth: i6, onValue: a, offValue: l } = s;
  lt(o, "oneHot");
  const c = X(o.shape), u = new Float32Array(c * i6);
  u.fill(l);
  const d = e.data.get(o.dataId).values;
  for (let h = 0; h < c; ++h)
    d[h] >= 0 && d[h] < i6 && (u[h * i6 + d[h]] = a);
  return e.makeTensorInfo([...o.shape, i6], r, u);
}
var FV = {
  kernelName: Gc,
  backendName: "cpu",
  kernelFunc: DV
};
function Al(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "string")
    throw new Error("zerosLike is not supported for string tensors");
  if (s.dtype === "complex64") {
    const o = Do({ inputs: { input: s }, backend: e }), r = Al({ inputs: { x: o }, backend: e }), i6 = Ir({ inputs: { input: s }, backend: e }), a = Al({ inputs: { x: i6 }, backend: e }), l = Je({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return _f({ backend: e, attrs: { shape: s.shape, value: 0, dtype: s.dtype } });
}
var VV = {
  kernelName: Uc,
  backendName: "cpu",
  kernelFunc: Al
};
function _w(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "string")
    throw new Error("onesLike is not supported for string tensors");
  if (s.dtype === "complex64") {
    const o = Do({ inputs: { input: s }, backend: e }), r = _w({ inputs: { x: o }, backend: e }), i6 = Ir({ inputs: { input: s }, backend: e }), a = Al({ inputs: { x: i6 }, backend: e }), l = Je({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return _f({ backend: e, attrs: { shape: s.shape, value: 1, dtype: s.dtype } });
}
var zV = {
  kernelName: $c,
  backendName: "cpu",
  kernelFunc: _w
};
function Uw(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s;
  if (t.length === 1)
    return Pl({ inputs: { input: t[0] }, backend: e, attrs: { dim: o } });
  const r = t[0].shape, i6 = t[0].dtype;
  t.forEach((u) => {
    Pe(r, u.shape, "All tensors passed to stack must have matching shapes"), C(i6 === u.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const a = [], l = t.map((u) => {
    const d = Pl({ inputs: { input: u }, backend: e, attrs: { dim: o } });
    return a.push(d), d;
  }), c = Cr({ inputs: l, backend: e, attrs: { axis: o } });
  return a.forEach((u) => e.disposeIntermediateTensorInfo(u)), c;
}
var PV = {
  kernelName: Ec,
  backendName: "cpu",
  kernelFunc: Uw
};
function AV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { paddings: r, constantValue: i6 } = s;
  lt(o, "pad");
  const a = r.map(
    (x6, w) => x6[0] + o.shape[w] + x6[1]
    /* afterPad */
  ), l = r.map((x6) => x6[0]), c = e.data.get(o.dataId).values, u = X(o.shape), d = o.shape.length, h = dt(o.shape), p = X(a), f = a.length, m = dt(a), g = Se(o.dtype, p);
  i6 !== 0 && g.fill(i6);
  for (let x6 = 0; x6 < u; x6++) {
    const y6 = Xo(x6, d, h).map((v, k6) => v + l[k6]), I = zn(y6, f, m);
    g[I] = c[x6];
  }
  return { dataId: e.write(g, a, o.dtype), shape: a, dtype: o.dtype };
}
var Yw = {
  kernelName: Lc,
  backendName: "cpu",
  kernelFunc: AV
};
var OV = le((n, t) => Math.pow(n, t));
var XV = fe(qi, OV);
var KV = {
  kernelName: qi,
  backendName: "cpu",
  kernelFunc: XV
};
function ZV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { paramsNestedSplits: o, paramsDenseValues: r, indices: i6 } = t, a = o.map((g) => e.data.get(g.dataId).values), l = o.map((g) => g.shape), c = e.data.get(r.dataId).values, u = e.data.get(i6.dataId).values, [d, h, p] = fw(a, l, c, r.shape, r.dtype, u, i6.shape), f = d.map((g) => e.makeTensorInfo([g.length], "int32", g)), m = e.makeTensorInfo(p, r.dtype, h);
  return f.concat([m]);
}
var BV = {
  kernelName: mb,
  backendName: "cpu",
  kernelFunc: ZV
};
function HV(n) {
  const { inputs: t, backend: e } = n, { starts: s, limits: o, deltas: r } = t, i6 = e.data.get(s.dataId).values, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, [c, u] = mw(i6, s.shape, s.dtype, a, o.shape, l, r.shape), d = e.makeTensorInfo([c.length], "int32", c), h = e.makeTensorInfo([u.length], s.dtype, u);
  return [d, h];
}
var _V = {
  kernelName: gb,
  backendName: "cpu",
  kernelFunc: HV
};
function UV(n) {
  const { inputs: t, backend: e, attrs: s } = n, { shape: o, values: r, defaultValue: i6, rowPartitionTensors: a } = t, { rowPartitionTypes: l } = s, c = e.data.get(o.dataId).values, u = e.data.get(r.dataId).values, d = e.data.get(i6.dataId).values, h = a.map((g) => e.data.get(g.dataId).values), p = a.map((g) => g.shape), [f, m] = gw(c, o.shape, u, r.shape, r.dtype, d, i6.shape, h, p, l);
  return e.makeTensorInfo(f, r.dtype, m);
}
var YV = {
  kernelName: bb,
  backendName: "cpu",
  kernelFunc: UV
};
function QV(n) {
  const { backend: t, attrs: e } = n, { start: s, stop: o, dtype: r, step: i6 } = e, a = bw(s, o, i6, r);
  return t.makeTensorInfo([a.length], r, a);
}
var JV = {
  kernelName: Gh,
  backendName: "cpu",
  kernelFunc: QV
};
var jV = Wt(ta, (n) => 1 / n);
var qV = {
  kernelName: ta,
  backendName: "cpu",
  kernelFunc: jV
};
function tz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s;
  lt(o, "resizeBilinear");
  const l = dt(o.shape), [c, u] = a, [d, h, p, f] = o.shape, m = e.data.get(o.dataId).values, g = new Float32Array(X([d, c, u, f])), b = [
    r && c > 1 ? h - 1 : h,
    r && u > 1 ? p - 1 : p
  ], x6 = [
    r && c > 1 ? c - 1 : c,
    r && u > 1 ? u - 1 : u
  ];
  let w = 0;
  const y6 = b[0] / x6[0], I = b[1] / x6[1];
  for (let v = 0; v < d; v++)
    for (let k6 = 0; k6 < c; k6++) {
      let S;
      i6 ? S = y6 * (k6 + 0.5) - 0.5 : S = y6 * k6;
      const N = Math.max(0, Math.floor(S)), R = S - N, M6 = Math.min(h - 1, Math.ceil(S)), V = v * l[0] + N * l[1], z = v * l[0] + M6 * l[1];
      for (let P = 0; P < u; P++) {
        let A;
        i6 ? A = I * (P + 0.5) - 0.5 : A = I * P;
        const O = Math.max(0, Math.floor(A)), B6 = A - O, Z = Math.min(p - 1, Math.ceil(A)), H6 = V + O * l[2], Y = z + O * l[2], Q6 = V + Z * l[2], j = z + Z * l[2];
        for (let J6 = 0; J6 < f; J6++) {
          const ot = m[H6 + J6], q = m[Y + J6], rt = m[Q6 + J6], ht = m[j + J6], ft = ot + (rt - ot) * B6, pt = q + (ht - q) * B6, wt2 = ft + (pt - ft) * R;
          g[w++] = wt2;
        }
      }
    }
  return e.makeTensorInfo([d, c, u, f], "float32", g);
}
var ez = {
  kernelName: Vc,
  backendName: "cpu",
  kernelFunc: tz
};
function nz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s;
  lt([r, o], "resizeBilinearGrad");
  const a = dt(o.shape), [l, c, u, d] = o.shape, [, h, p] = r.shape, f = new Float32Array(l * c * u * d), m = [
    i6 && h > 1 ? c - 1 : c,
    i6 && p > 1 ? u - 1 : u
  ], g = [
    i6 && h > 1 ? h - 1 : h,
    i6 && p > 1 ? p - 1 : p
  ], b = m[0] / g[0], x6 = m[1] / g[1], w = e.data.get(r.dataId).values;
  let y6 = 0;
  for (let I = 0; I < l; I++) {
    const v = I * a[0];
    for (let k6 = 0; k6 < h; k6++) {
      const S = k6 * b, N = Math.floor(S), R = Math.min(Math.ceil(S), c - 1), M6 = v + N * a[1], V = v + R * a[1], z = S - N, P = 1 - z;
      for (let A = 0; A < p; A++) {
        const O = A * x6, B6 = Math.floor(O), Z = Math.min(Math.ceil(O), u - 1), H6 = O - B6, Y = 1 - H6, Q6 = M6 + B6 * a[2], j = M6 + Z * a[2], J6 = V + B6 * a[2], ot = V + Z * a[2], q = P * Y, rt = P * H6, ht = z * Y, ft = z * H6;
        for (let pt = 0; pt < d; pt++) {
          const wt2 = w[y6++];
          f[Q6 + pt] += wt2 * q, f[j + pt] += wt2 * rt, f[J6 + pt] += wt2 * ht, f[ot + pt] += wt2 * ft;
        }
      }
    }
  }
  return e.makeTensorInfo([l, u, c, d], "float32", f);
}
var sz = {
  kernelName: Mh,
  backendName: "cpu",
  kernelFunc: nz
};
function oz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s;
  lt(o, "resizeNearestNeighbor");
  const l = dt(o.shape), [c, u] = a, [d, h, p, f] = o.shape, m = e.data.get(o.dataId).values, g = new Float32Array(d * c * u * f), b = [
    r && c > 1 ? h - 1 : h,
    r && u > 1 ? p - 1 : p
  ], x6 = [
    r && c > 1 ? c - 1 : c,
    r && u > 1 ? u - 1 : u
  ], w = b[0] / x6[0], y6 = b[1] / x6[1];
  let I = 0;
  for (let v = 0; v < d; v++) {
    const k6 = v * l[0];
    for (let S = 0; S < c; S++) {
      const N = i6 ? w * (S + 0.5) : w * S;
      let R = Math.min(h - 1, r ? Math.round(N) : Math.floor(N));
      i6 && (R = Math.max(0, R));
      const M6 = k6 + R * l[1];
      for (let V = 0; V < u; V++) {
        const z = i6 ? y6 * (V + 0.5) : y6 * V;
        let P = Math.min(p - 1, r ? Math.round(z) : Math.floor(z));
        i6 && (P = Math.max(0, P));
        const A = M6 + P * l[2];
        for (let O = 0; O < f; O++) {
          const B6 = m[A + O];
          g[I++] = B6;
        }
      }
    }
  }
  return e.makeTensorInfo([d, c, u, f], o.dtype, g);
}
var rz = {
  kernelName: Fc,
  backendName: "cpu",
  kernelFunc: oz
};
function iz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s;
  lt([r, o], "resizeNearestNeighborGrad");
  const a = dt(o.shape), l = dt(r.shape), [c, u, d, h] = o.shape, [, p, f] = r.shape, m = new Float32Array(c * u * d * h), g = e.data.get(r.dataId).values, b = [
    i6 && p > 1 ? u - 1 : u,
    i6 && f > 1 ? d - 1 : d
  ], x6 = [
    i6 && p > 1 ? p - 1 : p,
    i6 && f > 1 ? f - 1 : f
  ], w = b[0] / x6[0], y6 = b[1] / x6[1], I = 1 / w, v = 1 / y6, k6 = Math.ceil(I) * 2 + 2, S = Math.ceil(v) * 2 + 2;
  for (let N = 0; N < c; N++) {
    const R = N * a[0];
    for (let M6 = 0; M6 < u; M6++) {
      const V = R + M6 * a[1], z = Math.floor(M6 * I), P = Math.floor(z - k6 / 2);
      for (let A = 0; A < d; A++) {
        const O = V + A * a[2], B6 = Math.floor(A * v), Z = Math.floor(B6 - S / 2);
        for (let H6 = 0; H6 < h; H6++) {
          let Y = 0;
          for (let Q6 = 0; Q6 < k6; Q6++) {
            const j = Q6 + P;
            if (j < 0 || j >= p)
              continue;
            const J6 = R + j * l[1], ot = j * w, q = Math.min(u - 1, i6 ? Math.round(ot) : Math.floor(ot));
            if (M6 === q)
              for (let rt = 0; rt < S; rt++) {
                const ht = rt + Z;
                if (ht < 0 || ht >= f)
                  continue;
                const ft = J6 + ht * l[2], pt = ht * y6, wt2 = Math.min(d - 1, i6 ? Math.round(pt) : Math.floor(pt));
                A === wt2 && (Y += g[ft + H6]);
              }
          }
          m[O + H6] = Y;
        }
      }
    }
  }
  return e.makeTensorInfo(o.shape, o.dtype, m);
}
var az = {
  kernelName: Lh,
  backendName: "cpu",
  kernelFunc: iz
};
function lz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dims: r } = s;
  lt(o, "reverse");
  const i6 = o.shape.length, a = Ct(r, o.shape);
  if (i6 === 0)
    return rs({ inputs: { x: o }, backend: e });
  const l = new ve(o.shape, o.dtype), c = e.bufferSync(o);
  for (let u = 0; u < l.size; u++) {
    const d = l.indexToLoc(u), h = d.slice();
    a.forEach((p) => h[p] = o.shape[p] - 1 - h[p]), l.set(c.get(...h), ...d);
  }
  return e.makeTensorInfo(l.shape, l.dtype, l.values);
}
var cz = {
  kernelName: zc,
  backendName: "cpu",
  kernelFunc: lz
};
var uz = {
  kernelName: Hh,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { image: s } = n, { radians: o, fillValue: r, center: i6 } = t, a = e, l = Se(s.dtype, X(s.shape)), [c, u, d, h] = s.shape, [p, f] = Jp(i6, u, d), m = 255, g = Math.sin(o), b = Math.cos(o), x6 = a.data.get(s.dataId).values;
    for (let y6 = 0; y6 < c; y6++) {
      const I = y6 * d * u * h;
      for (let v = 0; v < u; v++) {
        const k6 = v * (d * h);
        for (let S = 0; S < d; S++) {
          const N = S * h;
          for (let R = 0; R < h; R++) {
            const M6 = [c, v, S, R], V = M6[2], z = M6[1];
            let P = (V - p) * b - (z - f) * g, A = (V - p) * g + (z - f) * b;
            P = Math.round(P + p), A = Math.round(A + f);
            let O = r;
            if (typeof r != "number" && (R === 3 ? O = m : O = r[R]), P >= 0 && P < d && A >= 0 && A < u) {
              const Z = A * (d * h), H6 = P * h, Y = I + Z + H6 + R;
              O = x6[Y];
            }
            const B6 = I + k6 + N + R;
            l[B6] = O;
          }
        }
      }
    }
    return { dataId: a.write(l, s.shape, s.dtype), shape: s.shape, dtype: s.dtype };
  }
};
var dz = Wt(sa, (n) => {
  const t = Math.floor(n);
  return n - t < 0.5 ? Math.floor(n) : n - t > 0.5 ? Math.ceil(n) : t % 2 === 0 ? t : t + 1;
});
var hz = {
  kernelName: sa,
  backendName: "cpu",
  kernelFunc: dz
};
function pz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o, updates: r } = t, { shape: i6 } = s, { sliceRank: a, numUpdates: l, sliceSize: c, strides: u, outputSize: d } = to(r, o, i6), h = true, p = e.bufferSync(o), f = e.bufferSync(r), m = bo(p, f, i6, d, c, l, a, u, 0, h);
  return e.makeTensorInfo(i6, m.dtype, m.values);
}
var fz = {
  kernelName: xb,
  backendName: "cpu",
  kernelFunc: pz
};
function mz(n, t) {
  let e = 0, s = n.length, o = 0;
  for (; e < s; )
    o = Math.floor((e + s) / 2), n[o] < t ? e = o + 1 : s = o;
  return s;
}
function gz(n, t) {
  let e = 0, s = n.length, o = 0;
  for (; e < s; )
    o = Math.floor((e + s) / 2), n[o] <= t ? e = o + 1 : s = o;
  return s;
}
function bz(n, t, e, s, o, r) {
  const i6 = ne("int32", e * o);
  for (let a = 0; a < e; ++a) {
    const l = n.slice(a * s, (a + 1) * s), c = a * o;
    for (let u = 0; u < o; ++u)
      i6[c + u] = r === "left" ? mz(l, t[u + c]) : gz(l, t[u + c]);
  }
  return i6;
}
function xz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sortedSequence: o, values: r } = t, { side: i6 } = s, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, c = bz(a, l, o.shape[0], o.shape[1], r.shape[1], i6);
  return e.makeTensorInfo(r.shape, "int32", c);
}
var yz = {
  kernelName: wb,
  backendName: "cpu",
  kernelFunc: xz
};
function wz(n) {
  const { inputs: t, backend: e } = n, { condition: s, t: o, e: r } = t;
  lt([s, o, r], "select");
  const i6 = s.shape.length, a = e.data.get(s.dataId).values, l = e.data.get(o.dataId).values, c = e.data.get(r.dataId).values, u = tn(o.dtype, r.dtype), d = ke(X(o.shape), u);
  let h = 0;
  const p = i6 === 0 || i6 > 1 || o.shape.length === 1 ? 1 : X(o.shape.slice(1));
  for (let f = 0; f < a.length; f++)
    for (let m = 0; m < p; m++)
      a[f] === 1 ? d[h++] = l[f] : d[h++] = c[f];
  return e.makeTensorInfo(o.shape, u, d);
}
var Iz = {
  kernelName: Pc,
  backendName: "cpu",
  kernelFunc: wz
};
var Cz = ru;
var vz = iu;
var Sz = Wt(ra, (n) => n >= 0 ? vz * n : Cz * (Math.exp(n) - 1));
var kz = {
  kernelName: ra,
  backendName: "cpu",
  kernelFunc: Sz
};
var Tz = Wt(la, (n) => n < 0 ? -1 : n > 0 ? 1 : 0);
var Nz = {
  kernelName: la,
  backendName: "cpu",
  kernelFunc: Tz
};
var Rz = Wt(ia, (n) => Math.sin(n));
var $z = {
  kernelName: ia,
  backendName: "cpu",
  kernelFunc: Rz
};
var Gz = Wt(aa, (n) => Math.sinh(n));
var Ez = {
  kernelName: aa,
  backendName: "cpu",
  kernelFunc: Gz
};
var Lz = 11920928955078125e-23;
var bg = Math.log(Lz) + 2;
var Mz = Wt(ua, (n) => {
  const t = n > -bg, e = n < bg, s = Math.exp(n);
  let o;
  return e ? o = s : t ? o = n : o = Math.log(1 + s), o;
});
var Wz = {
  kernelName: ua,
  backendName: "cpu",
  kernelFunc: Mz
};
function Dz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, paddings: i6 } = s;
  lt([o], "spaceToBatchND");
  const a = X(r), l = [[0, 0]];
  l.push(...i6);
  for (let v = 1 + r.length; v < o.shape.length; ++v)
    l.push([0, 0]);
  const c = Yw.kernelFunc({
    inputs: { x: o },
    backend: e,
    attrs: { paddings: l, constantValue: 0 }
  }), u = Na(c.shape, r, a, false), d = Ra(u.length, r.length, false), h = $a(c.shape, r, a, false), m = Zt({ inputs: { x: c }, backend: e, attrs: { shape: u } }), x6 = _e({ inputs: { x: m }, backend: e, attrs: { perm: d } }), I = Zt({ inputs: { x: x6 }, backend: e, attrs: { shape: h } });
  return e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(x6), I;
}
var Fz = {
  kernelName: Xc,
  backendName: "cpu",
  kernelFunc: Dz
};
function Vz(n) {
  const { inputs: t, backend: e } = n, { indices: s, values: o, denseShape: r, defaultValue: i6 } = t;
  if (r.shape.length !== 1)
    throw new Error(`Dense shape must be a vector, saw:
        ${r.shape}`);
  if (s.shape.length !== 2)
    throw new Error(`Indices must be a matrix, saw:
        ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Values must be a vector, saw:
        ${o.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Default value must be a scalar, saw:
        ${i6.shape}`);
  const a = e.data.get(s.dataId).values, l = e.data.get(o.dataId).values, c = e.data.get(r.dataId).values, u = e.data.get(i6.dataId).values[0], [d, h, p, f, m] = Iw(a, s.shape, s.dtype, l, o.dtype, c, u);
  return [
    e.makeTensorInfo(h, s.dtype, d),
    e.makeTensorInfo([h[0]], o.dtype, p),
    e.makeTensorInfo([f.length], "bool", new Uint8Array(f.map((g) => Number(g)))),
    e.makeTensorInfo([m.length], s.dtype, new Int32Array(m))
  ];
}
var zz = {
  kernelName: Wh,
  backendName: "cpu",
  kernelFunc: Vz
};
function Pz(n) {
  const { inputs: t, backend: e } = n, { inputIndices: s, inputShape: o, newShape: r } = t;
  if (s.shape.length !== 2)
    throw new Error(`Input indices should be a matrix but received shape
        ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Input shape should be a vector but received shape
        ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Target shape should be a vector but received shape ${r.shape}`);
  const i6 = Array.from(e.data.get(o.dataId).values), a = e.data.get(s.dataId).values, l = Array.from(e.data.get(r.dataId).values), [c, u, d] = Cw(a, s.shape, s.dtype, i6, l);
  return [
    e.makeTensorInfo(u, s.dtype, c),
    e.makeTensorInfo([d.length], r.dtype, new Int32Array(d))
  ];
}
var Az = {
  kernelName: Dh,
  backendName: "cpu",
  kernelFunc: Pz
};
function Oz(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
          ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
          ${r.shape}`);
  if (o.shape[0] !== r.shape[0])
    throw new Error("segmentIds and indices should have same size.");
  const i6 = e.data.get(s.dataId).values, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, [c, u] = Kf(i6, s.shape, s.dtype, a, l, true);
  return e.makeTensorInfo(u, s.dtype, c);
}
var Xz = {
  kernelName: Fh,
  backendName: "cpu",
  kernelFunc: Oz
};
function Kz(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
         ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
         ${r.shape}`);
  if (o.shape[0] !== r.shape[0])
    throw new Error("segmentIds and indices should have same size.");
  const i6 = e.data.get(s.dataId).values, a = e.data.get(o.dataId).values, l = e.data.get(r.dataId).values, [c, u] = Kf(i6, s.shape, s.dtype, a, l);
  return e.makeTensorInfo(u, s.dtype, c);
}
var Zz = {
  kernelName: Vh,
  backendName: "cpu",
  kernelFunc: Kz
};
function Bz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sparseIndices: o, sparseValues: r, defaultValue: i6 } = t, { outputShape: a } = s, { sliceRank: l, numUpdates: c, sliceSize: u, strides: d, outputSize: h } = to(r, o, a), p = false, f = e.bufferSync(o);
  let m;
  switch (r.dtype) {
    case "bool": {
      const g = e.bufferSync(r), b = !!e.data.get(i6.dataId).values[0];
      m = bo(f, g, a, h, u, c, l, d, b, p);
      break;
    }
    case "float32": {
      const g = e.bufferSync(r), b = e.data.get(i6.dataId).values[0];
      m = bo(f, g, a, h, u, c, l, d, b, p);
      break;
    }
    case "int32": {
      const g = e.bufferSync(r), b = e.data.get(i6.dataId).values[0];
      m = bo(f, g, a, h, u, c, l, d, b, p);
      break;
    }
    case "string": {
      const g = e.bufferSync(r), b = gs(e.data.get(i6.dataId).values[0]);
      m = bo(f, g, a, h, u, c, l, d, b, p);
      break;
    }
    default:
      throw new Error(`Unsupported type ${r.dtype}`);
  }
  return e.makeTensorInfo(a, m.dtype, m.values);
}
var Hz = {
  kernelName: Ib,
  backendName: "cpu",
  kernelFunc: Bz
};
function _z(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { numOrSizeSplits: r, axis: i6 } = s, a = Ct(i6, o.shape)[0], l = pf(o, r, a), c = new Array(o.shape.length).fill(0), u = o.shape.slice();
  return l.map((d) => {
    const h = [...u];
    h[a] = d;
    const p = Fo({ inputs: { x: o }, backend: e, attrs: { begin: c, size: h } });
    return c[a] += d, p;
  });
}
var Uz = {
  kernelName: Kc,
  backendName: "cpu",
  kernelFunc: _z
};
var Yz = {
  kernelName: zh,
  backendName: "cpu",
  kernelFunc: ({ inputs: n, backend: t }) => {
    const { x: e } = n, s = t;
    lt(e, "square");
    const o = s.data.get(e.dataId).values, r = new Float32Array(o.length);
    for (let a = 0; a < o.length; ++a) {
      const l = o[a];
      r[a] = l * l;
    }
    return { dataId: s.write(r, e.shape, e.dtype), shape: e.shape, dtype: e.dtype };
  }
};
var Qz = Wt(ba, (n, t) => {
  const e = t;
  return isNaN(n) ? NaN : n > 0 ? 1 : e.alpha;
});
var Jz = {
  kernelName: ba,
  backendName: "cpu",
  kernelFunc: Qz
};
function jz(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, end: i6, strides: a, beginMask: l, endMask: c, ellipsisMask: u, newAxisMask: d, shrinkAxisMask: h } = s;
  lt(o, "stridedSlice");
  const { finalShapeSparse: p, finalShape: f, isIdentity: m, sliceDim0: g, isSimpleSlice: b, begin: x6, end: w, strides: y6 } = Up(o.shape, r, i6, a, l, c, u, d, h);
  let I;
  if (m)
    I = Zt({ inputs: { x: o }, backend: e, attrs: { shape: f } });
  else if (g || b) {
    C(o.shape.length >= 1, () => `Input must have rank at least 1, got: ${o.shape.length}`);
    const v = Bp(x6, w, y6), k6 = Fo({ inputs: { x: o }, backend: e, attrs: { begin: x6, size: v } });
    I = Zt({ inputs: { x: k6 }, backend: e, attrs: { shape: f } }), e.disposeIntermediateTensorInfo(k6);
  } else {
    const v = e.bufferSync(o), k6 = kw(p, v, y6, x6);
    I = e.makeTensorInfo(f, k6.dtype, k6.values);
  }
  return I;
}
var qz = {
  kernelName: Ph,
  backendName: "cpu",
  kernelFunc: jz
};
function tP(n) {
  const { inputs: t, backend: e, attrs: s } = n, { separator: o, nGramWidths: r, leftPad: i6, rightPad: a, padWidth: l, preserveShortSequences: c } = s, { data: u, dataSplits: d } = t, h = e.data.get(u.dataId).values, p = e.data.get(d.dataId).values, [f, m] = Tw(h, p, o, r, i6, a, l, c);
  return [
    e.makeTensorInfo([f.length], "string", f),
    e.makeTensorInfo(d.shape, "int32", m)
  ];
}
var eP = {
  kernelName: Ah,
  backendName: "cpu",
  kernelFunc: tP
};
function nP(n) {
  const { inputs: t, backend: e, attrs: s } = n, { skipEmpty: o } = s, { input: r, delimiter: i6 } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (r.shape.length !== 1)
    throw new Error(`Input must be a vector, got shape: ${r.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Delimiter must be a scalar, got shape: ${i6.shape}`);
  const a = e.data.get(r.dataId).values, l = e.data.get(i6.dataId).values[0], [c, u, d] = Nw(a, l, o), h = u.length;
  return [
    e.makeTensorInfo([h, 2], "int32", c),
    e.makeTensorInfo([h], "string", u),
    e.makeTensorInfo([2], "int32", new Int32Array(d))
  ];
}
var sP = {
  kernelName: Oh,
  backendName: "cpu",
  kernelFunc: nP
};
function oP(n) {
  const { inputs: t, backend: e, attrs: s } = n, { numBuckets: o } = s, { input: r } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (o <= 0)
    throw new Error("Number of buckets must be at least 1");
  const i6 = e.data.get(r.dataId).values, a = Rw(i6, o);
  return e.makeTensorInfo(r.shape, "int32", a);
}
var rP = {
  kernelName: Xh,
  backendName: "cpu",
  kernelFunc: oP
};
var iP = Wt(fa, (n) => Math.tan(n));
var aP = {
  kernelName: fa,
  backendName: "cpu",
  kernelFunc: iP
};
var lP = Wt(ma, (n) => Math.tanh(n));
var cP = {
  kernelName: ma,
  backendName: "cpu",
  kernelFunc: lP
};
function uP(n) {
  const { inputs: t, backend: e } = n, { tensor: s, indices: o, updates: r } = t, { sliceRank: i6, numUpdates: a, sliceSize: l, strides: c, outputSize: u } = to(r, o, s.shape), d = false, h = e.bufferSync(o), p = e.bufferSync(r), f = e.bufferSync(s), m = bo(h, p, s.shape, u, l, a, i6, c, f, d);
  return e.makeTensorInfo(s.shape, m.dtype, m.values);
}
var dP = {
  kernelName: yb,
  backendName: "cpu",
  kernelFunc: uP
};
function hP(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reps: r } = s;
  lt(o, "tile");
  const i6 = Gw(e.bufferSync(o), r);
  return e.makeTensorInfo(i6.shape, i6.dtype, i6.values);
}
var pP = {
  kernelName: ga,
  backendName: "cpu",
  kernelFunc: hP
};
function fP(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { k: r, sorted: i6 } = s;
  lt(o, "topk");
  const a = e.data.get(o.dataId).values, [l, c] = Lw(a, o.shape, o.dtype, r, i6);
  return [
    e.makeTensorInfo(l.shape, l.dtype, l.values),
    e.makeTensorInfo(c.shape, c.dtype, c.values)
  ];
}
var mP = {
  kernelName: Kh,
  backendName: "cpu",
  kernelFunc: fP
};
function gP(n) {
  const { inputs: t, attrs: e, backend: s } = n, { image: o, transforms: r } = t, { interpolation: i6, fillMode: a, fillValue: l, outputShape: c } = e, [u, d, h, p] = o.shape, [f, m] = c ?? [d, h], g = [u, f, m, p], b = dt(o.shape), x6 = b[0], w = b[1], y6 = b[2], I = dt(g), v = I[0], k6 = I[1], S = I[2], N = Se(o.dtype, X(g));
  N.fill(l);
  const R = s.data.get(o.dataId).values, M6 = s.data.get(r.dataId).values;
  for (let z = 0; z < u; ++z) {
    const P = r.shape[0] === 1 ? M6 : M6.subarray(z * 8, z * 8 + 8);
    for (let A = 0; A < f; ++A)
      for (let O = 0; O < m; ++O)
        for (let B6 = 0; B6 < p; ++B6) {
          let Z;
          const H6 = P[6] * O + P[7] * A + 1;
          if (H6 === 0)
            continue;
          const Y = (P[0] * O + P[1] * A + P[2]) / H6, Q6 = (P[3] * O + P[4] * A + P[5]) / H6, j = xg(Y, h, a), J6 = xg(Q6, d, a);
          switch (i6) {
            case "nearest":
              Z = CP(R, d, h, x6, w, y6, z, J6, j, B6, l);
              break;
            case "bilinear":
              Z = vP(R, d, h, x6, w, y6, z, J6, j, B6, l);
              break;
            default:
              throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${i6}`);
          }
          const ot = z * v + A * k6 + O * S + B6;
          N[ot] = Z;
        }
    return s.makeTensorInfo(g, o.dtype, N);
  }
  return { dataId: s.write(N, g, o.dtype), shape: o.shape, dtype: o.dtype };
}
var bP = {
  kernelName: Zh,
  backendName: "cpu",
  kernelFunc: gP
};
function xg(n, t, e) {
  switch (e) {
    case "reflect":
      return xP(n, t);
    case "wrap":
      return yP(n, t);
    case "nearest":
      return IP(n, t);
    case "constant":
    default:
      return wP(n);
  }
}
function xP(n, t) {
  let e = n;
  if (e < 0)
    if (t <= 1)
      e = 0;
    else {
      const s = 2 * t;
      e < s && (e = s * Math.trunc(-e / s) + e), e = e < -t ? e + s : -e - 1;
    }
  else if (e > t - 1)
    if (t <= 1)
      e = 0;
    else {
      const s = 2 * t;
      e -= s * Math.trunc(e / s), e >= t && (e = s - e - 1);
    }
  return Os(0, e, t - 1);
}
function yP(n, t) {
  let e = n;
  if (e < 0)
    if (t <= 1)
      e = 0;
    else {
      const s = t - 1;
      e += t * (Math.trunc(-e / s) + 1);
    }
  else if (e > t - 1)
    if (t <= 1)
      e = 0;
    else {
      const s = t - 1;
      e -= t * Math.trunc(e / s);
    }
  return Os(0, e, t - 1);
}
function wP(n, t) {
  return n;
}
function IP(n, t) {
  return Os(0, n, t - 1);
}
function Jr(n, t, e, s, o, r, i6, a, l, c, u) {
  const d = i6 * s + a * o + l * r + c;
  return 0 <= a && a < t && 0 <= l && l < e ? n[d] : u;
}
function CP(n, t, e, s, o, r, i6, a, l, c, u) {
  const d = Math.round(a), h = Math.round(l);
  return Jr(n, t, e, s, o, r, i6, d, h, c, u);
}
function vP(n, t, e, s, o, r, i6, a, l, c, u) {
  const d = Math.floor(a), h = Math.floor(l), p = d + 1, f = h + 1, m = (f - l) * Jr(n, t, e, s, o, r, i6, d, h, c, u) + (l - h) * Jr(n, t, e, s, o, r, i6, d, f, c, u), g = (f - l) * Jr(n, t, e, s, o, r, i6, p, h, c, u) + (l - h) * Jr(n, t, e, s, o, r, i6, p, f, c, u);
  return (p - a) * m + (a - d) * g;
}
function SP(n) {
  const { inputs: t, attrs: e, backend: s } = n, { axis: o } = e, { x: r } = t;
  lt(r, "unique");
  const i6 = s.data.get(r.dataId).values, { outputValues: a, outputShape: l, indices: c } = Mw(i6, o, r.shape, r.dtype);
  return [
    s.makeTensorInfo(l, r.dtype, a),
    s.makeTensorInfo([c.length], "int32", c)
  ];
}
var kP = {
  kernelName: Bh,
  backendName: "cpu",
  kernelFunc: SP
};
function TP(n) {
  const { inputs: t, backend: e, attrs: s } = n, { value: o } = t;
  let { axis: r } = s;
  r < 0 && (r += o.shape.length);
  const i6 = o.shape.length, a = o.shape[r], l = new Array(i6 - 1);
  let c = 0;
  for (let p = 0; p < i6; p++)
    p !== r && (l[c++] = o.shape[p]);
  const u = new Array(i6).fill(0), d = o.shape.slice();
  d[r] = 1;
  const h = new Array(a);
  for (let p = 0; p < h.length; p++) {
    u[r] = p;
    const f = Fo({ inputs: { x: o }, backend: e, attrs: { begin: u, size: d } });
    h[p] = Zt({ inputs: { x: f }, backend: e, attrs: { shape: l } }), e.disposeIntermediateTensorInfo(f);
  }
  return h;
}
var NP = {
  kernelName: Hc,
  backendName: "cpu",
  kernelFunc: TP
};
function RP(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, segmentIds: r } = t, { numSegments: i6 } = s;
  lt(o, "unsortedSegmentSum");
  const a = o.shape.length, l = r.shape.length, c = [], u = [], d = a - l;
  let h = r;
  for (let f = 0; f < d; ++f) {
    const m = Pl({ inputs: { input: h }, backend: e, attrs: { dim: f + 1 } });
    h = m, u.push(m);
  }
  for (let f = 0; f < i6; ++f) {
    const m = Is(f, "int32"), g = e.makeTensorInfo([], "int32", m), b = U1({ inputs: { a: g, b: h }, backend: e }), x6 = Ys({ inputs: { x: b }, backend: e, attrs: { dtype: "float32" } }), w = wu({ inputs: { a: x6, b: o }, backend: e }), y6 = za({ inputs: { x: w }, backend: e, attrs: { axis: 0, keepDims: false } });
    c.push(y6), u.push(g), u.push(b), u.push(x6), u.push(w), u.push(y6);
  }
  const p = Uw({ inputs: c, backend: e, attrs: { axis: 0 } });
  return u.forEach((f) => e.disposeIntermediateTensorInfo(f)), p;
}
var $P = {
  kernelName: _c,
  backendName: "cpu",
  kernelFunc: RP
};
var GP = [
  SW,
  oM,
  TW,
  RW,
  uM,
  GW,
  LW,
  WW,
  FW,
  zW,
  AW,
  XW,
  ZW,
  _W,
  YW,
  jW,
  tD,
  nD,
  oD,
  CW,
  iD,
  lD,
  uD,
  hM,
  hD,
  lM,
  fM,
  fD,
  rM,
  gD,
  xD,
  yD,
  ID,
  vD,
  kD,
  ND,
  $D,
  ED,
  MD,
  DD,
  VD,
  PD,
  OD,
  KD,
  ZD,
  HD,
  UD,
  QD,
  JD,
  jD,
  qD,
  eF,
  oF,
  mW,
  iF,
  mM,
  fF,
  gM,
  mF,
  xM,
  IF,
  CF,
  SF,
  wM,
  CM,
  TF,
  RF,
  GF,
  LF,
  SM,
  TM,
  iM,
  WF,
  bD,
  FF,
  zF,
  AF,
  gW,
  RM,
  GM,
  XF,
  LM,
  ZF,
  _F,
  YF,
  jF,
  tV,
  nV,
  sV,
  WM,
  rV,
  aV,
  cV,
  dV,
  pV,
  mV,
  bV,
  FM,
  yV,
  CV,
  kV,
  zM,
  AM,
  RV,
  EV,
  WV,
  XM,
  FV,
  zV,
  PV,
  Yw,
  KV,
  xW,
  BM,
  BV,
  _V,
  YV,
  JV,
  aM,
  Fd,
  qV,
  yW,
  wW,
  IW,
  ez,
  sz,
  rz,
  az,
  cz,
  uz,
  hz,
  qM,
  fz,
  yz,
  Iz,
  kz,
  eW,
  Nz,
  $z,
  Ez,
  nW,
  vV,
  Wz,
  Fz,
  zz,
  Az,
  Xz,
  Zz,
  Hz,
  Uz,
  rW,
  Yz,
  aW,
  cW,
  Jz,
  qz,
  eP,
  sP,
  rP,
  pW,
  nF,
  aP,
  cP,
  dP,
  pP,
  mP,
  bP,
  KM,
  kP,
  NP,
  $P,
  VV
];
for (const n of GP)
  sn(n);
var po = {};
var Ya = {
  alpha: false,
  antialias: false,
  premultipliedAlpha: false,
  preserveDrawingBuffer: false,
  depth: false,
  stencil: false,
  failIfMajorPerformanceCaveat: true
};
function EP(n, t) {
  po[n] = t;
}
function Bn(n, t) {
  if (!(n in po) || t != null) {
    const s = MP(n, t);
    if (s !== null)
      po[n] = s;
    else
      return console.log("Could not get context for WebGL version", n), null;
  }
  const e = po[n];
  return e == null || e.isContextLost() ? (delete po[n], Bn(n)) : (e.disable(e.DEPTH_TEST), e.disable(e.STENCIL_TEST), e.disable(e.BLEND), e.disable(e.DITHER), e.disable(e.POLYGON_OFFSET_FILL), e.disable(e.SAMPLE_COVERAGE), e.enable(e.SCISSOR_TEST), e.enable(e.CULL_FACE), e.cullFace(e.BACK), po[n]);
}
function LP(n) {
  if (!F().getBool("IS_SAFARI") && typeof OffscreenCanvas < "u" && n === 2)
    return new OffscreenCanvas(300, 150);
  if (typeof document < "u")
    return document.createElement("canvas");
  throw new Error("Cannot create a canvas in this context");
}
function MP(n, t) {
  if (n !== 1 && n !== 2)
    throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
  const e = t ?? LP(n);
  return e.addEventListener("webglcontextlost", (s) => {
    s.preventDefault(), delete po[n];
  }, false), F().getBool("SOFTWARE_WEBGL_ENABLED") && (Ya.failIfMajorPerformanceCaveat = false), n === 1 ? (
    // tslint:disable-next-line
    e.getContext("webgl", Ya) || e.getContext("experimental-webgl", Ya)
  ) : e.getContext("webgl2", Ya);
}
var bi;
(function(n) {
  n[n.DENSE = 0] = "DENSE", n[n.SHARED_BATCH = 1] = "SHARED_BATCH";
})(bi || (bi = {}));
var un;
(function(n) {
  n[n.RENDER = 0] = "RENDER", n[n.UPLOAD = 1] = "UPLOAD", n[n.PIXELS = 2] = "PIXELS", n[n.DOWNLOAD = 3] = "DOWNLOAD";
})(un || (un = {}));
var Ce;
(function(n) {
  n[n.UNPACKED_FLOAT16 = 0] = "UNPACKED_FLOAT16", n[n.UNPACKED_FLOAT32 = 1] = "UNPACKED_FLOAT32", n[n.PACKED_4X1_UNSIGNED_BYTE = 2] = "PACKED_4X1_UNSIGNED_BYTE", n[n.PACKED_2X2_FLOAT32 = 3] = "PACKED_2X2_FLOAT32", n[n.PACKED_2X2_FLOAT16 = 4] = "PACKED_2X2_FLOAT16";
})(Ce || (Ce = {}));
function Pa(n, t) {
  return [t, n];
}
function WP(n, t) {
  return n * t;
}
function Qa(n) {
  const t = X(n), e = Math.ceil(t / 4);
  return hl(e);
}
function Gr(n, t) {
  return [
    Math.max(1, Math.ceil(t / 2)),
    Math.max(1, Math.ceil(n / 2))
  ];
}
function DP(n, t) {
  const [e, s] = Gr(n, t);
  return e * s * 4;
}
function Uf(n, t) {
  const e = n;
  let s, o, r, i6, a, l, c, u, d, h;
  return F().getNumber("WEBGL_VERSION") === 2 ? (s = e.R32F, o = e.R16F, r = e.RGBA16F, i6 = e.RGBA32F, a = e.RED, c = 4, u = 1, d = e.HALF_FLOAT, h = e.FLOAT, l = e.RGBA8) : (s = n.RGBA, o = n.RGBA, r = n.RGBA, i6 = e.RGBA, a = n.RGBA, c = 4, u = 4, d = t != null ? t.HALF_FLOAT_OES : null, h = n.FLOAT, l = n.RGBA), {
    internalFormatFloat: s,
    internalFormatHalfFloat: o,
    internalFormatPackedHalfFloat: r,
    internalFormatPackedFloat: i6,
    textureFormatFloat: a,
    downloadTextureFormat: l,
    downloadUnpackNumChannels: c,
    defaultNumChannels: u,
    textureTypeHalfFloat: d,
    textureTypeFloat: h
  };
}
function nt(n, t) {
  const e = t();
  return F().getBool("DEBUG") && FP(n), e;
}
function FP(n) {
  const t = n.getError();
  if (t !== n.NO_ERROR)
    throw new Error("WebGL Error: " + Jw(n, t));
}
var VP = 596e-10;
var zP = 65504;
function Qw(n) {
  return !!(F().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || n === 0 || VP < Math.abs(n) && Math.abs(n) < zP);
}
function Jw(n, t) {
  switch (t) {
    case n.NO_ERROR:
      return "NO_ERROR";
    case n.INVALID_ENUM:
      return "INVALID_ENUM";
    case n.INVALID_VALUE:
      return "INVALID_VALUE";
    case n.INVALID_OPERATION:
      return "INVALID_OPERATION";
    case n.INVALID_FRAMEBUFFER_OPERATION:
      return "INVALID_FRAMEBUFFER_OPERATION";
    case n.OUT_OF_MEMORY:
      return "OUT_OF_MEMORY";
    case n.CONTEXT_LOST_WEBGL:
      return "CONTEXT_LOST_WEBGL";
    default:
      return `Unknown error code ${t}`;
  }
}
function jr(n, t) {
  return Rs(n, () => n.getExtension(t), 'Extension "' + t + '" not supported on this browser.');
}
function jw(n, t) {
  const e = Rs(n, () => n.createShader(n.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
  if (nt(n, () => n.shaderSource(e, t)), nt(n, () => n.compileShader(e)), n.getShaderParameter(e, n.COMPILE_STATUS) === false)
    throw console.log(n.getShaderInfoLog(e)), new Error("Failed to compile vertex shader.");
  return e;
}
function qw(n, t) {
  const e = Rs(n, () => n.createShader(n.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
  if (nt(n, () => n.shaderSource(e, t)), nt(n, () => n.compileShader(e)), F().get("ENGINE_COMPILE_ONLY"))
    return e;
  if (n.getShaderParameter(e, n.COMPILE_STATUS) === false)
    throw Yf(t, n.getShaderInfoLog(e)), new Error("Failed to compile fragment shader.");
  return e;
}
var PP = /ERROR: [0-9]+:([0-9]+):/g;
function Yf(n, t) {
  const e = PP.exec(t);
  if (e == null) {
    console.log(`Couldn't parse line number in error: ${t}`), console.log(n);
    return;
  }
  const s = +e[1], o = n.split(`
`), r = o.length.toString().length + 2, i6 = o.map((d, h) => xo((h + 1).toString(), r) + d);
  let a = 0;
  for (let d = 0; d < i6.length; d++)
    a = Math.max(i6[d].length, a);
  const l = i6.slice(0, s - 1), c = i6.slice(s - 1, s), u = i6.slice(s);
  console.log(l.join(`
`)), console.log(t.split(`
`)[0]), console.log(`%c ${xo(c[0], a)}`, "border:1px solid red; background-color:#e3d2d2; color:#a61717"), console.log(u.join(`
`));
}
function tI(n) {
  return Rs(n, () => n.createProgram(), "Unable to create WebGLProgram.");
}
function eI(n, t) {
  if (nt(n, () => n.linkProgram(t)), !F().get("ENGINE_COMPILE_ONLY") && n.getProgramParameter(t, n.LINK_STATUS) === false)
    throw console.log(n.getProgramInfoLog(t)), new Error("Failed to link vertex and fragment shaders.");
}
function al(n, t) {
  if (nt(n, () => n.validateProgram(t)), n.getProgramParameter(t, n.VALIDATE_STATUS) === false)
    throw console.log(n.getProgramInfoLog(t)), new Error("Shader program validation failed.");
}
function nI(n, t) {
  const e = Rs(n, () => n.createBuffer(), "Unable to create WebGLBuffer");
  return nt(n, () => n.bindBuffer(n.ARRAY_BUFFER, e)), nt(n, () => n.bufferData(n.ARRAY_BUFFER, t, n.STATIC_DRAW)), e;
}
function sI(n, t) {
  const e = Rs(n, () => n.createBuffer(), "Unable to create WebGLBuffer");
  return nt(n, () => n.bindBuffer(n.ELEMENT_ARRAY_BUFFER, e)), nt(n, () => n.bufferData(n.ELEMENT_ARRAY_BUFFER, t, n.STATIC_DRAW)), e;
}
function AP() {
  return F().getNumber("WEBGL_VERSION") === 2 ? 1 : 4;
}
function oI(n) {
  return Rs(n, () => n.createTexture(), "Unable to create WebGLTexture.");
}
function rI(n, t) {
  const e = F().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (n <= 0 || t <= 0) {
    const s = `[${n}x${t}]`;
    throw new Error("Requested texture size " + s + " is invalid.");
  }
  if (n > e || t > e) {
    const s = `[${n}x${t}]`, o = `[${e}x${e}]`;
    throw new Error("Requested texture size " + s + " greater than WebGL maximum on this browser / GPU " + o + ".");
  }
}
function iI(n) {
  return Rs(n, () => n.createFramebuffer(), "Unable to create WebGLFramebuffer.");
}
function zd(n, t, e, s, o, r, i6) {
  const a = n.getAttribLocation(t, e);
  return a === -1 ? false : (nt(n, () => n.bindBuffer(n.ARRAY_BUFFER, s)), nt(n, () => n.vertexAttribPointer(a, o, n.FLOAT, false, r, i6)), nt(n, () => n.enableVertexAttribArray(a)), true);
}
function aI(n, t, e) {
  hI(n, e), nt(n, () => n.activeTexture(n.TEXTURE0 + e)), nt(n, () => n.bindTexture(n.TEXTURE_2D, t));
}
function OP(n, t) {
  hI(n, t), nt(n, () => n.activeTexture(n.TEXTURE0 + t)), nt(n, () => n.bindTexture(n.TEXTURE_2D, null));
}
function lI(n, t, e) {
  return Rs(n, () => n.getUniformLocation(t, e), 'uniform "' + e + '" not present in program.');
}
function cI(n, t, e) {
  return n.getUniformLocation(t, e);
}
function uI(n, t, e, s) {
  nt(n, () => aI(n, t, s)), nt(n, () => n.uniform1i(e, s));
}
function XP(n) {
  nt(n, () => n.bindFramebuffer(n.FRAMEBUFFER, null)), nt(n, () => n.viewport(0, 0, n.canvas.width, n.canvas.height)), nt(n, () => n.scissor(0, 0, n.canvas.width, n.canvas.height));
}
function ll(n, t, e) {
  nt(n, () => n.bindFramebuffer(n.FRAMEBUFFER, e)), nt(n, () => n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, t, 0));
}
function Pd(n, t) {
  nt(n, () => n.bindFramebuffer(n.FRAMEBUFFER, t)), nt(n, () => n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, null, 0));
}
function qr(n) {
  const t = n.checkFramebufferStatus(n.FRAMEBUFFER);
  if (t !== n.FRAMEBUFFER_COMPLETE)
    throw new Error("Error binding framebuffer: " + dI(n, t));
}
function dI(n, t) {
  switch (t) {
    case n.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
    case n.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
    case n.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
      return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
    case n.FRAMEBUFFER_UNSUPPORTED:
      return "FRAMEBUFFER_UNSUPPORTED";
    default:
      return `unknown error ${t}`;
  }
}
function Rs(n, t, e) {
  const s = nt(n, () => t());
  if (s == null)
    throw new Error(e);
  return s;
}
function hI(n, t) {
  const e = n.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1, s = t + n.TEXTURE0;
  if (s < n.TEXTURE0 || s > e) {
    const o = `[gl.TEXTURE0, gl.TEXTURE${e}]`;
    throw new Error(`textureUnit must be in ${o}.`);
  }
}
function Vo(n, t = 2) {
  return X(n.slice(0, n.length - t));
}
function zo(n) {
  if (n.length === 0)
    throw Error("Cannot get rows and columns of an empty shape array.");
  return [
    n.length > 1 ? n[n.length - 2] : 1,
    n[n.length - 1]
  ];
}
function ti(n) {
  let t = [1, 1, 1];
  return n.length === 0 || n.length === 1 && n[0] === 1 || (t = [Vo(n), ...zo(n)]), t;
}
function pI(n, t = false) {
  let e = F().getNumber("WEBGL_MAX_TEXTURE_SIZE"), s = F().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");
  s === 1 / 0 && F().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE") && (s = e / 2), t && (e = e * 2, s = s * 2, n = n.map((a, l) => l >= n.length - 2 ? Bl(n[l]) : n[l]), n.length === 1 && (n = [2, n[0]])), n.length !== 2 && (n = ws(n).newShape);
  let o = X(n), r = null;
  n.length <= 1 && o <= e ? r = [1, o] : n.length === 2 && n[0] <= e && n[1] <= e ? r = n : n.length === 3 && n[0] * n[1] <= e && n[2] <= e ? r = [n[0] * n[1], n[2]] : n.length === 3 && n[0] <= e && n[1] * n[2] <= e ? r = [n[0], n[1] * n[2]] : n.length === 4 && n[0] * n[1] * n[2] <= e && n[3] <= e ? r = [n[0] * n[1] * n[2], n[3]] : n.length === 4 && n[0] <= e && n[1] * n[2] * n[3] <= e && (r = [n[0], n[1] * n[2] * n[3]]);
  const i6 = r != null && Math.max(...r) > s && Math.min(...r) <= (t ? 2 : 1) && Math.min(...r) > 0;
  if (r == null || i6)
    if (t) {
      const a = Vo(n);
      let l = 2, c = 2;
      n.length && ([l, c] = zo(n)), o = a * (l / 2) * (c / 2), r = hl(o).map((u) => u * 2);
    } else
      r = hl(o);
  return r;
}
function Ja(n) {
  return n % 2 === 0;
}
function xi(n, t) {
  if (n = n.slice(-2), t = t.slice(-2), $t(n, t) || !n.length || !t.length || n[0] === 0 || n[1] === 0 || t[0] === 0 || t[1] === 0)
    return true;
  if (n.length !== t.length) {
    const e = n[n.length - 1], s = t[t.length - 1];
    if (e === s || Ja(e) && Ja(s) && (n[0] === 1 || t[0] === 1))
      return true;
  }
  return n[1] === t[1] && Ja(n[0]) && Ja(t[0]);
}
var cl;
var ul;
function fI(n) {
  if (cl == null) {
    const t = Bn(n);
    cl = t.getParameter(t.MAX_TEXTURE_SIZE);
  }
  return cl;
}
function KP() {
  cl = null;
}
function ZP() {
  ul = null;
}
function mI(n) {
  if (ul == null) {
    const t = Bn(n);
    ul = t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS);
  }
  return Math.min(16, ul);
}
function gI(n) {
  if (n === 0)
    return 0;
  let t;
  const e = Bn(n);
  return dn(e, "EXT_disjoint_timer_query_webgl2") && n === 2 ? t = 2 : dn(e, "EXT_disjoint_timer_query") ? t = 1 : t = 0, t;
}
function dn(n, t) {
  return n.getExtension(t) != null;
}
function Ad(n) {
  try {
    if (Bn(n) != null)
      return true;
  } catch (t) {
    return console.log("Error when getting WebGL context: ", t), false;
  }
  return false;
}
function bI(n) {
  if (n === 0)
    return false;
  const t = Bn(n);
  if (n === 1) {
    if (!dn(t, "OES_texture_float"))
      return false;
  } else if (!dn(t, "EXT_color_buffer_float"))
    return false;
  return Od(t);
}
function xI(n) {
  if (n === 0)
    return false;
  const t = Bn(n);
  if (n === 1) {
    if (!dn(t, "OES_texture_float") || !dn(t, "WEBGL_color_buffer_float"))
      return false;
  } else {
    if (dn(t, "EXT_color_buffer_float"))
      return Od(t);
    const s = "EXT_color_buffer_half_float";
    if (dn(t, s)) {
      const o = t.getExtension(s);
      return BP(t, o);
    }
    return false;
  }
  return Od(t);
}
function Od(n) {
  const t = Uf(n), e = n.createTexture();
  n.bindTexture(n.TEXTURE_2D, e), n.texImage2D(n.TEXTURE_2D, 0, t.internalFormatFloat, 1, 1, 0, t.textureFormatFloat, t.textureTypeFloat, null);
  const r = n.createFramebuffer();
  n.bindFramebuffer(n.FRAMEBUFFER, r), n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, e, 0);
  const i6 = n.checkFramebufferStatus(n.FRAMEBUFFER) === n.FRAMEBUFFER_COMPLETE;
  return n.bindTexture(n.TEXTURE_2D, null), n.bindFramebuffer(n.FRAMEBUFFER, null), n.deleteTexture(e), n.deleteFramebuffer(r), i6;
}
function BP(n, t) {
  const e = Uf(n, t), s = n.createTexture();
  n.bindTexture(n.TEXTURE_2D, s), n.texImage2D(n.TEXTURE_2D, 0, e.internalFormatHalfFloat, 1, 1, 0, e.textureFormatFloat, e.textureTypeHalfFloat, null);
  const i6 = n.createFramebuffer();
  n.bindFramebuffer(n.FRAMEBUFFER, i6), n.framebufferTexture2D(n.FRAMEBUFFER, n.COLOR_ATTACHMENT0, n.TEXTURE_2D, s, 0);
  const a = n.checkFramebufferStatus(n.FRAMEBUFFER) === n.FRAMEBUFFER_COMPLETE;
  return n.bindTexture(n.TEXTURE_2D, null), n.bindFramebuffer(n.FRAMEBUFFER, null), n.deleteTexture(s), n.deleteFramebuffer(i6), a;
}
function yI(n) {
  return n !== 2 ? false : Bn(n).fenceSync != null;
}
function Er(n, t) {
  Array.isArray(n) || (n = [n]), n.forEach((e) => {
    e != null && C(e.dtype !== "complex64", () => `${t} does not support complex64 tensors in the WebGL backend.`);
  });
}
var _Q = Object.freeze(Object.defineProperty({
  __proto__: null,
  assertNotComplex: Er,
  bindCanvasToFramebuffer: XP,
  bindColorTextureToFramebuffer: ll,
  bindTextureToProgramUniformSampler: uI,
  bindTextureUnit: aI,
  bindVertexBufferToProgramAttribute: zd,
  callAndCheck: nt,
  canBeRepresented: Qw,
  createFragmentShader: qw,
  createFramebuffer: iI,
  createProgram: tI,
  createStaticIndexBuffer: sI,
  createStaticVertexBuffer: nI,
  createTexture: oI,
  createVertexShader: jw,
  getBatchDim: Vo,
  getExtensionOrThrow: jr,
  getFramebufferErrorMessage: dI,
  getMaxTexturesInShader: mI,
  getNumChannels: AP,
  getProgramUniformLocation: cI,
  getProgramUniformLocationOrThrow: lI,
  getRowsCols: zo,
  getShapeAs3D: ti,
  getTextureShapeFromLogicalShape: pI,
  getWebGLDisjointQueryTimerVersion: gI,
  getWebGLErrorMessage: Jw,
  getWebGLMaxTextureSize: fI,
  hasExtension: dn,
  isCapableOfRenderingToFloatTexture: bI,
  isDownloadFloatTextureEnabled: xI,
  isReshapeFree: xi,
  isWebGLFenceEnabled: yI,
  isWebGLVersionEnabled: Ad,
  linkProgram: eI,
  logShaderSourceAndInfoLog: Yf,
  resetMaxTextureSize: KP,
  resetMaxTexturesInShader: ZP,
  unbindColorTextureFromFramebuffer: Pd,
  unbindTextureUnit: OP,
  validateFramebuffer: qr,
  validateProgram: al,
  validateTextureSize: rI
}, Symbol.toStringTag, { value: "Module" }));
var ct = F();
ct.registerFlag("HAS_WEBGL", () => ct.getNumber("WEBGL_VERSION") > 0);
ct.registerFlag("WEBGL_VERSION", () => Ad(2) ? 2 : Ad(1) ? 1 : 0);
ct.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => false);
ct.registerFlag("WEBGL_BUFFER_SUPPORTED", () => ct.get("WEBGL_VERSION") === 2);
ct.registerFlag("WEBGL_CPU_FORWARD", () => true);
ct.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => false);
ct.registerFlag("WEBGL_PACK", () => ct.getBool("HAS_WEBGL"));
ct.registerFlag("WEBGL_PACK_NORMALIZATION", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_CLIP", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_REDUCE", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_LAZILY_UNPACK", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_CONV_IM2COL", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_PACK_CONV2DTRANSPOSE", () => ct.getBool("WEBGL_PACK"));
ct.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => fI(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => mI(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
  const n = ct.getNumber("WEBGL_VERSION");
  return n === 0 ? 0 : gI(n);
});
ct.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => ct.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !Qh());
ct.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => bI(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => ct.getBool("WEBGL_FORCE_F16_TEXTURES") ? false : ct.getBool("WEBGL_RENDER_FLOAT32_CAPABLE"));
ct.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => xI(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_FENCE_API_ENABLED", () => yI(ct.getNumber("WEBGL_VERSION")));
ct.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => ct.getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? 4 : 0);
ct.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => -1, (n) => {
  if (typeof n != "number")
    throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be a number but got ${n}.`);
  if (n < 0 && n !== -1)
    throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${n}.`);
});
ct.registerFlag("WEBGL_FLUSH_THRESHOLD", () => Qh() ? 1 : -1, (n) => {
  if (typeof n != "number")
    throw new Error(`WEBGL_FLUSH_THRESHOLD must be a number but got ${n}.`);
  if (n < 0 && n !== -1)
    throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${n}.`);
});
ct.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128);
ct.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", () => false);
ct.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e5);
ct.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", () => 128);
ct.registerFlag("WEBGL_EXP_CONV", () => false);
ct.registerFlag("SOFTWARE_WEBGL_ENABLED", () => ct.getBool("IS_TEST"));
ct.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE", () => 1 / 0);
ct.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE", () => false);
ct.registerFlag("WEBGL2_ISNAN_CUSTOM", () => false);
ct.registerFlag("ENGINE_COMPILE_ONLY", () => false);
function Ae() {
  let n, t, e, s, o, r, i6, a, l, c;
  return F().getNumber("WEBGL_VERSION") === 2 ? (n = "#version 300 es", t = "in", e = "out", s = "in", o = "texture", r = "outputColor", i6 = "out vec4 outputColor;", a = F().getBool("WEBGL2_ISNAN_CUSTOM") ? `
      bool isnan_custom(float val) {
        uint floatToUint = floatBitsToUint(val);
        return (floatToUint & 0x7fffffffu) > 0x7f800000u;
      }

      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan_custom(val.x),
          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));
      }

      #define isnan(value) isnan_custom(value)
    ` : "", l = "", c = `
      #define round(value) newRound(value)
      int newRound(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 newRound(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `) : (n = "", t = "attribute", e = "varying", s = "varying", o = "texture2D", r = "gl_FragColor", i6 = "", a = `
      #define isnan(value) isnan_custom(value)
      bool isnan_custom(float val) {
        return (val > 0. || val < 1. || val == 0.) ? false : true;
      }
      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));
      }
    `, l = `
      uniform float INFINITY;

      bool isinf(float val) {
        return abs(val) == INFINITY;
      }
      bvec4 isinf(vec4 val) {
        return equal(abs(val), vec4(INFINITY));
      }
    `, c = `
      int round(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 round(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `), {
    version: n,
    attribute: t,
    varyingVs: e,
    varyingFs: s,
    texture2D: o,
    output: r,
    defineOutput: i6,
    defineSpecialNaN: a,
    defineSpecialInf: l,
    defineRound: c
  };
}
function Qo(n, t, e = "index") {
  const s = dt(t);
  return s.map((o, r) => {
    const i6 = `int ${n[r]} = ${e} / ${o}`, a = r === s.length - 1 ? `int ${n[r + 1]} = ${e} - ${n[r]} * ${o}` : `index -= ${n[r]} * ${o}`;
    return `${i6}; ${a};`;
  }).join("");
}
function Iu(n, t, e = "index") {
  const s = dt(t);
  return s.map((o, r) => {
    const i6 = `int ${n[r]} = ${e} / outShapeStrides[${r}]`, a = r === s.length - 1 ? `int ${n[r + 1]} = ${e} - ${n[r]} * outShapeStrides[${r}]` : `index -= ${n[r]} * outShapeStrides[${r}]`;
    return `${i6}; ${a};`;
  }).join("");
}
function HP(n, t) {
  const e = n.length, s = n.map((r) => `${t}[${r}]`), o = new Array(e - 1);
  o[e - 2] = s[e - 1];
  for (let r = e - 3; r >= 0; --r)
    o[r] = `(${o[r + 1]} * ${s[r + 1]})`;
  return o;
}
function _P(n, t, e = "index") {
  const s = n.map((r, i6) => i6), o = HP(s, t);
  return o.map((r, i6) => {
    const a = `int ${n[i6]} = ${e} / ${o[i6]}`, l = i6 === o.length - 1 ? `int ${n[i6 + 1]} = ${e} - ${n[i6]} * ${o[i6]}` : `index -= ${n[i6]} * ${o[i6]}`;
    return `${a}; ${l};`;
  }).join("");
}
function Qf(n) {
  const t = dt(n).map((e) => e.toString());
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * ${t[0]} + coords.y * ${t[1]} + coords.z;
  }
`;
}
function Jf() {
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;
  }
`;
}
var wI = `
  const float FLOAT_MAX = 1.70141184e38;
  const float FLOAT_MIN = 1.17549435e-38;

  lowp vec4 encode_float(highp float v) {
    if (isnan(v)) {
      return vec4(255, 255, 255, 255);
    }

    highp float av = abs(v);

    if(av < FLOAT_MIN) {
      return vec4(0.0, 0.0, 0.0, 0.0);
    } else if(v > FLOAT_MAX) {
      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;
    } else if(v < -FLOAT_MAX) {
      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;
    }

    highp vec4 c = vec4(0,0,0,0);

    highp float e = floor(log2(av));
    highp float m = exp2(fract(log2(av))) - 1.0;

    c[2] = floor(128.0 * m);
    m -= c[2] / 128.0;
    c[1] = floor(32768.0 * m);
    m -= c[1] / 32768.0;
    c[0] = floor(8388608.0 * m);

    highp float ebias = e + 127.0;
    c[3] = floor(ebias / 2.0);
    ebias -= c[3] * 2.0;
    c[2] += floor(ebias) * 128.0;

    c[3] += 128.0 * step(0.0, -v);

    return c / 255.0;
  }
`;
var { getBroadcastDims: II } = E$;
function UP(n, t, e) {
  const s = [];
  if (n.forEach((p) => {
    const f = X(p.shapeInfo.logicalShape);
    if (p.shapeInfo.isUniform ? s.push(`uniform float ${p.name}${f > 1 ? `[${f}]` : ""};`) : (s.push(`uniform sampler2D ${p.name};`), s.push(`uniform int offset${p.name};`)), e.enableShapeUniforms) {
      const { uniformShape: m } = jf(e.packedInputs, p.shapeInfo.logicalShape, p.shapeInfo.texShape);
      switch (m.length) {
        case 1:
          s.push(`uniform int ${p.name}Shape;`);
          break;
        case 2:
          s.push(`uniform ivec2 ${p.name}Shape;`);
          break;
        case 3:
          s.push(`uniform ivec3 ${p.name}Shape;`);
          break;
        case 4:
          s.push(`uniform ivec4 ${p.name}Shape;`);
          break;
      }
      s.push(`uniform ivec2 ${p.name}TexShape;`);
    }
  }), e.enableShapeUniforms) {
    switch (t.logicalShape.length) {
      case 1:
        s.push("uniform int outShape;");
        break;
      case 2:
        s.push("uniform ivec2 outShape;"), s.push("uniform int outShapeStrides;");
        break;
      case 3:
        s.push("uniform ivec3 outShape;"), s.push("uniform ivec2 outShapeStrides;");
        break;
      case 4:
        s.push("uniform ivec4 outShape;"), s.push("uniform ivec3 outShapeStrides;");
        break;
    }
    s.push("uniform ivec2 outTexShape;");
  }
  e.customUniforms && e.customUniforms.forEach((p) => {
    s.push(`uniform ${p.type} ${p.name}${p.arrayIndex ? `[${p.arrayIndex}]` : ""};`);
  });
  const o = s.join(`
`), r = n.map((p) => YP(p, t, e.packedInputs, e.enableShapeUniforms)).join(`
`), i6 = t.texShape, a = Ae(), l = jP(a);
  let c, u, d = eA(a);
  return t.isPacked ? (c = QP(t.logicalShape, i6, e.enableShapeUniforms), u = tA(a)) : (c = JP(t.logicalShape, i6, e.enableShapeUniforms), u = qP(a)), e.packedInputs && (d += rA), [
    d,
    l,
    u,
    o,
    c,
    r,
    e.userCode
  ].join(`
`);
}
function Lr(n, t = false) {
  const e = n.shapeInfo.logicalShape;
  switch (e.length) {
    case 0:
      return bA(n, t);
    case 1:
      return yA(n, t);
    case 2:
      return IA(n, t);
    case 3:
      return vA(n, t);
    case 4:
      return kA(n, t);
    case 5:
      return TA(n);
    case 6:
      return NA(n);
    default:
      throw new Error(`${e.length}-D input sampling is not yet supported`);
  }
}
function CI(n, t) {
  switch (n.shapeInfo.logicalShape.length) {
    case 0:
      return gA(n);
    case 1:
      return xA(n, t);
    case 2:
      return wA(n, t);
    case 3:
      return CA(n, t);
    default:
      return SA(n, t);
  }
}
function YP(n, t, e = false, s) {
  let o = "";
  e ? o += CI(n, s) : o += Lr(n, s);
  const r = n.shapeInfo.logicalShape, i6 = t.logicalShape;
  return r.length <= i6.length && (e ? o += RA(n, t) : o += $A(n, t)), o;
}
function QP(n, t, e) {
  switch (n.length) {
    case 0:
      return vI();
    case 1:
      return iA(n, t, e);
    case 2:
      return fA(n, t, e);
    case 3:
      return lA(n, t, e);
    default:
      return uA(n, t, e);
  }
}
function JP(n, t, e) {
  switch (n.length) {
    case 0:
      return vI();
    case 1:
      return aA(n, t, e);
    case 2:
      return mA(n, t, e);
    case 3:
      return cA(n, t, e);
    case 4:
      return dA(n, t, e);
    case 5:
      return hA(n, t);
    case 6:
      return pA(n, t);
    default:
      throw new Error(`${n.length}-D output sampling is not yet supported`);
  }
}
function jP(n) {
  return `
    float sampleTexture(sampler2D textureSampler, vec2 uv) {
      return ${n.texture2D}(textureSampler, uv).r;
    }
  `;
}
function qP(n) {
  return `
    void setOutput(float val) {
      ${n.output} = vec4(val, 0, 0, 0);
    }
  `;
}
function tA(n) {
  return `
    void setOutput(vec4 val) {
      ${n.output} = val;
    }
  `;
}
function eA(n) {
  return `${n.version}
    precision highp float;
    precision highp int;
    precision highp sampler2D;
    ${n.varyingFs} vec2 resultUV;
    ${n.defineOutput}
    const vec2 halfCR = vec2(0.5, 0.5);

    struct ivec5
    {
      int x;
      int y;
      int z;
      int w;
      int u;
    };

    struct ivec6
    {
      int x;
      int y;
      int z;
      int w;
      int u;
      int v;
    };

    uniform float NAN;
    ${n.defineSpecialNaN}
    ${n.defineSpecialInf}
    ${n.defineRound}

    int imod(int x, int y) {
      return x - y * (x / y);
    }

    int idiv(int a, int b, float sign) {
      int res = a / b;
      int mod = imod(a, b);
      if (sign < 0. && mod != 0) {
        res -= 1;
      }
      return res;
    }

    //Based on the work of Dave Hoskins
    //https://www.shadertoy.com/view/4djSRW
    #define HASHSCALE1 443.8975
    float random(float seed){
      vec2 p = resultUV * seed;
      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);
      p3 += dot(p3, p3.yzx + 19.19);
      return fract((p3.x + p3.y) * p3.z);
    }

    ${nA}
    ${sA}
    ${oA}
  `;
}
var nA = `
vec2 uvFromFlat(int texNumR, int texNumC, int index) {
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {
  int texelIndex = index / 2;
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var sA = `
vec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,
  int texNumC, int row, int col) {
  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var oA = `
vec2 packedUVfrom3D(int texNumR, int texNumC,
    int texelsInBatch, int texelsInLogicalRow, int b,
    int row, int col) {
  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var rA = `
  float getChannel(vec4 frag, vec2 innerDims) {
    vec2 modCoord = mod(innerDims, 2.);
    return modCoord.x == 0. ?
      (modCoord.y == 0. ? frag.r : frag.g) :
      (modCoord.y == 0. ? frag.b : frag.a);
  }
  float getChannel(vec4 frag, int dim) {
    float modCoord = mod(float(dim), 2.);
    return modCoord == 0. ? frag.r : frag.g;
  }
`;
function vI() {
  return `
    int getOutputCoords() {
      return 0;
    }
  `;
}
function iA(n, t, e) {
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  return s[0] === 1 ? e ? `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));
      }
    ` : `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ${s[1]}.0);
      }
    ` : s[1] === 1 ? e ? `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));
      }
    ` : `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ${s[0]}.0);
      }
    ` : e ? `
    int getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);
    }
  ` : `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));
      return 2 * (resTexRC.x * ${s[1]} + resTexRC.y);
    }
  `;
}
function aA(n, t, e) {
  return t[0] === 1 ? e ? `
      int getOutputCoords() {
        return int(resultUV.x * float(outTexShape[1]));
      }
    ` : `
      int getOutputCoords() {
        return int(resultUV.x * ${t[1]}.0);
      }
    ` : t[1] === 1 ? e ? `
      int getOutputCoords() {
        return int(resultUV.y * float(outTexShape[0]));
      }
    ` : `
      int getOutputCoords() {
        return int(resultUV.y * ${t[0]}.0);
      }
    ` : e ? `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      return resTexRC.x * outTexShape[1] + resTexRC.y;
    }
  ` : `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t[0]}, ${t[1]}));
      return resTexRC.x * ${t[1]} + resTexRC.y;
    }
  `;
}
function lA(n, t, e) {
  if (e)
    return `
    ivec3 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec3(b, r, c);
    }
  `;
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)], o = Math.ceil(n[2] / 2), r = o * Math.ceil(n[1] / 2);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));
      int index = resTexRC.x * ${s[1]} + resTexRC.y;

      int b = index / ${r};
      index -= b * ${r};

      int r = 2 * (index / ${o});
      int c = imod(index, ${o}) * 2;

      return ivec3(b, r, c);
    }
  `;
}
function cA(n, t, e) {
  if (e)
    return `
  ivec3 getOutputCoords() {
    ivec2 resTexRC = ivec2(resultUV.yx *
                           vec2(outTexShape[0], outTexShape[1]));
    int index = resTexRC.x * outTexShape[1] + resTexRC.y;
    ${Iu(["r", "c", "d"], n)}
    return ivec3(r, c, d);
  }
`;
  const s = Qo(["r", "c", "d"], n);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;
      ${s}
      return ivec3(r, c, d);
    }
  `;
}
function uA(n, t, e) {
  if (e)
    return `
    ivec4 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatchN = texelsInBatch * outShape[1];

      int b2 = index / texelsInBatchN;
      index -= b2 * texelsInBatchN;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec4(b2, b, r, c);
    }
  `;
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)], o = Math.ceil(n[n.length - 1] / 2), r = o * Math.ceil(n[n.length - 2] / 2);
  let i6 = r, a = "", l = "b, r, c";
  for (let c = 2; c < n.length - 1; c++)
    i6 *= n[n.length - c - 1], a = `
      int b${c} = index / ${i6};
      index -= b${c} * ${i6};
    ` + a, l = `b${c}, ` + l;
  return `
    ivec${n.length} getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));
      int index = resTexRC.x * ${s[1]} + resTexRC.y;

      ${a}

      int b = index / ${r};
      index -= b * ${r};

      int r = 2 * (index / ${o});
      int c = imod(index, ${o}) * 2;

      return ivec${n.length}(${l});
    }
  `;
}
function dA(n, t, e) {
  if (e)
    return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      ${Iu(["r", "c", "d", "d2"], n)}
      return ivec4(r, c, d, d2);
    }
  `;
  const s = Qo(["r", "c", "d", "d2"], n);
  return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;
      ${s}
      return ivec4(r, c, d, d2);
    }
  `;
}
function hA(n, t) {
  const e = Qo(["r", "c", "d", "d2", "d3"], n);
  return `
    ivec5 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${t[0]},
                             ${t[1]}));

      int index = resTexRC.x * ${t[1]} + resTexRC.y;

      ${e}

      ivec5 outShape = ivec5(r, c, d, d2, d3);
      return outShape;
    }
  `;
}
function pA(n, t) {
  const e = Qo(["r", "c", "d", "d2", "d3", "d4"], n);
  return `
    ivec6 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;

      ${e}

      ivec6 result = ivec6(r, c, d, d2, d3, d4);
      return result;
    }
  `;
}
function fA(n, t, e) {
  const s = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  if ($t(n, t))
    return e ? `
      ivec2 getOutputCoords() {
        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));
      }
    ` : `
      ivec2 getOutputCoords() {
        return 2 * ivec2(resultUV.yx * vec2(${s[0]}, ${s[1]}));
      }
    `;
  const o = Math.ceil(n[1] / 2);
  return e ? `
    ivec2 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));

      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;
      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec2(r, c);
    }
  ` : `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${s[0]}, ${s[1]}));

      int index = resTexRC.x * ${s[1]} + resTexRC.y;
      int r = 2 * (index / ${o});
      int c = imod(index, ${o}) * 2;

      return ivec2(r, c);
    }
  `;
}
function mA(n, t, e) {
  return $t(n, t) ? e ? `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));
      }
    ` : `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(${t[0]}, ${t[1]}));
      }
    ` : n[1] === 1 ? e ? `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(index, 0);
      }
    ` : `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${t[0]}, ${t[1]}));
        int index = resTexRC.x * ${t[1]} + resTexRC.y;
        return ivec2(index, 0);
      }
    ` : n[0] === 1 ? e ? `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(0, index);
      }
    ` : `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${t[0]}, ${t[1]}));
        int index = resTexRC.x * ${t[1]} + resTexRC.y;
        return ivec2(0, index);
      }
    ` : e ? `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      int r = index / outShape[1];
      int c = index - r * outShape[1];
      return ivec2(r, c);
    }
  ` : `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t[0]}, ${t[1]}));
      int index = resTexRC.x * ${t[1]} + resTexRC.y;
      int r = index / ${n[1]};
      int c = index - r * ${n[1]};
      return ivec2(r, c);
    }
  `;
}
function Jo(n) {
  return `offset${n}`;
}
function gA(n) {
  const t = n.name, e = "get" + t.charAt(0).toUpperCase() + t.slice(1), s = Ae();
  return `
    vec4 ${e}() {
      return ${s.texture2D}(${t}, halfCR);
    }
  `;
}
function bA(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1);
  if (n.shapeInfo.isUniform)
    return `float ${s}() {return ${e};}`;
  const [o, r] = n.shapeInfo.texShape;
  if (o === 1 && r === 1)
    return `
      float ${s}() {
        return sampleTexture(${e}, halfCR);
      }
    `;
  const i6 = Jo(e);
  if (t)
    return `
    float ${s}() {
      vec2 uv = uvFromFlat(${e}TexShape[0], ${e}TexShape[1], ${i6});
      return sampleTexture(${e}, uv);
    }
  `;
  const [a, l] = n.shapeInfo.texShape;
  return `
    float ${s}() {
      vec2 uv = uvFromFlat(${a}, ${l}, ${i6});
      return sampleTexture(${e}, uv);
    }
  `;
}
function xA(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), o = n.shapeInfo.texShape, r = Ae();
  if (t)
    return `
    vec4 ${s}(int index) {
      ivec2 packedTexShape = ivec2(ceil(float(${e}TexShape[0]) / 2.0), ceil(float(${e}TexShape[1]) / 2.0));
      vec2 uv = packedUVfrom1D(
        packedTexShape[0], packedTexShape[1], index);
      return ${r.texture2D}(${e}, uv);
    }
  `;
  const i6 = [Math.ceil(o[0] / 2), Math.ceil(o[1] / 2)];
  return `
    vec4 ${s}(int index) {
      vec2 uv = packedUVfrom1D(
        ${i6[0]}, ${i6[1]}, index);
      return ${r.texture2D}(${e}, uv);
    }
  `;
}
function yA(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1);
  if (n.shapeInfo.isUniform)
    return `
      float ${s}(int index) {
        ${Mr(n)}
      }
    `;
  const o = n.shapeInfo.texShape, r = o[0], i6 = o[1];
  if (i6 === 1 && r === 1)
    return `
      float ${s}(int index) {
        return sampleTexture(${e}, halfCR);
      }
    `;
  const a = Jo(e);
  return i6 === 1 ? t ? `
      float ${s}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${a}) + 0.5) / float(${e}TexShape[0]));
        return sampleTexture(${e}, uv);
      }
    ` : `
      float ${s}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${a}) + 0.5) / ${r}.0);
        return sampleTexture(${e}, uv);
      }
    ` : r === 1 ? t ? `
      float ${s}(int index) {
        vec2 uv = vec2((float(index + ${a}) + 0.5) / float(${e}TexShape[1]), 0.5);
        return sampleTexture(${e}, uv);
      }
    ` : `
      float ${s}(int index) {
        vec2 uv = vec2((float(index + ${a}) + 0.5) / ${i6}.0, 0.5);
        return sampleTexture(${e}, uv);
      }
    ` : t ? `
    float ${s}(int index) {
      vec2 uv = uvFromFlat(${e}TexShape[0], ${e}TexShape[1], index + ${a});
      return sampleTexture(${e}, uv);
    }
  ` : `
    float ${s}(int index) {
      vec2 uv = uvFromFlat(${r}, ${i6}, index + ${a});
      return sampleTexture(${e}, uv);
    }
  `;
}
function wA(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = n.shapeInfo.texShape, i6 = r[0], a = r[1], l = Ae();
  if (r != null && $t(e, r))
    return t ? `
      vec4 ${o}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);

        return ${l.texture2D}(${s}, uv);
      }
    ` : `
      vec4 ${o}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${a}.0, ${i6}.0);

        return ${l.texture2D}(${s}, uv);
      }
    `;
  if (t)
    return `
    vec4 ${o}(int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${s}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);
      return ${l.texture2D}(${s}, uv);
    }
  `;
  const c = [Math.ceil(r[0] / 2), Math.ceil(r[1] / 2)], u = Math.ceil(e[1] / 2);
  return `
    vec4 ${o}(int row, int col) {
      vec2 uv = packedUVfrom2D(${u}, ${c[0]}, ${c[1]}, row, col);
      return ${l.texture2D}(${s}, uv);
    }
  `;
}
function IA(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = n.shapeInfo.texShape;
  if (r != null && $t(e, r)) {
    if (t)
      return `
      float ${o}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    `;
    const h = r[0], p = r[1];
    return `
    float ${o}(int row, int col) {
      vec2 uv = (vec2(col, row) + halfCR) / vec2(${p}.0, ${h}.0);
      return sampleTexture(${s}, uv);
    }
  `;
  }
  const { newShape: i6, keptDims: a } = ws(e), l = i6;
  if (l.length < e.length) {
    const h = Wr(n, l), p = ["row", "col"];
    return `
      ${Lr(h, t)}
      float ${o}(int row, int col) {
        return ${o}(${Dr(p, a)});
      }
    `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${o}(int row, int col) {
        int index = round(dot(vec2(row, col), vec2(${e[1]}, 1)));
        ${Mr(n)}
      }
    `;
  const c = r[0], u = r[1], d = Jo(s);
  return u === 1 ? t ? `
      float ${o}(int row, int col) {
        float index = dot(vec3(row, col, ${d}), vec3(${s}Shape[1], 1, 1));
        vec2 uv = vec2(0.5, (index + 0.5) / float(${s}TexShape[0]));
        return sampleTexture(${s}, uv);
      }
    ` : `
    float ${o}(int row, int col) {
      float index = dot(vec3(row, col, ${d}), vec3(${e[1]}, 1, 1));
      vec2 uv = vec2(0.5, (index + 0.5) / ${c}.0);
      return sampleTexture(${s}, uv);
    }
  ` : c === 1 ? t ? `
      float ${o}(int row, int col) {
        float index = dot(vec3(row, col, ${d}), vec3(${s}Shape[1], 1, 1));
        vec2 uv = vec2((index + 0.5) / float(${s}TexShape[1]), 0.5);
        return sampleTexture(${s}, uv);
      }
    ` : `
    float ${o}(int row, int col) {
      float index = dot(vec3(row, col, ${d}), vec3(${e[1]}, 1, 1));
      vec2 uv = vec2((index + 0.5) / ${u}.0, 0.5);
      return sampleTexture(${s}, uv);
    }
  ` : t ? `
      float ${o}(int row, int col) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${s}Shape[1] + col + ${d};
        vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);
        return sampleTexture(${s}, uv);
      }
    ` : `
  float ${o}(int row, int col) {
    // Explicitly use integer operations as dot() only works on floats.
    int index = row * ${e[1]} + col + ${d};
    vec2 uv = uvFromFlat(${c}, ${u}, index);
    return sampleTexture(${s}, uv);
  }
`;
}
function CA(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = n.shapeInfo.texShape, i6 = [Math.ceil(r[0] / 2), Math.ceil(r[1] / 2)];
  if (e[0] === 1) {
    const h = e.slice(1), p = [1, 2], f = Wr(n, h), m = ["b", "row", "col"];
    return `
        ${CI(f, t)}
        vec4 ${o}(int b, int row, int col) {
          return ${o}(${Dr(m, p)});
        }
      `;
  }
  const a = Ae();
  if (t)
    return `
    vec4 ${o}(int b, int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${s}TexShape[0]) / 2.0), ceil(float(${s}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${s}Shape[2]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${s}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom3D(
        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);
      return ${a.texture2D}(${s}, uv);
    }
  `;
  const l = i6[0], c = i6[1], u = Math.ceil(e[2] / 2), d = u * Math.ceil(e[1] / 2);
  return `
    vec4 ${o}(int b, int row, int col) {
      vec2 uv = packedUVfrom3D(
        ${l}, ${c}, ${d}, ${u}, b, row, col);
      return ${a.texture2D}(${s}, uv);
    }
  `;
}
function vA(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = e[1] * e[2], i6 = e[2], { newShape: a, keptDims: l } = ws(e), c = a;
  if (c.length < e.length) {
    const m = Wr(n, c), g = ["row", "col", "depth"];
    return `
        ${Lr(m, t)}
        float ${o}(int row, int col, int depth) {
          return ${o}(${Dr(g, l)});
        }
      `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${o}(int row, int col, int depth) {
        int index = round(dot(vec3(row, col, depth),
                          vec3(${r}, ${i6}, 1)));
        ${Mr(n)}
      }
    `;
  const u = n.shapeInfo.texShape, d = u[0], h = u[1], p = n.shapeInfo.flatOffset;
  if (h === r && p == null)
    return t ? `
      float ${o}(int row, int col, int depth) {
        int stride1 = ${s}Shape[2];
        float texR = float(row);
        float texC = dot(vec2(col, depth), vec2(stride1, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
        float ${o}(int row, int col, int depth) {
          float texR = float(row);
          float texC = dot(vec2(col, depth), vec2(${i6}, 1));
          vec2 uv = (vec2(texC, texR) + halfCR) /
                     vec2(${h}.0, ${d}.0);
          return sampleTexture(${s}, uv);
        }
      `;
  if (h === i6 && p == null)
    return t ? `
      float ${o}(int row, int col, int depth) {
        float texR = dot(vec2(row, col), vec2(${s}Shape[1], 1));
        float texC = float(depth);
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
    float ${o}(int row, int col, int depth) {
      float texR = dot(vec2(row, col), vec2(${e[1]}, 1));
      float texC = float(depth);
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${h}.0, ${d}.0);
      return sampleTexture(${s}, uv);
    }
  `;
  const f = Jo(s);
  return t ? `
    float ${o}(int row, int col, int depth) {
      // Explicitly use integer operations as dot() only works on floats.
      int stride0 = ${s}Shape[1] * ${s}Shape[2];
      int stride1 = ${s}Shape[2];
      int index = row * stride0 + col * stride1 + depth + ${f};
      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index);
      return sampleTexture(${s}, uv);
    }
    ` : `
      float ${o}(int row, int col, int depth) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${r} + col * ${i6} + depth + ${f};
        vec2 uv = uvFromFlat(${d}, ${h}, index);
        return sampleTexture(${s}, uv);
      }
  `;
}
function SA(n, t) {
  const e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), o = Ae();
  if (t)
    return `
    vec4 ${s}(int b2, int b, int row, int col) {
      int valuesPerRow = int(ceil(float(${e}Shape[3]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${e}Shape[2]) / 2.0));
      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);
      texelsInBatch *= ${e}Shape[1];
      index = b2 * texelsInBatch + index;
      ivec2 packedTexShape = ivec2(ceil(float(${e}TexShape[0]) / 2.0), ceil(float(${e}TexShape[1]) / 2.0));
      int texR = index / packedTexShape[1];
      int texC = index - texR * packedTexShape[1];
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${o.texture2D}(${e}, uv);
    }
  `;
  const r = n.shapeInfo.logicalShape, i6 = r.length, a = n.shapeInfo.texShape, l = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)], c = l[0], u = l[1], d = Math.ceil(r[i6 - 1] / 2);
  let h = d * Math.ceil(r[i6 - 2] / 2), p = "int b, int row, int col", f = `b * ${h} + (row / 2) * ${d} + (col / 2)`;
  for (let m = 2; m < i6 - 1; m++)
    p = `int b${m}, ` + p, h *= r[i6 - m - 1], f = `b${m} * ${h} + ` + f;
  return `
    vec4 ${s}(${p}) {
      int index = ${f};
      int texR = index / ${u};
      int texC = index - texR * ${u};
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${u}, ${c});
      return ${o.texture2D}(${e}, uv);
    }
  `;
}
function kA(n, t) {
  const e = n.shapeInfo.logicalShape, s = n.name, o = "get" + s.charAt(0).toUpperCase() + s.slice(1), r = e[3], i6 = e[2] * r, a = e[1] * i6, { newShape: l, keptDims: c } = ws(e);
  if (l.length < e.length) {
    const x6 = Wr(n, l), w = ["row", "col", "depth", "depth2"];
    return `
      ${Lr(x6, t)}
      float ${o}(int row, int col, int depth, int depth2) {
        return ${o}(${Dr(w, c)});
      }
    `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${o}(int row, int col, int depth, int depth2) {
        int index = round(dot(vec4(row, col, depth, depth2),
                          vec4(${a}, ${i6}, ${r}, 1)));
        ${Mr(n)}
      }
    `;
  const u = n.shapeInfo.flatOffset, d = n.shapeInfo.texShape, h = d[0], p = d[1], f = `int stride2 = ${s}Shape[3];`, m = `int stride1 = ${s}Shape[2] * stride2;`, g = `int stride0 = ${s}Shape[1] * stride1;`;
  if (p === a && u == null)
    return t ? `
      float ${o}(int row, int col, int depth, int depth2) {
        ${f}
        ${m}
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(stride1, stride2, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
      float ${o}(int row, int col, int depth, int depth2) {
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(${i6}, ${r}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${p}.0, ${h}.0);
        return sampleTexture(${s}, uv);
      }
    `;
  if (p === r && u == null)
    return t ? `
      float ${o}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${s}Shape[1] * ${s}Shape[2], ${s}Shape[2], 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${s}TexShape[1], ${s}TexShape[0]);
        return sampleTexture(${s}, uv);
      }
    ` : `
      float ${o}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${e[1] * e[2]}, ${e[2]}, 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${p}.0, ${h}.0);
        return sampleTexture(${s}, uv);
      }
    `;
  const b = Jo(s);
  return t ? `
    float ${o}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      ${f}
      ${m}
      ${g}
      int index = row * stride0 + col * stride1 +
          depth * stride2 + depth2;
      vec2 uv = uvFromFlat(${s}TexShape[0], ${s}TexShape[1], index + ${b});
      return sampleTexture(${s}, uv);
    }
  ` : `
    float ${o}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${a} + col * ${i6} +
          depth * ${r} + depth2;
      vec2 uv = uvFromFlat(${h}, ${p}, index + ${b});
      return sampleTexture(${s}, uv);
    }
  `;
}
function TA(n) {
  const t = n.shapeInfo.logicalShape, e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), o = t[4], r = t[3] * o, i6 = t[2] * r, a = t[1] * i6, { newShape: l, keptDims: c } = ws(t);
  if (l.length < t.length) {
    const m = Wr(n, l), g = ["row", "col", "depth", "depth2", "depth3"];
    return `
      ${Lr(m)}
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        return ${s}(${Dr(g, c)});
      }
    `;
  }
  if (n.shapeInfo.isUniform)
    return `
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        float index = dot(
          vec4(row, col, depth, depth2),
          vec4(${a}, ${i6}, ${r}, ${o})) +
          depth3;
        ${Mr(n)}
      }
    `;
  const u = n.shapeInfo.flatOffset, d = n.shapeInfo.texShape, h = d[0], p = d[1];
  if (p === a && u == null)
    return `
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
                         vec4(${i6}, ${r}, ${o}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${p}.0, ${h}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  if (p === o && u == null)
    return `
      float ${s}(int row, int col, int depth, int depth2, int depth3) {
        float texR = dot(
          vec4(row, col, depth, depth2),
          vec4(${t[1] * t[2] * t[3]},
               ${t[2] * t[3]}, ${t[3]}, 1));
        int texC = depth3;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${p}.0, ${h}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  const f = Jo(e);
  return `
    float ${s}(int row, int col, int depth, int depth2, int depth3) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${a} + col * ${i6} + depth * ${r} +
          depth2 * ${o} + depth3 + ${f};
      vec2 uv = uvFromFlat(${h}, ${p}, index);
      return sampleTexture(${e}, uv);
    }
  `;
}
function NA(n) {
  const t = n.shapeInfo.logicalShape, e = n.name, s = "get" + e.charAt(0).toUpperCase() + e.slice(1), { newShape: o, keptDims: r } = ws(t);
  if (o.length < t.length) {
    const g = Wr(n, o), b = ["row", "col", "depth", "depth2", "depth3", "depth4"];
    return `
      ${Lr(g)}
      float ${s}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        return ${s}(${Dr(b, r)});
      }
    `;
  }
  const i6 = t[5], a = t[4] * i6, l = t[3] * a, c = t[2] * l, u = t[1] * c;
  if (n.shapeInfo.isUniform)
    return `
      float ${s}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
        int index = round(dot(
          vec4(row, col, depth, depth2),
          vec4(${u}, ${c}, ${l}, ${a})) +
          dot(
            vec2(depth3, depth4),
            vec2(${i6}, 1)));
        ${Mr(n)}
      }
    `;
  const d = n.shapeInfo.flatOffset, h = n.shapeInfo.texShape, p = h[0], f = h[1];
  if (f === u && d == null)
    return `
      float ${s}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
          vec4(${c}, ${l}, ${a}, ${i6})) +
               float(depth4);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${f}.0, ${p}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  if (f === i6 && d == null)
    return `
      float ${s}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        float texR = dot(vec4(row, col, depth, depth2),
          vec4(${t[1] * t[2] * t[3] * t[4]},
               ${t[2] * t[3] * t[4]},
               ${t[3] * t[4]},
               ${t[4]})) + float(depth3);
        int texC = depth4;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${f}.0, ${p}.0);
        return sampleTexture(${e}, uv);
      }
    `;
  const m = Jo(e);
  return `
    float ${s}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${u} + col * ${c} + depth * ${l} +
          depth2 * ${a} + depth3 * ${i6} + depth4 + ${m};
      vec2 uv = uvFromFlat(${p}, ${f}, index);
      return sampleTexture(${e}, uv);
    }
  `;
}
function Mr(n) {
  const t = n.name, e = X(n.shapeInfo.logicalShape);
  return e < 2 ? `return ${t};` : `
    for (int i = 0; i < ${e}; i++) {
      if (i == index) {
        return ${t}[i];
      }
    }
  `;
}
function RA(n, t) {
  const e = n.name, s = e.charAt(0).toUpperCase() + e.slice(1), o = "get" + s + "AtOutCoords", r = n.shapeInfo.logicalShape.length, i6 = t.logicalShape.length, a = II(n.shapeInfo.logicalShape, t.logicalShape), l = Vt(i6), c = i6 - r;
  let u;
  const d = ["x", "y", "z", "w", "u", "v"];
  r === 0 ? u = "" : i6 < 2 && a.length >= 1 ? u = "coords = 0;" : u = a.map((x6) => `coords.${d[x6 + c]} = 0;`).join(`
`);
  let h = "";
  i6 < 2 && r > 0 ? h = "coords" : h = n.shapeInfo.logicalShape.map((x6, w) => `coords.${d[w + c]}`).join(", ");
  let p = "return outputValue;";
  const m = X(n.shapeInfo.logicalShape) === 1, b = X(t.logicalShape) === 1;
  if (r === 1 && !m && !b)
    p = `
      return vec4(outputValue.xy, outputValue.xy);
    `;
  else if (m && !b)
    i6 === 1 ? p = `
        return vec4(outputValue.x, outputValue.x, 0., 0.);
      ` : p = `
        return vec4(outputValue.x);
      `;
  else if (a.length) {
    const x6 = r - 2, w = r - 1;
    a.indexOf(x6) > -1 && a.indexOf(w) > -1 ? p = "return vec4(outputValue.x);" : a.indexOf(x6) > -1 ? p = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);" : a.indexOf(w) > -1 && (p = "return vec4(outputValue.xx, outputValue.zz);");
  }
  return `
    vec4 ${o}() {
      ${l} coords = getOutputCoords();
      ${u}
      vec4 outputValue = get${s}(${h});
      ${p}
    }
  `;
}
function $A(n, t) {
  const e = n.name, s = e.charAt(0).toUpperCase() + e.slice(1), o = "get" + s + "AtOutCoords", r = t.texShape, i6 = n.shapeInfo.texShape, a = n.shapeInfo.logicalShape.length, l = t.logicalShape.length;
  if (!n.shapeInfo.isUniform && a === l && n.shapeInfo.flatOffset == null && $t(i6, r))
    return `
      float ${o}() {
        return sampleTexture(${e}, resultUV);
      }
    `;
  const c = Vt(l), u = II(n.shapeInfo.logicalShape, t.logicalShape), d = l - a;
  let h;
  const p = ["x", "y", "z", "w", "u", "v"];
  a === 0 ? h = "" : l < 2 && u.length >= 1 ? h = "coords = 0;" : h = u.map((m) => `coords.${p[m + d]} = 0;`).join(`
`);
  let f = "";
  return l < 2 && a > 0 ? f = "coords" : f = n.shapeInfo.logicalShape.map((m, g) => `coords.${p[g + d]}`).join(", "), `
    float ${o}() {
      ${c} coords = getOutputCoords();
      ${h}
      return get${s}(${f});
    }
  `;
}
function Vt(n) {
  if (n <= 1)
    return "int";
  if (n === 2)
    return "ivec2";
  if (n === 3)
    return "ivec3";
  if (n === 4)
    return "ivec4";
  if (n === 5)
    return "ivec5";
  if (n === 6)
    return "ivec6";
  throw Error(`GPU for rank ${n} is not yet supported`);
}
function jf(n, t, e) {
  const { newShape: s, keptDims: o } = ws(t), r = t.length, i6 = n && r === 3 && t[0] === 1, a = i6 ? t.slice(1) : s, l = !n && r > 1 && !$t(t, e) && s.length < r || i6;
  return { useSqueezeShape: l, uniformShape: l ? a : t, keptDims: o };
}
function Wr(n, t) {
  const e = JSON.parse(JSON.stringify(n));
  return e.shapeInfo.logicalShape = t, e;
}
function Dr(n, t) {
  return t.map((e) => n[e]).join(", ");
}
function GA(n, t, e, s) {
  const o = e.map((u, d) => {
    const h = {
      logicalShape: u.shape,
      texShape: u.isUniform ? null : u.texData.texShape,
      isUniform: u.isUniform,
      isPacked: u.isUniform ? false : u.texData.isPacked,
      flatOffset: null
    };
    return u.texData != null && u.texData.slice != null && u.texData.slice.flatOffset > 0 && (h.flatOffset = u.texData.slice.flatOffset), { name: t.variableNames[d], shapeInfo: h };
  }), r = o.map((u) => u.shapeInfo), i6 = {
    logicalShape: s.shape,
    texShape: s.texData.texShape,
    isUniform: false,
    isPacked: s.texData.isPacked,
    flatOffset: null
  }, a = UP(o, i6, t), l = qw(n.gl, a), c = n.createProgram(l);
  return F().get("ENGINE_COMPILE_ONLY") ? {
    program: t,
    fragmentShader: l,
    source: a,
    webGLProgram: c,
    inShapeInfos: r,
    outShapeInfo: i6,
    variablesLocations: null,
    customUniformLocations: null,
    infLoc: null,
    nanLoc: null,
    outShapeLocation: null,
    outShapeStridesLocation: null,
    outTexShapeLocation: null
  } : (n.buildVao(c), Object.assign({
    program: t,
    fragmentShader: l,
    source: a,
    webGLProgram: c,
    inShapeInfos: r,
    outShapeInfo: i6
  }, SI(n, t, c)));
}
function SI(n, t, e) {
  const s = [], o = [];
  let r, i6, a, l = null, c = null;
  c = n.getUniformLocation(e, "NAN", false), F().getNumber("WEBGL_VERSION") === 1 && (l = n.getUniformLocation(e, "INFINITY", false));
  const u = false;
  for (const d of t.variableNames) {
    const h = {
      name: d,
      uniform: n.getUniformLocation(e, d, u),
      offset: n.getUniformLocation(e, `offset${d}`, u)
    };
    t.enableShapeUniforms && (h.shape = n.getUniformLocation(e, `${d}Shape`, u), h.texShape = n.getUniformLocation(e, `${d}TexShape`, u)), s.push(h);
  }
  if (t.enableShapeUniforms && (r = n.getUniformLocation(e, "outShape", u), a = n.getUniformLocation(e, "outShapeStrides", u), i6 = n.getUniformLocation(e, "outTexShape", u)), t.customUniforms)
    for (const d of t.customUniforms)
      o.push(n.getUniformLocation(e, d.name, u));
  return {
    variablesLocations: s,
    customUniformLocations: o,
    infLoc: l,
    nanLoc: c,
    outShapeLocation: r,
    outShapeStridesLocation: a,
    outTexShapeLocation: i6
  };
}
function yg(n, t) {
  if (n.length !== t.length)
    throw Error(`Binary was compiled with ${n.length} inputs, but was executed with ${t.length} inputs`);
  n.forEach((e, s) => {
    const o = e.logicalShape, r = t[s], i6 = r.shape;
    if (!$t(o, i6))
      throw Error(`Binary was compiled with different shapes than the current args. Shapes ${o} and ${i6} must match`);
    if (e.isUniform && r.isUniform)
      return;
    const a = e.texShape, l = r.isUniform ? null : r.texData.texShape;
    if (!$t(a, l))
      throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${a} and ${l} must match`);
  });
}
function EA(n, t, e, s, o) {
  t.program.enableShapeUniforms || (yg(t.inShapeInfos, e), yg([t.outShapeInfo], [s]));
  const r = s.texData.texture, i6 = s.texData.texShape;
  s.texData.isPacked ? n.setOutputPackedMatrixTexture(r.texture, i6[0], i6[1]) : n.setOutputMatrixTexture(r.texture, i6[0], i6[1]), n.setProgram(t.webGLProgram), n.bindVertexArray(t.webGLProgram.vao), F().getNumber("WEBGL_VERSION") === 1 && t.infLoc !== null && n.gl.uniform1f(t.infLoc, 1 / 0), t.nanLoc !== null && n.gl.uniform1f(t.nanLoc, NaN);
  for (let l = 0; l < e.length; ++l) {
    const c = e[l], { uniform: u, offset: d, shape: h, texShape: p } = t.variablesLocations[l];
    if (h) {
      const { uniformShape: f } = jf(t.program.packedInputs, c.shape, c.texData.texShape);
      switch (f.length) {
        case 1:
          n.gl.uniform1iv(h, new Int32Array(f));
          break;
        case 2:
          n.gl.uniform2iv(h, new Int32Array(f));
          break;
        case 3:
          n.gl.uniform3iv(h, new Int32Array(f));
          break;
        case 4:
          n.gl.uniform4iv(h, new Int32Array(f));
          break;
      }
    }
    if (p && n.gl.uniform2i(p, c.texData.texShape[0], c.texData.texShape[1]), u != null) {
      if (c.isUniform) {
        if (X(c.shape) < 2)
          n.gl.uniform1f(u, c.uniformValues[0]);
        else {
          let f = c.uniformValues;
          f instanceof Float32Array || (f = new Float32Array(f)), n.gl.uniform1fv(u, f);
        }
        continue;
      }
      c.texData.slice != null && d != null && n.gl.uniform1i(d, c.texData.slice.flatOffset), n.setInputMatrixTexture(c.texData.texture.texture, u, l);
    }
  }
  const a = t.outShapeLocation;
  if (a)
    switch (s.shape.length) {
      case 1:
        n.gl.uniform1iv(a, new Int32Array(s.shape));
        break;
      case 2:
        n.gl.uniform2iv(a, new Int32Array(s.shape));
        break;
      case 3:
        n.gl.uniform3iv(a, new Int32Array(s.shape));
        break;
      case 4:
        n.gl.uniform4iv(a, new Int32Array(s.shape));
        break;
    }
  if (t.outShapeStridesLocation) {
    const l = dt(s.shape);
    switch (s.shape.length) {
      case 2:
        n.gl.uniform1iv(t.outShapeStridesLocation, new Int32Array(l));
        break;
      case 3:
        n.gl.uniform2iv(t.outShapeStridesLocation, new Int32Array(l));
        break;
      case 4:
        n.gl.uniform3iv(t.outShapeStridesLocation, new Int32Array(l));
        break;
    }
  }
  if (t.outTexShapeLocation && n.gl.uniform2i(t.outTexShapeLocation, s.texData.texShape[0], s.texData.texShape[1]), t.program.customUniforms && o)
    for (let l = 0; l < t.program.customUniforms.length; ++l) {
      const c = t.program.customUniforms[l], u = t.customUniformLocations[l], d = o[l];
      if (c.type === "float")
        n.gl.uniform1fv(u, d);
      else if (c.type === "vec2")
        n.gl.uniform2fv(u, d);
      else if (c.type === "vec3")
        n.gl.uniform3fv(u, d);
      else if (c.type === "vec4")
        n.gl.uniform4fv(u, d);
      else if (c.type === "int")
        n.gl.uniform1iv(u, d);
      else if (c.type === "ivec2")
        n.gl.uniform2iv(u, d);
      else if (c.type === "ivec3")
        n.gl.uniform3iv(u, d);
      else if (c.type === "ivec4")
        n.gl.uniform4iv(u, d);
      else
        throw Error(`uniform type ${c.type} is not supported yet.`);
    }
  n.executeProgram();
}
function LA(n, t, e) {
  let s = "";
  t.concat(e).forEach((i6) => {
    const a = i6.texData != null && i6.texData.slice != null && i6.texData.slice.flatOffset > 0;
    if (n.enableShapeUniforms && !i6.isUniform) {
      const l = i6.texData.texShape, { useSqueezeShape: c, uniformShape: u, keptDims: d } = jf(n.packedInputs, i6.shape, l);
      let h = "", p = "", f = "";
      if (u.length === 1 && n.packedInputs) {
        const I = [Math.ceil(l[0] / 2), Math.ceil(l[1] / 2)];
        h = `${I[0] > 1}_${I[1] > 1}`;
      } else if (u.length === 2 && !n.packedInputs)
        p = `${u[0] > 1}_${u[1] > 1}`;
      else if (u.length > 2 && !n.packedInputs) {
        const I = dt(u);
        f = `${I[0] === l[1]}_${I[I.length - 1] === l[1]}`;
      }
      const m = i6.shape.length, g = u.length === 2 && $t(i6.shape, l), b = X(i6.shape) === 1, x6 = Go(i6.shape, e.shape), w = !n.packedInputs && m === e.shape.length && $t(l, e.texData.texShape), y6 = n.packedInputs || u.length > 2 ? "" : `${l[0] > 1}_${l[1] > 1}`;
      s += `${m}_${w}_${c ? d : ""}_${u.length}_${b}_${x6}_${g}_${h}_${p}_${f}_${y6}_${a}`;
    } else {
      const l = i6.isUniform ? "uniform" : i6.texData.texShape;
      s += `${i6.shape}_${l}_${a}`;
    }
  });
  const o = n.userCode;
  let r = n.constructor.name;
  return r += "_" + s + "_" + o + `${F().getNumber("WEBGL_VERSION")}`, r;
}
function Me(n) {
  return F().getBool("WEBGL_USE_SHAPES_UNIFORMS") && n <= 4;
}
var MA = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.outPackingScheme = bi.DENSE, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const e = Ae();
    this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length), this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? Iu(["r", "c", "d"], t) : Qo(["r", "c", "d"], t)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getA(rc.x, rc.y, rc.z);
        }

        ${e.output} = result;
      }
    `;
  }
};
var WA = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outPackingScheme = bi.DENSE, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const e = Ae();
    this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length), this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? Iu(["r", "c", "d"], t) : Qo(["r", "c", "d"], t)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));
        }

        ${e.output} = result;
      }
    `;
  }
};
var DA = class {
  constructor(t) {
    this.variableNames = ["A"], this.outTexUsage = un.DOWNLOAD;
    const e = Ae();
    this.outputShape = t, this.userCode = `
      ${wI}

      void main() {
        float x = getAAtOutCoords();
        ${e.output} = encode_float(x);
      }
    `;
  }
};
var FA = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = false, this.outTexUsage = un.DOWNLOAD;
    const e = Ae();
    this.outputShape = t, this.userCode = `
      ${wI}

      void main() {
        ivec3 coords = getOutputCoords();
        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));
        ${e.output} = encode_float(x);
      }
    `;
  }
};
var VA = {
  R: 0,
  G: 1,
  B: 2,
  A: 3
};
var wg = class {
  constructor(t, e = false, s = "RGBA") {
    this.variableNames = ["A"], this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const o = Ae();
    this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length);
    let r = "result";
    e && (r = "floor(result * 255. + 0.5)");
    let i6 = "";
    for (let a = 0; a < s.length; a++) {
      const l = s[a];
      i6 += `
          if(offset == ${a}) {
            result = values[${VA[l]}];
          }`;
    }
    this.userCode = `
      ${this.enableShapeUniforms ? Jf() : Qf(t)}

      void main() {
        ivec3 coords = getOutputCoords();
        int flatIndex = getFlatIndex(coords);
        float result = 0.;
        int offset = imod(flatIndex, ${s.length});

        flatIndex = idiv(flatIndex, ${s.length}, 1.);

        int r = flatIndex / texShape[1];
        if (r < texShape[0]) {
          int c = imod(flatIndex, texShape[1]);
          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
          vec4 values = ${o.texture2D}(A, uv);
          ${i6}
        }
        ${o.output} = vec4(${r}, 0., 0., 0.);
      }
    `;
  }
};
var zA = class {
  constructor(t, e = false) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    const s = Ae();
    this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length);
    let o = "", r = "result";
    e && (r = "floor(result * 255. + 0.5)");
    for (let i6 = 0; i6 <= 1; i6++)
      for (let a = 0; a <= 1; a++) {
        const l = i6 * 2 + a;
        o += `
          localCoords = coords;
          if(localCoords[2] + ${a} < ${this.enableShapeUniforms ? "outShape[2]" : `${t[2]}`}) {
          localCoords[2] += ${a};
          if (localCoords[1] + ${i6} < ${this.enableShapeUniforms ? "outShape[1]" : `${t[1]}`}) {
            localCoords[1] += ${i6};

            flatIndex = getFlatIndex(localCoords);
            offset = imod(flatIndex, 4);

            flatIndex = idiv(flatIndex, 4, 1.);

            int r = flatIndex / texShape[1];
            int c = imod(flatIndex, texShape[1]);
            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
            values = ${s.texture2D}(A, uv);

            if (offset == 0) {
              result[${l}] = values[0];
            } else if (offset == 1) {
              result[${l}] = values[1];
            } else if (offset == 2) {
              result[${l}] = values[2];
            } else {
              result[${l}] = values[3];
            }
          }
        }
        `;
      }
    this.userCode = `
        ${this.enableShapeUniforms ? Jf() : Qf(t)}

        void main() {
          ivec3 coords = getOutputCoords();

          vec4 result = vec4(0.);
          int flatIndex, r, c, offset;
          ivec3 localCoords;
          vec2 uv;
          vec4 values;

          ${o}

          ${s.output} = ${r};
        }
    `;
  }
};
function kI(n) {
  const t = Ae(), e = `${t.version}
    precision highp float;
    ${t.attribute} vec3 clipSpacePos;
    ${t.attribute} vec2 uv;
    ${t.varyingVs} vec2 resultUV;

    void main() {
      gl_Position = vec4(clipSpacePos, 1);
      resultUV = uv;
    }`;
  return jw(n, e);
}
function TI(n) {
  const t = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
  return nI(n, t);
}
function NI(n) {
  const t = new Uint16Array([0, 1, 2, 2, 1, 3]);
  return sI(n, t);
}
function Aa(n, t, e, s, o, r) {
  rI(t, e);
  const i6 = oI(n), a = n.TEXTURE_2D;
  return nt(n, () => n.bindTexture(a, i6)), nt(n, () => n.texParameteri(a, n.TEXTURE_WRAP_S, n.CLAMP_TO_EDGE)), nt(n, () => n.texParameteri(a, n.TEXTURE_WRAP_T, n.CLAMP_TO_EDGE)), nt(n, () => n.texParameteri(a, n.TEXTURE_MIN_FILTER, n.NEAREST)), nt(n, () => n.texParameteri(a, n.TEXTURE_MAG_FILTER, n.NEAREST)), F().getNumber("WEBGL_VERSION") === 1 ? nt(n, () => n.texImage2D(a, 0, s, t, e, 0, o, r, null)) : nt(n, () => n.texStorage2D(a, 1, s, t, e)), nt(n, () => n.bindTexture(n.TEXTURE_2D, null)), { texture: i6, texShape: [e, t] };
}
function qf(n) {
  return n.internalFormatFloat;
}
function RI(n, t, e, s) {
  const [o, r] = Pa(t, e);
  return Aa(n, o, r, qf(s), s.textureFormatFloat, n.FLOAT);
}
function tm(n) {
  return n.internalFormatHalfFloat;
}
function $I(n, t, e, s) {
  const [o, r] = Pa(t, e);
  return Aa(n, o, r, tm(s), s.textureFormatFloat, s.textureTypeHalfFloat);
}
function em(n) {
  return n.downloadTextureFormat;
}
function GI(n, t, e, s) {
  const [o, r] = Pa(t, e);
  return Aa(n, o, r, em(s), n.RGBA, n.UNSIGNED_BYTE);
}
function nm(n) {
  return n.internalFormatPackedFloat;
}
function EI(n, t, e, s) {
  const [o, r] = Gr(t, e);
  return Aa(n, o, r, nm(s), n.RGBA, n.FLOAT);
}
function sm(n) {
  return n.internalFormatPackedHalfFloat;
}
function LI(n, t, e, s) {
  const [o, r] = Gr(t, e);
  return Aa(n, o, r, sm(s), n.RGBA, s.textureTypeHalfFloat);
}
function MI(n, t, e) {
  return nt(n, () => n.bindBuffer(n.ARRAY_BUFFER, e)), zd(n, t, "clipSpacePos", e, 3, 20, 0) && zd(n, t, "uv", e, 2, 20, 12);
}
function WI(n, t, e, s, o, r) {
  nt(n, () => n.bindTexture(n.TEXTURE_2D, t));
  let i6, a, l;
  o instanceof Uint8Array ? (i6 = new Uint8Array(e * s * 4), a = n.UNSIGNED_BYTE, l = n.RGBA) : (i6 = new Float32Array(e * s * 4), a = n.FLOAT, l = r.internalFormatPackedFloat), i6.set(o), F().getNumber("WEBGL_VERSION") === 2 ? nt(n, () => n.texSubImage2D(n.TEXTURE_2D, 0, 0, 0, e, s, n.RGBA, a, i6)) : nt(n, () => n.texImage2D(n.TEXTURE_2D, 0, l, e, s, 0, n.RGBA, a, i6)), nt(n, () => n.bindTexture(n.TEXTURE_2D, null));
}
function DI(n, t, e) {
  nt(n, () => n.bindTexture(n.TEXTURE_2D, t)), e.data instanceof Uint8Array ? F().getNumber("WEBGL_VERSION") === 2 ? nt(n, () => n.texSubImage2D(n.TEXTURE_2D, 0, 0, 0, e.width, e.height, n.RGBA, n.UNSIGNED_BYTE, e.data)) : nt(n, () => n.texImage2D(n.TEXTURE_2D, 0, n.RGBA, e.width, e.height, 0, n.RGBA, n.UNSIGNED_BYTE, e.data)) : F().getNumber("WEBGL_VERSION") === 2 ? nt(n, () => n.texSubImage2D(n.TEXTURE_2D, 0, 0, 0, n.RGBA, n.UNSIGNED_BYTE, e)) : nt(n, () => n.texImage2D(n.TEXTURE_2D, 0, n.RGBA, n.RGBA, n.UNSIGNED_BYTE, e)), nt(n, () => n.bindTexture(n.TEXTURE_2D, null));
}
function FI(n, t, e, s) {
  const o = n.createBuffer();
  nt(n, () => n.bindBuffer(n.PIXEL_PACK_BUFFER, o));
  const a = 4 * 4 * t * e;
  return nt(n, () => n.bufferData(n.PIXEL_PACK_BUFFER, a, n.STREAM_READ)), nt(n, () => n.readPixels(0, 0, e, t, n.RGBA, n.FLOAT, 0)), nt(n, () => n.bindBuffer(n.PIXEL_PACK_BUFFER, null)), o;
}
function VI(n, t, e) {
  const s = n, o = new Float32Array(e);
  return s.bindBuffer(s.PIXEL_PACK_BUFFER, t), s.getBufferSubData(s.PIXEL_PACK_BUFFER, 0, o), s.bindBuffer(s.PIXEL_PACK_BUFFER, null), o;
}
function zI(n, t, e, s) {
  const [o, r] = Pa(t, e), i6 = 4, a = new Uint8Array(WP(t * e, i6));
  return nt(n, () => n.readPixels(0, 0, o, r, s.downloadTextureFormat, n.UNSIGNED_BYTE, a)), new Float32Array(a.buffer);
}
function PI(n, t, e, s, o, r, i6, a) {
  const l = n, c = new Float32Array(DP(r, i6));
  return l.bindBuffer(l.PIXEL_PACK_BUFFER, t), l.getBufferSubData(l.PIXEL_PACK_BUFFER, 0, c), l.bindBuffer(l.PIXEL_PACK_BUFFER, null), c;
}
function AI(n, t, e) {
  const s = new Float32Array(t * e * 4);
  return nt(n, () => n.readPixels(0, 0, e, t, n.RGBA, n.FLOAT, s)), s;
}
var UQ = Object.freeze(Object.defineProperty({
  __proto__: null,
  bindVertexProgramAttributeStreams: MI,
  createBufferFromOutputTexture: FI,
  createFloat16MatrixTexture: $I,
  createFloat16PackedMatrixTexture: LI,
  createFloat32MatrixTexture: RI,
  createIndexBuffer: NI,
  createPackedMatrixTexture: EI,
  createUnsignedBytesMatrixTexture: GI,
  createVertexBuffer: TI,
  createVertexShader: kI,
  downloadByteEncodedFloatMatrixFromOutputTexture: zI,
  downloadFloat32MatrixFromBuffer: VI,
  downloadMatrixFromPackedOutputTexture: AI,
  downloadPackedMatrixFromBuffer: PI,
  getInternalFormatForFloat16MatrixTexture: tm,
  getInternalFormatForFloat16PackedMatrixTexture: sm,
  getInternalFormatForFloat32MatrixTexture: qf,
  getInternalFormatForPackedMatrixTexture: nm,
  getInternalFormatForUnsignedBytesMatrixTexture: em,
  uploadDenseMatrixToTexture: WI,
  uploadPixelDataToTexture: DI
}, Symbol.toStringTag, { value: "Module" }));
var Au = class {
  constructor(t) {
    this.outputTexture = null, this.program = null, this.disposed = false, this.itemsToPoll = [];
    const e = F().getNumber("WEBGL_VERSION");
    if (t != null ? (this.gl = t, EP(e, t)) : this.gl = Bn(e), t = this.gl, F().getNumber("WEBGL_VERSION") === 2) {
      const r = t;
      this.createVertexArray = () => nt(r, () => r.createVertexArray()), this.bindVertexArray = (i6) => nt(r, () => r.bindVertexArray(i6)), this.deleteVertexArray = (i6) => nt(r, () => r.deleteVertexArray(i6)), this.getVertexArray = () => nt(r, () => r.getParameter(r.VERTEX_ARRAY_BINDING));
    } else if (t != null) {
      const r = t.getExtension("OES_vertex_array_object");
      if (r == null)
        throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");
      this.createVertexArray = () => nt(t, () => r.createVertexArrayOES()), this.bindVertexArray = (i6) => nt(t, () => r.bindVertexArrayOES(i6)), this.deleteVertexArray = (i6) => nt(t, () => r.deleteVertexArrayOES(i6)), this.getVertexArray = () => nt(t, () => t.getParameter(r.VERTEX_ARRAY_BINDING_OES));
    }
    let s = "WEBGL_color_buffer_float";
    const o = "EXT_color_buffer_half_float";
    if (this.parallelCompilationExtension = this.gl.getExtension("KHR_parallel_shader_compile"), F().getNumber("WEBGL_VERSION") === 1) {
      const r = "OES_texture_float", i6 = "OES_texture_half_float";
      if (this.textureFloatExtension = jr(this.gl, r), dn(this.gl, i6))
        this.textureHalfFloatExtension = jr(this.gl, i6);
      else if (F().get("WEBGL_FORCE_F16_TEXTURES"))
        throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
      if (this.colorBufferFloatExtension = this.gl.getExtension(s), dn(this.gl, o))
        this.colorBufferHalfFloatExtension = jr(this.gl, o);
      else if (F().get("WEBGL_FORCE_F16_TEXTURES"))
        throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
    } else if (s = "EXT_color_buffer_float", dn(this.gl, s))
      this.colorBufferFloatExtension = this.gl.getExtension(s);
    else if (dn(this.gl, o))
      this.colorBufferHalfFloatExtension = this.gl.getExtension(o);
    else
      throw new Error("GL context does not support color renderable floats");
    this.vertexBuffer = TI(this.gl), this.indexBuffer = NI(this.gl), this.framebuffer = iI(this.gl), this.textureConfig = Uf(this.gl, this.textureHalfFloatExtension);
  }
  get debug() {
    return F().getBool("DEBUG");
  }
  dispose() {
    if (this.disposed)
      return;
    this.program != null && console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."), this.outputTexture != null && console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
    const t = this.gl;
    nt(t, () => t.finish()), nt(t, () => t.bindFramebuffer(t.FRAMEBUFFER, null)), nt(t, () => t.deleteFramebuffer(this.framebuffer)), nt(t, () => t.bindBuffer(t.ARRAY_BUFFER, null)), nt(t, () => t.bindBuffer(t.ELEMENT_ARRAY_BUFFER, null)), nt(t, () => t.deleteBuffer(this.indexBuffer)), this.disposed = true;
  }
  createFloat32MatrixTexture(t, e) {
    return this.throwIfDisposed(), RI(this.gl, t, e, this.textureConfig);
  }
  createFloat16MatrixTexture(t, e) {
    return this.throwIfDisposed(), $I(this.gl, t, e, this.textureConfig);
  }
  createUnsignedBytesMatrixTexture(t, e) {
    return this.throwIfDisposed(), GI(this.gl, t, e, this.textureConfig);
  }
  uploadPixelDataToTexture(t, e) {
    this.throwIfDisposed(), DI(this.gl, t, e);
  }
  uploadDenseMatrixToTexture(t, e, s, o) {
    this.throwIfDisposed(), WI(this.gl, t, e, s, o, this.textureConfig);
  }
  createFloat16PackedMatrixTexture(t, e) {
    return this.throwIfDisposed(), LI(this.gl, t, e, this.textureConfig);
  }
  createPackedMatrixTexture(t, e) {
    return this.throwIfDisposed(), EI(this.gl, t, e, this.textureConfig);
  }
  deleteMatrixTexture(t) {
    this.throwIfDisposed(), this.outputTexture === t && (Pd(this.gl, this.framebuffer), this.outputTexture = null), nt(this.gl, () => this.gl.deleteTexture(t));
  }
  downloadByteEncodedFloatMatrixFromOutputTexture(t, e, s) {
    return this.downloadMatrixDriver(t, () => zI(this.gl, e, s, this.textureConfig));
  }
  downloadPackedMatrixFromBuffer(t, e, s, o, r, i6) {
    return PI(this.gl, t, e, s, o, r, i6, this.textureConfig);
  }
  downloadFloat32MatrixFromBuffer(t, e) {
    return VI(this.gl, t, e);
  }
  createBufferFromTexture(t, e, s) {
    this.bindTextureToFrameBuffer(t);
    const o = FI(this.gl, e, s, this.textureConfig);
    return this.unbindTextureToFrameBuffer(), o;
  }
  createAndWaitForFence() {
    const t = this.createFence(this.gl);
    return this.pollFence(t);
  }
  createFence(t) {
    let e, s;
    if (F().getBool("WEBGL_FENCE_API_ENABLED")) {
      const o = t, r = o.fenceSync(o.SYNC_GPU_COMMANDS_COMPLETE, 0);
      t.flush(), s = () => {
        const i6 = o.clientWaitSync(r, 0, 0);
        return i6 === o.ALREADY_SIGNALED || i6 === o.CONDITION_SATISFIED;
      }, e = r;
    } else
      F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 ? (e = this.beginQuery(), this.endQuery(), s = () => this.isQueryAvailable(e, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))) : s = () => true;
    return { query: e, isFencePassed: s };
  }
  downloadMatrixFromPackedTexture(t, e, s) {
    return this.downloadMatrixDriver(t, () => AI(this.gl, e, s));
  }
  createProgram(t) {
    this.throwIfDisposed();
    const e = this.gl;
    this.vertexShader == null && (this.vertexShader = kI(e));
    const s = tI(e);
    nt(e, () => e.attachShader(s, this.vertexShader)), nt(e, () => e.attachShader(s, t)), eI(e, s);
    const o = Object.assign(s, { vao: this.createVertexArray() });
    return this.debug && al(e, o), o;
  }
  buildVao(t) {
    this.setProgram(t), this.bindVertexArray(t.vao);
    const e = this.gl;
    nt(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, this.indexBuffer)), MI(e, t, this.vertexBuffer);
  }
  deleteProgram(t) {
    this.throwIfDisposed(), t === this.program && (this.program = null), t != null && (nt(this.gl, () => this.gl.deleteProgram(t)), this.deleteVertexArray(t.vao));
  }
  setProgram(t) {
    this.throwIfDisposed(), this.program = t, this.program != null && this.debug && al(this.gl, this.program), nt(this.gl, () => this.gl.useProgram(t));
  }
  getUniformLocation(t, e, s = true) {
    return this.throwIfDisposed(), s ? lI(this.gl, t, e) : cI(this.gl, t, e);
  }
  getAttributeLocation(t, e) {
    return this.throwIfDisposed(), nt(this.gl, () => this.gl.getAttribLocation(t, e));
  }
  getUniformLocationNoThrow(t, e) {
    return this.throwIfDisposed(), this.gl.getUniformLocation(t, e);
  }
  setInputMatrixTexture(t, e, s) {
    this.throwIfDisposed(), this.throwIfNoProgram(), uI(this.gl, t, e, s);
  }
  setOutputMatrixTexture(t, e, s) {
    this.setOutputMatrixTextureDriver(t, s, e);
  }
  setOutputPackedMatrixTexture(t, e, s) {
    this.throwIfDisposed();
    const [o, r] = Gr(e, s);
    this.setOutputMatrixTextureDriver(t, o, r);
  }
  setOutputMatrixWriteRegion(t, e, s, o) {
    this.setOutputMatrixWriteRegionDriver(s, t, o, e);
  }
  setOutputPackedMatrixWriteRegion(t, e, s, o) {
    throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
  }
  debugValidate() {
    this.program != null && al(this.gl, this.program), qr(this.gl);
  }
  executeProgram() {
    this.throwIfDisposed(), this.throwIfNoProgram();
    const t = this.gl;
    if (this.debug) {
      const e = this.getVertexArray();
      console.assert(e === this.program.vao, "VAO changed between setProgram and executeProgram!"), this.debugValidate();
    }
    nt(t, () => t.drawElements(t.TRIANGLES, 6, t.UNSIGNED_SHORT, 0));
  }
  blockUntilAllProgramsCompleted() {
    this.throwIfDisposed(), nt(this.gl, () => this.gl.finish());
  }
  getQueryTimerExtension() {
    return this.disjointQueryTimerExtension == null && (this.disjointQueryTimerExtension = jr(this.gl, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2 ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query")), this.disjointQueryTimerExtension;
  }
  getQueryTimerExtensionWebGL2() {
    return this.getQueryTimerExtension();
  }
  getQueryTimerExtensionWebGL1() {
    return this.getQueryTimerExtension();
  }
  beginQuery() {
    if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      const s = this.gl, o = this.getQueryTimerExtensionWebGL2(), r = s.createQuery();
      return s.beginQuery(o.TIME_ELAPSED_EXT, r), r;
    }
    const t = this.getQueryTimerExtensionWebGL1(), e = t.createQueryEXT();
    return t.beginQueryEXT(t.TIME_ELAPSED_EXT, e), e;
  }
  endQuery() {
    if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      const e = this.gl, s = this.getQueryTimerExtensionWebGL2();
      e.endQuery(s.TIME_ELAPSED_EXT);
      return;
    }
    const t = this.getQueryTimerExtensionWebGL1();
    t.endQueryEXT(t.TIME_ELAPSED_EXT);
  }
  async waitForQueryAndGetTime(t) {
    return await id(() => this.disposed || // while testing contexts are created / disposed
    // in rapid succession, so without this check we
    // may poll for the query timer indefinitely
    this.isQueryAvailable(t, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))), this.getQueryTime(t, F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
  }
  getQueryTime(t, e) {
    if (e === 0)
      return null;
    if (e === 2) {
      const s = this.gl;
      return s.getQueryParameter(t, s.QUERY_RESULT) / 1e6;
    } else {
      const s = this.getQueryTimerExtensionWebGL1();
      return s.getQueryObjectEXT(t, s.QUERY_RESULT_EXT) / 1e6;
    }
  }
  isQueryAvailable(t, e) {
    if (e === 0)
      return true;
    if (e === 2) {
      const s = this.gl, o = this.getQueryTimerExtensionWebGL2(), r = s.getQueryParameter(t, s.QUERY_RESULT_AVAILABLE);
      return this.disjoint == null && (this.disjoint = this.gl.getParameter(o.GPU_DISJOINT_EXT)), r && !this.disjoint;
    } else {
      const s = this.getQueryTimerExtensionWebGL1(), o = s.getQueryObjectEXT(t, s.QUERY_RESULT_AVAILABLE_EXT);
      return this.disjoint == null && (this.disjoint = this.gl.getParameter(s.GPU_DISJOINT_EXT)), o && !this.disjoint;
    }
  }
  pollFence(t) {
    return new Promise((e) => {
      this.addItemToPoll(() => t.isFencePassed(), () => e());
    });
  }
  pollItems() {
    const t = PA(this.itemsToPoll.map((e) => e.isDoneFn));
    for (let e = 0; e <= t; ++e) {
      const { resolveFn: s } = this.itemsToPoll[e];
      s();
    }
    this.itemsToPoll = this.itemsToPoll.slice(t + 1);
  }
  addItemToPoll(t, e) {
    if (this.itemsToPoll.push({ isDoneFn: t, resolveFn: e }), this.itemsToPoll.length > 1)
      return;
    let s;
    "setTimeoutCustom" in F().platform && (s = F().platform.setTimeoutCustom.bind(F().platform)), id(() => (this.pollItems(), this.itemsToPoll.length === 0), () => 0, null, s);
  }
  bindTextureToFrameBuffer(t) {
    this.throwIfDisposed(), ll(this.gl, t, this.framebuffer), this.debug && qr(this.gl);
  }
  unbindTextureToFrameBuffer() {
    this.outputTexture != null ? (ll(this.gl, this.outputTexture, this.framebuffer), this.debug && qr(this.gl)) : Pd(this.gl, this.framebuffer);
  }
  downloadMatrixDriver(t, e) {
    this.bindTextureToFrameBuffer(t);
    const s = e();
    return this.unbindTextureToFrameBuffer(), s;
  }
  setOutputMatrixTextureDriver(t, e, s) {
    this.throwIfDisposed();
    const o = this.gl;
    ll(o, t, this.framebuffer), this.debug && qr(o), this.outputTexture = t, nt(o, () => o.viewport(0, 0, e, s)), nt(o, () => o.scissor(0, 0, e, s));
  }
  setOutputMatrixWriteRegionDriver(t, e, s, o) {
    this.throwIfDisposed(), nt(this.gl, () => this.gl.scissor(t, e, s, o));
  }
  throwIfDisposed() {
    if (this.disposed)
      throw new Error("Attempted to use disposed GPGPUContext.");
  }
  throwIfNoProgram() {
    if (this.program == null)
      throw new Error("No GPU program is currently set.");
  }
};
function PA(n) {
  let t = 0;
  for (; t < n.length && n[t](); ++t)
    ;
  return t - 1;
}
var { addImpl: AA, bincountImpl: OI, bincountReduceImpl: OA, bitwiseAndImpl: XA, castImpl: KA, ceilImpl: ZA, concatImpl: BA, equalImpl: HA, expImpl: _A, expm1Impl: UA, floorImpl: YA, gatherNdImpl: QA, gatherV2Impl: JA, greaterImpl: jA, greaterEqualImpl: qA, lessImpl: tO, lessEqualImpl: eO, linSpaceImpl: nO, logImpl: sO, maxImpl: oO, maximumImpl: rO, minimumImpl: iO, multiplyImpl: aO, negImpl: lO, notEqualImpl: cO, prodImpl: uO, raggedGatherImpl: dO, raggedRangeImpl: hO, raggedTensorToTensorImpl: pO, rangeImpl: fO, rsqrtImpl: mO, scatterImpl: gO, sigmoidImpl: bO, simpleAbsImpl: XI, sliceImpl: xO, sparseFillEmptyRowsImpl: yO, sparseReshapeImpl: wO, sparseSegmentReductionImpl: KI, sqrtImpl: IO, staticRegexReplaceImpl: CO, stridedSliceImpl: vO, stringNGramsImpl: SO, stringSplitImpl: kO, stringToHashBucketFastImpl: TO, subImpl: NO, tileImpl: RO, topKImpl: $O, transposeImpl: om, uniqueImpl: GO } = fW;
function ZI(n, t) {
  return ["x", "y", "z", "w", "u", "v"].slice(0, t).map((e) => `${n}.${e}`);
}
function Fe(n, t) {
  return t === 1 ? [n] : ZI(n, t);
}
function EO(n, t) {
  if (n === 1)
    return "rc";
  let e = "";
  for (let s = 0; s < n; s++)
    e += t[s], s < n - 1 && (e += ",");
  return e;
}
var LO = class {
  constructor(t) {
    if (this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.outputShape = t, this.rank = t.length, this.enableShapeUniforms = Me(this.outputShape.length), this.rank === 0)
      this.userCode = `
        void main() {
          setOutput(vec4(getA(), 0., 0., 0.));
        }
      `;
    else {
      const e = Fe("rc", this.rank), s = Vt(this.rank), o = this.getOutOfBoundsCondition(e), r = this.getSetup(e), i6 = this.getOutput(e);
      this.userCode = `
        void main() {
          ${s} rc = getOutputCoords();

          if(${o}) {
            setOutput(vec4(0));
          } else {
            ${r}

            setOutput(vec4(${i6}));
          }
        }
      `;
    }
  }
  getSourceCoordsArr(t) {
    const e = [];
    for (let s = 0; s <= 1; s++)
      for (let o = 0; o <= 1; o++) {
        let r = `${s === 0 ? "r" : "rp1"}, ${o === 0 ? "c" : "cp1"}`;
        for (let i6 = 2; i6 < this.rank; i6++)
          r = `${t[t.length - 1 - i6]},` + r;
        e.push(r);
      }
    return e;
  }
  getOutOfBoundsCondition(t) {
    if (this.rank === 1)
      return `rc > ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]}`;
    let e = "";
    for (let s = this.rank - 2; s < this.rank; s++)
      e += `${t[s]} >= ${this.enableShapeUniforms ? `outShape[${s}]` : this.outputShape[s]}`, s < this.rank - 1 && (e += "||");
    return e;
  }
  getSetup(t) {
    if (this.rank === 1)
      return "";
    const e = t.slice(-2), s = this.enableShapeUniforms ? `outShape[${this.rank} - 1]` : this.outputShape[this.rank - 1], o = this.enableShapeUniforms ? `outShape[${this.rank} - 2]` : this.outputShape[this.rank - 2];
    return `
      int r = ${e[0]};
      int c = ${e[1]};
      int rp1 = r + 1;
      int cp1 = c + 1;

      bool cEdge = cp1 >= ${s};
      bool rEdge = rp1 >= ${o};
    `;
  }
  getOutput(t) {
    const e = this.getSourceCoordsArr(t);
    return this.rank === 1 ? `getA(rc), (rc + 1 >= ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]} ? 0. : getA(rc + 1)), 0, 0` : `getA(${e[0]}),
            cEdge ? 0. : getA(${e[1]}),
            rEdge ? 0. : getA(${e[2]}),
            rEdge || cEdge ? 0. : getA(${e[3]})`;
  }
};
var BI = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "inputShape", type: "ivec3" }], this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length);
    let s = "";
    for (let o = 0; o < 4; o++) {
      let r = "thisRC = rc;";
      o % 2 === 1 && (r += "thisRC.z += 1;"), o > 1 && (r += "thisRC.y += 1;"), s += `
        ${r}
        ${o > 0 ? "if(thisRC.y < rows && thisRC.z < cols){" : ""}
          int flatIndex = getFlatIndex(thisRC);

          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);
          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));

          result[${o}] =
            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);
        ${o > 0 ? "}" : ""}
      `;
    }
    this.userCode = `
      ${MO(e, this.enableShapeUniforms)}
      ${this.enableShapeUniforms ? Jf() : Qf(t)}

      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0.);

        ivec3 thisRC;
        int rows = ${this.enableShapeUniforms ? "outShape[1]" : t[1]};
        int cols = ${this.enableShapeUniforms ? "outShape[2]" : t[2]};

        ${s}

        setOutput(result);
      }
    `;
  }
};
function MO(n, t) {
  return `
    ivec3 inputCoordsFromReshapedOutCoords(int index) {
      ${t ? _P(["r", "c", "d"], "inputShape") : Qo(["r", "c", "d"], n)}
      return ivec3(r, c, d);
    }
  `;
}
var WO = class {
  constructor(t) {
    this.gpgpu = t, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0, this.freeTextures = {}, this.usedTextures = {}, this.logEnabled = false;
  }
  acquireTexture(t, e, s) {
    const o = Cg(e, s), r = vg(t, o, s);
    r in this.freeTextures || (this.freeTextures[r] = []), r in this.usedTextures || (this.usedTextures[r] = []);
    const i6 = Ig(t, o, this.gpgpu.gl, this.gpgpu.textureConfig, s);
    if (this.freeTextures[r].length > 0) {
      this.numFreeTextures--, this.numUsedTextures++, this._numBytesFree -= i6, this.log();
      const l = this.freeTextures[r].pop();
      return this.usedTextures[r].push(l), l;
    }
    let a;
    return o === Ce.PACKED_2X2_FLOAT32 ? a = this.gpgpu.createPackedMatrixTexture(t[0], t[1]) : o === Ce.PACKED_2X2_FLOAT16 ? a = this.gpgpu.createFloat16PackedMatrixTexture(t[0], t[1]) : o === Ce.UNPACKED_FLOAT32 ? a = this.gpgpu.createFloat32MatrixTexture(t[0], t[1]) : o === Ce.UNPACKED_FLOAT16 ? a = this.gpgpu.createFloat16MatrixTexture(t[0], t[1]) : o === Ce.PACKED_4X1_UNSIGNED_BYTE && (a = this.gpgpu.createUnsignedBytesMatrixTexture(t[0], t[1])), this.usedTextures[r].push(a), this.numUsedTextures++, this._numBytesAllocated += i6, this.log(), a;
  }
  releaseTexture(t, e, s, o) {
    if (this.freeTextures == null)
      return;
    const r = Cg(s, o), i6 = vg(e, r, o);
    i6 in this.freeTextures || (this.freeTextures[i6] = []);
    const a = Ig(e, r, this.gpgpu.gl, this.gpgpu.textureConfig, o), l = F().getNumber("WEBGL_DELETE_TEXTURE_THRESHOLD");
    l !== -1 && this._numBytesAllocated > l ? (this.gpgpu.deleteMatrixTexture(t.texture), this._numBytesAllocated -= a) : (this.freeTextures[i6].push(t), this.numFreeTextures++, this._numBytesFree += a), this.numUsedTextures--;
    const c = this.usedTextures[i6], u = c && c.indexOf(t);
    if (u == null || u < 0)
      throw new Error("Cannot release a texture that was never provided by this texture manager");
    c[u] = c[c.length - 1], c.pop(), this.log();
  }
  log() {
    if (!this.logEnabled)
      return;
    const t = this.numFreeTextures + this.numUsedTextures;
    console.log("Free/Used", `${this.numFreeTextures} / ${this.numUsedTextures}`, `(${t})`);
    const e = this._numBytesFree / this._numBytesAllocated;
    console.log(`Bytes allocated: ${this._numBytesAllocated}`), console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100 * e)}%)`);
  }
  get numBytesAllocated() {
    return this._numBytesAllocated;
  }
  get numBytesFree() {
    return this._numBytesFree;
  }
  getNumUsedTextures() {
    return this.numUsedTextures;
  }
  getNumFreeTextures() {
    return this.numFreeTextures;
  }
  dispose() {
    if (this.freeTextures != null) {
      for (const t in this.freeTextures)
        this.freeTextures[t].forEach((e) => {
          this.gpgpu.deleteMatrixTexture(e.texture);
        });
      for (const t in this.usedTextures)
        this.usedTextures[t].forEach((e) => {
          this.gpgpu.deleteMatrixTexture(e.texture);
        });
      this.freeTextures = null, this.usedTextures = null, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0;
    }
  }
};
function DO(n, t) {
  const e = n;
  if (t === e.R32F)
    return 4;
  if (t === e.R16F)
    return 2;
  if (t === e.RGBA32F)
    return 16;
  if (t === n.RGBA)
    return 16;
  if (t === e.RGBA16F)
    return 8;
  if (t === e.RGBA8)
    return 4;
  throw new Error(`Unknown internal format ${t}`);
}
function Ig(n, t, e, s, o) {
  const r = FO(t, s);
  let i6;
  if (o) {
    const [l, c] = Gr(n[0], n[1]);
    i6 = l * c;
  } else {
    const [l, c] = Pa(n[0], n[1]);
    i6 = l * c;
  }
  const a = DO(e, r);
  return i6 * a;
}
function FO(n, t) {
  switch (n) {
    case Ce.PACKED_2X2_FLOAT32:
      return nm(t);
    case Ce.PACKED_2X2_FLOAT16:
      return sm(t);
    case Ce.UNPACKED_FLOAT32:
      return qf(t);
    case Ce.UNPACKED_FLOAT16:
      return tm(t);
    case Ce.PACKED_4X1_UNSIGNED_BYTE:
      return em(t);
    default:
      throw new Error(`Unknown physical texture type ${n}`);
  }
}
function VO(n) {
  return F().getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? n ? Ce.PACKED_2X2_FLOAT32 : Ce.UNPACKED_FLOAT32 : n ? Ce.PACKED_2X2_FLOAT16 : Ce.UNPACKED_FLOAT16;
}
function Cg(n, t) {
  if (n === un.UPLOAD)
    return Ce.PACKED_2X2_FLOAT32;
  if (n === un.RENDER || n == null)
    return VO(t);
  if (n === un.DOWNLOAD || n === un.PIXELS)
    return Ce.PACKED_4X1_UNSIGNED_BYTE;
  throw new Error(`Unknown logical texture type ${n}`);
}
function vg(n, t, e) {
  return `${n[0]}_${n[1]}_${t}_${e}`;
}
var qn = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length), this.userCode = `
      float unaryOperation(float x) {
        ${e}
      }

      void main() {
        float x = getAAtOutCoords();
        float y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};
var En = "if (isnan(x)) return x;";
var zO = "return x;";
var Sg = "return abs(x);";
var PO = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
var AO = En + `
  return (x < 0.0) ? 0.0 : x;
`;
var OO = En + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var Ms = "return x;";
var XO = "return 1.0 / (1.0 + exp(-1.0 * x));";
var KO = "return x;";
var ZO = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var BO = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var HO = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var _O = "return 1.0 / (1.0 + exp(-1.0 * x));";
var Vs = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length), this.userCode = `
      vec4 unaryOperation(vec4 x) {
        ${e}
      }

      void main() {
        vec4 x = getAAtOutCoords();
        vec4 y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};
var UO = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = false, this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length);
    const e = t.length, s = Fe("rc", e), o = Vt(e), r = EO(e, s), i6 = s.slice(-2), a = e <= 1 ? "rc" : `vec2(${i6.join(",")})`;
    this.userCode = `
      void main() {
        ${o} rc = getOutputCoords();
        vec4 packedInput = getA(${r});

        setOutput(getChannel(packedInput, ${a}));
      }
    `;
  }
};
var YO = C0;
var QO = 1e-7;
var JO = 1e-4;
var ja = {};
function jO(n) {
  return n in ja || (ja[n] = {}), ja[n];
}
var qO = F().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
var tX = 600;
function eX() {
  return F().global.screen == null ? 1024 : F().global.screen.height * F().global.screen.width * window.devicePixelRatio * tX / 1024 / 1024;
}
var Cu = class _Cu extends _d {
  nextDataId() {
    return _Cu.nextDataId++;
  }
  constructor(t) {
    if (super(), this.pendingRead = /* @__PURE__ */ new WeakMap(), this.pendingDisposal = /* @__PURE__ */ new WeakSet(), this.dataRefCount = /* @__PURE__ */ new WeakMap(), this.numBytesInGPU = 0, this.uploadWaitMs = 0, this.downloadWaitMs = 0, this.lastGlFlushTime = 0, this.warnedAboutMemory = false, this.pendingDeletes = 0, this.disposed = false, !F().getBool("HAS_WEBGL"))
      throw new Error("WebGL is not supported on this device");
    let e;
    if (t != null) {
      if (t instanceof Au)
        e = t;
      else {
        const s = Bn(F().getNumber("WEBGL_VERSION"), t);
        e = new Au(s);
      }
      this.binaryCache = {}, this.gpgpuCreatedLocally = false;
    } else {
      const s = Bn(F().getNumber("WEBGL_VERSION"));
      e = new Au(s), this.binaryCache = jO(F().getNumber("WEBGL_VERSION")), this.gpgpuCreatedLocally = true;
    }
    this.gpgpu = e, this.canvas = this.gpgpu.gl.canvas, this.textureManager = new WO(this.gpgpu), this.numMBBeforeWarning = eX(), this.texData = new qg(this, Ot());
  }
  numDataIds() {
    return this.texData.numDataIds() - this.pendingDeletes;
  }
  // Writes a new entry to the data store with a WebGL texture, and registers it
  // to the texture manager.
  writeTexture(t, e, s, o, r, i6) {
    const a = this.makeTensorInfo(e, s), l = this.texData.get(a.dataId);
    l.isPacked = false, l.texture = { texture: t, texShape: [o, r] }, l.texShape = [o, r];
    const c = ti(e), u = new wg(c, false, i6), d = this.runWebGLProgram(u, [a], s, [[o, r]]);
    return d.shape = e, l.texture = null, this.disposeIntermediateTensorInfo(a), d.dataId;
  }
  write(t, e, s) {
    if ((F().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || F().getBool("DEBUG")) && this.checkNumericalProblems(t), s === "complex64" && t != null)
      throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    const o = { id: this.nextDataId() };
    return this.texData.set(o, { shape: e, dtype: s, values: t, usage: un.UPLOAD, refCount: 1 }), o;
  }
  /** Return refCount of a `TensorData`. */
  refCount(t) {
    return this.texData.has(t) ? this.texData.get(t).refCount : 0;
  }
  /** Increase refCount of a `TextureData`. */
  incRef(t) {
    const e = this.texData.get(t);
    e.refCount++;
  }
  /** Decrease refCount of a `TextureData`. */
  decRef(t) {
    if (this.texData.has(t)) {
      const e = this.texData.get(t);
      e.refCount--;
    }
  }
  move(t, e, s, o, r) {
    if (F().getBool("DEBUG") && this.checkNumericalProblems(e), o === "complex64")
      throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    this.texData.set(t, { shape: s, dtype: o, values: e, usage: un.UPLOAD, refCount: r });
  }
  disposeIntermediateTensorInfo(t) {
    this.disposeData(t.dataId);
  }
  readSync(t) {
    const e = this.texData.get(t), { values: s, dtype: o, complexTensorInfos: r, slice: i6, shape: a, isPacked: l } = e;
    if (i6 != null) {
      let h;
      l ? h = new Vs(a, Ms) : h = new qn(a, Ms);
      const p = this.runWebGLProgram(h, [{ dataId: t, shape: a, dtype: o }], o), f = this.readSync(p.dataId);
      return this.disposeIntermediateTensorInfo(p), f;
    }
    if (s != null)
      return this.convertAndCacheOnCPU(t);
    if (o === "string")
      return s;
    const c = this.activeTimers != null;
    let u;
    c && (u = Ie());
    let d;
    if (o === "complex64") {
      const h = this.readSync(r.real.dataId), p = this.readSync(r.imag.dataId);
      d = xs(h, p);
    } else
      d = this.getValuesFromTexture(t);
    return c && (this.downloadWaitMs += Ie() - u), this.convertAndCacheOnCPU(t, d);
  }
  async read(t) {
    if (this.pendingRead.has(t)) {
      const f = this.pendingRead.get(t);
      return new Promise((m) => f.push(m));
    }
    const e = this.texData.get(t), { values: s, shape: o, slice: r, dtype: i6, complexTensorInfos: a, isPacked: l } = e;
    if (r != null) {
      let f;
      l ? f = new Vs(o, Ms) : f = new qn(o, Ms);
      const m = this.runWebGLProgram(f, [{ dataId: t, shape: o, dtype: i6 }], i6), g = this.read(m.dataId);
      return this.disposeIntermediateTensorInfo(m), g;
    }
    if (s != null)
      return this.convertAndCacheOnCPU(t);
    if (F().getBool("DEBUG") && !F().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && F().getNumber("WEBGL_VERSION") === 2)
      throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");
    let c = null, u;
    if (i6 !== "complex64" && F().get("WEBGL_BUFFER_SUPPORTED")) {
      u = this.decode(t);
      const f = this.texData.get(u.dataId);
      c = this.gpgpu.createBufferFromTexture(f.texture.texture, ...Qa(o));
    }
    this.pendingRead.set(t, []), i6 !== "complex64" && await this.gpgpu.createAndWaitForFence();
    let d;
    if (i6 === "complex64") {
      const f = await Promise.all([
        this.read(a.real.dataId),
        this.read(a.imag.dataId)
      ]), m = f[0], g = f[1];
      d = xs(m, g);
    } else if (c == null)
      d = this.getValuesFromTexture(t);
    else {
      const f = X(o);
      d = this.gpgpu.downloadFloat32MatrixFromBuffer(c, f);
    }
    if (u != null && this.disposeIntermediateTensorInfo(u), c != null) {
      const f = this.gpgpu.gl;
      nt(f, () => f.deleteBuffer(c));
    }
    const h = this.convertAndCacheOnCPU(t, d), p = this.pendingRead.get(t);
    return this.pendingRead.delete(t), p.forEach((f) => f(h)), this.pendingDisposal.has(t) && (this.pendingDisposal.delete(t), this.disposeData(t) && Ot().removeDataId(t, this), this.pendingDeletes--), h;
  }
  /**
   * Read tensor to a new texture that is densely packed for ease of use.
   * @param dataId The source tensor.
   * @param options
   *     customTexShape: Optional. If set, will use the user defined texture
   *     shape to create the texture.
   */
  readToGPU(t, e = {}) {
    const s = this.texData.get(t), { values: o, shape: r, slice: i6, dtype: a, isPacked: l, texture: c } = s;
    if (a === "complex64")
      throw new Error("Does not support reading texture for complex64 dtype.");
    if (i6 != null) {
      let p;
      l ? p = new Vs(r, Ms) : p = new qn(r, Ms);
      const f = this.runWebGLProgram(p, [{ dataId: t, shape: r, dtype: a }], a), m = this.readToGPU(f, e);
      return this.disposeIntermediateTensorInfo(f), m;
    }
    if (c == null)
      throw o != null ? new Error("Data is not on GPU but on CPU.") : new Error("There is no data on GPU or CPU.");
    const u = this.decode(t, e.customTexShape), d = Ot().makeTensorFromTensorInfo(u), h = this.texData.get(u.dataId);
    return Object.assign({ tensorRef: d }, h.texture);
  }
  bufferSync(t) {
    const e = this.readSync(t.dataId);
    if (t.dtype === "string")
      try {
        const s = e.map((o) => gs(o));
        return vt(t.shape, t.dtype, s);
      } catch {
        throw new Error("Failed to decode encoded string bytes into utf-8");
      }
    return vt(t.shape, t.dtype, e);
  }
  checkNumericalProblems(t) {
    if (t != null)
      for (let e = 0; e < t.length; e++) {
        const s = t[e];
        if (!Qw(s))
          throw F().getBool("WEBGL_RENDER_FLOAT32_CAPABLE") ? Error(`The value ${s} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`) : Error(`The value ${s} cannot be represented on this device.`);
      }
  }
  getValuesFromTexture(t) {
    const { shape: e, dtype: s, isPacked: o } = this.texData.get(t), r = X(e);
    if (F().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
      const h = this.decode(t), p = this.texData.get(h.dataId), f = this.gpgpu.downloadMatrixFromPackedTexture(p.texture.texture, ...Qa(e)).subarray(0, r);
      return this.disposeIntermediateTensorInfo(h), f;
    }
    const i6 = F().getBool("WEBGL_PACK") && o === true, a = i6 ? ti(e) : e, l = i6 ? new FA(a) : new DA(a), c = this.runWebGLProgram(l, [{ shape: a, dtype: s, dataId: t }], "float32"), u = this.texData.get(c.dataId), d = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture.texture, u.texShape[0], u.texShape[1]).subarray(0, r);
    return this.disposeIntermediateTensorInfo(c), d;
  }
  timerAvailable() {
    return F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
  }
  time(t) {
    const e = this.activeTimers, s = [];
    let o = false;
    this.programTimersStack == null ? (this.programTimersStack = s, o = true) : this.activeTimers.push(s), this.activeTimers = s, t();
    const r = Ks(this.activeTimers.map((l) => l.query)).filter((l) => l != null), i6 = Ks(this.activeTimers.map((l) => l.name)).filter((l) => l != null);
    this.activeTimers = e, o && (this.programTimersStack = null);
    const a = {
      uploadWaitMs: this.uploadWaitMs,
      downloadWaitMs: this.downloadWaitMs,
      kernelMs: null,
      wallMs: null
      // will be filled by the engine
    };
    return (async () => {
      if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        const l = await Promise.all(r);
        a.kernelMs = tb(l), a.getExtraProfileInfo = () => l.map((c, u) => ({ name: i6[u], ms: c })).map((c) => `${c.name}: ${c.ms}`).join(", ");
      } else
        a.kernelMs = {
          error: "WebGL query timers are not supported in this environment."
        };
      return this.uploadWaitMs = 0, this.downloadWaitMs = 0, a;
    })();
  }
  memory() {
    return {
      unreliable: false,
      numBytesInGPU: this.numBytesInGPU,
      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
      numBytesInGPUFree: this.textureManager.numBytesFree
    };
  }
  startTimer() {
    return F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? this.gpgpu.beginQuery() : { startMs: Ie(), endMs: null };
  }
  endTimer(t) {
    return F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? (this.gpgpu.endQuery(), t) : (t.endMs = Ie(), t);
  }
  async getQueryTime(t) {
    if (F().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0)
      return this.gpgpu.waitForQueryAndGetTime(t);
    const e = t;
    return e.endMs - e.startMs;
  }
  /**
   * Decrease the RefCount on the dataId and dispose the memory if the dataId
   * has 0 refCount. If there are pending read on the data, the disposal would
   * added to the pending delete queue. Return true if the dataId is removed
   * from backend or the backend does not contain the dataId, false if the
   * dataId is not removed. Memory may or may not be released even when dataId
   * is removed, which also depends on dataRefCount, see `releaseGPU`.
   * @param dataId
   * @oaram force Optional, remove the data regardless of refCount
   */
  disposeData(t, e = false) {
    if (this.pendingDisposal.has(t))
      return false;
    if (!this.texData.has(t))
      return true;
    if (e ? this.texData.get(t).refCount = 0 : this.texData.get(t).refCount--, !e && this.texData.get(t).refCount > 0)
      return false;
    if (this.pendingRead.has(t))
      return this.pendingDisposal.add(t), this.pendingDeletes++, false;
    this.releaseGPUData(t);
    const { complexTensorInfos: s } = this.texData.get(t);
    return s != null && (this.disposeData(s.real.dataId, e), this.disposeData(s.imag.dataId, e)), this.texData.delete(t), true;
  }
  releaseGPUData(t) {
    const { texture: e, dtype: s, texShape: o, usage: r, isPacked: i6, slice: a } = this.texData.get(t), l = a && a.origDataId || t, c = this.dataRefCount.get(l);
    c > 1 ? this.dataRefCount.set(l, c - 1) : (this.dataRefCount.delete(l), e != null && (this.numBytesInGPU -= this.computeBytes(o, s), this.textureManager.releaseTexture(e, o, r, i6)));
    const u = this.texData.get(t);
    u.texture = null, u.texShape = null, u.isPacked = false, u.slice = null;
  }
  getTexture(t) {
    return this.uploadToGPU(t), this.texData.get(t).texture.texture;
  }
  /**
   * Returns internal information for the specific data bucket. Used in unit
   * tests.
   */
  getDataInfo(t) {
    return this.texData.get(t);
  }
  /*
  Tests whether all the inputs to an op are small and on the CPU. This heuristic
  determines when it would be faster to execute a kernel on the CPU. WebGL
  kernels opt into running this check and forwarding when appropriate.
  TODO(https://github.com/tensorflow/tfjs/issues/872): Develop a more
  sustainable strategy for optimizing backend execution of ops.
   */
  shouldExecuteOnCPU(t, e = qO) {
    return F().getBool("WEBGL_CPU_FORWARD") && t.every((s) => this.texData.get(s.dataId).texture == null && X(s.shape) < e);
  }
  getGPGPUContext() {
    return this.gpgpu;
  }
  where(t) {
    ln("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
    const e = t.dataSync();
    return YO(t.shape, e);
  }
  packedUnaryOp(t, e, s) {
    const o = new Vs(t.shape, e), r = this.compileAndRun(o, [t], s);
    return Ot().makeTensorFromTensorInfo(r);
  }
  // TODO(msoulanille) remove this once the backend has been modularized
  // a copy is needed here to break a circular dependency.
  // Also remove the op from unary_op.
  abs(t) {
    if (this.shouldExecuteOnCPU([t]) && t.dtype !== "complex64") {
      const o = XI(this.texData.get(t.dataId).values);
      return this.makeOutput(t.shape, t.dtype, o);
    }
    if (F().getBool("WEBGL_PACK_UNARY_OPERATIONS"))
      return this.packedUnaryOp(t, Sg, t.dtype);
    const e = new qn(t.shape, Sg), s = this.compileAndRun(e, [t]);
    return Ot().makeTensorFromTensorInfo(s);
  }
  makeTensorInfo(t, e, s) {
    let o;
    if (e === "string" && s != null && s.length > 0 && vr(s[0])) {
      const r = s.map((i6) => ms(i6));
      o = this.write(r, t, e);
    } else
      o = this.write(s, t, e);
    return this.texData.get(o).usage = null, { dataId: o, shape: t, dtype: e };
  }
  makeOutput(t, e, s) {
    return Ot().makeTensorFromTensorInfo(this.makeTensorInfo(t, e, s), this);
  }
  unpackTensor(t) {
    const e = new UO(t.shape);
    return this.runWebGLProgram(e, [t], t.dtype);
  }
  packTensor(t) {
    const e = new LO(t.shape);
    return this.runWebGLProgram(e, [t], t.dtype, null, true);
  }
  packedReshape(t, e) {
    const s = [
      Vo(t.shape),
      ...zo(t.shape)
    ], o = {
      dtype: t.dtype,
      shape: s,
      dataId: t.dataId
    }, r = [
      Vo(e),
      ...zo(e)
    ], i6 = new BI(r, s), a = true, l = [s], c = this.runWebGLProgram(i6, [o], t.dtype, l, a);
    return { dataId: c.dataId, shape: e, dtype: c.dtype };
  }
  decode(t, e) {
    const s = this.texData.get(t), { isPacked: o, shape: r, dtype: i6 } = s;
    if (e != null) {
      const h = X(r), p = e[0] * e[1] * 4;
      C(h <= p, () => "customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data.");
    }
    const a = ti(r);
    let l;
    o ? l = new WA(a) : l = new MA(a);
    const c = true, u = [e ?? Qa(a)], d = this.runWebGLProgram(l, [{ shape: a, dtype: i6, dataId: t }], i6, u, c, e);
    return { dtype: i6, shape: r, dataId: d.dataId };
  }
  runWebGLProgram(t, e, s, o, r = false, i6) {
    const a = this.makeTensorInfo(t.outputShape, s), l = this.texData.get(a.dataId);
    if (t.packedOutput && (l.isPacked = true), t.outPackingScheme === bi.DENSE) {
      const b = i6 ?? Qa(t.outputShape);
      l.texShape = b.map((x6) => x6 * 2);
    }
    if (t.outTexUsage != null && (l.usage = t.outTexUsage), X(a.shape) === 0)
      return l.values = Se(a.dtype, 0), a;
    const c = [], u = e.map((b) => {
      if (b.dtype === "complex64")
        throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");
      let x6 = this.texData.get(b.dataId);
      if (x6.texture == null) {
        if (!t.packedInputs && X(b.shape) <= F().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))
          return {
            shape: b.shape,
            texData: null,
            isUniform: true,
            uniformValues: x6.values
          };
        t.packedInputs && (x6.isPacked = true, x6.shape = b.shape);
      }
      if (this.uploadToGPU(b.dataId), !!x6.isPacked != !!t.packedInputs)
        b = x6.isPacked ? this.unpackTensor(b) : this.packTensor(b), c.push(b), x6 = this.texData.get(b.dataId);
      else if (x6.isPacked && !xi(x6.shape, b.shape)) {
        const w = b, y6 = b.shape;
        b.shape = x6.shape, b = this.packedReshape(b, y6), c.push(b), x6 = this.texData.get(b.dataId), w.shape = y6;
      }
      return { shape: b.shape, texData: x6, isUniform: false };
    });
    this.uploadToGPU(a.dataId);
    const d = { shape: a.shape, texData: l, isUniform: false }, h = LA(t, u, d), p = this.getAndSaveBinary(h, () => GA(this.gpgpu, t, u, d)), f = this.activeTimers != null;
    let m;
    f && (m = this.startTimer()), F().get("ENGINE_COMPILE_ONLY") || EA(this.gpgpu, p, u, d, o), c.forEach((b) => this.disposeIntermediateTensorInfo(b)), f && (m = this.endTimer(m), this.activeTimers.push({ name: t.constructor.name, query: this.getQueryTime(m) }));
    const g = F().getNumber("WEBGL_FLUSH_THRESHOLD");
    if (g > 0) {
      const b = Ie();
      b - this.lastGlFlushTime > g && (this.gpgpu.gl.flush(), this.lastGlFlushTime = b);
    }
    if (!F().getBool("WEBGL_LAZILY_UNPACK") && l.isPacked && r === false) {
      const b = this.unpackTensor(a);
      return this.disposeIntermediateTensorInfo(a), b;
    }
    return a;
  }
  compileAndRun(t, e, s, o, r = false) {
    return s = s || e[0].dtype, this.runWebGLProgram(t, e, s, o, r);
  }
  getAndSaveBinary(t, e) {
    return t in this.binaryCache || (this.binaryCache[t] = e()), this.binaryCache[t];
  }
  getTextureManager() {
    return this.textureManager;
  }
  dispose() {
    this.disposed || (F().getBool("IS_TEST") || Object.keys(this.binaryCache).forEach((e) => {
      this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram), delete this.binaryCache[e];
    }), this.textureManager.dispose(), this.canvas != null && typeof HTMLCanvasElement < "u" && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null, this.gpgpuCreatedLocally && (this.gpgpu.program = null, this.gpgpu.dispose()), this.disposed = true);
  }
  floatPrecision() {
    return this.floatPrecisionValue == null && (this.floatPrecisionValue = D(() => {
      if (!F().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
        const t = F().getBool("DEBUG");
        F().set("DEBUG", false);
        const e = this.abs(gt(1e-8)).dataSync()[0];
        if (F().set("DEBUG", t), e > 0)
          return 32;
      }
      return 16;
    })), this.floatPrecisionValue;
  }
  /** Returns the smallest representable number.  */
  epsilon() {
    return this.floatPrecision() === 32 ? QO : JO;
  }
  uploadToGPU(t) {
    const e = this.texData.get(t), { shape: s, dtype: o, values: r, texture: i6, usage: a, isPacked: l } = e;
    if (i6 != null)
      return;
    const c = this.activeTimers != null;
    let u;
    c && (u = Ie());
    let d = e.texShape;
    if (d == null && (d = pI(s, l), e.texShape = d), r != null) {
      const h = ti(s);
      let p, f = d[1], m = d[0];
      const g = r instanceof Uint8Array || r instanceof Uint8ClampedArray;
      (l || !g) && ([f, m] = Gr(d[0], d[1])), l ? p = new zA(h, g) : p = new wg(h, g);
      const b = g ? [m, f] : d, x6 = this.makeTensorInfo(b, o), w = this.texData.get(x6.dataId);
      g ? w.usage = un.PIXELS : w.usage = un.UPLOAD, w.texShape = b, this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(x6.dataId), f, m, r);
      const y6 = [[m, f]], v = this.runWebGLProgram(p, [x6], o, y6, true), k6 = this.texData.get(v.dataId);
      e.texShape = k6.texShape, e.isPacked = k6.isPacked, e.usage = k6.usage, F().get("ENGINE_COMPILE_ONLY") ? this.disposeData(v.dataId) : (e.texture = k6.texture, e.values = null, this.texData.delete(v.dataId)), this.disposeIntermediateTensorInfo(x6), c && (this.uploadWaitMs += Ie() - u);
    } else {
      const h = this.acquireTexture(d, a, o, l);
      e.texture = h;
    }
  }
  convertAndCacheOnCPU(t, e) {
    const s = this.texData.get(t), { dtype: o } = s;
    return e != null && (s.values = nX(e, o)), s.values;
  }
  acquireTexture(t, e, s, o) {
    if (this.numBytesInGPU += this.computeBytes(t, s), !this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {
      const r = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
      this.warnedAboutMemory = true, console.warn(`High memory usage in GPU: ${r} MB, most likely due to a memory leak`);
    }
    return this.textureManager.acquireTexture(t, e, o);
  }
  computeBytes(t, e) {
    return t[0] * t[1] * ri(e);
  }
  checkCompileCompletion() {
    for (const [, t] of Object.entries(this.binaryCache))
      this.checkCompletion_(t);
  }
  async checkCompileCompletionAsync() {
    const t = [];
    if (this.gpgpu.parallelCompilationExtension) {
      for (const [, e] of Object.entries(this.binaryCache))
        t.push(this.checkCompletionAsync_(e));
      return Promise.all(t);
    } else {
      for (const [, e] of Object.entries(this.binaryCache)) {
        const s = new Promise((o) => {
          try {
            this.checkCompletion_(e), o(true);
          } catch (r) {
            throw r;
          }
        });
        t.push(s);
      }
      return Promise.all(t);
    }
  }
  async checkCompletionAsync_(t) {
    return this.gpgpu.gl.getProgramParameter(t.webGLProgram, this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR) ? this.checkCompletion_(t) : (await su(), this.checkCompletionAsync_(t));
  }
  checkCompletion_(t) {
    if (this.gpgpu.gl.getProgramParameter(t.webGLProgram, this.gpgpu.gl.LINK_STATUS) === false)
      throw console.log(this.gpgpu.gl.getProgramInfoLog(t.webGLProgram)), this.gpgpu.gl.getShaderParameter(t.fragmentShader, this.gpgpu.gl.COMPILE_STATUS) === false ? (Yf(t.source, this.gpgpu.gl.getShaderInfoLog(t.fragmentShader)), new Error("Failed to compile fragment shader.")) : new Error("Failed to link vertex and fragment shaders.");
    return true;
  }
  getUniformLocations() {
    for (const t of Object.values(this.binaryCache)) {
      this.gpgpu.buildVao(t.webGLProgram);
      const { variablesLocations: e, customUniformLocations: s, infLoc: o, nanLoc: r, outShapeLocation: i6, outShapeStridesLocation: a, outTexShapeLocation: l } = SI(this.gpgpu, t.program, t.webGLProgram);
      t.variablesLocations = e, t.customUniformLocations = s, t.infLoc = o, t.nanLoc = r, t.outShapeLocation = i6, t.outShapeStridesLocation = a, t.outTexShapeLocation = l;
    }
  }
  /**
   * Create a TF.js tensor out of an existing WebGL texture. A new texture will
   * be created.
   */
  createTensorFromGPUData(t, e, s) {
    t.channels = t.channels || "RGBA";
    const { texture: o, height: r, width: i6, channels: a } = t, l = Ot().backend;
    if (!l.gpgpu.gl.isTexture(o))
      throw new Error("The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.");
    const c = l.writeTexture(o, e, s, r, i6, a);
    return Ot().makeTensorFromDataId(c, e, s, l);
  }
};
Cu.nextDataId = 0;
function nX(n, t) {
  if (t === "float32" || t === "complex64")
    return n;
  if (t === "int32" || t === "bool") {
    const e = t === "int32" ? new Int32Array(n.length) : new Uint8Array(n.length);
    for (let s = 0; s < e.length; ++s)
      e[s] = Math.round(n[s]);
    return e;
  } else
    throw new Error(`Unknown dtype ${t}`);
}
function sX() {
  F().set("WEBGL_FORCE_F16_TEXTURES", true);
}
Jh() && Pb(
  "webgl",
  () => new Cu(),
  2
  /* priority */
);
var YQ = { forceHalfFloat: sX };
var rm = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
var Po = class {
  constructor(t, e, s) {
    this.variableNames = ["A", "B"], this.outputShape = bt(e, s), this.enableShapeUniforms = Me(this.outputShape.length), this.userCode = `
      float binaryOperation(float a, float b) {
        ${t}
      }

      void main() {
        float a = getAAtOutCoords();
        float b = getBAtOutCoords();
        setOutput(binaryOperation(a, b));
      }
    `;
  }
};
var jo = `
  result.r = isNaN.r ? NAN : result.r;
  result.g = isNaN.g ? NAN : result.g;
  result.b = isNaN.b ? NAN : result.b;
  result.a = isNaN.a ? NAN : result.a;
`;
var Fr = class {
  constructor(t, e, s, o = false) {
    this.variableNames = ["A", "B"], this.supportsBroadcasting = true, this.packedInputs = true, this.packedOutput = true, this.outputShape = bt(e, s);
    const r = this.outputShape.length;
    this.enableShapeUniforms = Me(r);
    let i6 = "";
    if (o)
      if (r === 0 || X(this.outputShape) === 1)
        i6 = `
          result.y = 0.;
          result.z = 0.;
          result.w = 0.;
        `;
      else if (i6 = `
          ${Vt(r)} coords = getOutputCoords();
        `, r === 1)
        this.enableShapeUniforms ? i6 += `
            result.y = (coords + 1) >= outShape ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          ` : i6 += `
            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
      else {
        const l = Fe("coords", r);
        this.enableShapeUniforms ? i6 += `
            bool nextRowOutOfBounds =
              (${l[r - 2]} + 1) >= outShape[${r} - 2];
            bool nextColOutOfBounds =
              (${l[r - 1]} + 1) >= outShape[${r} - 1];
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          ` : i6 += `
            bool nextRowOutOfBounds =
              (${l[r - 2]} + 1) >= ${this.outputShape[r - 2]};
            bool nextColOutOfBounds =
              (${l[r - 1]} + 1) >= ${this.outputShape[r - 1]};
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
      }
    this.userCode = `
      vec4 binaryOperation(vec4 a, vec4 b) {
        ${t}
      }

      void main() {
        vec4 a = getAAtOutCoords();
        vec4 b = getBAtOutCoords();

        vec4 result = binaryOperation(a, b);
        ${i6}

        setOutput(result);
      }
    `;
  }
};
function nn(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  return e.incRef(s.dataId), { dataId: s.dataId, shape: s.shape, dtype: s.dtype };
}
var oX = {
  kernelName: Ki,
  backendName: "webgl",
  kernelFunc: nn
};
function oo(n) {
  const { inputs: t, backend: e } = n, { real: s, imag: o } = t, r = e.makeTensorInfo(s.shape, "complex64"), i6 = e.texData.get(r.dataId), a = nn({ inputs: { x: s }, backend: e }), l = nn({ inputs: { x: o }, backend: e });
  return i6.complexTensorInfos = { real: a, imag: l }, r;
}
var rX = {
  kernelName: ih,
  backendName: "webgl",
  kernelFunc: oo
};
var HI = "return (a < 0.) ? b * a : a;";
var _I = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function iX(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { alpha: r } = s, i6 = e.makeTensorInfo([], "float32", Is(r, "float32")), a = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new Fr(_I, o.shape, i6.shape) : new Po(HI, o.shape, i6.shape), l = e.runWebGLProgram(a, [o, i6], "float32");
  return e.disposeIntermediateTensorInfo(i6), l;
}
var aX = {
  kernelName: fc,
  backendName: "webgl",
  kernelFunc: iX
};
var UI = "return (a < 0.) ? b * a : a;";
var YI = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function lX(n) {
  const { inputs: t, backend: e } = n, { x: s, alpha: o } = t, r = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new Fr(YI, s.shape, o.shape) : new Po(UI, s.shape, o.shape);
  return e.runWebGLProgram(r, [s, o], "float32");
}
var cX = {
  kernelName: Mc,
  backendName: "webgl",
  kernelFunc: lX
};
var Vr = "if (isnan(x)) return x;";
function Nt({ opSnippet: n, packedOpSnippet: t, cpuKernelImpl: e, dtype: s }) {
  return ({ inputs: o, backend: r }) => {
    const { x: i6 } = o, a = r, l = s || i6.dtype;
    if (a.shouldExecuteOnCPU([i6]) && e != null) {
      const d = a.texData.get(i6.dataId), h = e(d.values, l);
      return a.makeTensorInfo(i6.shape, l, h);
    }
    const c = F().getBool("WEBGL_PACK_UNARY_OPERATIONS") && t != null;
    let u;
    return c ? u = new Vs(i6.shape, t) : u = new qn(i6.shape, n), a.runWebGLProgram(u, [i6], l);
  };
}
function Re({ opSnippet: n, packedOpSnippet: t, checkOutOfBounds: e = false, supportsComplex: s = false, cpuKernelImpl: o, dtype: r }) {
  return ({ inputs: i6, backend: a }) => {
    const { a: l, b: c } = i6, u = a;
    if (s && l.dtype === "complex64") {
      const f = u.texData.get(l.dataId), m = u.texData.get(c.dataId), [g, b] = [
        [f.complexTensorInfos.real, m.complexTensorInfos.real],
        [f.complexTensorInfos.imag, m.complexTensorInfos.imag]
      ].map((w) => {
        const [y6, I] = w, v = {
          dataId: y6.dataId,
          dtype: y6.dtype,
          shape: l.shape
        }, k6 = {
          dataId: I.dataId,
          dtype: I.dtype,
          shape: c.shape
        }, S = new Po(n, l.shape, c.shape);
        return u.runWebGLProgram(S, [v, k6], tn(y6.dtype, I.dtype));
      }), x6 = oo({ inputs: { real: g, imag: b }, backend: u });
      return u.disposeIntermediateTensorInfo(g), u.disposeIntermediateTensorInfo(b), x6;
    }
    const d = r || tn(l.dtype, c.dtype);
    if ((l.dtype === "string" || c.dtype === "string" || u.shouldExecuteOnCPU([l, c])) && o != null) {
      const f = u.texData.get(l.dataId).values, m = u.texData.get(c.dataId).values, g = l.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        ys(f)
      ) : f, b = l.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        ys(m)
      ) : m, [x6, w] = o(l.shape, c.shape, g, b, d), y6 = u.makeTensorInfo(w, d), I = u.texData.get(y6.dataId);
      return I.values = x6, y6;
    }
    const h = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") && t != null;
    let p;
    return h ? p = new Fr(t, l.shape, c.shape, e) : p = new Po(n, l.shape, c.shape), u.runWebGLProgram(p, [l, c], d);
  };
}
function yi(n, t = false) {
  if (n === "linear")
    return t ? KO : zO;
  if (n === "relu")
    return t ? BO : AO;
  if (n === "elu")
    return t ? ZO : PO;
  if (n === "relu6")
    return t ? HO : OO;
  if (n === "prelu")
    return t ? YI : UI;
  if (n === "leakyrelu")
    return t ? _I : HI;
  if (n === "sigmoid")
    return t ? _O : XO;
  throw new Error(`Activation ${n} has not been implemented for the WebGL backend.`);
}
var QI = class {
  constructor(t, e, s, o = false, r = false, i6 = false, a = null, l = false, c = false) {
    this.variableNames = ["matrixA", "matrixB"], this.packedInputs = true, this.packedOutput = true, this.outputShape = s, this.enableShapeUniforms = Me(this.outputShape.length);
    const u = o ? t[1] : t[2], d = Math.ceil(u / 2), h = o ? "i * 2, rc.y" : "rc.y, i * 2", p = r ? "rc.z, i * 2" : "i * 2, rc.z", f = o ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"], m = r ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
    let g = "", b = "";
    a && (l ? g = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${a}
        }` : c ? g = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${a}
        }` : g = `vec4 activation(vec4 x) {
          ${a}
        }`, b = "result = activation(result);");
    const x6 = i6 ? "result += getBiasAtOutCoords();" : "";
    i6 && this.variableNames.push("bias"), l && this.variableNames.push("preluActivationWeights"), c && this.variableNames.push("leakyreluAlpha");
    let w = "rc.x", y6 = "rc.x";
    t[0] < e[0] ? w = `imod(rc.x, ${t[0]})` : e[0] < t[0] && (y6 = `imod(rc.x, ${e[0]})`), this.userCode = `
      ${g}
      // Don't use uniform for sharedDimensionPacked for performance.
      const float sharedDimension = ${d}.0;

      vec4 dot2x2ARowBCol(ivec3 rc) {
        vec4 result = vec4(0);
        int batchA = ${w};
        int batchB = ${y6};
        for (int i = 0; i < ${d}; i++) {
          vec4 a = getMatrixA(batchA, ${h});
          vec4 b = getMatrixB(batchB, ${p});

          // These swizzled products need to be separately added.
          // See: https://github.com/tensorflow/tfjs/issues/1735
          result += (${f[0]} * ${m[0]});
          result += (${f[1]} * ${m[1]});
        }
        return result;
      }

      void main() {
        ivec3 rc = getOutputCoords();
        vec4 result = dot2x2ARowBCol(rc);

        ${x6}

        ${b}

        setOutput(result);
      }
    `;
  }
};
var kg = {
  REAL: "return areal * breal - aimag * bimag;",
  IMAG: "return areal * bimag + aimag * breal;"
};
var Tg = class {
  constructor(t, e, s) {
    this.variableNames = ["AReal", "AImag", "BReal", "BImag"], this.outputShape = bt(e, s), this.userCode = `
      float binaryOpComplex(
          float areal, float aimag, float breal, float bimag) {
        ${t}
      }

      void main() {
        float areal = getARealAtOutCoords();
        float aimag = getAImagAtOutCoords();
        float breal = getBRealAtOutCoords();
        float bimag = getBImagAtOutCoords();
        setOutput(binaryOpComplex(areal, aimag, breal, bimag));
      }
    `;
  }
};
var Ng = "return a * b;";
function im(n) {
  const { inputs: t, backend: e } = n, { a: s, b: o } = t, r = tn(s.dtype, o.dtype);
  if (s.dtype === "complex64") {
    const a = e.texData.get(s.dataId), l = e.texData.get(o.dataId), c = new Tg(kg.REAL, s.shape, o.shape), u = new Tg(kg.IMAG, s.shape, o.shape), d = [
      {
        dataId: a.complexTensorInfos.real.dataId,
        dtype: a.complexTensorInfos.real.dtype,
        shape: s.shape
      },
      {
        dataId: a.complexTensorInfos.imag.dataId,
        dtype: a.complexTensorInfos.imag.dtype,
        shape: s.shape
      },
      {
        dataId: l.complexTensorInfos.real.dataId,
        dtype: l.complexTensorInfos.real.dtype,
        shape: o.shape
      },
      {
        dataId: l.complexTensorInfos.imag.dataId,
        dtype: l.complexTensorInfos.imag.dtype,
        shape: o.shape
      }
    ], h = e.runWebGLProgram(c, d, "float32"), p = e.runWebGLProgram(u, d, "float32"), f = oo({ inputs: { real: h, imag: p }, backend: e });
    return e.disposeIntermediateTensorInfo(h), e.disposeIntermediateTensorInfo(p), f;
  }
  if (e.shouldExecuteOnCPU([s, o])) {
    const a = e.texData.get(s.dataId), l = e.texData.get(o.dataId), [c, u] = aO(s.shape, o.shape, a.values, l.values, r), d = e.makeTensorInfo(u, r), h = e.texData.get(d.dataId);
    return h.values = c, d;
  }
  let i6;
  return F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? i6 = new Fr(Ng, s.shape, o.shape) : i6 = new Po(Ng, s.shape, o.shape), e.runWebGLProgram(i6, [s, o], r);
}
var uX = {
  kernelName: ji,
  backendName: "webgl",
  kernelFunc: im
};
function dX(n, t, e) {
  const s = [
    Vo(n.shape),
    ...zo(n.shape)
  ], o = {
    dtype: n.dtype,
    shape: s,
    dataId: n.dataId
  }, r = [
    Vo(t),
    ...zo(t)
  ], i6 = new BI(r, s), a = true, l = [s], c = e.runWebGLProgram(i6, [o], n.dtype, l, a);
  return { dataId: c.dataId, shape: t, dtype: c.dtype };
}
function et(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { shape: r } = s, i6 = e, a = X(o.shape), l = Yd(r, a), c = X(l);
  C(a === c, () => `The new shape (${l}) has ${c} elements and the old shape (${o.shape}) has ${a} elements. The new shape and old shape must have the same number of elements.`);
  const u = i6.texData.get(o.dataId);
  return u.isPacked && !xi(o.shape, l) && !(u.texture !== null && xi(u.shape, l)) ? dX(o, l, i6) : (i6.incRef(o.dataId), { dataId: o.dataId, shape: l, dtype: o.dtype });
}
var hX = {
  kernelName: Dc,
  backendName: "webgl",
  kernelFunc: et
};
var Rg = class {
  constructor(t, e) {
    this.variableNames = ["x"];
    const { windowSize: s, batchSize: o, inSize: r, outSize: i6 } = t;
    this.outputShape = [o, i6];
    const a = Math.floor(s / 4) * 4, l = s % 4;
    let c = "sumValue += dot(values, ones);";
    if (e != null) {
      const d = 1 / e;
      c = `sumValue += dot(values * ${Co(d) ? d.toPrecision(2) : d}, ones);`;
    }
    let u = "";
    r % s > 0 && (u = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return 0.0;
        }
      `), this.userCode = `
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${u}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${s};

        float sumValue = 0.0;

        for (int i = 0; i < ${a}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${c}
        }

        int inIdx = inOffset + ${a};
        if (${l === 1}) {
          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);

          ${c}
        } else if (${l === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1), 0.0, 0.0);

          ${c}
        } else if (${l === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2), 0.0);

          ${c}
        }
        setOutput(sumValue);
      }
    `;
  }
};
var pX = class {
  constructor(t, e) {
    this.variableNames = ["x"];
    const { windowSize: s, batchSize: o, inSize: r, outSize: i6 } = t;
    this.outputShape = [o, i6];
    let a = "0.0", l = "";
    e === "prod" ? a = "1.0" : e === "min" ? (a = "1.0 / 1e-20", l = "min") : e === "max" && (a = "-1.0 / 1e-20", l = "max");
    let c = `${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e === "sum" ? c = "sumValue" : e === "prod" ? c = "prodValue" : e === "all" ? c = "allValue" : e === "any" && (c = "anyValue");
    const u = Math.floor(s / 4) * 4, d = s % 4;
    let h = `
      if (${e === "sum"}) {
        sumValue += dot(values, ones);
      } else if (${e === "prod"}) {
        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);
        prodValue *= tmp[0] * tmp[1];
      } else {
        minMaxValue = ${l}(values, minMaxValue);
        if (${e === "min"} || ${e === "max"}) {
          minMaxValue = ${l}(values, minMaxValue);
          bvec4 isNaN = isnan(values);
          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {
            minMaxValue = vec4(NAN);
          }
        }
      }
    `, p = "vec4";
    e === "all" ? (a = "1.0", h = `
        bool reducedAllValue = all(values);
        float floatedReducedAllValue = float(reducedAllValue);
        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);
      `, p = "bvec4") : e === "any" && (a = "0.0", h = `
        bool reducedAnyValue = any(values);
        float floatedReducedAnyValue = float(reducedAnyValue);
        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);
      `, p = "bvec4");
    let f = "";
    r % s > 0 && (f = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return initializationValue;
        }
      `), this.userCode = `
      const float initializationValue = ${a};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${f}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${s};

        vec4 minMaxValue = vec4(${a});
        float prodValue = 1.0;
        float sumValue = 0.0;
        float allValue = 1.0;
        float anyValue = 0.0;

        for (int i = 0; i < ${u}; i += 4) {
          int inIdx = inOffset + i;
          ${p} values = ${p}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${h}
        }

        int inIdx = inOffset + ${u};
        if (${d === 1}) {
          ${p} values = ${p}(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          ${h}
        } else if (${d === 2}) {
          ${p} values = ${p}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          ${h}
        } else if (${d === 3}) {
          ${p} values = ${p}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          ${h}
        }
        setOutput(${c});
      }
    `;
  }
};
function fX(n) {
  const t = [];
  for (; t.length === 0 || t[t.length - 1].outSize !== 1; ) {
    const e = t.length ? t[t.length - 1].outSize : n[1], s = ou(e);
    t.push({
      inSize: e,
      windowSize: s,
      outSize: Math.ceil(e / s)
    });
  }
  return t;
}
function qo(n, t, e, s) {
  const o = fX(n.shape);
  let r = n;
  for (let i6 = 0; i6 < o.length; i6++) {
    const { inSize: a, windowSize: l, outSize: c } = o[i6];
    let u, d;
    e === "mean" ? u = i6 === 0 ? new Rg({ windowSize: l, inSize: a, batchSize: n.shape[0], outSize: c }, a) : new Rg({ windowSize: l, inSize: a, batchSize: n.shape[0], outSize: c }) : u = new pX({ windowSize: l, inSize: a, batchSize: n.shape[0], outSize: c }, e), d = r, r = s.runWebGLProgram(u, [r], t), d.dataId !== n.dataId && s.disposeIntermediateTensorInfo(d);
  }
  return r;
}
var mX = class {
  constructor(t, e) {
    this.variableNames = ["A"];
    const s = new Array(t.length);
    for (let i6 = 0; i6 < s.length; i6++)
      s[i6] = t[e[i6]];
    this.outputShape = s, this.rank = s.length;
    const o = Vt(this.rank), r = gX(e);
    this.userCode = `
    void main() {
      ${o} resRC = getOutputCoords();
      setOutput(getA(${r}));
    }
    `;
  }
};
function gX(n) {
  const t = n.length;
  if (t > 6)
    throw Error(`Transpose for rank ${t} is not yet supported`);
  const e = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"], s = new Array(t);
  for (let o = 0; o < n.length; o++)
    s[n[o]] = e[o];
  return s.join();
}
var bX = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true;
    const s = new Array(t.length);
    for (let u = 0; u < s.length; u++)
      s[u] = t[e[u]];
    if (this.outputShape = s, this.rank = s.length, this.rank > 6)
      throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);
    const o = Vt(this.rank), r = ZI("rc", this.rank), i6 = new Array(this.rank);
    for (let u = 0; u < e.length; u++)
      i6[e[u]] = r[u];
    const a = `vec2(${i6.slice(-2).join()})`, l = `++${r[this.rank - 1]} < ${s[this.rank - 1]}`, c = `getChannel(getA(${i6.join()}), ${a})`;
    this.userCode = `
    void main() {
      ${o} rc = getOutputCoords();
      vec4 result = vec4(0.);
      result[0] = ${c};
      if(${l}) {
        result[1] = ${c};
      }
      --${r[this.rank - 1]};
      if(++${r[this.rank - 2]} < ${s[this.rank - 2]}) {
        result[2] = ${c};
        if(${l}) {
          result[3] = ${c};
        }
      }
      setOutput(result);
    }
    `;
  }
};
function vu(n, t, e) {
  const s = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new bX(n.shape, t) : new mX(n.shape, t);
  return e.runWebGLProgram(s, [n], n.dtype);
}
function xX(n, t, e, s) {
  const o = t, r = n.shape.length, i6 = Ct(o, n.shape);
  let a = i6;
  const l = qt(a, r), c = l != null;
  let u = n;
  c && (u = vu(n, l, s), a = ie(a.length, r)), Ne("sum", a, r);
  const [d, h] = ye(u.shape, a);
  let p = d;
  e && (p = re(d, i6));
  const f = X(h), g = X(n.shape) / f, b = et({ inputs: { x: u }, attrs: { shape: [g, f] }, backend: s }), x6 = Yh(n.dtype), w = qo(b, x6, "sum", s), y6 = et({ inputs: { x: w }, attrs: { shape: p }, backend: s });
  return s.disposeIntermediateTensorInfo(b), s.disposeIntermediateTensorInfo(w), c && s.disposeIntermediateTensorInfo(u), y6;
}
function Su(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s;
  return xX(o, r, i6, e);
}
var yX = {
  kernelName: Oc,
  backendName: "webgl",
  kernelFunc: Su
};
function ze(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { perm: r } = s, i6 = e, a = o.shape.length, l = new Array(a);
  for (let u = 0; u < l.length; u++)
    l[u] = o.shape[r[u]];
  let c;
  if (i6.shouldExecuteOnCPU([o])) {
    const d = i6.texData.get(o.dataId).values, h = om(d, o.shape, o.dtype, r, l);
    c = i6.makeTensorInfo(l, o.dtype);
    const p = i6.texData.get(c.dataId);
    p.values = h;
  } else
    c = vu(o, r, i6);
  return c;
}
var wX = {
  kernelName: ar,
  backendName: "webgl",
  kernelFunc: ze
};
var JI = 1e3;
function Ol({ a: n, b: t, transposeA: e, transposeB: s, backend: o, bias: r = null, preluActivationWeights: i6 = null, leakyreluAlpha: a = 0, activation: l = null }) {
  const c = n.shape.length, u = t.shape.length, d = e ? n.shape[c - 2] : n.shape[c - 1], h = s ? t.shape[u - 1] : t.shape[u - 2], p = e ? n.shape[c - 1] : n.shape[c - 2], f = s ? t.shape[u - 2] : t.shape[u - 1], m = n.shape.slice(0, -2), g = t.shape.slice(0, -2), b = X(m), x6 = X(g), y6 = bt(n.shape.slice(0, -2), t.shape.slice(0, -2)).concat([p, f]);
  C(d === h, () => `Error in matMul: inner shapes (${d}) and (${h}) of Tensors with shapes ${n.shape} and ${t.shape} and transposeA=${e} and transposeB=${s} must match.`);
  const I = e ? [b, d, p] : [b, p, d], v = s ? [x6, f, h] : [x6, h, f], k6 = et({ inputs: { x: n }, backend: o, attrs: { shape: I } }), S = et({ inputs: { x: t }, backend: o, attrs: { shape: v } }), N = [k6, S], R = Math.max(b, x6), M6 = e ? k6.shape[1] : k6.shape[2], V = r != null, z = i6 != null, P = l === "leakyrelu", A = l != null ? yi(l, true) : null, O = V || z || P || A != null;
  let B6;
  if ((p === 1 || f === 1) && M6 > JI && O === false) {
    let H6 = k6, Y = S;
    e && (H6 = ze({ inputs: { x: k6 }, backend: o, attrs: { perm: [0, 2, 1] } }), N.push(H6)), s && (Y = ze({ inputs: { x: S }, backend: o, attrs: { perm: [0, 2, 1] } }), N.push(Y));
    const Q6 = f !== 1, j = f === 1;
    let J6 = H6;
    Q6 && (J6 = et({
      inputs: { x: H6 },
      backend: o,
      attrs: { shape: [R, M6, 1] }
    }), N.push(J6));
    const ot = f === 1 ? 2 : 1;
    let q = Y;
    j && (q = et({
      inputs: { x: Y },
      backend: o,
      attrs: { shape: [R, 1, M6] }
    }), N.push(q));
    const rt = im({ inputs: { a: J6, b: q }, backend: o });
    B6 = Su({ inputs: { x: rt }, backend: o, attrs: { axis: ot, keepDims: true } }), N.push(rt);
  } else {
    const H6 = tn(n.dtype, t.dtype), Y = new QI(I, v, [R, p, f], e, s, V, A, z, P), Q6 = [k6, S];
    if (r != null && Q6.push(r), z && Q6.push(i6), P) {
      const j = o.makeTensorInfo([], "float32", Is(a, "float32"));
      Q6.push(j), N.push(j);
    }
    B6 = o.runWebGLProgram(Y, Q6, H6);
  }
  const Z = et({ inputs: { x: B6 }, backend: o, attrs: { shape: y6 } });
  N.push(B6);
  for (const H6 of N)
    o.disposeIntermediateTensorInfo(H6);
  return Z;
}
function IX(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r, bias: i6, preluActivationWeights: a } = t, { transposeA: l, transposeB: c, activation: u, leakyreluAlpha: d } = s;
  return Ol({
    a: o,
    b: r,
    transposeA: l,
    transposeB: c,
    backend: e,
    bias: i6,
    preluActivationWeights: a,
    leakyreluAlpha: d,
    activation: u
  });
}
var CX = {
  kernelName: ml,
  backendName: "webgl",
  kernelFunc: IX
};
var $g = "return abs(x);";
function vX(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (e.shouldExecuteOnCPU([s]) && s.dtype !== "complex64") {
    const r = e.texData.get(s.dataId), i6 = XI(r.values);
    return e.makeTensorInfo(s.shape, s.dtype, i6);
  }
  let o;
  return F().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? o = new Vs(s.shape, $g) : o = new qn(s.shape, $g), e.runWebGLProgram(o, [s], s.dtype);
}
var SX = {
  kernelName: Ul,
  backendName: "webgl",
  kernelFunc: vX
};
var kX = En + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return acos(x);
`;
var TX = Nt({ opSnippet: kX });
var NX = {
  kernelName: vi,
  backendName: "webgl",
  kernelFunc: TX
};
var RX = En + `
  if (x < 1.0) return NAN;
return log(x + sqrt(x * x - 1.0));`;
var $X = Nt({ opSnippet: RX });
var GX = {
  kernelName: Si,
  backendName: "webgl",
  kernelFunc: $X
};
var Gg = "return a + b;";
var EX = Re({
  opSnippet: Gg,
  packedOpSnippet: Gg,
  supportsComplex: true,
  cpuKernelImpl: AA
});
var LX = {
  kernelName: Sr,
  backendName: "webgl",
  kernelFunc: EX
};
var MX = class {
  constructor(t, e) {
    this.outputShape = [], this.outputShape = t, this.variableNames = e.map((r, i6) => `T${i6}`);
    const s = [];
    this.variableNames.forEach((r) => {
      s.push(`float v${r} = get${r}AtOutCoords();`);
    });
    const o = this.variableNames.map((r) => `v${r}`).join(" + ");
    this.userCode = `
      void main() {
        ${s.join(`
        `)}

        float result = ${o};
        setOutput(result);
      }
    `;
  }
};
var WX = class {
  constructor(t, e) {
    this.outputShape = [], this.packedInputs = true, this.packedOutput = true, this.outputShape = t, this.variableNames = e.map((r, i6) => `T${i6}`);
    const s = [];
    this.variableNames.forEach((r) => {
      s.push(`vec4 v${r} = get${r}AtOutCoords();`);
    });
    const o = this.variableNames.map((r) => `v${r}`).join(" + ");
    this.userCode = `
      void main() {
        ${s.join(`
        `)}

        vec4 result = ${o};
        setOutput(result);
      }
    `;
  }
};
function dl(n) {
  const { inputs: t, backend: e } = n, s = t;
  if (s.length === 1)
    return nn({ inputs: { x: s[0] }, backend: e });
  if (s.length > F().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    const l = Math.floor(s.length / 2), c = dl({ inputs: s.slice(0, l), backend: e }), u = dl({ inputs: s.slice(l), backend: e });
    return dl({ inputs: [c, u], backend: e });
  }
  const o = s.map((l) => l.dtype).reduce((l, c) => tn(l, c)), r = s.map((l) => l.shape), a = F().getBool("WEBGL_PACK") ? new WX(s[0].shape, r) : new MX(s[0].shape, r);
  return e.runWebGLProgram(a, s, o);
}
var DX = {
  kernelName: qd,
  backendName: "webgl",
  kernelFunc: dl
};
function FX(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a);
  let d = o;
  u != null && (d = ze({ inputs: { x: o }, backend: e, attrs: { perm: u } }), c = ie(c.length, a)), Ne("all", c, a);
  const [h, p] = ye(d.shape, c), f = X(p), m = et({ inputs: { x: d }, backend: e, attrs: { shape: [-1, f] } }), g = qo(m, m.dtype, "all", e);
  let b;
  if (i6) {
    const x6 = re(h, l);
    b = et({ inputs: { x: g }, backend: e, attrs: { shape: x6 } });
  } else
    b = et({ inputs: { x: g }, backend: e, attrs: { shape: h } });
  return e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g), u != null && e.disposeIntermediateTensorInfo(d), b;
}
var VX = {
  kernelName: th,
  backendName: "webgl",
  kernelFunc: FX
};
function zX(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a);
  let d = o;
  u != null && (d = ze({ inputs: { x: o }, backend: e, attrs: { perm: u } }), c = ie(c.length, a)), Ne("any", c, a);
  const [h, p] = ye(d.shape, c), f = X(p), m = et({ inputs: { x: d }, backend: e, attrs: { shape: [-1, f] } }), g = qo(m, m.dtype, "any", e);
  let b;
  if (i6) {
    const x6 = re(h, l);
    b = et({ inputs: { x: g }, backend: e, attrs: { shape: x6 } });
  } else
    b = et({ inputs: { x: g }, backend: e, attrs: { shape: h } });
  return e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g), u != null && e.disposeIntermediateTensorInfo(d), b;
}
var PX = {
  kernelName: eh,
  backendName: "webgl",
  kernelFunc: zX
};
var AX = class {
  constructor(t, e, s) {
    this.variableNames = ["A"];
    const { windowSize: o, batchSize: r, outSize: i6 } = t;
    s || this.variableNames.push("bestIndicesA"), this.outputShape = [r, i6];
    const a = e === "max" ? ">" : "<", l = s ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
    this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${o};

        int bestIndex = inOffset;
        float bestValue = getA(batch, bestIndex);

        for (int i = 0; i < ${o}; i++) {
          int inIdx = ${l};
          float candidate = getA(batch, inIdx);
          if (candidate ${a} bestValue) {
            bestValue = candidate;
            bestIndex = inIdx;
          }
        }
        setOutput(float(bestIndex));
      }
    `;
  }
};
var OX = class {
  constructor(t, e, s, o) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, C(t.length > 2, () => `Packed arg${s.charAt(0).toUpperCase() + s.slice(1)} supports only inputs with rank above 2.`);
    const r = t[t.length - 1], i6 = Math.ceil(r / e);
    this.outputShape = t.slice(0, -1), i6 > 1 && this.outputShape.push(i6), o || this.variableNames.push("bestIndicesA");
    const a = this.outputShape, l = a.length, c = Vt(l), u = Fe("coords", l);
    let d, h;
    if (i6 === 1) {
      h = l + 1;
      const S = Vt(h);
      d = `
        ${S} sourceLocR = ${S}(${u.join()}, 0);
        ++${u[l - 1]};
        ${S} sourceLocG = ${S}(${u.join()}, 0);
        ++${u[l - 2]};
        ${S} sourceLocA = ${S}(${u.join()}, 0);
        --${u[l - 1]};
        ${S} sourceLocB = ${S}(${u.join()}, 0);
        --${u[l - 2]};`;
    } else
      h = l, d = `
        ${c} sourceLocR = coords;
        ++${u[l - 1]};
        ${c} sourceLocG = coords;
        ++${u[l - 2]};
        ${c} sourceLocA = coords;
        --${u[l - 1]};
        ${c} sourceLocB = coords;
        --${u[l - 2]};`;
    const p = ["x", "y", "z", "w", "u", "v"].slice(0, h), f = "." + p[h - 1], m = p.map((S) => "int " + S), g = Fe("sourceLocR", h - 1).concat("inIdx.r"), b = Fe("sourceLocG", h - 1).concat("inIdx.g"), x6 = Fe("sourceLocB", h - 1).concat("inIdx.b"), w = Fe("sourceLocA", h - 1).concat("inIdx.a"), y6 = s === "max" ? "greaterThan" : "lessThan", I = o ? "" : `
          inIdx = round(vec4(getBestIndicesAChannel(${g.join()}),
                             getBestIndicesAChannel(${b.join()}),
                             getBestIndicesAChannel(${x6.join()}),
                             getBestIndicesAChannel(${w.join()})));`, v = `vec4(
            getAChannel(${g.join()}),
            hasNextCol ? getAChannel(${b.join()}) : 0.,
            hasNextRow ? getAChannel(${x6.join()}) : 0.,
            hasNextRow && hasNextCol ? getAChannel(${w.join()}) : 0.)`, k6 = o ? "" : `
      float getBestIndicesAChannel(${m.join()}) {
        return getChannel(getBestIndicesA(${p.join()}),
                                          vec2(${p.slice(-2).join()}));
      }`;
    this.userCode = `
      float getAChannel(${m.join()}) {
        return getChannel(getA(${p.join()}),
                               vec2(${p.slice(-2).join()}));
      }
      ${k6}
      void main() {
        ${c} coords = getOutputCoords();
        bool hasNextCol = ${u[l - 1]} < ${a[l - 1] - 1};
        bool hasNextRow = ${u[l - 2]} < ${a[l - 2] - 1};
        ${d}
        ivec4 srcIdx = ivec4(sourceLocR${f}, sourceLocG${f},
          sourceLocB${f}, sourceLocA${f}) * ${e};
        ivec4 inIdx = srcIdx;
        vec4 bestIndex = vec4(inIdx);
        vec4 bestValue = ${v};

        for (int i = 0; i < ${e}; i++) {
          inIdx = srcIdx;
          ${I}
          vec4 candidate = ${v};
          bvec4 nan = isnan(candidate);
          bvec4 replace = bvec4(
            vec4(${y6}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));

          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,
                           replace.y  ? candidate.y : bestValue.y,
                           replace.z  ? candidate.z : bestValue.z,
                           replace.w  ? candidate.w : bestValue.w);
          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));
          srcIdx++;
        }
        setOutput(bestIndex);
      }
    `;
  }
};
function jI(n, t, e, s = null) {
  let o = t.shape[0], r = t.shape[1];
  s != null && (o = s.shape[0], r = s.shape[1]);
  const i6 = ou(r), a = { windowSize: i6, inSize: r, batchSize: o, outSize: Math.ceil(r / i6) }, l = new AX(a, e, s == null), c = [t];
  s != null && c.push(s);
  const u = n.runWebGLProgram(l, c, "int32");
  if (u.shape[1] === 1)
    return u;
  const d = jI(n, t, e, u);
  return n.disposeIntermediateTensorInfo(u), d;
}
function qI(n, t, e, s = null) {
  const o = s != null ? s.shape : t.shape, r = o[o.length - 1], i6 = ou(r), a = new OX(o, i6, e, s == null), l = s == null ? [t] : [t, s], c = n.runWebGLProgram(a, l, "int32");
  if (c.shape.length === t.shape.length) {
    const u = qI(n, t, e, c);
    return n.disposeIntermediateTensorInfo(c), u;
  }
  return c;
}
function tC(n, t, e, s) {
  const o = [e];
  if (Ne("arg" + s.charAt(0).toUpperCase() + s.slice(1), o, t.shape.length), !F().getBool("WEBGL_PACK_REDUCE") || t.shape.length <= 2) {
    const r = [], i6 = n.texData.get(t.dataId), a = i6 !== null && i6.isPacked;
    let l = t;
    a && (l = n.unpackTensor(t), r.push(l));
    const [c, u] = ye(l.shape, o), d = X(u), h = et({ inputs: { x: l }, backend: n, attrs: { shape: [-1, d] } });
    r.push(h);
    const p = jI(n, h, s);
    r.push(p);
    const f = et({ inputs: { x: p }, backend: n, attrs: { shape: c } });
    return r.forEach((m) => n.disposeIntermediateTensorInfo(m)), f;
  }
  return qI(n, t, s);
}
function XX(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = ze({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), Ne("argMax", [i6[0]], l.shape.length);
  const u = tC(e, l, i6[0], "max");
  return c.forEach((d) => e.disposeIntermediateTensorInfo(d)), u;
}
var KX = {
  kernelName: Yl,
  backendName: "webgl",
  kernelFunc: XX
};
function ZX(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r } = s;
  let i6 = Ct(r, o.shape);
  const a = qt(i6, o.shape.length);
  let l = o;
  const c = [];
  a != null && (l = ze({ inputs: { x: o }, backend: e, attrs: { perm: a } }), c.push(l), i6 = ie(i6.length, l.shape.length)), Ne("argMin", [i6[0]], l.shape.length);
  const u = tC(e, l, i6[0], "min");
  return c.forEach((d) => e.disposeIntermediateTensorInfo(d)), u;
}
var BX = {
  kernelName: Ql,
  backendName: "webgl",
  kernelFunc: ZX
};
var HX = En + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return asin(x);
`;
var _X = Nt({ opSnippet: HX });
var UX = {
  kernelName: ki,
  backendName: "webgl",
  kernelFunc: _X
};
var YX = En + "return log(x + sqrt(x * x + 1.0));";
var QX = Nt({ opSnippet: YX });
var JX = {
  kernelName: Ti,
  backendName: "webgl",
  kernelFunc: QX
};
var jX = En + `
  return atan(x);
`;
var qX = Nt({ opSnippet: jX });
var tK = {
  kernelName: Ni,
  backendName: "webgl",
  kernelFunc: qX
};
var eK = rm + `
  return atan(a, b);
`;
var nK = `
  vec4 result = atan(a, b);
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + jo + `
  return result;
`;
var sK = Re({ opSnippet: eK, packedOpSnippet: nK });
var oK = {
  kernelName: $i,
  backendName: "webgl",
  kernelFunc: sK
};
var rK = En + `
  if ((x < -1.0) || (x > 1.0)) return NAN;
return (log(1.0 + x) - log(1.0 - x)) / 2.0;`;
var iK = Nt({ opSnippet: rK });
var aK = {
  kernelName: Ri,
  backendName: "webgl",
  kernelFunc: iK
};
var wi = class {
  constructor(t, e, s, o = false, r = false) {
    if (this.variableNames = ["x"], e === "avg" && s)
      throw new Error("Cannot compute positions for average pool.");
    const i6 = t.filterWidth, a = t.strideHeight, l = t.strideWidth, c = t.dilationHeight, u = t.dilationWidth, d = t.effectiveFilterHeight, h = t.effectiveFilterWidth, p = t.padInfo.top, f = t.padInfo.left;
    this.outputShape = t.outShape;
    const m = e === "avg", g = `((batch  * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + d`, b = `(xR * ${t.inWidth} + xC) * ${t.inChannels} + d`;
    let x6 = "0.0";
    if (m || (x6 = "-1.0 / 1e-20"), s) {
      const S = ">=";
      this.userCode = `
        const ivec2 strides = ivec2(${a}, ${l});
        const ivec2 pads = ivec2(${p}, ${f});

        void main() {
          ivec4 coords = getOutputCoords();
          int batch = coords[0];
          int d = coords[3];

          ivec2 xRCCorner = coords.yz * strides - pads;
          int xRCorner = xRCCorner.x;
          int xCCorner = xRCCorner.y;

          // max/min x(?, ?, d) to get y(yR, yC, d).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;
          float avgValue = 0.0;

          for (int wR = 0; wR < ${d};
              wR += ${c}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${h};
                wC += ${u}) {
              int xC = xCCorner + wC;

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              float value = getX(batch, xR, xC, d);

              // If a min / max value has already been found, use it. If not,
              // use the current value.
              float currMinMaxValue = mix(
                  value, minMaxValue, minMaxValueFound);
              if (value ${S} currMinMaxValue) {
                minMaxValue = value;
                minMaxValueFound = 1.0;
                minMaxPosition = ${o ? r ? g : b : `wR * ${h} + wC`};
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    const w = "max";
    let y6 = `${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e === "avg" && (y6 = "avgValue / max(count, 1.0)");
    const I = Math.floor(i6 / 4) * 4, v = i6 % 4, k6 = `
      if (${m}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${w}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec2 strides = ivec2(${a}, ${l});
      const ivec2 pads = ivec2(${p}, ${f});
      const float initializationValue = ${x6};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xR, int xC, int d) {
        if (xC < 0 || xC >= ${t.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xR, xC, d);
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d = coords[3];

        ivec2 xRCCorner = coords.yz * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // max/min x(?, ?, d) to get y(yR, yC, d).
        // ? = to be determined
        vec4 minMaxValue = vec4(${x6});
        float avgValue = 0.0;
        count = 0.0;

        for (int wR = 0; wR < ${d};
            wR += ${c}) {
          int xR = xRCorner + wR;

          if (xR < 0 || xR >= ${t.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${I}; wC += 4) {
            int xC = xCCorner + wC * ${u};

            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${u}, d),
              getValue(batch, xR, xC + 2 * ${u}, d),
              getValue(batch, xR, xC + 3 * ${u}, d)
            );

            ${k6}
          }

          int xC = xCCorner + ${I};
          if (${v === 1}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              initializationValue,
              initializationValue,
              initializationValue
            );

            ${k6}
          } else if (${v === 2}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${u}, d),
              initializationValue,
              initializationValue
            );

            ${k6}
          } else if (${v === 3}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${u}, d),
              getValue(batch, xR, xC + 2 * ${u}, d),
              initializationValue
            );

            ${k6}
          }
        }
        setOutput(${y6});
      }
    `;
  }
};
var am = class {
  constructor(t, e, s, o = false, r = false) {
    if (this.variableNames = ["x"], e === "avg" && s)
      throw new Error("Cannot compute positions for average pool.");
    const i6 = t.filterWidth, a = t.strideDepth, l = t.strideHeight, c = t.strideWidth, u = t.dilationDepth, d = t.dilationHeight, h = t.dilationWidth, p = t.effectiveFilterDepth, f = t.effectiveFilterHeight, m = t.effectiveFilterWidth, g = t.padInfo.front, b = t.padInfo.top, x6 = t.padInfo.left;
    this.outputShape = t.outShape;
    const w = e === "avg";
    let y6 = "0.0";
    if (w || (y6 = "-1.0 / 1e-20"), s) {
      const R = ">=";
      this.userCode = `
        const ivec3 strides =
            ivec3(${a}, ${l}, ${c});
        const ivec3 pads = ivec3(${g}, ${b}, ${x6});

        void main() {
          ivec5 coords = getOutputCoords();
          int batch = coords.x;
          int ch = coords.u;

          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
          int xDCorner = xCorner.x;
          int xRCorner = xCorner.y;
          int xCCorner = xCorner.z;

          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;

          for (int wD = 0; wD < ${p};
              wD += ${u}) {
            int xD = xDCorner + wD;

            if (xD < 0 || xD >= ${t.inDepth}) {
              continue;
            }

            for (int wR = 0; wR < ${f};
                wR += ${d}) {
              int xR = xRCorner + wR;

              if (xR < 0 || xR >= ${t.inHeight}) {
                continue;
              }

              for (int wC = 0; wC < ${m};
                  wC += ${h}) {
                int xC = xCCorner + wC;

                if (xC < 0 || xC >= ${t.inWidth}) {
                  continue;
                }

                float value = getX(batch, xD, xR, xC, ch);

                // If a min / max value has already been found, use it. If not,
                // use the current value.
                float currMinMaxValue = mix(
                    value, minMaxValue, minMaxValueFound);
                if (value ${R} currMinMaxValue) {
                  minMaxValue = value;
                  minMaxValueFound = 1.0;
                  minMaxPosition = ${o ? r ? `(((batch * ${t.inDepth} + xD) * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch` : `((xD * ${t.inHeight} + xR) * ${t.inWidth} + xC) * ${t.inChannels} + ch` : `wD * ${f} * ${m} +
                      wR * ${m} + wC`};
                }
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    const I = "max";
    let v = `${e}(${e}(${e}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e === "avg" && (v = "avgValue / max(count, 1.0)");
    const k6 = Math.floor(i6 / 4) * 4, S = i6 % 4, N = `
      if (${w}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${I}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec3 strides =
        ivec3(${a}, ${l}, ${c});
      const ivec3 pads = ivec3(${g}, ${b}, ${x6});
      const float initializationValue = ${y6};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xD, int xR, int xC, int ch) {
        if (xC < 0 || xC >= ${t.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xD, xR, xC, ch);
      }

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xDCorner = xCorner.x;
        int xRCorner = xCorner.y;
        int xCCorner = xCorner.z;

        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).
        // ? = to be determined
        vec4 minMaxValue = vec4(${y6});
        float avgValue = 0.0;
        count = 0.0;

        for (int wD = 0; wD < ${p};
            wD += ${u}) {
          int xD = xDCorner + wD;

          if (xD < 0 || xD >= ${t.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${f};
            wR += ${d}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${k6}; wC += 4) {
              int xC = xCCorner + wC * ${h};

              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${h}, ch),
                getValue(batch, xD, xR, xC + 2 * ${h}, ch),
                getValue(batch, xD, xR, xC + 3 * ${h}, ch)
              );

              ${N}
            }

            int xC = xCCorner + ${k6};
            if (${S === 1}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                initializationValue,
                initializationValue,
                initializationValue
              );

              ${N}
            } else if (${S === 2}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${h}, ch),
                initializationValue,
                initializationValue
              );

              ${N}
            } else if (${S === 3}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${h}, ch),
                getValue(batch, xD, xR, xC + 2 * ${h}, ch),
                initializationValue
              );

              ${N}
            }
          }
        }
        setOutput(${v});
      }
    `;
  }
};
function lK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  Er(o, "avgPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  C(Le(i6, c), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  if (u.filterWidth === 1 && u.filterHeight === 1 && $t(u.inShape, u.outShape))
    return nn({ inputs: { x: o }, backend: e });
  const d = new wi(u, "avg", false);
  return e.runWebGLProgram(d, [o], "float32");
}
var cK = {
  kernelName: Jl,
  backendName: "webgl",
  kernelFunc: lK
};
function uK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dimRoundingMode: l, dataFormat: c } = s, u = [1, 1, 1], d = vs(o.shape, r, i6, u, a, l, c), h = new am(d, "avg", false);
  return e.runWebGLProgram(h, [o], "float32");
}
var dK = {
  kernelName: jl,
  backendName: "webgl",
  kernelFunc: uK
};
var hK = class {
  constructor(t) {
    this.variableNames = ["dy"], this.outputShape = t.inShape;
    const e = t.filterHeight, s = t.filterWidth, o = t.strideHeight, r = t.strideWidth, i6 = t.dilationHeight, a = t.dilationWidth, l = t.effectiveFilterHeight, c = t.effectiveFilterWidth, u = l - 1 - t.padInfo.top, d = c - 1 - t.padInfo.left, h = 1 / (e * s);
    this.userCode = `
      const ivec2 pads = ivec2(${u}, ${d});
      const float avgMultiplier = float(${h});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${l};
            wR += ${i6}) {
          float dyR = float(dyRCorner + wR) / ${o}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${c};
            wC+= ${a}) {
            float dyC = float(dyCCorner + wC) / ${r}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);

            dotProd += dyValue * avgMultiplier;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var pK = class {
  constructor(t) {
    this.variableNames = ["dy"], this.outputShape = t.inShape;
    const e = t.filterDepth, s = t.filterHeight, o = t.filterWidth, r = t.strideDepth, i6 = t.strideHeight, a = t.strideWidth, l = t.dilationDepth, c = t.dilationHeight, u = t.dilationWidth, d = t.effectiveFilterDepth, h = t.effectiveFilterHeight, p = t.effectiveFilterWidth, f = d - 1 - t.padInfo.front, m = h - 1 - t.padInfo.top, g = p - 1 - t.padInfo.left, b = 1 / (e * s * o);
    this.userCode = `
      const ivec3 pads = ivec3(${f}, ${m}, ${g});
      const float avgMultiplier = float(${b});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${d};
            wD += ${l}) {
          float dyD = float(dyDCorner + wD) / ${r}.0;

          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${h};
              wR += ${c}) {
            float dyR = float(dyRCorner + wR) / ${i6}.0;

            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${p};
                wC += ${u}) {
              float dyC = float(dyCCorner + wC) / ${a}.0;

              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);

              dotProd += dyValue * avgMultiplier;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function fK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r, { filterSize: a, strides: l, pad: c, dimRoundingMode: u } = s, d = [1, 1, 1], h = vs(i6.shape, a, l, d, c, u), p = new pK(h);
  return e.runWebGLProgram(p, [o], i6.dtype);
}
var mK = {
  kernelName: sh,
  backendName: "webgl",
  kernelFunc: fK
};
function gK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r;
  Er([o, r], "avgPoolGrad");
  const { filterSize: a, strides: l, pad: c } = s, u = $n(i6.shape, a, l, 1, c), d = new hK(u);
  return e.runWebGLProgram(d, [o], i6.dtype);
}
var bK = {
  kernelName: nh,
  backendName: "webgl",
  kernelFunc: gK
};
function xK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { a: o, b: r } = t, { transposeA: i6, transposeB: a } = s;
  return Ol({ a: o, b: r, transposeA: i6, transposeB: a, backend: e });
}
var yK = {
  kernelName: ql,
  backendName: "webgl",
  kernelFunc: xK
};
var wK = class {
  constructor(t, e, s, o, r, i6) {
    this.outputShape = [], this.variableNames = ["x", "mean", "variance"], bt(t, e), bt(t, s);
    let a = "0.0";
    o != null && (bt(t, o), this.variableNames.push("offset"), a = "getOffsetAtOutCoords()");
    let l = "1.0";
    r != null && (bt(t, r), this.variableNames.push("scale"), l = "getScaleAtOutCoords()"), this.outputShape = t, this.userCode = `
      void main() {
        float x = getXAtOutCoords();
        float mean = getMeanAtOutCoords();
        float variance = getVarianceAtOutCoords();
        float offset = ${a};
        float scale = ${l};
        float inv = scale * inversesqrt(variance + float(${i6}));
        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));
      }
    `;
  }
};
var IK = class {
  constructor(t, e, s, o, r, i6) {
    this.packedInputs = true, this.packedOutput = true, this.variableNames = ["x", "mean", "variance"], bt(t, e), bt(t, s);
    let a = "vec4(0.0)";
    o != null && (bt(t, o), this.variableNames.push("offset"), a = "getOffsetAtOutCoords()");
    let l = "vec4(1.0)";
    r != null && (bt(t, r), this.variableNames.push("scale"), l = "getScaleAtOutCoords()"), this.outputShape = t, this.userCode = `
      void main() {
        vec4 offset = ${a};
        vec4 scale = ${l};

        vec4 x = getXAtOutCoords();
        vec4 mean = getMeanAtOutCoords();
        vec4 variance = getVarianceAtOutCoords();

        vec4 inv = scale * inversesqrt(variance + vec4(${i6}));

        setOutput((x - mean) * inv + offset);
      }
    `;
  }
};
var CK = ({ inputs: n, backend: t, attrs: e }) => {
  const { x: s, mean: o, variance: r, offset: i6, scale: a } = n;
  C(o.shape.length === r.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), C(i6 == null || o.shape.length === i6.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), C(a == null || o.shape.length === a.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  let { varianceEpsilon: l } = e;
  l == null && (l = 1e-3);
  const c = [s, o, r];
  let u = null;
  i6 != null && (u = i6.shape, c.push(i6));
  let d = null;
  a != null && (d = a.shape, c.push(a));
  const h = F().getBool("WEBGL_PACK_NORMALIZATION") ? new IK(s.shape, o.shape, r.shape, u, d, l) : new wK(s.shape, o.shape, r.shape, u, d, l);
  return t.runWebGLProgram(h, c, c[0].dtype);
};
var vK = {
  kernelName: dc,
  backendName: "webgl",
  kernelFunc: CK
};
var SK = class {
  constructor(t) {
    this.variableNames = ["source"], this.outputShape = t, this.rank = t.length;
    const e = Vt(this.rank);
    this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
    const s = kK(this.rank);
    let o;
    const r = t.map((i6, a) => `sourceLoc.${Xd[a]} = start[${a}] + coords.${Xd[a]};`);
    o = `
        ${e} sourceLoc;
        ${e} coords = getOutputCoords();
        ${r.join(`
`)}
      `, this.userCode = `
      void main() {
        ${o}
        setOutput(getSource(${s}));
      }
    `;
  }
};
var Xd = ["x", "y", "z", "w", "u", "v"];
function kK(n) {
  if (n === 1)
    return "sourceLoc";
  if (n <= 6)
    return Xd.slice(0, n).map((t) => "sourceLoc." + t).join(",");
  throw Error(`Slicing for rank ${n} is not yet supported`);
}
var TK = class {
  constructor(t) {
    this.variableNames = ["source"], this.packedInputs = true, this.packedOutput = true, this.outputShape = t, this.rank = t.length, this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
    const e = Vt(this.rank), s = Fe("coords", this.rank), o = Fe("sourceLoc", this.rank), r = this.rank === 1 ? "sourceLoc" : `vec2(${o.slice(-2).join()})`, i6 = `getChannel(getSource(${o.join()}), ${r})`, a = `
      result.x = ${i6};
      if (++${s[this.rank - 1]} < ${t[this.rank - 1]}) {
        ++${o[this.rank - 1]};
        result.y = ${i6};
        --${o[this.rank - 1]};
      }
    `, l = this.rank === 1 ? "" : `
      --${s[this.rank - 1]};
      if (++${s[this.rank - 2]} < ${t[this.rank - 2]}) {
        ++${o[this.rank - 2]};
        result.z = ${i6};
        if (++${s[this.rank - 1]} < ${t[this.rank - 1]}) {
          ++${o[this.rank - 1]};
          result.w = ${i6};
        }
      }
    `, c = this.rank <= 4 ? `sourceLoc = coords +
            ${e}(${t.map((u, d) => `start[${d}]`).join()});` : t.map((u, d) => `${o[d]} = ${s[d]} + start[${d}];`).join(`
`);
    this.userCode = `
      void main() {
        ${e} coords = getOutputCoords();
        ${e} sourceLoc;
        ${c}
        vec4 result = vec4(0.);
        ${a}
        ${l}
        setOutput(result);
      }
    `;
  }
};
function NK(n, t, e, s) {
  const o = s.texData.get(n.dataId), r = s.makeTensorInfo(e, n.dtype), i6 = s.texData.get(r.dataId);
  Object.assign(i6, o), i6.refCount = 1, i6.shape = e, i6.dtype = n.dtype;
  let a = _p(t, dt(n.shape));
  o.slice && (a += o.slice.flatOffset), i6.slice = {
    flatOffset: a,
    // Point to the original dataId, which is used to do ref counting.
    origDataId: o.slice && o.slice.origDataId || n.dataId
  };
  const l = s.dataRefCount.get(i6.slice.origDataId) || 1;
  return s.dataRefCount.set(i6.slice.origDataId, l + 1), r;
}
function zr(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, size: i6 } = s, [a, l] = nu(o, r, i6);
  if (Zp(o, a, l), X(l) === 0)
    return e.makeTensorInfo(l, o.dtype, []);
  if (e.shouldExecuteOnCPU([o]) || o.dtype === "string") {
    const d = e.texData.get(o.dataId), h = xO(d.values, a, l, o.shape, o.dtype);
    return e.makeTensorInfo(l, o.dtype, h);
  }
  const { isPacked: c } = e.texData.get(o.dataId), u = Hp(o.shape, a, l);
  if (c || !u) {
    const d = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TK(l) : new SK(l), h = [a];
    return e.runWebGLProgram(d, [o], o.dtype, h);
  }
  return e.uploadToGPU(o.dataId), NK(o, a, l, e);
}
var RK = {
  kernelName: Ac,
  backendName: "webgl",
  kernelFunc: zr
};
var $K = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, crops: i6 } = s;
  C(o.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
  const a = r.reduce((x6, w) => x6 * w), l = Na(o.shape, r, a), c = Ra(l.length, r.length), u = $a(o.shape, r, a), d = jp(i6, r.length), h = qp(u, i6, r.length), p = [], f = et({ inputs: { x: o }, backend: e, attrs: { shape: l } }), m = ze({ inputs: { x: f }, backend: e, attrs: { perm: c } }), g = et({
    inputs: { x: m },
    backend: e,
    attrs: { shape: u }
  }), b = zr({
    inputs: { x: g },
    backend: e,
    attrs: { begin: d, size: h }
  });
  return p.push(f), p.push(m), p.push(g), p.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), b;
};
var GK = {
  kernelName: tc,
  backendName: "webgl",
  kernelFunc: $K
};
function EK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6 } = s, a = e.readSync(o.dataId), l = e.readSync(r.dataId), c = OI(a, l, r.dtype, r.shape, i6);
  return e.makeTensorInfo([i6], r.dtype, c);
}
var LK = {
  kernelName: oh,
  backendName: "webgl",
  kernelFunc: EK
};
var MK = `
  int r = int(a.r) & int(b.r);
  int g = int(a.g) & int(b.g);
  int rb = int(a.b) & int(b.b);
  int ra = int(a.a) & int(b.a);
  return vec4(r, g, rb, ra);
`;
var WK = `
  return float(int(a.r) & int(b.r));
`;
function DK(n) {
  const { inputs: t, backend: e } = n, { a: s, b: o } = t, r = F().getBool("WEBGL_PACK_BINARY_OPERATIONS"), i6 = F().getNumber("WEBGL_VERSION");
  if (e.shouldExecuteOnCPU([s, o]) || i6 === 1) {
    const l = e.texData.get(s.dataId).values, c = e.texData.get(o.dataId).values, [u, d] = XA(s.shape, o.shape, l, c, s.dtype), h = e.makeTensorInfo(d, s.dtype), p = e.texData.get(h.dataId);
    return p.values = u, h;
  }
  let a;
  return r ? a = new Fr(MK, s.shape, o.shape, false) : a = new Po(WK, s.shape, o.shape), e.runWebGLProgram(a, [s, o], s.dtype);
}
var FK = {
  kernelName: rh,
  backendName: "webgl",
  kernelFunc: DK
};
function VK(n) {
  const { inputs: t, backend: e } = n, { s0: s, s1: o } = t, r = e.readSync(s.dataId), i6 = e.readSync(o.dataId), a = bt(Array.from(r), Array.from(i6));
  return e.makeTensorInfo([a.length], "int32", Int32Array.from(a));
}
var zK = {
  kernelName: cb,
  backendName: "webgl",
  kernelFunc: VK
};
var PK = "return float(a != b);";
var eC = Re({ opSnippet: PK, cpuKernelImpl: cO, dtype: "bool" });
var AK = {
  kernelName: Rc,
  backendName: "webgl",
  kernelFunc: eC
};
function Oa(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.texData.get(s.dataId);
  return nn({ inputs: { x: o.complexTensorInfos.real }, backend: e });
}
var OK = {
  kernelName: Eh,
  backendName: "webgl",
  kernelFunc: Oa
};
var XK = "return float(int(x));";
function KK(n, t) {
  const e = new qn(n.shape, XK), s = t.runWebGLProgram(e, [n], "int32");
  return { dataId: s.dataId, shape: s.shape, dtype: s.dtype };
}
function Kd(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dtype: r } = s;
  if (r === "complex64") {
    if (o.dtype === "complex64")
      return nn({ inputs: { x: o }, backend: e });
    const i6 = be(o.shape), a = Kd({ inputs: { x: o }, backend: e, attrs: { dtype: "float32" } }), l = oo({ inputs: { real: a, imag: i6 }, backend: e });
    return i6.dispose(), e.disposeIntermediateTensorInfo(a), l;
  }
  if (o.dtype === "complex64") {
    const i6 = Oa({ inputs: { input: o }, backend: e }), a = Kd({ inputs: { x: i6 }, backend: e, attrs: { dtype: r } });
    return e.disposeIntermediateTensorInfo(i6), a;
  }
  if (!Qd(o.dtype, r)) {
    const i6 = nn({ inputs: { x: o }, backend: e });
    return { dataId: i6.dataId, shape: i6.shape, dtype: r };
  }
  if (e.shouldExecuteOnCPU([o])) {
    const i6 = e.texData.get(o.dataId).values, [a, l, c] = KA(i6, o.shape, o.dtype, r);
    return e.makeTensorInfo(a, l, c);
  }
  if (r === "int32")
    return KK(o, e);
  if (r === "bool") {
    const i6 = e.makeTensorInfo([], "bool", Se("bool", 1)), l = eC({ inputs: { a: o, b: i6 }, backend: e });
    return e.disposeIntermediateTensorInfo(i6), l;
  }
  throw new Error(`Error in Cast: failed to cast ${o.dtype} to ${r}`);
}
var ZK = {
  kernelName: Gi,
  backendName: "webgl",
  kernelFunc: Kd
};
var Eg = "return ceil(x);";
var BK = Nt({ opSnippet: Eg, packedOpSnippet: Eg, cpuKernelImpl: ZA });
var HK = {
  kernelName: Ei,
  backendName: "webgl",
  kernelFunc: BK
};
var _K = class {
  constructor(t) {
    this.variableNames = ["A"], this.customUniforms = [
      { name: "minVal", type: "float" },
      { name: "maxVal", type: "float" }
    ], this.outputShape = t, this.userCode = `

      void main() {
        float value = getAAtOutCoords();
        if (isnan(value)) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, minVal, maxVal));
      }
    `;
  }
};
var UK = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "minVal", type: "float" },
      { name: "maxVal", type: "float" }
    ], this.outputShape = t, this.userCode = `
      void main() {
        vec4 value = getAAtOutCoords();

        if (any(isnan(value))) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));
      }
    `;
  }
};
function YK(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { clipValueMin: r, clipValueMax: i6 } = s;
  let a;
  F().getBool("WEBGL_PACK_CLIP") ? a = new UK(o.shape) : a = new _K(o.shape);
  const l = [[r], [i6]];
  return e.runWebGLProgram(a, [o], o.dtype, l);
}
var QK = {
  kernelName: Li,
  backendName: "webgl",
  kernelFunc: YK
};
var JK = class {
  constructor(t) {
    this.variableNames = ["real", "imag"], this.outputShape = t, this.userCode = `
      void main() {
        float re = abs(getRealAtOutCoords());
        float im = abs(getImagAtOutCoords());
        float mx = max(re, im);

        // sadly the length function in glsl is not underflow-safe
        // (at least not on Intel GPUs). So the safe solution is
        // to ensure underflow-safety in all cases.
        setOutput(
          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))
        );
      }
    `;
  }
};
function Lg(n, t) {
  return {
    dataId: t.dataId,
    dtype: t.dtype,
    shape: n.shape
  };
}
function jK(n) {
  const { inputs: t, backend: e } = n, { x: s } = t, o = e.texData.get(s.dataId), r = new JK(s.shape), i6 = [
    Lg(s, o.complexTensorInfos.real),
    Lg(s, o.complexTensorInfos.imag)
  ];
  return e.runWebGLProgram(r, i6, i6[0].dtype);
}
var qK = {
  kernelName: ec,
  backendName: "webgl",
  kernelFunc: jK
};
var tZ = class {
  // Concats 2d tensors along axis=1. See comments in MathBackendWebGL.concat().
  constructor(t) {
    this.outputShape = [], this.outputShape = ts(
      t,
      1
      /* axis */
    ), this.variableNames = t.map((i6, a) => `T${a}`);
    const e = new Array(t.length - 1);
    e[0] = t[0][1];
    for (let i6 = 1; i6 < e.length; i6++)
      e[i6] = e[i6 - 1] + t[i6][1];
    const s = [`if (yC < ${e[0]}) setOutput(getT0(yR, yC));`];
    for (let i6 = 1; i6 < e.length; i6++) {
      const a = e[i6 - 1];
      s.push(`else if (yC < ${e[i6]}) setOutput(getT${i6}(yR, yC-${a}));`);
    }
    const o = e.length, r = e[e.length - 1];
    s.push(`else setOutput(getT${o}(yR, yC-${r}));`), this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int yR = coords.x;
        int yC = coords.y;

        ${s.join(`
        `)}
      }
    `;
  }
};
var eZ = class {
  constructor(t, e) {
    this.packedInputs = true, this.packedOutput = true, this.outputShape = [], this.outputShape = ts(t, e);
    const s = this.outputShape, o = s.length, r = Vt(o), i6 = Fe("coords", o), a = ["x", "y", "z", "w", "u", "v"].slice(0, o);
    this.variableNames = t.map((m, g) => `T${g}`);
    const l = new Array(t.length - 1);
    l[0] = t[0][e];
    for (let m = 1; m < l.length; m++)
      l[m] = l[m - 1] + t[m][e];
    const c = a[e], u = a.slice(-2), d = a.join();
    let h = `if (${c} < ${l[0]}) {
        return getChannel(
            getT0(${d}), vec2(${u.join()}));
        }`;
    for (let m = 1; m < l.length; m++) {
      const g = l[m - 1];
      h += `
        if (${c} < ${l[m]}  && ${c} >= ${l[m - 1]}) {
          return getChannel(
            getT${m}(${qa(a, c, g)}),
            vec2(${qa(u, c, g)}));
        }`;
    }
    const p = l.length, f = l[l.length - 1];
    h += `
        return getChannel(
          getT${p}(${qa(a, c, f)}),
          vec2(${qa(u, c, f)}));`, this.userCode = `
      float getValue(${a.map((m) => "int " + m)}) {
        ${h}
      }

      void main() {
        ${r} coords = getOutputCoords();
        vec4 result = vec4(getValue(${i6}), 0., 0., 0.);

        ${i6[o - 1]} = ${i6[o - 1]} + 1;
        if (${i6[o - 1]} < ${s[o - 1]}) {
          result.g = getValue(${i6});
        }

        ${i6[o - 2]} = ${i6[o - 2]} + 1;
        if (${i6[o - 2]} < ${s[o - 2]}) {
          result.a = getValue(${i6});
        }

        ${i6[o - 1]} = ${i6[o - 1]} - 1;
        if (${i6[o - 2]} < ${s[o - 2]} &&
            ${i6[o - 1]} < ${s[o - 1]}) {
          result.b = getValue(${i6});
        }
        setOutput(result);
      }
    `;
  }
};
function qa(n, t, e) {
  const s = n.indexOf(t);
  return n.map((r, i6) => i6 === s ? `${r} - ${e}` : r).join();
}
function ku(n) {
  const { inputs: t, backend: e } = n, { input: s } = t, o = e.texData.get(s.dataId);
  return nn({ inputs: { x: o.complexTensorInfos.imag }, backend: e });
}
var nZ = {
  kernelName: vh,
  backendName: "webgl",
  kernelFunc: ku
};
function ei(n, t, e) {
  const s = n[0].dtype;
  if (s === "complex64") {
    const p = n.map((x6) => Oa({ inputs: { input: x6 }, backend: e })), f = n.map((x6) => ku({ inputs: { input: x6 }, backend: e })), m = ei(p, t, e), g = ei(f, t, e), b = oo({ inputs: { real: m, imag: g }, backend: e });
    return p.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), f.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g), b;
  }
  let o = e.shouldExecuteOnCPU(n);
  if (s === "string" && (o = true), o) {
    const p = n.map((y6) => {
      const v = [-1, X(y6.shape.slice(t))];
      return et({ inputs: { x: y6 }, backend: e, attrs: { shape: v } });
    }), f = p.map((y6) => ({ vals: e.readSync(y6.dataId), shape: y6.shape })), m = ts(
      p.map((y6) => y6.shape),
      1
      /* axis */
    ), g = p[0].shape[0] === 1, b = BA(f, m, s, g), x6 = ts(n.map((y6) => y6.shape), t), w = e.makeTensorInfo(x6, s, b);
    return p.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), w;
  }
  const r = n.filter((p) => X(p.shape) > 0), i6 = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && r[0].shape.length > 1;
  if (r.length === 1) {
    const p = i6 ? new qn(n[0].shape, Ms) : new Vs(n[0].shape, Ms);
    return e.runWebGLProgram(p, n, s);
  }
  const a = F().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");
  if (r.length > a) {
    const p = [];
    for (let m = 0; m < r.length; m += a) {
      const g = r.slice(m, m + a);
      p.push(ei(g, t, e));
    }
    const f = ei(p, t, e);
    for (const m of p)
      e.disposeIntermediateTensorInfo(m);
    return f;
  }
  if (i6) {
    const p = new eZ(r.map((f) => f.shape), t);
    return e.runWebGLProgram(p, r, s);
  }
  const { tensors2D: l, outShape: c } = sZ(r, t, e), u = new tZ(l.map((p) => p.shape)), d = e.runWebGLProgram(u, l, s);
  l.forEach((p) => e.disposeIntermediateTensorInfo(p));
  const h = et({ inputs: { x: d }, attrs: { shape: c }, backend: e });
  return e.disposeIntermediateTensorInfo(d), h;
}
function sZ(n, t, e) {
  const s = ts(n.map((r) => r.shape), t);
  return { tensors2D: n.map((r) => et({
    inputs: { x: r },
    attrs: { shape: [-1, X(r.shape.slice(t))] },
    backend: e
  })), outShape: s };
}
function nC(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s, r = Ct(o, t[0].shape)[0], i6 = t.map((c) => c.shape);
  Yp(i6, r);
  const a = ts(t.map((c) => c.shape), r);
  if (X(a) === 0)
    return e.makeTensorInfo(a, t[0].dtype, []);
  const l = t.filter((c) => X(c.shape) > 0);
  return l.length === 1 ? nn({ inputs: { x: l[0] }, backend: e }) : ei(l, r, e);
}
var oZ = {
  kernelName: nc,
  backendName: "webgl",
  kernelFunc: nC
};
var sC = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.outputShape = t.outShape;
    const i6 = t.padInfo.top, a = t.padInfo.left, l = t.strideHeight, c = t.strideWidth, u = t.dilationHeight, d = t.dilationWidth, h = t.filterHeight, p = t.filterWidth, f = Math.floor(t.inChannels / 4) * 4, m = t.inChannels % 4, g = t.dataFormat === "channelsLast", b = g ? 1 : 2, x6 = g ? 2 : 3, w = g ? 3 : 1;
    let y6 = "", I = "";
    s && (o ? y6 = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${s}
        }` : r ? y6 = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${s}
        }` : y6 = `
          float activation(float x) {
            ${s}
          }
        `, I = "result = activation(result);");
    const v = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${y6}

      const ivec2 strides = ivec2(${l}, ${c});
      const ivec2 pads = ivec2(${i6}, ${a});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d2 = coords[${w}];

        ivec2 xRCCorner =
            ivec2(coords[${b}], coords[${x6}]) * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${h}; wR++) {
          int xR = xRCorner + wR * ${u};

          if (xR < 0 || xR >= ${t.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${p}; wC++) {
            int xC = xCCorner + wC * ${d};

            if (xC < 0 || xC >= ${t.inWidth}) {
              continue;
            }

            for (int d1 = 0; d1 < ${f}; d1 += 4) {
              vec4 wValues = vec4(
                getW(wR, wC, d1, d2),
                getW(wR, wC, d1 + 1, d2),
                getW(wR, wC, d1 + 2, d2),
                getW(wR, wC, d1 + 3, d2)
              );

              if (${g}) {
                vec4 xValues = vec4(
                  getX(batch, xR, xC, d1),
                  getX(batch, xR, xC, d1 + 1),
                  getX(batch, xR, xC, d1 + 2),
                  getX(batch, xR, xC, d1 + 3)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec4 xValues = vec4(
                  getX(batch, d1, xR, xC),
                  getX(batch, d1 + 1, xR, xC),
                  getX(batch, d1 + 2, xR, xC),
                  getX(batch, d1 + 3, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }
            }

            if (${m === 1}) {

              if (${g}) {
                dotProd +=
                    getX(batch, xR, xC, ${f}) *
                    getW(wR, wC, ${f}, d2);
              } else {
                dotProd +=
                    getX(batch, ${f}, xR, xC) *
                    getW(wR, wC, ${f}, d2);
              }

            } else if (${m === 2}) {
              vec2 wValues = vec2(
                getW(wR, wC, ${f}, d2),
                getW(wR, wC, ${f} + 1, d2)
              );

              if (${g}) {
                vec2 xValues = vec2(
                  getX(batch, xR, xC, ${f}),
                  getX(batch, xR, xC, ${f} + 1)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec2 xValues = vec2(
                  getX(batch, ${f}, xR, xC),
                  getX(batch, ${f} + 1, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            } else if (${m === 3}) {
              vec3 wValues = vec3(
                getW(wR, wC, ${f}, d2),
                getW(wR, wC, ${f} + 1, d2),
                getW(wR, wC, ${f} + 2, d2)
              );

              if (${g}) {
                vec3 xValues = vec3(
                  getX(batch, xR, xC, ${f}),
                  getX(batch, xR, xC, ${f} + 1),
                  getX(batch, xR, xC, ${f} + 2)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec3 xValues = vec3(
                  getX(batch, ${f}, xR, xC),
                  getX(batch, ${f} + 1, xR, xC),
                  getX(batch, ${f} + 2, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            }
          }
        }

        float result = dotProd;
        ${v}
        ${I}
        setOutput(result);
      }
    `;
  }
};
var rZ = class {
  constructor(t) {
    this.variableNames = ["x", "W"], this.outputShape = t.outShape;
    const e = t.padInfo.front, s = t.padInfo.top, o = t.padInfo.left, r = t.strideDepth, i6 = t.strideHeight, a = t.strideWidth, l = t.dilationDepth, c = t.dilationHeight, u = t.dilationWidth, d = t.filterDepth, h = t.filterHeight, p = t.filterWidth, f = Math.floor(t.inChannels / 4) * 4, m = t.inChannels % 4;
    this.userCode = `
      const ivec3 strides = ivec3(${r}, ${i6}, ${a});
      const ivec3 pads = ivec3(${e}, ${s}, ${o});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d2 = coords.u;

        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xFCorner = xFRCCorner.x;
        int xRCorner = xFRCCorner.y;
        int xCCorner = xFRCCorner.z;

        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get
        // y(yF, yR, yC, d2). ? = to be determined. : = across all
        // values in that axis.
        float dotProd = 0.0;
        for (int wF = 0; wF < ${d}; wF++) {
          int xF = xFCorner + wF * ${l};

          if (xF < 0 || xF >= ${t.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${h}; wR++) {
            int xR = xRCorner + wR * ${c};

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${p}; wC++) {
              int xC = xCCorner + wC * ${u};

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              for (int d1 = 0; d1 < ${f}; d1 += 4) {
                vec4 xValues = vec4(
                  getX(batch, xF, xR, xC, d1),
                  getX(batch, xF, xR, xC, d1 + 1),
                  getX(batch, xF, xR, xC, d1 + 2),
                  getX(batch, xF, xR, xC, d1 + 3)
                );
                vec4 wValues = vec4(
                  getW(wF, wR, wC, d1, d2),
                  getW(wF, wR, wC, d1 + 1, d2),
                  getW(wF, wR, wC, d1 + 2, d2),
                  getW(wF, wR, wC, d1 + 3, d2)
                );

                dotProd += dot(xValues, wValues);
              }

              if (${m === 1}) {
                dotProd +=
                  getX(batch, xF, xR, xC, ${f}) *
                  getW(wF, wR, wC, ${f}, d2);
              } else if (${m === 2}) {
                vec2 xValues = vec2(
                  getX(batch, xF, xR, xC, ${f}),
                  getX(batch, xF, xR, xC, ${f} + 1)
                );
                vec2 wValues = vec2(
                  getW(wF, wR, wC, ${f}, d2),
                  getW(wF, wR, wC, ${f} + 1, d2)
                );
                dotProd += dot(xValues, wValues);
              } else if (${m === 3}) {
                vec3 xValues = vec3(
                  getX(batch, xF, xR, xC, ${f}),
                  getX(batch, xF, xR, xC, ${f} + 1),
                  getX(batch, xF, xR, xC, ${f} + 2)
                );
                vec3 wValues = vec3(
                  getW(wF, wR, wC, ${f}, d2),
                  getW(wF, wR, wC, ${f} + 1, d2),
                  getW(wF, wR, wC, ${f} + 2, d2)
                );
                dotProd += dot(xValues, wValues);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var oC = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "pads", type: "ivec2" },
      { name: "strides", type: "ivec2" },
      { name: "dilations", type: "ivec2" },
      { name: "inDims", type: "ivec2" }
    ], this.outputShape = t.outShape, this.enableShapeUniforms = Me(this.outputShape.length);
    const i6 = t.padInfo.left, a = t.strideWidth, l = t.dilationWidth, c = t.filterHeight, u = t.filterWidth, d = u;
    let h = `
       int xR; int xC; int xCOffset;
       vec4 wTexel; vec4 previous; vec4 final;`;
    for (let g = 0; g < u; g++)
      h += `
           vec4 xTexelC${g * 2};
           int xTexelC${g * 2}Ready;
           vec4 xTexelC${g * 2 + 1};
           int xTexelC${g * 2 + 1}Ready;
           vec4 xC${g};`;
    h += `
     for (int r = 0; r < ${c}; r++) {
      for (int d1 = 0; d1 < ${t.inChannels}; d1 += 2) {
       `;
    for (let g = 0; g < u; g++)
      h += `
           xTexelC${g * 2} = vec4(0.0);
           xTexelC${g * 2}Ready = 0;
           xTexelC${g * 2 + 1} = vec4(0.0);
           xTexelC${g * 2 + 1}Ready = 0;
           xC${g} = vec4(0.0);`;
    h += `
         xR = xRCorner + r * dilations[0];
         if (xR >=0 && xR < inDims[0]) {
       `;
    for (let g = 0; g < (d + 1) / 2; g++) {
      const b = g * 2;
      if (h += `
           xC = xCCorner + ${b * l};
           `, a === 1) {
        if (b < u && (i6 % 2 === 1 ? (h += `
                 xCOffset = xC + 1;
                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b}Ready == 0) {
                   xTexelC${b} = getX(batch, xR, xCOffset, d1);

                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${b}.zw = vec2(0.0);
                   }
                   xTexelC${b}Ready = 1;
                 }
               `, l === 1 && b > 0 ? h += `
                 xC${b} = vec4(xTexelC${b - 2}.zw, xTexelC${b}.xy);
                 ` : h += `
                   xCOffset = xC + 1 - 2;

                   if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       previous.zw = vec2(0.0);
                     }

                     xC${b} = vec4(previous.zw, xTexelC${b}.xy);
                   } else {
                     xC${b} = vec4(0.0, 0.0, xTexelC${b}.xy);
                   }
                   `) : h += `
                 if (xC >= 0 && xC < inDims[1] && xTexelC${b}Ready == 0) {
                   xTexelC${b} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${b}.zw = vec2(0.0);
                   }
                   xTexelC${b}Ready = 1;
                 }

                 xC${b} = xTexelC${b};
                 `, b + 1 < u)) {
          const x6 = i6 % 2 === 0 ? Bl(l) : l;
          l % 2 === 0 && i6 % 2 === 1 || l % 2 !== 0 && i6 % 2 !== 1 ? (h += `
                   xCOffset = xC + imod(pads[1], 2) + ${x6};

                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b + 1}Ready == 0) {
                     xTexelC${b + 1} = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       xTexelC${b + 1}.zw = vec2(0.0);
                     }
                     xTexelC${b + 1}Ready = 1;
                   }
                   `, l > 1 ? h += `
                     xCOffset -= 2;
                     if (xCOffset >= 0 && xCOffset < inDims[1]) {
                      previous = getX(batch, xR, xCOffset, d1);
                      xC${b + 1} = vec4(previous.zw, xTexelC${b + 1}.xy);
                     } else {
                      xC${b + 1} = vec4(0.0, 0.0, xTexelC${b + 1}.xy);
                     }
                     ` : h += `
                     xC${b + 1} = vec4(xTexelC${b}.zw, xTexelC${b + 1}.xy);
                     `) : x6 === 1 ? h += `
                     xC${b + 1} = xTexelC${b};
                     ` : h += `
                     xCOffset = xC + ${x6};

                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b + 1}Ready == 0) {
                       xTexelC${b + 1} = getX(batch, xR, xCOffset, d1);
                       if (xCOffset + 1 >= inDims[1]) {
                         xTexelC${b + 1}.zw = vec2(0.0);
                       }
                       xTexelC${b + 1}Ready = 1;
                     }

                     xC${b + 1} = xTexelC${b + 1};
                     `;
        }
      } else
        b < u && (i6 % 2 === 1 ? (h += `
                 xCOffset = xC + 1 - strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b}Ready == 0) {
                   xTexelC${b} = getX(batch, xR, xCOffset, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${b}.zw = vec2(0.0);
                   }
                   xTexelC${b}Ready = 1;
                 }

                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${b + 1}Ready == 0) {
                   xTexelC${b + 1} = getX(batch, xR, xC + 1, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xC + 2 >= inDims[1]) {
                     xTexelC${b + 1}.zw = vec2(0.0);
                   }
                   xTexelC${b + 1}Ready = 1;
                 }

                 xC${b} = vec4(xTexelC${b}.zw, xTexelC${b + 1}.zw);
               `, b + 1 < u && (h += `
                   final = vec4(0.0);
                   xCOffset = xC + 1 + strides[1];
                   if(xCOffset >= 0 && xCOffset < inDims[1]) {
                     final = getX(batch, xR, xCOffset, d1);
                   }
                   xC${b + 1} = vec4(xTexelC${b + 1}.xy, final.xy);
                 `)) : (h += `
                 if(xC >= 0 && xC < inDims[1] && xTexelC${b}Ready == 0) {
                   xTexelC${b} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${b}.zw = vec2(0.0);
                   }
                   xTexelC${b}Ready = 1;
                 }

                 xCOffset = xC + strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${b + 1}Ready == 0) {
                   xTexelC${b + 1} = getX(batch, xR, xCOffset, d1);
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${b + 1}.zw = vec2(0.);
                   }
                   xTexelC${b + 1}Ready = 1;
                 }

                 xC${b} = vec4(
                   xTexelC${b}.xy, xTexelC${b + 1}.xy);
               `, b + 1 < u && (h += `
                   xC${b + 1} = vec4(xTexelC${b}.zw, xTexelC${b + 1}.zw);
                 `)));
      b < u && (h += `
             wTexel = getW(r, ${b}, d1, d2);
             dotProd += xC${b}.xxzz * vec4(wTexel.xy, wTexel.xy);
             if(d1 + 1 < ${t.inChannels}) {
               dotProd += xC${b}.yyww * vec4(wTexel.zw, wTexel.zw);
             }
           `, b + 1 < u && (h += `
               wTexel = getW(r, ${b + 1}, d1, d2);
               dotProd += xC${b + 1}.xxzz * vec4(wTexel.xy, wTexel.xy);
               if(d1 + 1 < ${t.inChannels}) {
                 dotProd += xC${b + 1}.yyww * vec4(wTexel.zw, wTexel.zw);
               }
             `));
    }
    h += `
     }
   `, h += `
     }
   `, h += `
     }
   `;
    let p = "", f = "";
    s && (o ? p = `vec4 activation(vec4 a) {
           vec4 b = getPreluActivationWeightsAtOutCoords();
           ${s}
         }` : r ? p = `vec4 activation(vec4 a) {
           vec4 b = getLeakyreluAlphaAtOutCoords();
           ${s}
         }` : p = `vec4 activation(vec4 x) {
           ${s}
         }`, f = "result = activation(result);");
    const m = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
       ${p}

       void main() {
         ivec4 coords = getOutputCoords();
         int batch = coords.x;
         ivec2 xRCCorner = coords.yz * strides - pads;
         int d2 = coords.w;
         int xRCorner = xRCCorner.x;
         int xCCorner = xRCCorner.y;

         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
         vec4 dotProd = vec4(0.000000000000001);

         ${h}

         vec4 result = dotProd - vec4(0.000000000000001);
         ${m}
         ${f}
         setOutput(result);
       }
     `;
  }
};
var iZ = class {
  constructor(t, e) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "inputShape", type: "ivec4" },
      { name: "pad", type: "ivec2" },
      { name: "stride", type: "ivec2" },
      { name: "dilation", type: "ivec2" },
      { name: "inChannels", type: "int" },
      { name: "itemsPerBlockRow", type: "int" },
      { name: "outWidth", type: "int" }
    ], this.outputShape = t, this.enableShapeUniforms = Me(this.outputShape.length);
    const { dataFormat: s } = e, o = Ae(), r = s === "channelsLast", i6 = r ? 1 : 2, a = r ? 2 : 3, l = this.enableShapeUniforms ? "if(blockIndex < outShape[2] && pos < outShape[1]) {" : `if(blockIndex < ${t[2]} && pos < ${t[1]}) {`;
    let c = "";
    for (let u = 0; u <= 1; u++)
      for (let d = 0; d <= 1; d++)
        c += `
          blockIndex = rc.z + ${d};
          pos = rc.y + ${u};

          ${l}
            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];
            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);

            if(d0 < inputShape[${i6}] && d0 >= 0) {
              // Use custom imod instead mod. On Intel GPU, mod may generate
              // unexpected value.
              // https://github.com/tensorflow/tfjs/issues/5447
              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];
              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /
                  inChannels);

              if(d1 < inputShape[${a}] && d1 >= 0) {

                ch = imod(pos, inChannels);

                if (${r}) {
                  innerDims = vec2(d1, ch);
                  result[${u * 2 + d}] = getChannel(
                    getA(rc.x, d0, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                } else {
                  innerDims = vec2(d0, d1);
                  result[${u * 2 + d}] = getChannel(
                    getA(rc.x, ch, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                }
              }
            }
          }
        `;
    this.userCode = `
      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0);

        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;
        vec2 innerDims;

        ${c}

        ${o.output} = result;
      }
    `;
  }
};
function Xl(n, t) {
  const e = n.length;
  return e >= 3 ? t ? [
    ...n.slice(0, -3),
    n[e - 3] * n[e - 2],
    n[e - 1]
    /* channel */
  ] : [
    ...n.slice(0, -3),
    n[e - 3],
    n[e - 2] * n[e - 1]
    /* height * width */
  ] : !t && e === 1 && n[0] > 1 ? [n[0], 1] : null;
}
function rC({ x: n, filter: t, convInfo: e, backend: s, bias: o = null, preluActivationWeights: r = null, leakyreluAlpha: i6 = 0, activation: a = null }) {
  const l = n.shape, c = s.texData.get(n.dataId), u = e.inChannels, d = l[0] * l[1] * l[2], h = e.outChannels, p = e.dataFormat === "channelsLast", f = false, m = false;
  let g;
  const b = [];
  if (r != null) {
    const y6 = Xl(r.shape, p);
    y6 != null && (r = et({
      inputs: { x: r },
      backend: s,
      attrs: { shape: y6 }
    }), b.push(r));
  }
  if (o != null) {
    const y6 = Xl(o.shape, p);
    y6 != null && (o = et({ inputs: { x: o }, backend: s, attrs: { shape: y6 } }), b.push(o));
  }
  if (!((d === 1 || h === 1) && u > JI) && c.isPacked && p && c.texture != null && l[2] % 2 !== 0 && $t(c.shape.slice(-3), l.slice(-3))) {
    const y6 = l[0] * l[1] * (l[2] + 1), I = {
      dataId: n.dataId,
      shape: [1, y6, e.inChannels],
      dtype: n.dtype
    }, v = c.shape;
    c.shape = c.shape.slice(), c.shape[c.shape.length - 2]++, C(xi(c.shape, I.shape), () => `packed reshape ${c.shape} to ${I.shape} isn't free`);
    const k6 = et({
      inputs: { x: t },
      backend: s,
      attrs: { shape: [1, e.inChannels, e.outChannels] }
    });
    b.push(k6);
    const S = Ol({
      a: I,
      b: k6,
      backend: s,
      transposeA: f,
      transposeB: m,
      bias: o,
      activation: a,
      preluActivationWeights: r,
      leakyreluAlpha: i6
    }), N = s.texData.get(S.dataId);
    C(N.isPacked, () => "batchMatMul result is expected to be packed"), c.shape = v, N.shape = e.outShape, g = nn({ inputs: { x: S }, backend: s }), g.shape = e.outShape, b.push(S);
  } else {
    const y6 = e.outHeight * e.outWidth, I = et({
      inputs: { x: n },
      backend: s,
      attrs: {
        shape: p ? [e.batchSize, y6, e.inChannels] : [e.batchSize, e.inChannels, y6]
      }
    }), v = et({
      inputs: { x: t },
      backend: s,
      attrs: { shape: [1, e.inChannels, e.outChannels] }
    }), k6 = Ol({
      a: p ? I : v,
      b: p ? v : I,
      transposeA: !p,
      transposeB: m,
      backend: s,
      bias: o,
      activation: a,
      preluActivationWeights: r,
      leakyreluAlpha: i6
    });
    g = et({ inputs: { x: k6 }, backend: s, attrs: { shape: e.outShape } }), b.push(I), b.push(v), b.push(k6);
  }
  for (const y6 of b)
    s.disposeIntermediateTensorInfo(y6);
  return g;
}
function iC({ x: n, filter: t, convInfo: e, backend: s, bias: o = null, preluActivationWeights: r = null, leakyreluAlpha: i6 = 0, activation: a = null }) {
  const { filterWidth: l, filterHeight: c, inChannels: u, outWidth: d, outHeight: h, dataFormat: p } = e, f = p === "channelsLast", m = l * c * u, g = h * d, b = [e.batchSize, m, g], x6 = true, w = false, y6 = [];
  if (r != null) {
    const Z = Xl(r.shape, f);
    Z != null && (r = et({
      inputs: { x: r },
      backend: s,
      attrs: { shape: Z }
    }), y6.push(r));
  }
  if (o != null) {
    const Z = Xl(o.shape, f);
    Z != null && (o = et({ inputs: { x: o }, backend: s, attrs: { shape: Z } }), y6.push(o));
  }
  const I = et({
    inputs: { x: t },
    backend: s,
    attrs: { shape: [1, m, X(t.shape) / m] }
  });
  y6.push(I);
  const v = new iZ(b, e), k6 = [
    n.shape,
    [e.padInfo.top, e.padInfo.left],
    [e.strideHeight, e.strideWidth],
    [e.dilationHeight, e.dilationWidth],
    [e.inChannels],
    [e.filterWidth * e.inChannels],
    [e.outWidth]
  ], S = s.runWebGLProgram(v, [n], "float32", k6), N = et({ inputs: { x: S }, backend: s, attrs: { shape: b } });
  y6.push(S), y6.push(N);
  const R = o != null, M6 = r != null, V = a === "leakyrelu", z = a ? yi(a, true) : null, P = new QI(f ? N.shape : I.shape, f ? I.shape : N.shape, f ? [e.batchSize, g, e.outChannels] : [e.batchSize, e.outChannels, g], x6, w, R, z, M6, V), A = f ? [N, I] : [I, N];
  if (o && A.push(o), M6 && A.push(r), V) {
    const Z = s.makeTensorInfo([], "float32", Is(i6, "float32"));
    A.push(Z), y6.push(Z);
  }
  const O = s.runWebGLProgram(P, A, "float32"), B6 = et({ inputs: { x: O }, backend: s, attrs: { shape: e.outShape } });
  y6.push(O);
  for (const Z of y6)
    s.disposeIntermediateTensorInfo(Z);
  return B6;
}
function aZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dataFormat: l, dilations: c, dimRoundingMode: u } = s, d = Ss(l), h = Te(o.shape, r.shape, i6, c, a, u, false, d);
  let p;
  if (h.filterHeight === 1 && h.filterWidth === 1 && h.dilationHeight === 1 && h.dilationWidth === 1 && h.strideHeight === 1 && h.strideWidth === 1 && (h.padInfo.type === "SAME" || h.padInfo.type === "VALID"))
    p = rC({ x: o, filter: r, convInfo: h, backend: e });
  else if (h.strideWidth <= 2 && d === "channelsLast" && F().getBool("WEBGL_EXP_CONV")) {
    const m = new oC(h), g = [
      [h.padInfo.top, h.padInfo.left],
      [h.strideHeight, h.strideWidth],
      [h.dilationHeight, h.dilationWidth],
      [h.inHeight, h.inWidth]
    ];
    p = e.runWebGLProgram(m, [o, r], "float32", g);
  } else if (F().getBool("WEBGL_CONV_IM2COL"))
    p = iC({ x: o, filter: r, convInfo: h, backend: e });
  else {
    const m = new sC(h);
    p = e.runWebGLProgram(m, [o, r], "float32");
  }
  const f = et({ inputs: { x: p }, backend: e, attrs: { shape: h.outShape } });
  return e.disposeIntermediateTensorInfo(p), f;
}
var lZ = {
  kernelName: sc,
  backendName: "webgl",
  kernelFunc: aZ
};
var cZ = class {
  constructor(t) {
    this.variableNames = ["x", "dy"], this.outputShape = t.filterShape;
    const e = t.strideHeight, s = t.strideWidth, o = t.padInfo.top, r = t.padInfo.left, i6 = t.dataFormat === "channelsLast";
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int d2 = coords.w;

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int b = 0; b < ${t.batchSize}; b++) {
          for (int yR = 0; yR < ${t.outHeight}; yR++) {
            int xR = wR + yR * ${e} - ${o};

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${t.outWidth}; yC++) {
              int xC = wC + yC * ${s} - ${r};

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              ${i6 ? `float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);` : `float dyValue = getDy(b, d2, yR, yC);
              float xValue = getX(b, d1, xR, xC);
              dotProd += (xValue * dyValue);`}
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var uZ = class {
  constructor(t) {
    this.variableNames = ["dy", "W"], this.outputShape = t.inShape;
    const e = t.filterHeight, s = t.filterWidth, o = t.strideHeight, r = t.strideWidth, i6 = t.dataFormat === "channelsLast", a = e - 1 - t.padInfo.top, l = s - 1 - t.padInfo.left, c = i6 ? 1 : 2, u = i6 ? 2 : 3, d = i6 ? 3 : 1;
    this.userCode = `
      const ivec2 pads = ivec2(${a}, ${l});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[${d}];

        ivec2 dyCorner = ivec2(coords[${c}], coords[${u}]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${e}; wR++) {
          float dyR = float(dyRCorner + wR) / ${o}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${e} - 1 - wR;

          for (int wC = 0; wC < ${s}; wC++) {
            float dyC = float(dyCCorner + wC) / ${r}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${s} - 1 - wC;

            for (int d2 = 0; d2 < ${t.outChannels}; d2++) {

              if (${i6}) {
                float xValue = getDy(batch, idyR, idyC, d2);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              } else {
                float xValue = getDy(batch, d2, idyR, idyC);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var dZ = class {
  constructor(t) {
    this.variableNames = ["x", "dy"], this.outputShape = t.filterShape;
    const e = t.strideDepth, s = t.strideHeight, o = t.strideWidth, r = t.padInfo.front, i6 = t.padInfo.top, a = t.padInfo.left;
    this.userCode = `
      void main() {
        ivec5 coords = getOutputCoords();
        int wF = coords.x;
        int wR = coords.y;
        int wC = coords.z;
        int d1 = coords.w;
        int d2 = coords.u;

        float dotProd = 0.0;

        for (int b = 0; b < ${t.batchSize}; b++) {
          for (int yF = 0; yF < ${t.outDepth}; yF++) {
            int xF = wF + yF * ${e} - ${r};

            if (xF < 0 || xF >= ${t.inDepth}) {
              continue;
            }

            for (int yR = 0; yR < ${t.outHeight}; yR++) {
              int xR = wR + yR * ${s} - ${i6};

              if (xR < 0 || xR >= ${t.inHeight}) {
                continue;
              }

              for (int yC = 0; yC < ${t.outWidth}; yC++) {
                int xC = wC + yC * ${o} - ${a};

                if (xC < 0 || xC >= ${t.inWidth}) {
                  continue;
                }

                float dyValue = getDy(b, yF, yR, yC, d2);
                float xValue = getX(b, xF, xR, xC, d1);
                dotProd += (xValue * dyValue);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var hZ = class {
  constructor(t) {
    this.variableNames = ["dy", "W"], this.outputShape = t.inShape;
    const e = t.filterDepth, s = t.filterHeight, o = t.filterWidth, r = t.strideDepth, i6 = t.strideHeight, a = t.strideWidth, l = e - 1 - t.padInfo.front, c = s - 1 - t.padInfo.top, u = o - 1 - t.padInfo.left;
    this.userCode = `
      const ivec3 pads = ivec3(${l}, ${c}, ${u});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.u;


        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyFCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        float dotProd = 0.0;
        for (int wF = 0; wF < ${e}; wF++) {
          float dyF = float(dyFCorner + wF) / ${r}.0;

          if (dyF < 0.0 || dyF >= ${t.outDepth}.0 || fract(dyF) > 0.0) {
            continue;
          }
          int idyF = int(dyF);

          int wFPerm = ${e} - 1 - wF;

          for (int wR = 0; wR < ${s}; wR++) {
            float dyR = float(dyRCorner + wR) / ${i6}.0;

            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||
              fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            int wRPerm = ${s} - 1 - wR;

            for (int wC = 0; wC < ${o}; wC++) {
              float dyC = float(dyCCorner + wC) / ${a}.0;

              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              int wCPerm = ${o} - 1 - wC;

              for (int d2 = 0; d2 < ${t.outChannels}; d2++) {
                float xValue = getDy(batch, idyF, idyR, idyC, d2);
                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function pZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, dataFormat: l, dimRoundingMode: c, filterShape: u } = s, d = Ss(l), h = Te(o.shape, u, i6, 1, a, c, false, d), p = new cZ(h);
  return e.runWebGLProgram(p, [o, r], "float32");
}
var fZ = {
  kernelName: ah,
  backendName: "webgl",
  kernelFunc: pZ
};
var mZ = class {
  constructor(t) {
    this.variableNames = ["dy", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "strides", type: "vec2" }
    ], this.outputShape = t.inShape, this.enableShapeUniforms = Me(this.outputShape.length);
    const e = t.filterHeight, s = t.filterWidth, o = e - 1 - t.padInfo.top, r = s - 1 - t.padInfo.left;
    this.userCode = `
      const ivec2 pads = ivec2(${o}, ${r});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];

        ivec2 dyCorner = ivec2(coords[1], coords[2]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        vec4 result = vec4(0.);
        for (int wR = 0; wR < ${e}; wR++) {
          float dyR = float(dyRCorner + wR) / strides[0];
          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);
          int wRPerm = ${e} - 1 - wR;

          for (int wC = 0; wC < ${s}; wC++) {
            int wCPerm = ${s} - 1 - wC;

            float dyC = float(dyCCorner + wC) / strides[1];
            bool idyCVal = (dyC >= 0.0) && (dyC < ${t.outWidth}.0)
              && (fract(dyC) == 0.0);
            int idyC = int(dyC);

            float dyC2 = float(dyCCorner + wC + 1) / strides[1];
            bool idyCVal2 = (dyC2 >= 0.0) && (dyC2 < ${t.outWidth}.0)
              && (fract(dyC2) == 0.0);
            int idyC2 = int(dyC2);

            if (idyCVal && idyCVal2) {
              for (int d2 = 0; d2 < ${t.outChannels}; d2 += 2) {
                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);
                vec4 dySample = getDy(batch, idyR, idyC, d2);
                vec4 dySample2 = (idyC / 2 == idyC2 / 2) ?
                  dySample : getDy(batch, idyR, idyC2, d2);

                vec2 dyValue = mod(float(idyC), 2.) == 0. ?
                  dySample.xy : dySample.zw;
                result.xy += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));

                dyValue = mod(float(idyC2), 2.) == 0. ?
                  dySample2.xy : dySample2.zw;
                result.zw += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));
              }
            } else if (idyCVal) {
              for (int d2 = 0; d2 < ${t.outChannels}; d2 += 2) {
                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);
                vec4 dySample = getDy(batch, idyR, idyC, d2);
                vec2 dyValue = mod(float(idyC), 2.) == 0. ?
                  dySample.xy : dySample.zw;
                result.xy += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));
              }
            } else if (idyCVal2) {
              for (int d2 = 0; d2 < ${t.outChannels}; d2 += 2) {
                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);
                vec4 dySample = getDy(batch, idyR, idyC2, d2);
                vec2 dyValue = mod(float(idyC2), 2.) == 0. ?
                  dySample.xy : dySample.zw;
                result.zw += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));
              }
            }
          }
        }
        setOutput(result);
      }
    `;
  }
};
function gZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { inputShape: i6, strides: a, pad: l, dataFormat: c, dimRoundingMode: u } = s, d = Ss(c), h = Te(i6, r.shape, a, 1, l, u, false, d);
  if (F().getBool("WEBGL_PACK_CONV2DTRANSPOSE") && d === "channelsLast") {
    const p = [
      [h.strideHeight, h.strideWidth]
    ], f = new mZ(h);
    return e.runWebGLProgram(f, [o, r], "float32", p);
  } else {
    const p = new uZ(h);
    return e.runWebGLProgram(p, [o, r], "float32");
  }
}
var bZ = {
  kernelName: oc,
  backendName: "webgl",
  kernelFunc: gZ
};
function xZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l } = s, c = Js(o.shape, r.shape, i6, l, a), u = new rZ(c);
  return e.runWebGLProgram(u, [o, r], "float32");
}
var yZ = {
  kernelName: rc,
  backendName: "webgl",
  kernelFunc: xZ
};
function wZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, pad: a, filterShape: l } = s, c = Js(o.shape, l, i6, 1, a), u = new dZ(c);
  return e.runWebGLProgram(u, [o, r], "float32");
}
var IZ = {
  kernelName: lh,
  backendName: "webgl",
  kernelFunc: wZ
};
function CZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { pad: i6, strides: a, inputShape: l } = s, c = Js(l, r.shape, a, 1, i6), u = new hZ(c);
  return e.runWebGLProgram(u, [o, r], "float32");
}
var vZ = {
  kernelName: ch,
  backendName: "webgl",
  kernelFunc: CZ
};
var SZ = Vr + `
  return cos(x);
`;
var kZ = `
  vec4 result = cos(x);
  bvec4 isNaN = isnan(x);
  ${jo}
  return result;
`;
var TZ = Nt({ opSnippet: SZ, packedOpSnippet: kZ });
var NZ = {
  kernelName: Mi,
  backendName: "webgl",
  kernelFunc: TZ
};
var RZ = `
  float e2x = exp(-x);
  return (e2x + 1.0 / e2x) / 2.0;
`;
var $Z = Nt({ opSnippet: RZ });
var GZ = {
  kernelName: Wi,
  backendName: "webgl",
  kernelFunc: $Z
};
var EZ = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["Image", "Boxes", "BoxInd"], this.outputShape = [];
    const [i6, a, l, c] = t, [u] = e, [d, h] = s;
    this.outputShape = [u, d, h, c];
    const p = o === "bilinear" ? 1 : 0, [f, m] = [`${a - 1}.0`, `${l - 1}.0`], [g, b, x6] = d > 1 ? [
      `${(a - 1) / (d - 1)}`,
      "(y2-y1) * height_ratio",
      `y1*${f} + float(y)*(height_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (y1+y2) * ${f}`
    ], [w, y6, I] = h > 1 ? [
      `${(l - 1) / (h - 1)}`,
      "(x2-x1) * width_ratio",
      `x1*${m} + float(x)*(width_scale)`
    ] : [
      "0.0",
      "0.0",
      `0.5 * (x1+x2) * ${m}`
    ];
    this.userCode = `
      const float height_ratio = float(${g});
      const float width_ratio = float(${w});
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int y = coords[1];
        int x = coords[2];
        int d = coords[3];

        // get box vals
        float y1 = getBoxes(b,0);
        float x1 = getBoxes(b,1);
        float y2 = getBoxes(b,2);
        float x2 = getBoxes(b,3);

        // get image in batch index
        int bInd = round(getBoxInd(b));
        if(bInd < 0 || bInd >= ${i6}) {
          return;
        }

        float height_scale = ${b};
        float width_scale = ${y6};

        float in_y = ${x6};
        if( in_y < 0.0 || in_y > ${f} ) {
          setOutput(float(${r}));
          return;
        }
        float in_x = ${I};
        if( in_x < 0.0 || in_x > ${m} ) {
          setOutput(float(${r}));
          return;
        }

        vec2 sourceFracIndexCR = vec2(in_x,in_y);
        if(${p} == 1) {
          // Compute the four integer indices.
          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);
          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));

          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);
          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);
          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);
          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);

          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);

          float top = topLeft + (topRight - topLeft) * fracCR.x;
          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          float newValue = top + (bottom - top) * fracCR.y;
          setOutput(newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          ivec2 sourceNearestCR = ivec2(floor(
            sourceFracIndexCR + vec2(0.5,0.5)));
          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutput(newValue);
        }
      }
    `;
  }
};
var LZ = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { image: o, boxes: r, boxInd: i6 } = t, { cropSize: a, method: l, extrapolationValue: c } = s, u = new EZ(o.shape, r.shape, a, l, c);
  return e.runWebGLProgram(u, [o, r, i6], "float32");
};
var MZ = {
  kernelName: dh,
  backendName: "webgl",
  kernelFunc: LZ
};
var Ii;
(function(n) {
  n.Prod = "*", n.Sum = "+";
})(Ii || (Ii = {}));
var Mg = class {
  constructor(t, e, s, o) {
    this.op = t, this.outputShape = e, this.variableNames = ["x"], this.customUniforms = [{ name: "index", type: "float" }];
    const r = this.outputShape.length, i6 = this.op === Ii.Prod ? "1.0" : "0.0", a = s ? i6 : `getX(${Wg(r, "coords", this.op)})`, l = this.outputShape[this.outputShape.length - 1];
    let c = "", u = "";
    s ? (c = o ? `end != ${l - 1}` : "end != 0", u = o ? "end + 1" : "end - 1") : (c = o ? `end + pow2 < ${l}` : "end >= pow2", u = o ? "end + pow2" : "end - pow2"), this.userCode = `
      void main() {
        ${Vt(r)} coords = getOutputCoords();
        int end = ${Dg(r, "coords", this.op)};
        float val = ${a};
        int pow2 = int(pow(2.0, index));
        if (${c}) {
          int idx = ${u};
          ${Dg(r, "coords", this.op)} = idx;
          val ${this.op}= getX(${Wg(r, "coords", this.op)});
        }
        setOutput(val);
      }
    `;
  }
};
function Wg(n, t, e) {
  if (n === 1)
    return `${t}`;
  if (n === 2)
    return `${t}.x, ${t}.y`;
  if (n === 3)
    return `${t}.x, ${t}.y, ${t}.z`;
  if (n === 4)
    return `${t}.x, ${t}.y, ${t}.z, ${t}.w`;
  throw new Error(`Cumulative ${e} for rank ${n} is not yet supported`);
}
function Dg(n, t, e) {
  if (n === 1)
    return `${t}`;
  if (n === 2)
    return `${t}.y`;
  if (n === 3)
    return `${t}.z`;
  if (n === 4)
    return `${t}.w`;
  throw new Error(`Cumulative ${e} for rank ${n} is not yet supported`);
}
function aC(n, t, e, s, o, r) {
  const i6 = t.shape.length, a = qt([s], i6);
  let l = t;
  a != null && (l = ze({ inputs: { x: t }, backend: e, attrs: { perm: a } }));
  const c = ie(1, i6)[0];
  if (c !== i6 - 1)
    throw new Error(`WebGL cumprod shader expects an inner-most axis=${t.shape.length - 1} but got axis=${s}`);
  const u = l.shape[c];
  let d = nn({ inputs: { x: l }, backend: e });
  for (let h = 0; h <= Math.ceil(Math.log2(u)) - 1; h++) {
    const p = new Mg(n, l.shape, false, r), f = [[h]], m = d;
    d = e.runWebGLProgram(p, [d], d.dtype, f), e.disposeIntermediateTensorInfo(m);
  }
  if (o) {
    const h = new Mg(n, l.shape, o, r), p = d;
    d = e.runWebGLProgram(h, [d], d.dtype), e.disposeIntermediateTensorInfo(p);
  }
  if (a != null) {
    const h = js(a), p = ze({ inputs: { x: d }, backend: e, attrs: { perm: h } });
    return e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(l), p;
  }
  return d;
}
function WZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  return aC(Ii.Prod, o, e, r, i6, a);
}
var DZ = {
  kernelName: uh,
  backendName: "webgl",
  kernelFunc: WZ
};
function FZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, exclusive: i6, reverse: a } = s;
  return aC(Ii.Sum, o, e, r, i6, a);
}
var VZ = {
  kernelName: ic,
  backendName: "webgl",
  kernelFunc: FZ
};
function zZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, weights: r } = t, { size: i6, binaryOutput: a } = s;
  if (o.shape.length === 1) {
    const l = e.readSync(o.dataId), c = e.readSync(r.dataId), u = OI(l, c, r.dtype, r.shape, i6);
    return e.makeTensorInfo([i6], r.dtype, u);
  } else if (o.shape.length === 2) {
    const l = e.bufferSync(o), c = e.bufferSync(r), u = OA(l, c, i6, a);
    return e.makeTensorInfo(u.shape, r.dtype, u.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${o.shape.length}.`);
}
var PZ = {
  kernelName: hh,
  backendName: "webgl",
  kernelFunc: zZ
};
var AZ = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.outputShape = [], this.outputShape = t, this.blockSize = e, this.dataFormat = s, this.userCode = `
    void main() {
      ivec4 coords = getOutputCoords();
      int b = coords[0];
      int h = ${this.getHeightCoordString()};
      int w = ${this.getWidthCoordString()};
      int d = ${this.getDepthCoordString()};

      int in_h = h / ${e};
      int offset_h = imod(h, ${e});
      int in_w = w / ${e};
      int offset_w = imod(w, ${e});
      int offset_d = (offset_h * ${e} + offset_w) *
        ${this.getOutputDepthSize()};
      int in_d = d + offset_d;

      float result = ${this.getInputSamplingString()};
      setOutput(result);
    }
  `;
  }
  getHeightCoordString() {
    return this.dataFormat === "NHWC" ? "coords[1]" : "coords[2]";
  }
  getWidthCoordString() {
    return this.dataFormat === "NHWC" ? "coords[2]" : "coords[3]";
  }
  getDepthCoordString() {
    return this.dataFormat === "NHWC" ? "coords[3]" : "coords[1]";
  }
  getOutputDepthSize() {
    return this.dataFormat === "NHWC" ? this.outputShape[3] : this.outputShape[1];
  }
  getInputSamplingString() {
    return this.dataFormat === "NHWC" ? "getX(b, in_h, in_w, in_d)" : "getX(b, in_d, in_h, in_w)";
  }
};
function OZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockSize: r, dataFormat: i6 } = s, a = o.shape[0], l = i6 === "NHWC" ? o.shape[1] : o.shape[2], c = i6 === "NHWC" ? o.shape[2] : o.shape[3], u = i6 === "NHWC" ? o.shape[3] : o.shape[1], d = l * r, h = c * r, p = u / (r * r), f = i6 === "NHWC" ? [a, d, h, p] : [a, p, d, h], m = new AZ(f, r, i6);
  return e.runWebGLProgram(m, [o], o.dtype);
}
var XZ = {
  kernelName: ph,
  backendName: "webgl",
  kernelFunc: OZ
};
var lC = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.customUniforms = [
      { name: "pads", type: "ivec2" },
      { name: "strides", type: "ivec2" },
      { name: "dilations", type: "ivec2" },
      { name: "inDims", type: "ivec2" }
    ], this.outputShape = t.outShape, this.enableShapeUniforms = Me(this.outputShape.length);
    const i6 = t.filterHeight, a = t.filterWidth, l = t.outChannels / t.inChannels;
    let c = "", u = "";
    s && (o ? c = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${s}
        }` : r ? c = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${s}
        }` : c = `
          float activation(float x) {
            ${s}
          }
        `, u = "result = activation(result);");
    const d = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${c}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${l};
        int q = d2 - d1 * ${l};

        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.
        for (int wR = 0; wR < ${i6}; wR++) {
          int xR = xRCorner + wR * dilations[0];

          if (xR < 0 || xR >= inDims[0]) {
            continue;
          }

          for (int wC = 0; wC < ${a}; wC++) {
            int xC = xCCorner + wC * dilations[1];

            if (xC < 0 || xC >= inDims[1]) {
              continue;
            }

            float xVal = getX(batch, xR, xC, d1);
            float wVal = getW(wR, wC, d1, q);
            dotProd += xVal * wVal;
          }
        }

        float result = dotProd;
        ${d}
        ${u}
        setOutput(result);
      }
    `;
  }
};
var cC = class {
  constructor(t, e = false, s = null, o = false, r = false) {
    this.variableNames = ["x", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [
      { name: "pads", type: "ivec2" },
      { name: "strides", type: "ivec2" },
      { name: "dilations", type: "ivec2" },
      { name: "inDims", type: "ivec2" }
    ], this.outputShape = t.outShape, this.enableShapeUniforms = Me(this.outputShape.length);
    const i6 = t.outChannels / t.inChannels, a = t.padInfo.left, l = t.strideWidth, c = t.dilationWidth, u = t.filterHeight, d = t.filterWidth, h = d;
    let p = `
      int xR; int xC; int xCOffset;
      vec4 wTexel; vec4 previous; vec4 final;`;
    for (let b = 0; b < d; b++)
      p += `
          vec4 xTexelC${b * 2};
          int xTexelC${b * 2}Ready;
          vec4 xTexelC${b * 2 + 1};
          int xTexelC${b * 2 + 1}Ready;
          vec4 xC${b};`;
    p += `
    for (int r = 0; r < ${u}; r++) {
      `;
    for (let b = 0; b < d; b++)
      p += `
          xTexelC${b * 2} = vec4(0.0);
          xTexelC${b * 2}Ready = 0;
          xTexelC${b * 2 + 1} = vec4(0.0);
          xTexelC${b * 2 + 1}Ready = 0;
          xC${b} = vec4(0.0);`;
    p += `
        xR = xRCorner + r * dilations[0];
        if (xR >=0 && xR < inDims[0]) {
      `;
    for (let b = 0; b < (h + 1) / 2; b++) {
      const x6 = b * 2;
      if (p += `
          xC = xCCorner + ${x6 * c};
          `, l === 1) {
        if (x6 < d && (a % 2 === 1 ? (p += `
                xCOffset = xC + 1;
                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xCOffset, d1);

                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }
              `, c === 1 && x6 > 0 ? p += `
                xC${x6} = vec4(xTexelC${x6 - 2}.zw, xTexelC${x6}.xy);
                ` : p += `
                  xCOffset = xC + 1 - 2;

                  if (xCOffset >= 0 && xCOffset < inDims[1]) {
                    previous = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      previous.zw = vec2(0.0);
                    }

                    xC${x6} = vec4(previous.zw, xTexelC${x6}.xy);
                  } else {
                    xC${x6} = vec4(0.0, 0.0, xTexelC${x6}.xy);
                  }
                  `) : p += `
                if (xC >= 0 && xC < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }

                xC${x6} = xTexelC${x6};
                `, x6 + 1 < d)) {
          const w = a % 2 === 0 ? Bl(c) : c;
          c % 2 === 0 && a % 2 === 1 || c % 2 !== 0 && a % 2 !== 1 ? (p += `
                  xCOffset = xC + imod(pads[1], 2) + ${w};

                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                    xTexelC${x6 + 1} = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      xTexelC${x6 + 1}.zw = vec2(0.0);
                    }
                    xTexelC${x6 + 1}Ready = 1;
                  }
                  `, c > 1 ? p += `
                    xCOffset -= 2;
                    if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);
                     xC${x6 + 1} = vec4(previous.zw, xTexelC${x6 + 1}.xy);
                    } else {
                     xC${x6 + 1} = vec4(0.0, 0.0, xTexelC${x6 + 1}.xy);
                    }
                    ` : p += `
                    xC${x6 + 1} = vec4(xTexelC${x6}.zw, xTexelC${x6 + 1}.xy);
                    `) : w === 1 ? p += `
                    xC${x6 + 1} = xTexelC${x6};
                    ` : p += `
                    xCOffset = xC + ${w};

                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                      xTexelC${x6 + 1} = getX(batch, xR, xCOffset, d1);
                      if (xCOffset + 1 >= inDims[1]) {
                        xTexelC${x6 + 1}.zw = vec2(0.0);
                      }
                      xTexelC${x6 + 1}Ready = 1;
                    }

                    xC${x6 + 1} = xTexelC${x6 + 1};
                    `;
        }
      } else
        x6 < d && (a % 2 === 1 ? (p += `
                xCOffset = xC + 1 - strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xCOffset, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }

                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                  xTexelC${x6 + 1} = getX(batch, xR, xC + 1, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xC + 2 >= inDims[1]) {
                    xTexelC${x6 + 1}.zw = vec2(0.0);
                  }
                  xTexelC${x6 + 1}Ready = 1;
                }

                xC${x6} = vec4(xTexelC${x6}.zw, xTexelC${x6 + 1}.zw);
              `, x6 + 1 < d && (p += `
                  final = vec4(0.0);
                  xCOffset = xC + 1 + strides[1];
                  if(xCOffset >= 0 && xCOffset < inDims[1]) {
                    final = getX(batch, xR, xCOffset, d1);
                  }
                  xC${x6 + 1} = vec4(xTexelC${x6 + 1}.xy, final.xy);
                `)) : (p += `
                if(xC >= 0 && xC < inDims[1] && xTexelC${x6}Ready == 0) {
                  xTexelC${x6} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${x6}.zw = vec2(0.0);
                  }
                  xTexelC${x6}Ready = 1;
                }

                xCOffset = xC + strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${x6 + 1}Ready == 0) {
                  xTexelC${x6 + 1} = getX(batch, xR, xCOffset, d1);
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${x6 + 1}.zw = vec2(0.);
                  }
                  xTexelC${x6 + 1}Ready = 1;
                }

                xC${x6} = vec4(
                  xTexelC${x6}.xy, xTexelC${x6 + 1}.xy);
              `, x6 + 1 < d && (p += `
                  xC${x6 + 1} = vec4(xTexelC${x6}.zw, xTexelC${x6 + 1}.zw);
                `)));
      x6 < d && (p += `
            wTexel = getW(r, ${x6}, d1, q);
            dotProd += xC${x6} * vec4(wTexel.xz, wTexel.xz);
          `, x6 + 1 < d && (p += `
              wTexel = getW(r, ${x6 + 1}, d1, q);
              dotProd += xC${x6 + 1} * vec4(wTexel.xz, wTexel.xz);
            `));
    }
    p += `
    }
  `, p += `
      }
    `;
    let f = "", m = "";
    s && (o ? f = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${s}
        }` : r ? f = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${s}
        }` : f = `vec4 activation(vec4 x) {
          ${s}
        }`, m = "result = activation(result);");
    const g = e ? "result += getBiasAtOutCoords();" : "";
    e && this.variableNames.push("bias"), o && this.variableNames.push("preluActivationWeights"), r && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${f}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${i6};
        int q = d2 - d1 * ${i6};
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
        vec4 dotProd = vec4(0.000000000000001);

        ${p}

        vec4 result = dotProd - vec4(0.000000000000001);
        ${g}
        ${m}
        setOutput(result);
      }
    `;
  }
};
function KZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l, dimRoundingMode: c } = s;
  let u = l;
  u == null && (u = [1, 1]), C(Le(i6, u), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i6} and dilations '${u}'`);
  const d = Te(
    o.shape,
    r.shape,
    i6,
    u,
    a,
    c,
    true
    /* depthwise */
  );
  let h;
  F().getBool("WEBGL_PACK_DEPTHWISECONV") && d.strideWidth <= 2 && d.outChannels / d.inChannels === 1 ? h = new cC(d) : h = new lC(d);
  const p = [
    [d.padInfo.top, d.padInfo.left],
    [d.strideHeight, d.strideWidth],
    [d.dilationHeight, d.dilationWidth],
    [d.inHeight, d.inWidth]
  ];
  return e.runWebGLProgram(h, [o, r], "float32", p);
}
var ZZ = {
  kernelName: ac,
  backendName: "webgl",
  kernelFunc: KZ
};
var BZ = class {
  constructor(t) {
    this.variableNames = ["x", "dy"], this.outputShape = t.filterShape;
    const e = t.strideHeight, s = t.strideWidth, o = t.padInfo.top, r = t.padInfo.left, i6 = t.outChannels / t.inChannels;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int dm = coords.w;
        int d2 = d1 * ${i6} + dm;

        float dotProd = 0.0;

        // TO DO: Vec4 over the batch size
        for (int b = 0; b < ${t.batchSize}; b++) {
          for (int yR = 0; yR < ${t.outHeight}; yR++) {
            int xR = wR + yR * ${e} - ${o};

            if (xR < 0 || xR >= ${t.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${t.outWidth}; yC++) {
              int xC = wC + yC * ${s} - ${r};

              if (xC < 0 || xC >= ${t.inWidth}) {
                continue;
              }

              float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var HZ = class {
  constructor(t) {
    this.variableNames = ["dy", "W"], this.outputShape = t.inShape;
    const e = t.filterHeight, s = t.filterWidth, o = t.strideHeight, r = t.strideWidth, i6 = e - 1 - t.padInfo.top, a = s - 1 - t.padInfo.left, l = t.outChannels / t.inChannels;
    this.userCode = `
      const ivec2 pads = ivec2(${i6}, ${a});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];
        ivec2 dyCorner = coords.yz - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        float dotProd = 0.0;

        for (int wR = 0; wR < ${e}; wR++) {
          float dyR = float(dyRCorner + wR) / ${o}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${e} - 1 - wR;

          for (int wC = 0; wC < ${s}; wC++) {
            float dyC = float(dyCCorner + wC) / ${r}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${s} - 1 - wC;

            // TO DO: Vec4 over the channelMul
            for (int dm = 0; dm < ${l}; dm++) {
              int d2 = d1 * ${l} + dm;
              float xValue = getDy(batch, idyR, idyC, d2);
              float wValue = getW(wRPerm, wCPerm, d1, dm);
              dotProd += xValue * wValue;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function _Z(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, dy: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, filterShape: u } = s, d = Te(
    o.shape,
    u,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), h = new BZ(d);
  return e.runWebGLProgram(h, [o, r], "float32");
}
var UZ = {
  kernelName: fh,
  backendName: "webgl",
  kernelFunc: _Z
};
function YZ(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, filter: r } = t, { strides: i6, dilations: a, pad: l, dimRoundingMode: c, inputShape: u } = s, d = Te(
    u,
    r.shape,
    i6,
    a,
    l,
    c,
    true
    /* depthwise */
  ), h = new HZ(d);
  return e.runWebGLProgram(h, [o, r], "float32");
}
var QZ = {
  kernelName: mh,
  backendName: "webgl",
  kernelFunc: YZ
};
var JZ = class {
  constructor(t) {
    this.variableNames = ["X"], this.outputShape = [t, t], this.userCode = `
      void main() {
          ivec2 coords = getOutputCoords();
          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;
          setOutput(val);
      }
    `;
  }
};
function jZ(n) {
  const { inputs: t, backend: e } = n, { x: s } = t, o = [...s.shape, ...s.shape], r = X(s.shape), i6 = et({ inputs: { x: s }, backend: e, attrs: { shape: [r] } }), a = new JZ(r), l = e.runWebGLProgram(a, [i6], i6.dtype), c = et({ inputs: { x: l }, backend: e, attrs: { shape: o } });
  return e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(l), c;
}
var qZ = {
  kernelName: ub,
  backendName: "webgl",
  kernelFunc: jZ
};
var tB = class {
  constructor(t) {
    this.variableNames = ["x", "W"], this.outputShape = t.outShape;
    const { inHeight: e, inWidth: s, padInfo: o, strideHeight: r, strideWidth: i6, filterHeight: a, filterWidth: l, dilationHeight: c, dilationWidth: u } = t, { top: d, left: h } = o;
    this.userCode = `
      const ivec2 strides = ivec2(${r}, ${i6});
      const ivec2 pads = ivec2(${d}, ${h});
      const float neg_infinity = -3.4e38;

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.w;
        ivec2 outTopLeftCorner =
            coords.yz * strides - pads;
        int hBeg = outTopLeftCorner.x;
        int wBeg = outTopLeftCorner.y;

        float curVal = neg_infinity;
        for (int h = 0; h < ${a}; h++) {
          int hIn = hBeg + h * ${c};

          if (hIn >= 0 && hIn < ${e}) {
            for (int w = 0; w < ${l}; w++) {
              int wIn = wBeg + w * ${u};

              if (wIn >= 0 && wIn < ${s}) {
                float xVal = getX(batch, hIn, wIn, d1);
                float wVal = getW(h, w, d1);

                float val = xVal + wVal;
                if (val > curVal) {
                  curVal = val;
                }
              }
            }
          }
        }

        float result = curVal;
        setOutput(result);
      }
    `;
  }
};
function eB(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r } = t, { strides: i6, pad: a, dilations: l } = s, c = Ia(o.shape, r.shape, i6, a, "NHWC", l);
  let u;
  const d = new tB(c);
  u = e.runWebGLProgram(d, [o, r], "float32");
  const h = et({ inputs: { x: u }, backend: e, attrs: { shape: c.outShape } });
  return e.disposeIntermediateTensorInfo(u), h;
}
var nB = {
  kernelName: lc,
  backendName: "webgl",
  kernelFunc: eB
};
function sB(n) {
  const { inputs: t, backend: e, attrs: s } = n, { equation: o } = s, r = t, { allDims: i6, summedDims: a, idDims: l } = lf(o, r.length);
  uf(i6.length, l, r);
  const { path: c, steps: u } = df(a, l), d = u.length;
  let h = null, p = i6.length;
  const f = [];
  for (let m = 0; m < d; ++m) {
    for (const g of u[m]) {
      const { permutationIndices: b, expandDims: x6 } = cf(p, l[g]);
      let w;
      hf(b) ? w = r[g] : (w = ze({ inputs: { x: r[g] }, backend: e, attrs: { perm: b } }), f.push(w));
      const y6 = w.shape.slice();
      for (let I = 0; I < x6.length; ++I)
        y6.splice(x6[I], 0, 1);
      $t(w.shape, y6) || (w = et({ inputs: { x: w }, backend: e, attrs: { shape: y6 } }), f.push(w)), h === null ? h = w : (h = im({ inputs: { a: w, b: h }, backend: e }), f.push(h));
    }
    m < d - 1 && (c[m] >= 0 && (h = Su({
      inputs: { x: h },
      backend: e,
      attrs: {
        axis: c[m] - (i6.length - p),
        keepDims: false
      }
    }), f.push(h)), p--);
  }
  for (const m of f)
    m !== h && e.disposeIntermediateTensorInfo(m);
  return h;
}
var oB = {
  kernelName: bh,
  backendName: "webgl",
  kernelFunc: sB
};
var rB = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
var iB = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var aB = Nt({ opSnippet: rB, packedOpSnippet: iB });
var lB = {
  kernelName: Fi,
  backendName: "webgl",
  kernelFunc: aB
};
var cB = "return (b >= 0.0) ? a : a * (b + 1.0);";
var uB = `
  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));
  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));
`;
var dB = (n) => {
  const { inputs: t, backend: e } = n, { dy: s, y: o } = t, r = F().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new Fr(uB, s.shape, o.shape) : new Po(cB, s.shape, o.shape);
  return e.runWebGLProgram(r, [s, o], s.dtype);
};
var hB = {
  kernelName: xh,
  backendName: "webgl",
  kernelFunc: dB
};
var pB = `
  return vec4(equal(a, b));
`;
var fB = "return float(a == b);";
var mB = Re({
  opSnippet: fB,
  packedOpSnippet: pB,
  dtype: "bool",
  cpuKernelImpl: HA
});
var gB = {
  kernelName: cc,
  backendName: "webgl",
  kernelFunc: mB
};
var bB = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  float p = ${tf};
  float a1 = ${ef};
  float a2 = ${nf};
  float a3 = ${sf};
  float a4 = ${of};
  float a5 = ${rf};

  float sign = sign(x);
  x = abs(x);
  float t = 1.0 / (1.0 + p * x);
  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));
`;
var xB = Nt({ opSnippet: bB });
var yB = {
  kernelName: Vi,
  backendName: "webgl",
  kernelFunc: xB
};
var wB = Vr + `
  return exp(x);
`;
var IB = `
  vec4 result = exp(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var uC = Nt({
  opSnippet: wB,
  packedOpSnippet: IB,
  cpuKernelImpl: _A,
  dtype: "float32"
});
var CB = {
  kernelName: zi,
  backendName: "webgl",
  kernelFunc: uC
};
function Zd(n) {
  const { inputs: t, attrs: e, backend: s } = n, { dim: o } = e, { input: r } = t, i6 = r.shape.length, a = r.shape.slice();
  let l = o;
  return o < 0 && (C(-(i6 + 1) <= o, () => `Axis must be in the interval [${-(i6 + 1)}, ${i6}]`), l = i6 + o + 1), a.splice(l, 0, 1), et({ inputs: { x: r }, backend: s, attrs: { shape: a } });
}
var vB = {
  kernelName: uc,
  backendName: "webgl",
  kernelFunc: Zd
};
var Fg = "return exp(x) - 1.0;";
var SB = Nt({ opSnippet: Fg, packedOpSnippet: Fg, cpuKernelImpl: UA });
var kB = {
  kernelName: Pi,
  backendName: "webgl",
  kernelFunc: SB
};
var Vg = class {
  constructor(t, e, s) {
    this.variableNames = ["real", "imag"];
    const o = e[1];
    this.outputShape = e;
    const r = s ? `2.0 * ${Math.PI}` : `-2.0 * ${Math.PI}`, i6 = s ? `${o}.0` : "1.0";
    let a;
    if (t === "real")
      a = "return real * expR - imag * expI;";
    else if (t === "imag")
      a = "return real * expI + imag * expR;";
    else
      throw new Error(`FFT component must be either "real" or "imag", got ${t}.`);
    this.userCode = `
      const float exponentMultiplier = ${r};

      float unaryOpComplex(float real, float expR, float imag, float expI) {
        ${a}
      }

      float mulMatDFT(int batch, int index) {
        float indexRatio = float(index) / float(${o});
        float exponentMultiplierTimesIndexRatio =
            exponentMultiplier * indexRatio;

        float result = 0.0;

        for (int i = 0; i < ${o}; i++) {
          // x = (-2|2 * PI / N) * index * i;
          float x = exponentMultiplierTimesIndexRatio * float(i);
          float expR = cos(x);
          float expI = sin(x);
          float real = getReal(batch, i);
          float imag = getImag(batch, i);

          result +=
              unaryOpComplex(real, expR, imag, expI) / ${i6};
        }

        return result;
      }

      void main() {
        ivec2 coords = getOutputCoords();
        setOutput(mulMatDFT(coords[0], coords[1]));
      }
    `;
  }
};
function dC(n, t, e) {
  const s = e.texData.get(n.dataId), o = X(n.shape), r = n.shape[n.shape.length - 1], i6 = o / r, a = et({ inputs: { x: n }, backend: e, attrs: { shape: [i6, r] } }), l = a.shape, c = new Vg("real", l, t), u = new Vg("imag", l, t), d = [
    {
      dataId: s.complexTensorInfos.real.dataId,
      dtype: s.complexTensorInfos.real.dtype,
      shape: l
    },
    {
      dataId: s.complexTensorInfos.imag.dataId,
      dtype: s.complexTensorInfos.imag.dtype,
      shape: l
    }
  ], h = e.runWebGLProgram(c, d, "float32"), p = e.runWebGLProgram(u, d, "float32"), f = oo({ inputs: { real: h, imag: p }, backend: e });
  e.disposeIntermediateTensorInfo(h), e.disposeIntermediateTensorInfo(p);
  const m = et({ inputs: { x: f }, backend: e, attrs: { shape: n.shape } });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(f), m;
}
function TB(n) {
  const { inputs: t, backend: e } = n, { input: s } = t;
  return dC(s, false, e);
}
var NB = {
  kernelName: yh,
  backendName: "webgl",
  kernelFunc: TB
};
var RB = class {
  constructor(t, e) {
    this.outputShape = [], this.customUniforms = [{ name: "value", type: "float" }], this.variableNames = ["x"], this.outputShape = t, this.userCode = `
      void main() {
        // Input can be obtained from uniform value.
        setOutput(value);
      }
    `;
  }
};
function Xa(n) {
  const { backend: t, attrs: e } = n, { shape: s, value: o } = e;
  let { dtype: r } = e;
  if (r = r || Oo(o), r === "string") {
    const i6 = ne(r, X(s));
    return i6.fill(o), t.makeTensorInfo(s, r, i6);
  } else {
    const i6 = new RB(s, o), a = [[o]];
    return t.runWebGLProgram(i6, [], r, a);
  }
}
var $B = {
  kernelName: wh,
  backendName: "webgl",
  kernelFunc: Xa
};
var GB = class {
  constructor(t) {
    this.variableNames = ["Image"], this.outputShape = [];
    const e = t[2];
    this.outputShape = t, this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];

          int coordX = ${e} - x - 1;
          float outputValue;
          if(coordX >= 0 && coordX < ${e}) {
            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);
          } else {
            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
};
var EB = {
  kernelName: Ih,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, backend: t }) => {
    const { image: e } = n, s = t, o = new GB(e.shape);
    return s.runWebGLProgram(o, [e], e.dtype);
  }
};
var zg = "return floor(x);";
var LB = Nt({ opSnippet: zg, packedOpSnippet: zg, cpuKernelImpl: YA });
var MB = {
  kernelName: Ai,
  backendName: "webgl",
  kernelFunc: LB
};
var WB = `
  float s = sign(a) * sign(b);
  int ia = round(a);
  int ib = round(b);
  if (ib != 0) {
    // Windows (D3D) wants guaranteed non-zero int division at compile-time.
    return float(idiv(ia, ib, s));
  } else {
    return NAN;
  }
`;
var DB = `
  ivec4 ia = round(a);
  ivec4 ib = round(b);
  bvec4 cond = notEqual(ib, ivec4(0));
  ivec4 result = ivec4(0);
  vec4 s = sign(a) * sign(b);

  // Windows (D3D) wants guaranteed non-zero int division at compile-time.
  if (cond[0]) {
    result[0] = idiv(ia[0], ib[0], s[0]);
  }
  if (cond[1]) {
    result[1] = idiv(ia[1], ib[1], s[1]);
  }
  if (cond[2]) {
    result[2] = idiv(ia[2], ib[2], s[2]);
  }
  if (cond[3]) {
    result[3] = idiv(ia[3], ib[3], s[3]);
  }
  return vec4(result);
`;
var FB = Re({ opSnippet: WB, packedOpSnippet: DB, dtype: "int32" });
var VB = {
  kernelName: Oi,
  backendName: "webgl",
  kernelFunc: FB
};
var zB = class {
  constructor(t) {
    this.variableNames = ["A"];
    const e = Ae(), [s, o] = t;
    this.outputShape = t, this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${o}.0, ${s}.0);

        vec4 values = ${e.texture2D}(A, uv);
        float value;
        if (depth == 0) {
          value = values.r;
        } else if (depth == 1) {
          value = values.g;
        } else if (depth == 2) {
          value = values.b;
        } else if (depth == 3) {
          value = values.a;
        }

        setOutput(floor(value * 255.0 + 0.5));
      }
    `;
  }
};
var PB = class {
  constructor(t) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true;
    const e = Ae(), [s, o] = t;
    this.outputShape = t, this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];

        vec4 result = vec4(0.);

        for(int row=0; row<=1; row++) {
          for(int col=0; col<=1; col++) {
            texC = coords[1] + row;
            depth = coords[2] + col;

            vec2 uv = (vec2(texC, texR) + halfCR) /
                       vec2(${o}.0, ${s}.0);
            vec4 values = ${e.texture2D}(A, uv);
            float value;
            if (depth == 0) {
              value = values.r;
            } else if (depth == 1) {
              value = values.g;
            } else if (depth == 2) {
              value = values.b;
            } else if (depth == 3) {
              value = values.a;
            }

            result[row * 2 + col] = floor(value * 255.0 + 0.5);
          }
        }

        ${e.output} = result;
      }
    `;
  }
};
var AB = {
  kernelName: cd,
  backendName: "webgl",
  kernelFunc: OB
};
var nr;
var Ou = F().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
function OB(n) {
  const { inputs: t, backend: e, attrs: s } = n;
  let { pixels: o } = t;
  const { numChannels: r } = s, i6 = typeof HTMLVideoElement < "u" && o instanceof HTMLVideoElement, a = typeof HTMLImageElement < "u" && o instanceof HTMLImageElement, [l, c] = i6 ? [
    o.videoWidth,
    o.videoHeight
  ] : [o.width, o.height], u = [c, l], d = [c, l, r];
  if (a || i6) {
    const m = F().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
    (nr == null || m !== Ou) && (Ou = m, nr = document.createElement("canvas").getContext("2d", { willReadFrequently: Ou })), nr.canvas.width = l, nr.canvas.height = c, nr.drawImage(o, 0, 0, l, c), o = nr.canvas;
  }
  const h = e.makeTensorInfo(u, "int32");
  e.texData.get(h.dataId).usage = un.PIXELS, e.gpgpu.uploadPixelDataToTexture(e.getTexture(h.dataId), o);
  const p = F().getBool("WEBGL_PACK") ? new PB(d) : new zB(d), f = e.runWebGLProgram(p, [h], "int32");
  return e.disposeData(h.dataId), f;
}
function XB(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dataFormat: u, dilations: d, dimRoundingMode: h, activation: p, leakyreluAlpha: f } = s, m = Ss(u), g = Te(o.shape, r.shape, l, d, c, h, false, m);
  let b;
  const x6 = [], w = i6 != null, y6 = a != null, I = p === "leakyrelu", v = () => {
    const S = [o, r], N = (R, M6) => {
      if (M6 === "NCHW" && R.shape.length === 1 && R.shape[0] !== 1) {
        const V = et({
          inputs: { x: R },
          backend: e,
          attrs: { shape: [R.shape[0], 1, 1] }
        });
        return x6.push(V), V;
      }
      return R;
    };
    if (w && S.push(N(i6, u)), y6 && S.push(N(a, u)), I) {
      const R = e.makeTensorInfo([], "float32", Is(f, "float32"));
      S.push(R), x6.push(R);
    }
    return S;
  };
  if (g.filterHeight === 1 && g.filterWidth === 1 && g.dilationHeight === 1 && g.dilationWidth === 1 && g.strideHeight === 1 && g.strideWidth === 1 && (g.padInfo.type === "SAME" || g.padInfo.type === "VALID"))
    b = rC({
      x: o,
      filter: r,
      convInfo: g,
      backend: e,
      bias: i6,
      activation: p,
      preluActivationWeights: a,
      leakyreluAlpha: f
    });
  else if (g.strideWidth <= 2 && m === "channelsLast" && F().getBool("WEBGL_EXP_CONV")) {
    const S = p ? yi(p, true) : null, N = new oC(g, w, S, y6, I), R = [
      [g.padInfo.top, g.padInfo.left],
      [g.strideHeight, g.strideWidth],
      [g.dilationHeight, g.dilationWidth],
      [g.inHeight, g.inWidth]
    ], M6 = v();
    b = e.runWebGLProgram(N, M6, "float32", R);
  } else if (F().getBool("WEBGL_CONV_IM2COL"))
    b = iC({
      x: o,
      filter: r,
      convInfo: g,
      backend: e,
      bias: i6,
      activation: p,
      preluActivationWeights: a,
      leakyreluAlpha: f
    });
  else {
    const S = p ? yi(p, false) : null, N = new sC(g, w, S, y6, I), R = v();
    b = e.runWebGLProgram(N, R, "float32");
  }
  const k6 = et({ inputs: { x: b }, backend: e, attrs: { shape: g.outShape } });
  return x6.push(b), x6.forEach((S) => e.disposeIntermediateTensorInfo(S)), k6;
}
var KB = {
  kernelName: gl,
  backendName: "webgl",
  kernelFunc: XB
};
function ZB(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, filter: r, bias: i6, preluActivationWeights: a } = t, { strides: l, pad: c, dilations: u, dimRoundingMode: d, activation: h, leakyreluAlpha: p } = s, f = [];
  let m = u;
  m == null && (m = [1, 1]), C(Le(l, m), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${l} and dilations '${m}'`);
  const g = Te(
    o.shape,
    r.shape,
    l,
    m,
    c,
    d,
    true
    /* depthwise */
  ), b = F().getBool("WEBGL_PACK_DEPTHWISECONV") && g.strideWidth <= 2 && g.outChannels / g.inChannels === 1, x6 = h ? yi(h, b) : null, w = [o, r], y6 = i6 != null, I = a != null, v = h === "leakyrelu";
  if (y6 && w.push(i6), I && w.push(a), v) {
    const R = e.makeTensorInfo([], "float32", Is(p, "float32"));
    w.push(R), f.push(R);
  }
  let k6;
  b ? k6 = new cC(g, y6, x6, I, v) : k6 = new lC(g, y6, x6, I, v);
  const S = [
    [g.padInfo.top, g.padInfo.left],
    [g.strideHeight, g.strideWidth],
    [g.dilationHeight, g.dilationWidth],
    [g.inHeight, g.inWidth]
  ], N = e.runWebGLProgram(k6, w, "float32", S);
  return f.forEach((R) => e.disposeIntermediateTensorInfo(R)), N;
}
var BB = {
  kernelName: Cb,
  backendName: "webgl",
  kernelFunc: ZB
};
var HB = class {
  constructor(t, e, s, o) {
    this.sliceDim = t, this.strides = e, this.paramsShape = o, this.variableNames = ["x", "indices"], this.outputShape = s;
    const r = Vt(s.length);
    let i6 = `
    int index;`;
    for (let a = 0; a < this.sliceDim; a++)
      i6 += `
          index = round(getIndices(coords[0], ${a}));
          out_of_bounds = out_of_bounds || index < 0;
          out_of_bounds = out_of_bounds || index >= ${this.paramsShape[a]};
          flattenIndex += index * ${this.strides[a]};`;
    this.userCode = `
         void main() {
          ${r} coords = getOutputCoords();
          int flattenIndex = 0;
          bool out_of_bounds = false;

          ${i6}

          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));
        }
      `;
  }
};
function _B(n) {
  const { inputs: t, backend: e } = n, { params: s, indices: o } = t, r = o.shape, i6 = r[r.length - 1], a = X(s.shape), [l, c, u, d] = eu(s, o), h = et({ inputs: { x: o }, backend: e, attrs: { shape: [c, i6] } }), p = et({
    inputs: { x: s },
    backend: e,
    attrs: { shape: [X(s.shape) / u, u] }
  });
  if (e.shouldExecuteOnCPU([s, o]) || s.dtype === "string") {
    const b = e.readSync(o.dataId), x6 = e.bufferSync(s), w = QA(b, x6, s.dtype, c, i6, u, d, s.shape, a);
    return e.makeTensorInfo(l, s.dtype, w.values);
  }
  const f = new HB(i6, d, [c, u], s.shape), m = e.runWebGLProgram(f, [p, h], p.dtype), g = et({ inputs: { x: m }, backend: e, attrs: { shape: l } });
  return e.disposeIntermediateTensorInfo(h), e.disposeIntermediateTensorInfo(p), e.disposeIntermediateTensorInfo(m), g;
}
var UB = {
  kernelName: db,
  backendName: "webgl",
  kernelFunc: _B
};
var YB = class {
  constructor(t, e) {
    this.variableNames = ["A", "indices"], this.outputShape = e, this.rank = e.length;
    const s = Vt(this.rank), o = QB(t);
    this.userCode = `
      void main() {
        ${s} resRC = getOutputCoords();
        int index = int(getIndices(resRC.x, resRC.z));
        float inBounds = (index >= 0) && (index < ${t[2]}) ? 1.0 : 0.0;
        setOutput(inBounds * getA(${o}));
      }
    `;
  }
};
function QB(n, t) {
  const e = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"], s = [];
  for (let o = 0; o < n.length; o++)
    o === 2 ? s.push("index") : s.push(`${e[o]}`);
  return s.join();
}
function hC(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, indices: r } = t, { axis: i6, batchDims: a } = s, l = Ct(i6, o.shape)[0];
  if (F().get("DEBUG")) {
    const x6 = e.readSync(r.dataId), w = o.shape[l];
    for (let y6 = 0; y6 < x6.length; ++y6) {
      const I = x6[y6];
      C(I <= w - 1 && I >= 0, () => `GatherV2: the index value ${I} is not in [0, ${w - 1}]`);
    }
  }
  const c = ff(o, r, l, a), u = X(r.shape), d = [], h = et({
    inputs: { x: o },
    backend: e,
    attrs: {
      shape: [
        c.batchSize,
        c.outerSize,
        c.dimSize,
        c.sliceSize
      ]
    }
  }), p = et({
    inputs: { x: r },
    backend: e,
    attrs: { shape: [c.batchSize, u / c.batchSize] }
  });
  d.push(h), d.push(p);
  const f = [
    c.batchSize,
    c.outerSize,
    u / c.batchSize,
    c.sliceSize
  ];
  if (e.shouldExecuteOnCPU([o, r]) || o.dtype === "string") {
    const x6 = e.bufferSync(p), w = e.bufferSync(h), y6 = JA(w, x6, f);
    return d.forEach((I) => e.disposeIntermediateTensorInfo(I)), e.makeTensorInfo(c.outputShape, y6.dtype, y6.values);
  }
  const m = new YB(h.shape, f), g = e.runWebGLProgram(m, [h, p], h.dtype);
  d.push(g);
  const b = et({ inputs: { x: g }, backend: e, attrs: { shape: c.outputShape } });
  return d.forEach((x6) => e.disposeIntermediateTensorInfo(x6)), b;
}
var JB = {
  kernelName: hc,
  backendName: "webgl",
  kernelFunc: hC
};
var jB = "return float(a > b);";
var qB = `
  return vec4(greaterThan(a, b));
`;
var tH = Re({
  opSnippet: jB,
  packedOpSnippet: qB,
  cpuKernelImpl: jA,
  dtype: "bool"
});
var eH = {
  kernelName: pc,
  backendName: "webgl",
  kernelFunc: tH
};
var nH = "return float(a >= b);";
var sH = `
  return vec4(greaterThanEqual(a, b));
`;
var oH = Re({
  opSnippet: nH,
  packedOpSnippet: sH,
  dtype: "bool",
  cpuKernelImpl: qA
});
var rH = {
  kernelName: Xi,
  backendName: "webgl",
  kernelFunc: oH
};
function iH(n) {
  const { inputs: t, backend: e } = n, { input: s } = t;
  return dC(s, true, e);
}
var aH = {
  kernelName: Ch,
  backendName: "webgl",
  kernelFunc: iH
};
var lH = "return float(!isnan(x) && !isinf(x));";
var cH = Nt({ opSnippet: lH, dtype: "bool" });
var uH = {
  kernelName: Zi,
  backendName: "webgl",
  kernelFunc: cH
};
var dH = "return float(isinf(x));";
var hH = Nt({ opSnippet: dH, dtype: "bool" });
var pH = {
  kernelName: Bi,
  backendName: "webgl",
  kernelFunc: hH
};
var fH = "return float(isnan(x));";
var mH = Nt({ opSnippet: fH, dtype: "bool" });
var gH = {
  kernelName: Hi,
  backendName: "webgl",
  kernelFunc: mH
};
var bH = "return float(a < b);";
var xH = `
  return vec4(lessThan(a, b));
`;
var yH = Re({
  opSnippet: bH,
  packedOpSnippet: xH,
  cpuKernelImpl: tO,
  dtype: "bool"
});
var wH = {
  kernelName: mc,
  backendName: "webgl",
  kernelFunc: yH
};
var IH = "return float(a <= b);";
var CH = `
  return vec4(lessThanEqual(a, b));
`;
var vH = Re({
  opSnippet: IH,
  packedOpSnippet: CH,
  cpuKernelImpl: eO,
  dtype: "bool"
});
var SH = {
  kernelName: gc,
  backendName: "webgl",
  kernelFunc: vH
};
function kH(n) {
  const { backend: t, attrs: e } = n, { start: s, stop: o, num: r } = e, i6 = nO(s, o, r);
  return t.makeTensorInfo([i6.length], "float32", i6);
}
var TH = {
  kernelName: hb,
  backendName: "webgl",
  kernelFunc: kH
};
var NH = Vr + `
  return x < 0.0 ? 0./0. : log(x);
`;
var RH = `
  vec4 result = log(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);
  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);
  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);
  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);
  return result;
`;
var $H = Nt({ opSnippet: NH, packedOpSnippet: RH, cpuKernelImpl: sO });
var GH = {
  kernelName: _i,
  backendName: "webgl",
  kernelFunc: $H
};
var EH = Vr + `
  return log(1.0 + x);
`;
var LH = Nt({ opSnippet: EH });
var MH = {
  kernelName: Ui,
  backendName: "webgl",
  kernelFunc: LH
};
var WH = "return float(a >= 1.0 && b >= 1.0);";
var DH = `
  return vec4(
    vec4(greaterThanEqual(a, vec4(1.0))) *
    vec4(greaterThanEqual(b, vec4(1.0))));
`;
var FH = Re({
  opSnippet: WH,
  packedOpSnippet: DH,
  dtype: "bool"
});
var VH = {
  kernelName: bc,
  backendName: "webgl",
  kernelFunc: FH
};
var zH = "return float(!(x >= 1.0));";
var PH = Nt({ opSnippet: zH });
var AH = {
  kernelName: xc,
  backendName: "webgl",
  kernelFunc: PH
};
var OH = "return float(a >= 1.0 || b >= 1.0);";
var XH = `
  return min(
    vec4(greaterThanEqual(a, vec4(1.0))) +
    vec4(greaterThanEqual(b, vec4(1.0))),
    vec4(1.0));
`;
var KH = Re({ opSnippet: OH, packedOpSnippet: XH, dtype: "bool" });
var ZH = {
  kernelName: yc,
  backendName: "webgl",
  kernelFunc: KH
};
var BH = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["x"], this.outputShape = [];
    const i6 = e, a = t[3] - 1;
    this.outputShape = t;
    let l;
    const c = `float(${s}) + float(${o}) * sum`;
    r === 0.5 ? l = `inversesqrt(${c})` : r === 1 ? l = `1.0/(${c})` : l = `exp(log(${c}) * float(-${r}));`, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];
        int d = coords[3];
        float x = getX(b, r, c, d);
        float sum = 0.0;
        for (int j = -${i6}; j <= ${i6}; j++) {
          int idx = d + j;
          if (idx >= 0 && idx <=  ${a}) {
            float z = getX(b, r, c, idx);
            sum += z * z;
          }
        }
        float val = x * ${l};
        setOutput(val);
      }
    `;
  }
};
var HH = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["x"], this.outputShape = [], this.packedInputs = true, this.packedOutput = true;
    const i6 = e, a = t[3] - 1;
    this.outputShape = t;
    let l;
    const c = `float(${s}) + float(${o}) * sum`;
    r === 0.5 ? l = `inversesqrt(${c})` : r === 1 ? l = `1.0/(${c})` : l = `exp(log(${c}) * float(-${r}));`, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords.x;
        int r = coords.y;
        int c = coords.z;
        int d = coords.w;

        bool hasNextCol = d < ${this.outputShape[3]};
        bool hasNextRow = c < ${this.outputShape[2]};

        vec4 sum = vec4(0.);
        vec4 xFragAtOutputCoords = getX(b, r, c, d);

        vec4 xAtOutputCoords = vec4(
          getChannel(xFragAtOutputCoords, vec2(c, d)),
          hasNextCol ?
            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,
          hasNextRow ?
            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,
          (hasNextRow && hasNextCol) ?
            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0
        );

        int firstChannel = d - ${i6};
        vec2 cache = vec2(0.);
        if(firstChannel >= 0){
          vec4 firstChannelFrag = getX(b, r, c, firstChannel);
          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));
            if(hasNextRow){
              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));
            }
        }

        ivec2 depth = ivec2(d, d + 1);
        for (int j = - ${i6}; j <= ${i6}; j++) {
          ivec2 idx = depth + j;
          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));
          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${a}));

          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;
          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;

          if(depthInRange || depthPlusOneInRange){
            vec4 z = vec4(0.);
            vec4 xFragAtCurrentDepth;
            z.xz = cache.xy;
            if(depthPlusOneInRange && hasNextCol){
              xFragAtCurrentDepth = idx.y != d ?
                getX(b, r, c, idx.y) : xFragAtOutputCoords;
              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));
              if(hasNextRow){
                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));
              }
            }
            cache.xy = z.yw;
            sum += z * z;
          }
        }
        vec4 result = xAtOutputCoords * ${l};
        setOutput(result);
      }
    `;
  }
};
var _H = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { depthRadius: r, bias: i6, alpha: a, beta: l } = s, c = F().getBool("WEBGL_PACK_NORMALIZATION") ? new HH(o.shape, r, i6, a, l) : new BH(o.shape, r, i6, a, l);
  return e.runWebGLProgram(c, [o], o.dtype);
};
var UH = {
  kernelName: wc,
  backendName: "webgl",
  kernelFunc: _H
};
var YH = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["inputImage", "outputImage", "dy"], this.outputShape = [], this.outputShape = t, this.depth = t[3], this.depthRadius = e, this.bias = s, this.alpha = o, this.beta = r, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];

        float result = 0.0;
        for (int d = 0; d < ${this.depth}; ++d) {
          int depthBegin = int(max(0.0, float(d - ${e})));
          int depthEnd = int(min(float(${this.depth}),
              float(d + ${e} + 1)));

          const int MIN_DEPTH_BEGIN = 0;
          const int MAX_DEPTH_END = ${this.depth};

          float norm = 0.0;
          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd) {
              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);
            }
            else {
              break;
            }
          }

          norm = float(${o}) * norm + float(${s});

          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd){
              float dyi = -2.0 * float(${o})
                * float(${r})
                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)
                / norm;
              if (k == d) {
                dyi += pow(norm, -1.0 * ${r});
              }
              if (k == coords[3]) {
                dyi *= getDy(b, r, c, d);
                result += dyi;
              }
            }
            else {
              break;
            }
          }
      }
      setOutput(result);
      }
    `;
  }
};
var QH = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, y: r, dy: i6 } = t, { depthRadius: a, bias: l, alpha: c, beta: u } = s, d = new YH(o.shape, a, l, c, u);
  return e.runWebGLProgram(d, [o, r, i6], o.dtype);
};
var JH = {
  kernelName: Sh,
  backendName: "webgl",
  kernelFunc: QH
};
function jH(n, t, e, s) {
  const o = X(t), i6 = X(n.shape) / o, a = et({ inputs: { x: n }, attrs: { shape: [i6, o] }, backend: s }), l = qo(a, n.dtype, "max", s), c = et({ inputs: { x: l }, attrs: { shape: e }, backend: s });
  return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(l), c;
}
function pC(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reductionIndices: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a), d = u != null, h = e.shouldExecuteOnCPU([o]);
  let p = o;
  if (d) {
    if (h) {
      const w = e.texData.get(p.dataId).values, y6 = new Array(a);
      for (let k6 = 0; k6 < y6.length; k6++)
        y6[k6] = o.shape[u[k6]];
      const I = om(w, o.shape, o.dtype, u, y6);
      p = e.makeTensorInfo(y6, o.dtype);
      const v = e.texData.get(p.dataId);
      v.values = I;
    } else
      p = vu(o, u, e);
    c = ie(c.length, a);
  }
  Ne("max", c, a);
  const [f, m] = ye(p.shape, c);
  let g = f;
  i6 && (g = re(f, l));
  let b;
  if (h) {
    const w = e.texData.get(p.dataId).values, y6 = oO(w, X(m), g, o.dtype);
    b = e.makeTensorInfo(g, o.dtype);
    const I = e.texData.get(b.dataId);
    I.values = y6;
  } else
    b = jH(p, m, g, e);
  return d && e.disposeIntermediateTensorInfo(p), b;
}
var qH = {
  kernelName: Ic,
  backendName: "webgl",
  kernelFunc: pC
};
var t_ = rm + `
  return max(a, b);
`;
var e_ = `
  vec4 result = vec4(max(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + jo + `
  return result;
`;
var n_ = Re({
  opSnippet: t_,
  packedOpSnippet: e_,
  cpuKernelImpl: rO
});
var s_ = {
  kernelName: Yi,
  backendName: "webgl",
  kernelFunc: n_
};
function o_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  Er(o, "maxPool");
  const { filterSize: r, strides: i6, pad: a, dimRoundingMode: l } = s, c = 1;
  C(Le(i6, c), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${i6} and dilations '${c}'`);
  const u = $n(o.shape, r, i6, c, a, l);
  if (u.filterWidth === 1 && u.filterHeight === 1 && $t(u.inShape, u.outShape))
    return nn({ inputs: { x: o }, backend: e });
  const d = new wi(u, "max", false);
  return e.runWebGLProgram(d, [o], o.dtype);
}
var r_ = {
  kernelName: Cc,
  backendName: "webgl",
  kernelFunc: o_
};
function i_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { filterSize: r, strides: i6, pad: a, dataFormat: l, dimRoundingMode: c } = s, u = [1, 1, 1], d = vs(o.shape, r, i6, u, a, c, l), h = new am(d, "max", false);
  return e.runWebGLProgram(h, [o], o.dtype);
}
var a_ = {
  kernelName: vc,
  backendName: "webgl",
  kernelFunc: i_
};
var l_ = class {
  constructor(t) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = t.inShape;
    const e = t.strideHeight, s = t.strideWidth, o = t.dilationHeight, r = t.effectiveFilterHeight, i6 = t.effectiveFilterWidth, a = r - 1 - t.padInfo.top, l = i6 - 1 - t.padInfo.left, c = r * i6 - 1;
    this.userCode = `
      const ivec2 pads = ivec2(${a}, ${l});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${r};
          wR += ${o}) {
          float dyR = float(dyRCorner + wR) / ${e}.0;

          if (dyR < 0.0 || dyR >= ${t.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${i6}; wC++) {
            float dyC = float(dyCCorner + wC) / ${s}.0;

            if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);
            int maxPosValue = ${c} - int(getMaxPos(b, idyR, idyC, d));

            // Get the current value, check it against the value from the
            // position matrix.
            int curPosValue = wR * ${i6} + wC;
            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

            dotProd += dyValue * mask;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var c_ = class {
  constructor(t) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = t.inShape;
    const e = t.strideDepth, s = t.strideHeight, o = t.strideWidth, r = t.dilationDepth, i6 = t.dilationHeight, a = t.dilationWidth, l = t.effectiveFilterDepth, c = t.effectiveFilterHeight, u = t.effectiveFilterWidth, d = l - 1 - t.padInfo.front, h = c - 1 - t.padInfo.top, p = u - 1 - t.padInfo.left, f = l * c * u - 1;
    this.userCode = `
      const ivec3 pads = ivec3(${d}, ${h}, ${p});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${l};
           wD += ${r}) {
          float dyD = float(dyDCorner + wD) / ${e}.0;

          if (dyD < 0.0 || dyD >= ${t.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${c};
              wR += ${i6}) {
            float dyR = float(dyRCorner + wR) / ${s}.0;

            if (dyR < 0.0 || dyR >= ${t.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${u};
                wC += ${a}) {
              float dyC = float(dyCCorner + wC) / ${o}.0;

              if (dyC < 0.0 || dyC >= ${t.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);
              int maxPosValue = ${f} -
                  int(getMaxPos(batch, idyD, idyR, idyC, ch));

              // Get the current value, check it against the value from the
              // position matrix.
              int curPosValue =
                  wD * ${c} * ${u} +
                  wR * ${u} + wC;
              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

              dotProd += dyValue * mask;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
function u_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r } = t, i6 = r, { filterSize: a, strides: l, pad: c, dimRoundingMode: u } = s, d = [1, 1, 1], h = vs(i6.shape, a, l, d, c, u), p = new am(
    h,
    "max",
    true
    /* get positions */
  ), f = e.runWebGLProgram(p, [i6], i6.dtype), m = new c_(h), g = e.runWebGLProgram(m, [o, f], i6.dtype);
  return e.disposeIntermediateTensorInfo(f), g;
}
var d_ = {
  kernelName: Th,
  backendName: "webgl",
  kernelFunc: u_
};
function h_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { dy: o, input: r, output: i6 } = t, a = r;
  Er([r, i6], "maxPoolGrad");
  const { filterSize: l, strides: c, pad: u, dimRoundingMode: d } = s, h = $n(a.shape, l, c, 1, u, d), p = true, f = new wi(h, "max", p), m = e.runWebGLProgram(f, [a], a.dtype), g = new l_(h), b = e.runWebGLProgram(g, [o, m], a.dtype);
  return e.disposeIntermediateTensorInfo(m), b;
}
var p_ = {
  kernelName: kh,
  backendName: "webgl",
  kernelFunc: h_
};
function f_(n, t, e, s) {
  let o = new wi(e, "max", false);
  const r = s.runWebGLProgram(o, [n], "float32");
  o = new wi(e, "max", true, true, t);
  const i6 = s.runWebGLProgram(o, [n], "float32");
  return [r, i6];
}
var m_ = {
  kernelName: pb,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { x: s } = n, { filterSize: o, strides: r, pad: i6, includeBatchInIndex: a } = t, l = e;
    C(s.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${s.shape.length}.`);
    const c = [1, 1];
    C(Le(r, c), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${r} and dilations '${c}'`);
    const u = $n(s.shape, o, r, c, i6), [d, h] = f_(s, a, u, l);
    return [d, h];
  }
};
function g_(n, t, e, s) {
  const o = X(t), i6 = X(n.shape) / o, a = et({ inputs: { x: n }, attrs: { shape: [i6, o] }, backend: s }), l = qo(a, "float32", "mean", s), c = et({ inputs: { x: l }, attrs: { shape: e }, backend: s });
  return s.disposeIntermediateTensorInfo(a), s.disposeIntermediateTensorInfo(l), c;
}
var b_ = {
  kernelName: Sc,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { x: s } = n, { keepDims: o, axis: r } = t, i6 = e, a = s.shape.length, l = Ct(r, s.shape);
    let c = l;
    const u = qt(c, a), d = u != null, h = i6.shouldExecuteOnCPU([s]), p = [];
    let f = s;
    if (d) {
      if (h) {
        const y6 = i6.texData.get(f.dataId).values, I = new Array(a);
        for (let S = 0; S < I.length; S++)
          I[S] = s.shape[u[S]];
        const v = om(y6, s.shape, s.dtype, u, I);
        f = i6.makeTensorInfo(I, s.dtype);
        const k6 = i6.texData.get(f.dataId);
        k6.values = v;
      } else
        f = vu(s, u, i6);
      p.push(f), c = ie(c.length, a);
    }
    Ne("sum", c, a);
    const [m, g] = ye(f.shape, c);
    let b = m;
    o && (b = re(m, l));
    const x6 = g_(f, g, b, i6);
    for (const w of p)
      i6.disposeIntermediateTensorInfo(w);
    return x6;
  }
};
function x_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = Ct(r, o.shape);
  let c = l;
  const u = qt(c, a);
  let d = o;
  u != null && (d = ze({ inputs: { x: o }, backend: e, attrs: { perm: u } }), c = ie(c.length, o.shape.length)), Ne("min", c, a);
  const [h, p] = ye(d.shape, c), f = X(p), m = et({ inputs: { x: d }, backend: e, attrs: { shape: [-1, f] } }), g = qo(m, m.dtype, "min", e);
  let b;
  if (i6) {
    const x6 = re(h, l);
    b = et({ inputs: { x: g }, backend: e, attrs: { shape: x6 } });
  } else
    b = et({ inputs: { x: g }, backend: e, attrs: { shape: h } });
  return e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(g), u != null && e.disposeIntermediateTensorInfo(d), b;
}
var y_ = {
  kernelName: kc,
  backendName: "webgl",
  kernelFunc: x_
};
var w_ = rm + `
  return min(a, b);
`;
var I_ = `
  vec4 result = vec4(min(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + jo + `
  return result;
`;
var C_ = Re({
  opSnippet: w_,
  packedOpSnippet: I_,
  cpuKernelImpl: iO
});
var v_ = {
  kernelName: Qi,
  backendName: "webgl",
  kernelFunc: C_
};
var S_ = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.outputShape = e.map(
      (u, d) => u[0] + t[d] + u[1]
      /* afterPad */
    );
    const o = t.length, r = Vt(o), i6 = e.map((u) => u[0]).join(","), a = e.map((u, d) => u[0] + t[d]).join(","), l = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, o), c = s === "reflect" ? 0 : 1;
    if (o === 1) {
      this.userCode = `
        int start = ${i6};
        int end = ${a};

        void main() {
          int outC = getOutputCoords();
          if (outC < start) {
            outC = start * 2 - outC - ${c};
          } else if(outC >= end) {
            outC = (end - 1) * 2 - outC + ${c};
          }
          setOutput(getX(outC - start));
        }
      `;
      return;
    }
    this.userCode = `
      ${r} start = ${r}(${i6});
      ${r} end = ${r}(${a});

      void main() {
        ${r} outC = getOutputCoords();
        for (int i = 0; i < ${o}; i++) {
          if (outC[i] < start[i]) {
            outC[i] = start[i] * 2 - outC[i] - ${c};
          } else if(outC[i] >= end[i]) {
            outC[i] = (end[i] - 1) * 2 - outC[i] + ${c};
          }
        }
        ${r} coords = outC - start;
        setOutput(getX(${l}));
      }
    `;
  }
};
var k_ = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true, this.outputShape = e.map(
      (f, m) => f[0] + t[m] + f[1]
      /* afterPad */
    );
    const o = t.length, r = Vt(o), i6 = e.map((f) => f[0]).join(","), a = e.map((f, m) => f[0] + t[m]).join(","), l = Fe("rc", o), c = Fe("source", o), u = `${l[o - 1]} < ${this.outputShape[o - 1]}`, d = o === 1 ? "source" : `vec2(${c.slice(-2).join()})`, h = s === "reflect" ? 0 : 1;
    let p = "";
    if (o === 1) {
      const f = `
        ${r} source = rc;
        if (source < start) {
          source = start * 2 - source - ${h};
        } else if (source >= end) {
          source = (end - 1) * 2 - source + ${h};
        }
        source -= start;
      `;
      p = `
        ${r} rc = outputLoc;
        ${f}
        result[0] = getChannel(getX(${c.join()}), ${d});
        ${l[o - 1]} += 1;
        if(${u}) {
          ${f}
          result[1] = getChannel(getX(${c.join()}), ${d});
        }
      `;
    } else {
      const f = `
        ${r} source = rc;
        ${r} lt = ${r}(lessThan(source, start));
        ${r} gte = ${r}(greaterThanEqual(source, end));
        ${r} orig = 1 - (lt + gte);
        source = orig * source +
                lt * (start * 2 - source - ${h}) +
                gte * ((end - 1) * 2 - source + ${h});
        source -= start;
      `;
      p = `
        ${r} rc = outputLoc;
        ${f}
        result[0] = getChannel(getX(${c.join()}), ${d});
        ${l[o - 1]} += 1;
        if(${u}) {
          ${f}
          result[1] = getChannel(getX(${c.join()}), ${d});
        }
        rc = outputLoc;
        ${l[o - 2]} += 1;
        if(${l[o - 2]} < ${this.outputShape[o - 2]}) {
          ${f}
          result[2] = getChannel(getX(${c.join()}), ${d});
          ${l[o - 1]} += 1;
          if(${u}) {
            ${f}
            result[3] = getChannel(getX(${c.join()}), ${d});
          }
        }
      `;
    }
    this.userCode = `
      const ${r} start = ${r}(${i6});
      const ${r} end = ${r}(${a});

      void main() {
        ${r} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${p}
        setOutput(result);
      }
    `;
  }
};
var T_ = ({ inputs: n, backend: t, attrs: e }) => {
  const { x: s } = n, { paddings: o, mode: r } = e, i6 = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new k_(s.shape, o, r) : new S_(s.shape, o, r);
  return t.runWebGLProgram(i6, [s], s.dtype);
};
var N_ = {
  kernelName: Tc,
  backendName: "webgl",
  kernelFunc: T_
};
var R_ = `if (b == 0.0) return NAN;
  return mod(a, b);`;
var $_ = `
  vec4 result = mod(a, b);
  bvec4 isNaN = equal(b, vec4(0.0));
  ` + jo + `
  return result;
`;
var G_ = Re({
  opSnippet: R_,
  packedOpSnippet: $_
});
var E_ = {
  kernelName: Ji,
  backendName: "webgl",
  kernelFunc: G_
};
var L_ = class {
  constructor(t, e, s) {
    this.variableNames = ["probs"], this.customUniforms = [{ name: "seed", type: "float" }], this.outputShape = [t, s], this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];

        float r = random(seed);
        float cdf = 0.0;

        for (int i = 0; i < ${e - 1}; i++) {
          cdf += getProbs(batch, i);

          if (r < cdf) {
            setOutput(float(i));
            return;
          }
        }

        // If no other event happened, last event happened.
        setOutput(float(${e - 1}));
      }
    `;
  }
};
var M_ = `
if (a == b) {
  return 1.0;
};
return a / b;`;
var W_ = `
  // vec4 one = vec4(equal(a, b));
  // return one + (vec4(1.0) - one) * a / b;
  vec4 result = a / b;
  if(a.x == b.x) {
    result.x = 1.;
  }
  if(a.y == b.y) {
    result.y = 1.;
  }
  if(a.z == b.z) {
    result.z = 1.;
  }
  if(a.w == b.w) {
    result.w = 1.;
  }

  return result;
`;
var fC = Re({ opSnippet: M_, packedOpSnippet: W_, checkOutOfBounds: true });
var D_ = {
  kernelName: Di,
  backendName: "webgl",
  kernelFunc: fC
};
var Pg = "return a - b;";
var mC = Re({
  opSnippet: Pg,
  packedOpSnippet: Pg,
  supportsComplex: true,
  cpuKernelImpl: NO
});
var F_ = {
  kernelName: pa,
  backendName: "webgl",
  kernelFunc: mC
};
function gC(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { dim: r } = s, i6 = Ct([r], o.shape), a = pC({
    inputs: { x: o },
    backend: e,
    attrs: { reductionIndices: i6, keepDims: false }
  }), l = re(a.shape, i6), c = et({ inputs: { x: a }, backend: e, attrs: { shape: l } }), u = mC({ inputs: { a: o, b: c }, backend: e }), d = uC({ inputs: { x: u }, backend: e }), h = Su({ inputs: { x: d }, backend: e, attrs: { axis: i6, keepDims: false } }), p = et({ inputs: { x: h }, backend: e, attrs: { shape: l } }), f = fC({ inputs: { a: d, b: p }, backend: e });
  return e.disposeIntermediateTensorInfo(a), e.disposeIntermediateTensorInfo(c), e.disposeIntermediateTensorInfo(u), e.disposeIntermediateTensorInfo(d), e.disposeIntermediateTensorInfo(h), e.disposeIntermediateTensorInfo(p), f;
}
var V_ = {
  kernelName: Zc,
  backendName: "webgl",
  kernelFunc: gC
};
function z_(n) {
  const { inputs: t, backend: e, attrs: s } = n, { logits: o } = t, { numSamples: r, seed: i6, normalized: a } = s, l = a ? o : gC({ inputs: { logits: o }, backend: e, attrs: { dim: o.shape.length - 1 } }), c = l.shape[0], u = l.shape[1], d = new L_(c, u, r), h = [[i6]], p = e.runWebGLProgram(d, [l], "int32", h);
  return a || e.disposeIntermediateTensorInfo(l), p;
}
var P_ = {
  kernelName: fb,
  backendName: "webgl",
  kernelFunc: z_
};
var A_ = En + `
  return -x;
`;
var O_ = `
  vec4 result = -x;
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
function X_(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (e.shouldExecuteOnCPU([s])) {
    const r = e.texData.get(s.dataId), [i6, a] = lO(r.values, s.shape, s.dtype);
    return e.makeTensorInfo(a, s.dtype, i6);
  }
  let o;
  return F().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? o = new Vs(s.shape, O_) : o = new qn(s.shape, A_), e.runWebGLProgram(o, [s], s.dtype);
}
var K_ = {
  kernelName: Nc,
  backendName: "webgl",
  kernelFunc: X_
};
var Z_ = zp;
function B_(n) {
  ln("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l } = s, c = e.readSync(o.dataId), u = e.readSync(r.dataId), { selectedIndices: d } = Z_(c, u, i6, a, l);
  return e.makeTensorInfo([d.length], "int32", new Int32Array(d));
}
var H_ = {
  kernelName: Nh,
  backendName: "webgl",
  kernelFunc: B_
};
var __ = Pp;
function U_(n) {
  ln("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, padToMaxOutputSize: c } = s, u = e.readSync(o.dataId), d = e.readSync(r.dataId), { selectedIndices: h, validOutputs: p } = __(u, d, i6, a, l, c);
  return [
    e.makeTensorInfo([h.length], "int32", new Int32Array(h)),
    e.makeTensorInfo([], "int32", new Int32Array([p]))
  ];
}
var Y_ = {
  kernelName: Rh,
  backendName: "webgl",
  kernelFunc: U_
};
var Q_ = Ap;
function J_(n) {
  ln("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs: t, backend: e, attrs: s } = n, { boxes: o, scores: r } = t, { maxOutputSize: i6, iouThreshold: a, scoreThreshold: l, softNmsSigma: c } = s, u = e.readSync(o.dataId), d = e.readSync(r.dataId), h = i6, p = a, f = l, m = c, { selectedIndices: g, selectedScores: b } = Q_(u, d, h, p, f, m);
  return [
    e.makeTensorInfo([g.length], "int32", new Int32Array(g)),
    e.makeTensorInfo([b.length], "float32", new Float32Array(b))
  ];
}
var j_ = {
  kernelName: $h,
  backendName: "webgl",
  kernelFunc: J_
};
var q_ = class {
  constructor(t, e, s, o) {
    this.variableNames = ["indices"], this.outputShape = [t, e], this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int index = round(getIndices(coords.x));
        setOutput(mix(float(${o}), float(${s}),
                      float(index == coords.y)));
      }
    `;
  }
};
var t9 = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o } = t, { dtype: r, depth: i6, onValue: a, offValue: l } = s, c = X(o.shape), u = new q_(c, i6, a, l), d = et({ inputs: { x: o }, backend: e, attrs: { shape: [c] } }), h = e.runWebGLProgram(u, [d], r);
  e.disposeIntermediateTensorInfo(d);
  const p = [...o.shape, i6], f = et({ inputs: { x: h }, backend: e, attrs: { shape: p } });
  return e.disposeIntermediateTensorInfo(h), f;
};
var e9 = {
  kernelName: Gc,
  backendName: "webgl",
  kernelFunc: t9
};
function Kl(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "complex64") {
    const o = Oa({ inputs: { input: s }, backend: e }), r = Kl({ inputs: { x: o }, backend: e }), i6 = ku({ inputs: { input: s }, backend: e }), a = Kl({ inputs: { x: i6 }, backend: e }), l = oo({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return Xa({
      attrs: {
        shape: s.shape,
        dtype: s.dtype,
        value: s.dtype === "string" ? "" : 0
      },
      backend: e
    });
}
var n9 = {
  kernelName: Uc,
  backendName: "webgl",
  kernelFunc: Kl
};
function bC(n) {
  const { inputs: t, backend: e } = n, { x: s } = t;
  if (s.dtype === "string")
    throw new Error("onesLike is not supported under string dtype");
  if (s.dtype === "complex64") {
    const o = Oa({ inputs: { input: s }, backend: e }), r = bC({ inputs: { x: o }, backend: e }), i6 = ku({ inputs: { input: s }, backend: e }), a = Kl({ inputs: { x: i6 }, backend: e }), l = oo({ inputs: { real: r, imag: a }, backend: e });
    return e.disposeIntermediateTensorInfo(o), e.disposeIntermediateTensorInfo(r), e.disposeIntermediateTensorInfo(i6), e.disposeIntermediateTensorInfo(a), l;
  } else
    return Xa({ attrs: { shape: s.shape, dtype: s.dtype, value: 1 }, backend: e });
}
var s9 = {
  kernelName: $c,
  backendName: "webgl",
  kernelFunc: bC
};
function o9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { axis: o } = s;
  if (t.length === 1)
    return Zd({ inputs: { input: t[0] }, backend: e, attrs: { dim: o } });
  const r = t[0].shape, i6 = t[0].dtype;
  t.forEach((u) => {
    Pe(r, u.shape, "All tensors passed to stack must have matching shapes"), C(i6 === u.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const a = [], l = t.map((u) => {
    const d = Zd({ inputs: { input: u }, backend: e, attrs: { dim: o } });
    return a.push(d), d;
  }), c = nC({ inputs: l, backend: e, attrs: { axis: o } });
  return a.forEach((u) => e.disposeIntermediateTensorInfo(u)), c;
}
var r9 = {
  kernelName: Ec,
  backendName: "webgl",
  kernelFunc: o9
};
var i9 = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.customUniforms = [{ name: "value", type: "float" }], this.outputShape = e.map(
      (c, u) => c[0] + t[u] + c[1]
      /* afterPad */
    );
    const o = t.length, r = Vt(o), i6 = e.map((c) => c[0]).join(","), a = e.map((c, u) => c[0] + t[u]).join(","), l = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, o);
    if (o === 1) {
      this.userCode = `
        int start = ${i6};
        int end = ${a};

        void main() {
          int outC = getOutputCoords();
          if (outC < start || outC >= end) {
            setOutput(value);
          } else {
            setOutput(getX(outC - start));
          }
        }
      `;
      return;
    }
    this.userCode = `
      ${r} start = ${r}(${i6});
      ${r} end = ${r}(${a});

      void main() {
        ${r} outC = getOutputCoords();
        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {
          setOutput(value);
        } else {
          ${r} coords = outC - start;
          setOutput(getX(${l}));
        }
      }
    `;
  }
};
var a9 = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "value", type: "float" }], this.outputShape = e.map(
      (m, g) => m[0] + t[g] + m[1]
      /* afterPad */
    );
    const o = t.length, r = Vt(o), i6 = e.map((m) => m[0]).join(","), a = e.map((m, g) => m[0] + t[g]).join(","), l = Fe("rc", o), c = Fe("source", o), u = `${l[o - 1]} < ${this.outputShape[o - 1]}`, d = o === 1 ? "source" : `vec2(${c.slice(-2).join()})`, h = [
      `${r} rc = outputLoc;`,
      `${l[o - 1]} += 1;
       if(${u}) {
      `,
      o === 1 ? "" : `}
       rc = outputLoc;
       ${l[o - 2]} += 1;
       if(${l[o - 2]} < ${this.outputShape[o - 2]}) {`,
      o === 1 ? "" : `  ${l[o - 1]} += 1;
         if(${u}) {`
    ], p = o === 1 ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
    let f = "";
    for (let m = 0, g = o === 1 ? 2 : 4; m < g; m++)
      f += `
        ${h[m]}
        if (${p}) {
          result[${m}] = float(value);
        } else {
          ${r} source = rc - start;
          result[${m}] = getChannel(getX(${c.join()}), ${d});
        }
      `;
    f += o === 1 ? "} " : "}}", this.userCode = `
      const ${r} start = ${r}(${i6});
      const ${r} end = ${r}(${a});

      void main() {
        ${r} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${f}
        setOutput(result);
      }
    `;
  }
};
var xC = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { paddings: r, constantValue: i6 } = s;
  if (X(o.shape) === 0) {
    const c = r.map(
      (u, d) => u[0] + o.shape[d] + u[1]
      /* afterPad */
    );
    return Xa({
      backend: e,
      attrs: { shape: c, value: i6, dtype: o.dtype }
    });
  }
  const a = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new a9(o.shape, r, i6) : new i9(o.shape, r, i6), l = [[i6]];
  return e.runWebGLProgram(a, [o], o.dtype, l);
};
var l9 = {
  kernelName: Lc,
  backendName: "webgl",
  kernelFunc: xC
};
var c9 = `
  if(a < 0.0 && floor(b) < b){
    return NAN;
  }
  if (b == 0.0) {
    return 1.0;
  }
  return (round(mod(b, 2.0)) != 1) ?
      pow(abs(a), b) : sign(a) * pow(abs(a), b);
`;
var u9 = `
  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.
  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));
  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);
  vec4 result = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  bvec4 isExpZero = equal(b, vec4(0.0));
  result.r = isExpZero.r ? 1.0 : result.r;
  result.g = isExpZero.g ? 1.0 : result.g;
  result.b = isExpZero.b ? 1.0 : result.b;
  result.a = isExpZero.a ? 1.0 : result.a;

  bvec4 isNaN1 = lessThan(a, vec4(0.0));
  bvec4 isNaN2 = lessThan(floor(b), b);
  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);
  ` + jo + `
  return result;
`;
var d9 = Re({ opSnippet: c9, packedOpSnippet: u9 });
var h9 = {
  kernelName: qi,
  backendName: "webgl",
  kernelFunc: d9
};
function p9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { axis: r, keepDims: i6 } = s, a = o.shape.length, l = [], c = Ct(r, o.shape);
  let u = c;
  const d = qt(u, a);
  let h = o;
  d != null && (h = ze({ inputs: { x: o }, backend: e, attrs: { perm: d } }), u = ie(u.length, a), l.push(h)), Ne("prod", u, a);
  let p;
  if (e.shouldExecuteOnCPU([h])) {
    const f = e.texData.get(h.dataId).values, { outVals: m, outShape: g, outDtype: b } = uO(h.shape, h.dtype, f, u);
    p = e.makeTensorInfo(g, b, m);
  } else {
    const [f, m] = ye(h.shape, u), g = X(m), b = et({ inputs: { x: h }, backend: e, attrs: { shape: [-1, g] } }), x6 = Yh(o.dtype), w = qo(b, x6, "prod", e);
    p = et({ inputs: { x: w }, backend: e, attrs: { shape: f } }), l.push(b), l.push(w);
  }
  if (i6) {
    l.push(p);
    const f = re(p.shape, c);
    p = et({ inputs: { x: p }, backend: e, attrs: { shape: f } });
  }
  return l.forEach((f) => e.disposeIntermediateTensorInfo(f)), p;
}
var f9 = {
  kernelName: Wc,
  backendName: "webgl",
  kernelFunc: p9
};
function m9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { paramsNestedSplits: o, paramsDenseValues: r, indices: i6 } = t, { outputRaggedRank: a } = s, l = o.map((b) => e.readSync(b.dataId)), c = o.map((b) => b.shape), u = e.readSync(r.dataId), d = e.readSync(i6.dataId), [h, p, f] = dO(l, c, u, r.shape, r.dtype, d, i6.shape, a), m = h.map((b) => e.makeTensorInfo([b.length], "int32", b)), g = e.makeTensorInfo(f, r.dtype, p);
  return m.concat([g]);
}
var g9 = {
  kernelName: mb,
  backendName: "webgl",
  kernelFunc: m9
};
function b9(n) {
  const { inputs: t, backend: e } = n, { starts: s, limits: o, deltas: r } = t, i6 = e.readSync(s.dataId), a = e.readSync(o.dataId), l = e.readSync(r.dataId), [c, u] = hO(i6, s.shape, s.dtype, a, o.shape, l, r.shape), d = e.makeTensorInfo([c.length], "int32", c), h = e.makeTensorInfo([u.length], s.dtype, u);
  return [d, h];
}
var x9 = {
  kernelName: gb,
  backendName: "webgl",
  kernelFunc: b9
};
function y9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { shape: o, values: r, defaultValue: i6, rowPartitionTensors: a } = t, { rowPartitionTypes: l } = s, c = e.readSync(o.dataId), u = e.readSync(r.dataId), d = e.readSync(i6.dataId), h = a.map((g) => e.readSync(g.dataId)), p = a.map((g) => g.shape), [f, m] = pO(c, o.shape, u, r.shape, r.dtype, d, i6.shape, h, p, l);
  return e.makeTensorInfo(f, r.dtype, m);
}
var w9 = {
  kernelName: bb,
  backendName: "webgl",
  kernelFunc: y9
};
var yC = (n) => {
  const { backend: t, attrs: e } = n, { start: s, stop: o, step: r, dtype: i6 } = e, a = fO(s, o, r, i6);
  return t.makeTensorInfo([a.length], i6, a);
};
var I9 = {
  kernelName: Gh,
  backendName: "webgl",
  kernelFunc: yC
};
var C9 = "return 1.0 / x;";
var v9 = Nt({ opSnippet: C9 });
var S9 = {
  kernelName: ta,
  backendName: "webgl",
  kernelFunc: v9
};
var k9 = En + `
  return (x < 0.0) ? 0.0 : x;
`;
var T9 = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var N9 = Nt({ opSnippet: k9, packedOpSnippet: T9 });
var R9 = {
  kernelName: ea,
  backendName: "webgl",
  kernelFunc: N9
};
var $9 = En + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var G9 = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var E9 = Nt({ opSnippet: $9, packedOpSnippet: G9 });
var L9 = {
  kernelName: na,
  backendName: "webgl",
  kernelFunc: E9
};
var M9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ];
    let h;
    r ? h = "(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)" : h = "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${u[0] / d[0]},
          ${u[1] / d[1]});
      const vec2 inputShapeRC = vec2(${a}.0, ${l}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${h};

        // Compute the four integer indices.
        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));
        ivec2 sourceCeilRC = ivec2(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);
        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);
        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);
        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);

        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);

        float top = topLeft + (topRight - topLeft) * fracRC.y;
        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
        float newValue = top + (bottom - top) * fracRC.x;

        setOutput(newValue);
      }
    `;
  }
};
var W9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ];
    let h;
    r ? h = "(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)" : h = "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${u[0] / d[0]},
          ${u[1] / d[1]},
          ${u[1] / d[1]});
      const vec3 inputShapeRC = vec3(${a}.0, ${l}.0,
                                     ${l}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${h};

        // Compute the four integer indices.
        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));
        ivec3 sourceCeilRC = ivec3(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${c - 1};
        bool hasNextRow = coords.z < ${s - 1};

        // In parallel, construct four corners for all four components in
        // packed 2x2 cell.
        vec4 topLeft = vec4(
          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 bottomLeft = vec4(
          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 topRight = vec4(
          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec4 bottomRight = vec4(
          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);

        vec4 top = mix(topLeft, topRight, fracRC.yyzz);
        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);
        vec4 newValue = mix(top, bottom, fracRC.x);

        setOutput(newValue);
      }
    `;
  }
};
function D9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s, [l, c] = a, u = F().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new W9(o.shape, l, c, r, i6) : new M9(o.shape, l, c, r, i6);
  return e.runWebGLProgram(u, [o], "float32");
}
var F9 = {
  kernelName: Vc,
  backendName: "webgl",
  kernelFunc: D9
};
var V9 = class {
  constructor(t, e, s) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = e;
    const [, o, r] = e, [, i6, a] = t, l = [
      s && i6 > 1 ? o - 1 : o,
      s && a > 1 ? r - 1 : r
    ], c = [
      s && i6 > 1 ? i6 - 1 : i6,
      s && a > 1 ? a - 1 : a
    ], u = l[0] / c[0], d = l[1] / c[1], h = 1 / u, p = 1 / d, f = Math.ceil(h) * 2 + 2, m = Math.ceil(p) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${u});
        const float widthScale = float(${d});

        const float invHeightScale = float(${h});
        const float invWidthScale = float(${p});

        const int winHeight = int(${f});
        const int winWidth = int(${m});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(startRLerp - float(winHeight / 2));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(startCLerp - float(winWidth / 2));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${i6}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${a}) {
              continue;
            }

            float dxR = float(dyR) * heightScale;
            int topDxRIndex = int(floor(dxR));
            int bottomDxRIndex = int(min(ceil(dxR), ${o - 1}.0));
            float dxRLerp = dxR - float(topDxRIndex);
            float inverseDxRLerp = 1.0 - dxRLerp;

            float dxC = float(dyC) * widthScale;
            int leftDxCIndex = int(floor(dxC));
            int rightDxCIndex = int(min(ceil(dxC), ${r - 1}.0));
            float dxCLerp = dxC - float(leftDxCIndex);
            float inverseDxCLerp = 1.0 - dxCLerp;

            if (r == topDxRIndex && c == leftDxCIndex) {
              // topLeft
              accumulator +=
                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;
            }

            if (r == topDxRIndex && c == rightDxCIndex) {
              // topRight
              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;
            }

            if (r == bottomDxRIndex && c == leftDxCIndex) {
              // bottomLeft
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;
            }

            if (r == bottomDxRIndex && c == rightDxCIndex) {
              // bottomRight
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};
function z9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s, a = new V9(r.shape, o.shape, i6);
  return e.runWebGLProgram(a, [r], r.dtype);
}
var P9 = {
  kernelName: Mh,
  backendName: "webgl",
  kernelFunc: z9
};
var A9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ], h = o ? "0.5" : "0.0";
    let p;
    r ? p = "max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))" : p = "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${u[0] / d[0]},
          ${u[1] / d[1]});
      const vec2 inputShapeRC = vec2(${a}.0, ${l}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${p};

        // Compute the coordinators of nearest neighbor point.
        ivec2 sourceNearestRC = ivec2(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h})));
        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);

        setOutput(newValue);
      }
    `;
  }
};
var O9 = class {
  constructor(t, e, s, o, r) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = [];
    const [i6, a, l, c] = t;
    this.outputShape = [i6, e, s, c];
    const u = [
      o && e > 1 ? a - 1 : a,
      o && s > 1 ? l - 1 : l
    ], d = [
      o && e > 1 ? e - 1 : e,
      o && s > 1 ? s - 1 : s
    ], h = o ? "0.5" : "0.0";
    let p;
    r ? p = "max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))" : p = "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${u[0] / d[0]},
          ${u[1] / d[1]},
          ${u[1] / d[1]});
      const vec3 inputShapeRC = vec3(${a}.0, ${l}.0,
                                     ${l}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${p};

        // Compute the coordinators of nearest neighbor point.
        ivec3 sourceNearestRC = ivec3(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${h})));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${c - 1};
        bool hasNextRow = coords.z < ${s - 1};

        vec4 newValue = vec4(
          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),
          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);

        setOutput(newValue);
      }
    `;
  }
};
function X9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o } = t, { alignCorners: r, halfPixelCenters: i6, size: a } = s, [l, c] = a, u = F().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new O9(o.shape, l, c, r, i6) : new A9(o.shape, l, c, r, i6);
  return e.runWebGLProgram(u, [o], o.dtype);
}
var K9 = {
  kernelName: Fc,
  backendName: "webgl",
  kernelFunc: X9
};
var Z9 = class {
  constructor(t, e, s) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = e;
    const [, o, r] = e, [, i6, a] = t, l = [
      s && i6 > 1 ? o - 1 : o,
      s && a > 1 ? r - 1 : r
    ], c = [
      s && i6 > 1 ? i6 - 1 : i6,
      s && a > 1 ? a - 1 : a
    ], u = l[0] / c[0], d = l[1] / c[1], h = 1 / u, p = 1 / d, f = Math.ceil(h) * 2 + 2, m = Math.ceil(p) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${u});
        const float widthScale = float(${d});

        const float invHeightScale = float(${h});
        const float invWidthScale = float(${p});

        const int winHeight = int(${f});
        const int winWidth = int(${m});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(floor(startRLerp - float(winHeight / 2)));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(floor(startCLerp - float(winWidth / 2)));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${i6}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${a}) {
              continue;
            }

            float sourceFracRow =
              float(${l[0]}) *
                (float(dyR) / float(${c[0]}));

            float sourceFracCol =
                float(${l[1]}) *
                  (float(dyC) / float(${c[1]}));

            int sourceNearestRow = int(min(
                float(int(${o}) - 1),
                ${s} ? float(round(sourceFracRow)) :
                                  float(floor(sourceFracRow))));

            int sourceNearestCol = int(min(
                float(int(${r}) - 1),
                ${s} ? float(round(sourceFracCol)) :
                                  float(floor(sourceFracCol))));

            if (r == sourceNearestRow && c == sourceNearestCol) {
              accumulator += getDy(b, dyR, dyC, d);
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};
function B9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { images: o, dy: r } = t, { alignCorners: i6 } = s, a = new Z9(r.shape, o.shape, i6);
  return e.runWebGLProgram(a, [r], r.dtype);
}
var H9 = {
  kernelName: Lh,
  backendName: "webgl",
  kernelFunc: B9
};
var _9 = class {
  constructor(t, e) {
    this.variableNames = ["x"];
    const s = t.length;
    if (s > 4)
      throw new Error(`WebGL backend: Reverse of rank-${s} tensor is not yet supported`);
    if (this.outputShape = t, s === 1) {
      this.userCode = `
        void main() {
          int coord = getOutputCoords();
          setOutput(getX(${t[0]} - coord - 1));
        }
      `;
      return;
    }
    const o = (a) => e.indexOf(a) !== -1 && t[a] !== 1 ? `${t[a]} - coords[${a}] - 1` : `coords[${a}]`, r = t.map((a, l) => o(l)).join(","), i6 = Vt(s);
    this.userCode = `
      void main() {
        ${i6} coords = getOutputCoords();
        setOutput(getX(${r}));
      }
    `;
  }
};
var U9 = class {
  constructor(t, e) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true;
    const s = t.length;
    if (s > 4)
      throw new Error(`WebGL backend: Reverse of rank-${s} tensor is not yet supported`);
    this.outputShape = t;
    const o = Fe("rc", s), r = `${o[s - 1]} + 1 < ${this.outputShape[s - 1]}`, i6 = `${o[s - 2]} + 1 < ${this.outputShape[s - 2]}`, a = Vt(s);
    s === 1 ? this.userCode = `
        void main(){
          int rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = getChannel(getX(${t[0]} - rc - 1),
            ${t[0]} - rc - 1);
          if(${r}){
              result.g = getChannel(getX(${t[0]} - (rc  + 1) - 1),
                ${t[0]} - (rc  + 1) - 1);
          }
          setOutput(result);
        }
      ` : this.userCode = `
        void main() {
          ${a} rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = ${l(o.slice())};
          if(${r}){
            result.g = ${c(o.slice())};
          }
          if(${i6}) {
            result.b = ${u(o.slice())};
            if(${r}) {
              result.a = ${d(o.slice())};
            }
          }
          setOutput(result);
        }
    `;
    function l(f) {
      return h(f);
    }
    function c(f) {
      return f[s - 1] = "(" + f[s - 1] + " + 1)", h(f);
    }
    function u(f) {
      return f[s - 2] = "(" + f[s - 2] + " + 1)", h(f);
    }
    function d(f) {
      return f[s - 1] = "(" + f[s - 1] + " + 1)", f[s - 2] = "(" + f[s - 2] + " + 1)", h(f);
    }
    function h(f) {
      const m = t.map((x6, w) => p(w, f)), g = m.join(","), b = m.slice(-2).join(",");
      return `getChannel(getX(${g}), vec2(${b}))`;
    }
    function p(f, m) {
      return e.indexOf(f) !== -1 && t[f] !== 1 ? `${t[f]} - ${m[f]} - 1` : `${m[f]}`;
    }
  }
};
function Y9(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { dims: r } = s, i6 = o.shape.length, a = Ct(r, o.shape);
  if (i6 === 0)
    return nn({ inputs: { x: o }, backend: e });
  const l = F().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new U9(o.shape, a) : new _9(o.shape, a);
  return e.runWebGLProgram(l, [o], o.dtype);
}
var Q9 = {
  kernelName: zc,
  backendName: "webgl",
  kernelFunc: Y9
};
var J9 = class {
  constructor(t, e) {
    this.variableNames = ["Image"], this.outputShape = [], this.customUniforms = [{ name: "params", type: "vec4" }];
    const s = t[1], o = t[2];
    this.outputShape = t;
    let r = "";
    typeof e == "number" ? r = `float outputValue = ${e.toFixed(2)};` : r = `
        vec3 fill = vec3(${e.join(",")});
        float outputValue = fill[coords[3]];`, this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];
          int y = coords[1];
          float coordXFloat = (float(x) - params[0]) * params[3] -
            (float(y) - params[1]) * params[2];
          float coordYFloat = (float(x) - params[0]) * params[2] +
            (float(y) - params[1]) * params[3];
          int coordX = int(round(coordXFloat + params[0]));
          int coordY = int(round(coordYFloat + params[1]));
          ${r}
          if(coordX >= 0 && coordX < ${o} && coordY >= 0 && coordY < ${s}) {
            outputValue = getImage(coords[0], coordY, coordX, coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
};
var j9 = {
  kernelName: Hh,
  backendName: "webgl",
  kernelFunc: ({ inputs: n, attrs: t, backend: e }) => {
    const { image: s } = n, { radians: o, fillValue: r, center: i6 } = t, a = e, l = new J9(s.shape, r), [c, u] = Jp(i6, s.shape[1], s.shape[2]), d = [[c, u, Math.sin(o), Math.cos(o)]];
    return a.runWebGLProgram(l, [s], s.dtype, d);
  }
};
var q9 = `
  // OpenGL ES does not support round function.
  // The algorithm is based on banker's rounding.
  float base = floor(x);
  if ((x - base) < 0.5) {
    return floor(x);
  } else if ((x - base) > 0.5) {
    return ceil(x);
  } else {
    if (mod(base, 2.0) == 0.0) {
      return base;
    } else {
      return base + 1.0;
    }
  }
`;
var tU = Nt({ opSnippet: q9 });
var eU = {
  kernelName: sa,
  backendName: "webgl",
  kernelFunc: tU
};
var nU = "return inversesqrt(x);";
var sU = Nt({ opSnippet: nU, cpuKernelImpl: mO });
var oU = {
  kernelName: oa,
  backendName: "webgl",
  kernelFunc: sU
};
var lm = class {
  constructor(t, e, s, o, r, i6, a = true, l = false) {
    this.variableNames = ["updates", "indices", "defaultValue"], this.outputShape = i6;
    const c = Vt(r.length), u = Vt(i6.length);
    let d = "";
    s === 1 ? d = "i" : s === 2 && (d = "i, j");
    const h = `getIndices(${d})`;
    let p = "";
    o === 1 ? p = "i" : o === 2 && (p = "i, coords[1]");
    const f = `getUpdates(${p})`;
    let m = "";
    l && (m = "coords[0], coords[1]");
    const g = `getDefaultValue(${m})`, b = e > 1 ? "strides[j]" : "strides";
    this.userCode = `
        ${c} strides = ${c}(${r});

        void main() {
          ${u} coords = getOutputCoords();
          float sum = 0.0;
          bool found = false;
          for (int i = 0; i < ${t}; i++) {
            int flattenedIndex = 0;
            for (int j = 0; j < ${e}; j++) {
              int index = round(${h});
              flattenedIndex += index * ${b};
            }
            if (flattenedIndex == coords[0]) {
              sum += ${f};
              found = true;
            }
          }
          setOutput(mix(${g}, sum, float(found)));
        }
      `;
  }
};
var rU = class {
  constructor(t, e, s, o, r, i6, a = true, l = false) {
    this.variableNames = ["updates", "indices", "defaultValue"], this.packedInputs = true, this.packedOutput = true, this.outputShape = i6;
    const c = Vt(r.length), u = Vt(i6.length);
    let d = "";
    s === 1 ? d = "i" : s === 2 && (d = "i, j");
    const h = `getIndices(${d})`;
    let p = "";
    o === 1 ? p = "i" : o === 2 && (p = "i, coords[1]");
    const f = `getUpdates(${p})`;
    let m = "";
    l && (m = "coords[0], coords[1]");
    const g = `getDefaultValue(${m})`, b = e > 1 ? "strides[j]" : "strides", x6 = e > 1 ? "strides[j + 1]" : "strides";
    this.userCode = `
        ${c} strides = ${c}(${r});

        void main() {
          ${u} coords = getOutputCoords();
          vec4 sum = vec4(0.);
          vec4 found = vec4(0.);
          for (int i = 0; i < ${t}; i+=2) {
            ivec2 flattenedIndex = ivec2(0);
            for (int j = 0; j < ${e}; j+=2) {
              ivec4 index = round(${h});
              flattenedIndex += index.xz * ${b};
              if (j + 1 < ${e}) {
                flattenedIndex += index.yw * ${x6};
              }
            }
            if (flattenedIndex[0] == coords[0] || flattenedIndex[1] == coords[0] ||
                flattenedIndex[0] == coords[0] + 1 || flattenedIndex[1] == coords[0] + 1) {
              vec4 updVals = ${f};
              if (flattenedIndex[0] == coords[0]) {
                sum.xy += updVals.xy;
                found.xy = vec2(1.);
              } else if (flattenedIndex[0] == coords[0] + 1) {
                sum.zw += updVals.xy;
                found.zw = vec2(1.);
              }
              if (flattenedIndex[1] == coords[0]) {
                sum.xy += updVals.zw;
                found.xy = vec2(1.);
              } else if (flattenedIndex[1] == coords[0] + 1) {
                sum.zw += updVals.zw;
                found.zw = vec2(1.);
              }
            }
          }
          setOutput(mix(${g}, sum, found));
        }
      `;
  }
};
function iU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { indices: o, updates: r } = t, { shape: i6 } = s, { sliceRank: a, numUpdates: l, sliceSize: c, strides: u, outputSize: d } = to(r, o, i6), h = [d / c, c];
  if (d === 0)
    return e.makeTensorInfo(i6, o.dtype);
  const p = et({ inputs: { x: o }, backend: e, attrs: { shape: [l, a] } }), f = et({ inputs: { x: r }, backend: e, attrs: { shape: [l, c] } }), m = e.makeTensorInfo([], "float32", new Float32Array([0]));
  let g;
  F().getBool("WEBGL_PACK") ? g = new rU(l, a, p.shape.length, f.shape.length, u, h) : g = new lm(l, a, p.shape.length, f.shape.length, u, h);
  const b = e.runWebGLProgram(g, [f, p, m], f.dtype), x6 = et({ inputs: { x: b }, backend: e, attrs: { shape: i6 } });
  return e.disposeIntermediateTensorInfo(p), e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(b), e.disposeIntermediateTensorInfo(m), x6;
}
var aU = {
  kernelName: xb,
  backendName: "webgl",
  kernelFunc: iU
};
var lU = class {
  constructor(t, e, s, o) {
    this.variableNames = ["sortedSequence", "values"], this.customUniforms = [{ name: "numInputs", type: "int" }], this.outputShape = [t, s];
    const r = "while (left < right) {", i6 = `for (int i = 0; i < ${Math.ceil(Math.log2(e + 1))}; ++i) { if (left >= right) break;`, a = F().getNumber("WEBGL_VERSION") === 2 ? r : i6, l = o === "left" ? "<" : "<=";
    this.userCode = `
       int findBound(int batch, float value) {
         int left = 0;
         int right = numInputs;
         int mid;
         ${a}
           mid = (left + right) / 2;
           if (getSortedSequence(batch, mid) ${l} value) {
             left = mid + 1;
           } else {
             right = mid;
           }
         }
         return right;
       }

       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int valueIndex = coords[1];

         float value = getValues(batch, valueIndex);

         setOutput(float(findBound(batch, value)));
       }
     `;
  }
};
function cU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sortedSequence: o, values: r } = t, { side: i6 } = s, a = new lU(o.shape[0], o.shape[1], r.shape[1], i6), l = [[o.shape[1]]];
  return e.runWebGLProgram(a, [o, r], "int32", l);
}
var uU = {
  kernelName: wb,
  backendName: "webgl",
  kernelFunc: cU
};
var dU = class {
  constructor(t, e, s) {
    this.variableNames = ["c", "a", "b"], this.outputShape = e;
    let o, r;
    if (s > 4)
      throw Error(`Where for rank ${s} is not yet supported`);
    if (s === 1)
      r = "resRC", o = "resRC";
    else {
      const a = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"], l = [], c = [];
      for (let u = 0; u < e.length; u++)
        c.push(`${a[u]}`), u < t && l.push(`${a[u]}`);
      o = l.join(), r = c.join();
    }
    const i6 = Vt(s);
    this.userCode = `
      void main() {
        ${i6} resRC = getOutputCoords();
        float cVal = getC(${o});
        if (cVal >= 1.0) {
          setOutput(getA(${r}));
        } else {
          setOutput(getB(${r}));
        }
      }
    `;
  }
};
function hU(n) {
  const { inputs: t, backend: e } = n, { condition: s, t: o, e: r } = t, i6 = new dU(s.shape.length, o.shape, o.shape.length);
  return e.runWebGLProgram(i6, [s, o, r], tn(o.dtype, r.dtype));
}
var pU = {
  kernelName: Pc,
  backendName: "webgl",
  kernelFunc: hU
};
var fU = `
  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.
  // see: https://arxiv.org/abs/1706.02515
  float scaleAlpha = ${ru};
  float scale = ${iu};
  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);
`;
var mU = Nt({ opSnippet: fU });
var gU = {
  kernelName: ra,
  backendName: "webgl",
  kernelFunc: mU
};
var bU = Vr + `
  return 1.0 / (1.0 + exp(-1.0 * x));
`;
var xU = `
  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var yU = Nt({
  opSnippet: bU,
  packedOpSnippet: xU,
  cpuKernelImpl: bO
});
var wU = {
  kernelName: ca,
  backendName: "webgl",
  kernelFunc: yU
};
var IU = `
  if (isnan(x)) { return 0.0; }
  return sign(x);
`;
var CU = Nt({ opSnippet: IU });
var vU = {
  kernelName: la,
  backendName: "webgl",
  kernelFunc: CU
};
var SU = Vr + `
  return sin(x);
`;
var kU = `
  vec4 result = sin(x);
  bvec4 isNaN = isnan(x);
  ${jo}
  return result;
`;
var TU = Nt({ opSnippet: SU, packedOpSnippet: kU });
var NU = {
  kernelName: ia,
  backendName: "webgl",
  kernelFunc: TU
};
var RU = `
  float e2x = exp(x);
  return (e2x - 1.0 / e2x) / 2.0;
`;
var $U = Nt({ opSnippet: RU });
var GU = {
  kernelName: aa,
  backendName: "webgl",
  kernelFunc: $U
};
var EU = `
  float epsilon = 1.1920928955078125e-7;
  float threshold = log(epsilon) + 2.0;

  bool too_large = x > -threshold;
  bool too_small = x < threshold;

  float result;
  float exp_x = exp(x);

  if (too_large){
    result = x;
  }
  else if (too_small){
    result = exp_x;
  }
  else{
    result = log(exp_x + 1.0);
  }
  return result;
`;
var LU = Nt({ opSnippet: EU });
var MU = {
  kernelName: ua,
  backendName: "webgl",
  kernelFunc: LU
};
var WU = (n) => {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { blockShape: r, paddings: i6 } = s;
  C(o.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
  const a = r.reduce((b, x6) => b * x6), l = [[0, 0]];
  l.push(...i6);
  for (let b = 1 + r.length; b < o.shape.length; ++b)
    l.push([0, 0]);
  const c = [], u = xC({
    inputs: { x: o },
    backend: e,
    attrs: { paddings: l, constantValue: 0 }
  }), d = Na(u.shape, r, a, false), h = Ra(d.length, r.length, false), p = $a(u.shape, r, a, false), f = et({ inputs: { x: u }, backend: e, attrs: { shape: d } }), m = ze({
    inputs: { x: f },
    backend: e,
    attrs: { perm: h }
  }), g = et({ inputs: { x: m }, backend: e, attrs: { shape: p } });
  return c.push(u), c.push(f), c.push(m), c.forEach((b) => e.disposeIntermediateTensorInfo(b)), g;
};
var DU = {
  kernelName: Xc,
  backendName: "webgl",
  kernelFunc: WU
};
function FU(n) {
  const { inputs: t, backend: e } = n, { indices: s, values: o, denseShape: r, defaultValue: i6 } = t;
  if (r.shape.length !== 1)
    throw new Error(`Dense shape must be a vector, saw:
         ${r.shape}`);
  if (s.shape.length !== 2)
    throw new Error(`Indices must be a matrix, saw:
         ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Values must be a vector, saw:
         ${o.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Default value must be a scalar, saw:
        ${i6.shape}`);
  const a = e.readSync(s.dataId), l = e.readSync(o.dataId), c = e.readSync(r.dataId), u = e.readSync(i6.dataId)[0], [d, h, p, f, m] = yO(a, s.shape, s.dtype, l, o.dtype, c, u);
  return [
    e.makeTensorInfo(h, s.dtype, d),
    e.makeTensorInfo([h[0]], o.dtype, p),
    e.makeTensorInfo([f.length], "bool", new Uint8Array(f.map((g) => Number(g)))),
    e.makeTensorInfo([m.length], s.dtype, new Int32Array(m))
  ];
}
var VU = {
  kernelName: Wh,
  backendName: "webgl",
  kernelFunc: FU
};
function zU(n) {
  const { inputs: t, backend: e } = n, { inputIndices: s, inputShape: o, newShape: r } = t;
  if (s.shape.length !== 2)
    throw new Error(`Input indices should be a matrix but received shape ${s.shape}`);
  if (o.shape.length !== 1)
    throw new Error(`Input shape should be a vector but received shape ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Target shape should be a vector but received shape ${r.shape}`);
  const i6 = Array.from(e.readSync(o.dataId)), a = e.readSync(s.dataId), l = Array.from(e.readSync(r.dataId)), [c, u, d] = wO(a, s.shape, s.dtype, i6, l);
  return [
    e.makeTensorInfo(u, s.dtype, c),
    e.makeTensorInfo([d.length], r.dtype, new Int32Array(d))
  ];
}
var PU = {
  kernelName: Dh,
  backendName: "webgl",
  kernelFunc: zU
};
function AU(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
              ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
              ${r.shape}`);
  const i6 = e.readSync(s.dataId), a = e.readSync(o.dataId), l = e.readSync(r.dataId), [c, u] = KI(i6, s.shape, s.dtype, a, l, true);
  return e.makeTensorInfo(u, s.dtype, c);
}
var OU = {
  kernelName: Fh,
  backendName: "webgl",
  kernelFunc: AU
};
function XU(n) {
  const { inputs: t, backend: e } = n, { data: s, indices: o, segmentIds: r } = t;
  if (s.shape.length < 1)
    throw new Error("Data should be at least 1 dimensional but received scalar");
  if (o.shape.length !== 1)
    throw new Error(`Indices should be a vector but received shape
             ${o.shape}`);
  if (r.shape.length !== 1)
    throw new Error(`Segment ids should be a vector but received shape
             ${r.shape}`);
  const i6 = e.readSync(s.dataId), a = e.readSync(o.dataId), l = e.readSync(r.dataId), [c, u] = KI(i6, s.shape, s.dtype, a, l);
  return e.makeTensorInfo(u, s.dtype, c);
}
var KU = {
  kernelName: Vh,
  backendName: "webgl",
  kernelFunc: XU
};
function ZU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { sparseIndices: o, sparseValues: r, defaultValue: i6 } = t, { outputShape: a } = s, { sliceRank: l, numUpdates: c, sliceSize: u, strides: d, outputSize: h } = to(r, o, a), p = false;
  if (r.dtype === "string") {
    const b = e.bufferSync(o), x6 = e.bufferSync(r), w = gs(e.readSync(i6.dataId)[0]), y6 = gO(b, x6, a, h, u, c, l, d, w, p);
    return e.makeTensorInfo(a, y6.dtype, y6.values);
  }
  const f = new lm(c, l, o.shape.length, r.shape.length, d, [h, 1], p), m = e.runWebGLProgram(f, [r, o, i6], r.dtype), g = et({ inputs: { x: m }, backend: e, attrs: { shape: a } });
  return e.disposeIntermediateTensorInfo(m), g;
}
var BU = {
  kernelName: Ib,
  backendName: "webgl",
  kernelFunc: ZU
};
function HU(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { numOrSizeSplits: r, axis: i6 } = s, a = Ct(i6, o.shape)[0], l = pf(o, r, a), c = o.shape.length, u = new Array(c).fill(0), d = o.shape.slice();
  return l.map((h) => {
    const p = [...d];
    p[a] = h;
    const f = zr({ inputs: { x: o }, backend: e, attrs: { begin: u, size: p } });
    return u[a] += h, f;
  });
}
var _U = {
  kernelName: Kc,
  backendName: "webgl",
  kernelFunc: HU
};
var Ag = "return sqrt(x);";
var UU = Nt({ opSnippet: Ag, packedOpSnippet: Ag, cpuKernelImpl: IO });
var YU = {
  kernelName: da,
  backendName: "webgl",
  kernelFunc: UU
};
var QU = "return x * x;";
var JU = Nt({ opSnippet: QU });
var jU = {
  kernelName: zh,
  backendName: "webgl",
  kernelFunc: JU
};
var Og = "return (a - b) * (a - b);";
var qU = Re({ opSnippet: Og, packedOpSnippet: Og });
var t5 = {
  kernelName: ha,
  backendName: "webgl",
  kernelFunc: qU
};
function e5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t;
  if (o.dtype !== "string")
    throw new Error("Input must be of datatype string");
  const r = e.readSync(o.dataId), i6 = ys(r), a = CO(i6, "string", s);
  return e.makeTensorInfo(o.shape, "string", a);
}
var n5 = {
  kernelName: Bc,
  backendName: "webgl",
  kernelFunc: e5
};
function s5({ inputs: n, attrs: t, backend: e }) {
  const { x: s } = n, o = En + `
    return x > 0.0 ? 1.0 : float(${t.alpha});
  `, r = new qn(s.shape, o);
  return e.runWebGLProgram(r, [s], s.dtype);
}
var o5 = {
  kernelName: ba,
  backendName: "webgl",
  kernelFunc: s5
};
var r5 = class {
  constructor(t, e, s) {
    this.variableNames = ["x"], this.outputShape = s;
    const o = s.length, r = Vt(s.length), i6 = Vt(s.length);
    let a = "";
    if (o === 1)
      a = "coords * strides + begin";
    else {
      let l = 0;
      a = s.map((c, u) => (l++, s.length === 1 ? `coords * strides[${u}] + begin[${u}]` : `coords[${l - 1}] * strides[${u}] + begin[${u}]`)).join(",");
    }
    this.userCode = `
      ${r} begin = ${r}(${t});
      ${r} strides = ${r}(${e});

      void main() {
        ${i6} coords = getOutputCoords();
        setOutput(getX(${a}));
      }
    `;
  }
};
function i5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { begin: r, end: i6, strides: a, beginMask: l, endMask: c, ellipsisMask: u, newAxisMask: d, shrinkAxisMask: h } = s, { finalShapeSparse: p, finalShape: f, isIdentity: m, sliceDim0: g, isSimpleSlice: b, begin: x6, end: w, strides: y6 } = Up(o.shape, r, i6, a, l, c, u, d, h);
  let I;
  if (m)
    I = et({ inputs: { x: o }, backend: e, attrs: { shape: f } });
  else if (g || b) {
    C(o.shape.length >= 1, () => `Input must have rank at least 1, got: ${o.shape.length}`);
    const k6 = Bp(x6, w, y6), S = zr({ inputs: { x: o }, backend: e, attrs: { begin: x6, size: k6 } });
    I = et({ inputs: { x: S }, backend: e, attrs: { shape: f } }), e.disposeIntermediateTensorInfo(S);
  } else if (e.shouldExecuteOnCPU([o])) {
    const S = e.readSync(o.dataId), N = vt(o.shape, o.dtype, S), R = vO(p, N, y6, x6);
    I = e.makeTensorInfo(f, o.dtype, R.values);
  } else {
    const S = new r5(x6, y6, p);
    I = e.runWebGLProgram(S, [o], o.dtype);
  }
  const v = et({ inputs: { x: I }, backend: e, attrs: { shape: f } });
  return e.disposeIntermediateTensorInfo(I), v;
}
var a5 = {
  kernelName: Ph,
  backendName: "webgl",
  kernelFunc: i5
};
function l5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { separator: o, nGramWidths: r, leftPad: i6, rightPad: a, padWidth: l, preserveShortSequences: c } = s, { data: u, dataSplits: d } = t, h = e.readSync(u.dataId), p = e.readSync(d.dataId), [f, m] = SO(h, p, o, r, i6, a, l, c);
  return [
    e.makeTensorInfo([f.length], "string", f),
    e.makeTensorInfo(d.shape, "int32", m)
  ];
}
var c5 = {
  kernelName: Ah,
  backendName: "webgl",
  kernelFunc: l5
};
function u5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { skipEmpty: o } = s, { input: r, delimiter: i6 } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (r.shape.length !== 1)
    throw new Error(`Input must be a vector, got shape: ${r.shape}`);
  if (i6.shape.length !== 0)
    throw new Error(`Delimiter must be a scalar, got shape: ${i6.shape}`);
  const a = e.readSync(r.dataId), l = e.readSync(i6.dataId)[0], [c, u, d] = kO(a, l, o), h = u.length;
  return [
    e.makeTensorInfo([h, 2], "int32", c),
    e.makeTensorInfo([h], "string", u),
    e.makeTensorInfo([2], "int32", new Int32Array(d))
  ];
}
var d5 = {
  kernelName: Oh,
  backendName: "webgl",
  kernelFunc: u5
};
function h5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { numBuckets: o } = s, { input: r } = t;
  if (r.dtype !== "string")
    throw new Error("Input must be of datatype string");
  if (o <= 0)
    throw new Error("Number of buckets must be at least 1");
  const i6 = e.readSync(r.dataId), a = TO(i6, o);
  return e.makeTensorInfo(r.shape, "int32", a);
}
var p5 = {
  kernelName: Xh,
  backendName: "webgl",
  kernelFunc: h5
};
var f5 = "return tan(x);";
var m5 = Nt({ opSnippet: f5 });
var g5 = {
  kernelName: fa,
  backendName: "webgl",
  kernelFunc: m5
};
var b5 = `
  float e2x = exp(-2.0 * abs(x));
  return sign(x) * (1.0 - e2x) / (1.0 + e2x);
`;
var x5 = Nt({ opSnippet: b5 });
var y5 = {
  kernelName: ma,
  backendName: "webgl",
  kernelFunc: x5
};
function w5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { tensor: o, indices: r, updates: i6 } = t, { sliceRank: a, numUpdates: l, sliceSize: c, strides: u, outputSize: d } = to(i6, r, o.shape), h = [d / c, c];
  if (d === 0)
    return e.makeTensorInfo(o.shape, r.dtype);
  const p = et({ inputs: { x: r }, backend: e, attrs: { shape: [l, a] } }), f = et({ inputs: { x: i6 }, backend: e, attrs: { shape: [l, c] } }), m = et({ inputs: { x: o }, backend: e, attrs: { shape: h } }), g = new lm(l, a, p.shape.length, f.shape.length, u, h, false, true), b = e.runWebGLProgram(g, [f, p, m], m.dtype), x6 = et({ inputs: { x: b }, backend: e, attrs: { shape: o.shape } });
  return e.disposeIntermediateTensorInfo(p), e.disposeIntermediateTensorInfo(f), e.disposeIntermediateTensorInfo(m), e.disposeIntermediateTensorInfo(b), x6;
}
var I5 = {
  kernelName: yb,
  backendName: "webgl",
  kernelFunc: w5
};
var C5 = class {
  constructor(t, e) {
    this.variableNames = ["A"];
    const s = new Array(t.length);
    for (let i6 = 0; i6 < s.length; i6++)
      s[i6] = t[i6] * e[i6];
    this.outputShape = s, this.rank = s.length;
    const o = Vt(this.rank), r = v5(t);
    this.userCode = `
      void main() {
        ${o} resRC = getOutputCoords();
        setOutput(getA(${r}));
      }
    `;
  }
};
function v5(n) {
  const t = n.length;
  if (t > 5)
    throw Error(`Tile for rank ${t} is not yet supported`);
  if (t === 1)
    return `imod(resRC, ${n[0]})`;
  const e = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"], s = [];
  for (let o = 0; o < n.length; o++)
    s.push(`imod(${e[o]}, ${n[o]})`);
  return s.join();
}
function wC(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { reps: r } = s;
  if (o.dtype === "string" || o.shape.length > 5) {
    const l = e.readSync(o.dataId), c = o.dtype === "string" ? l.map((h) => gs(h)) : l, u = vt(o.shape, o.dtype, c), d = RO(u, r);
    return e.makeTensorInfo(d.shape, d.dtype, d.values);
  }
  const i6 = new C5(o.shape, r);
  return e.runWebGLProgram(i6, [o], o.dtype);
}
var S5 = {
  kernelName: ga,
  backendName: "webgl",
  kernelFunc: wC
};
var k5 = class {
  /**
   * @param shape desired output shape (can be larger than input shape, output
   *                                    will be padded with -Infinity)
   */
  constructor(t) {
    this.variableNames = ["x", "indices"], this.customUniforms = [
      { name: "n", type: "int" },
      { name: "firstPass", type: "int" },
      { name: "negativeInf", type: "float" },
      { name: "dir", type: "int" },
      { name: "inc", type: "int" }
    ], this.outputShape = t, this.userCode = `
       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // We compare elements pair-wise within a group of size 2 * inc.
         // The comparing rule for each group alternates between ascending
         // and descending. Within each group, we compare each pair at
         // positions i and i+inc. To decide whether an element at position i
         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than
         // inc, it is in the first half of the group, we denote it as x0,
         // otherwise we denote it as x1.
         // For example, as shown in the Bitonic top K paper referenced above,
         // Figure5(a) shows that element[1] is in the
         // second half of the group when group size is 2, but it is in the
         // first half of the group when group size is 4.

         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;
         int i = isFirstInPair ? elemIdx : elemIdx - inc;

         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));
         float x0 = i0 < n ? getX(batch, i0) : negativeInf;
         float x1 = i1 < n ? getX(batch, i1) : negativeInf;

         // Denotes which direction indices are in (ascending or descending).
         bool reverse = imod(elemIdx, 2 * dir) >= dir;
         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);
         if (reverse == isGreater) { // Elements in opposite order of direction
           int iTemp = i0;
           i0 = i1;
           i1 = iTemp;
         }
         if (isFirstInPair) {
            setOutput(float(i0));
         } else {
            setOutput(float(i1));
         }
       }
     `;
  }
};
var T5 = class {
  /**
   * @param shape desired output shape (must be half of the input size)
   */
  constructor(t) {
    this.variableNames = ["x", "indices"], this.customUniforms = [
      { name: "n", type: "int" },
      { name: "firstPass", type: "int" },
      { name: "k", type: "int" }
    ], this.outputShape = t, this.userCode = `
    void main() {
         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // The output size is half of the previous size.
         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),
         // we only need to output the indices at positions |, the indices at
         // positions _ can be thrown away, see Figure5(b) After Phase 2
         // (Merge phase) in the Bitonic Top K paper referenced above.
         // For example, the paper shows we only need to output the orange bars.
         // The output sequence should look like this | | | | | | | |.
         // Because the sequence is halved, to map the output index back
         // to the previous sequence to find the corresponding value,
         // we need to double the index. When we double the index,
         // we basically interpolate a position, so 2i looks like
         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position
         // of each 2k positions by - elemIdx % k. E.g. for output at
         // index 4,5,6,7, we want to get the corresponding element at
         // original index 8,9,10,11, for output at index 8,9,10,11,
         // we want to get the corresponding element at original index
         // 16,17,18,19, so on and so forth.

         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));
         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));

         float x0 = getX(batch, i0);
         float x1 = i1 < n ? getX(batch, i1) : x0;

         setOutput(x0 >= x1 ? float(i0) : float(i1));
       }
     `;
  }
};
function lo(n, t) {
  t !== null && n.disposeIntermediateTensorInfo(t);
}
function Xg(n) {
  let t = 1;
  for (; t < n; )
    t *= 2;
  return t;
}
function N5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o } = t, { k: r, sorted: i6 } = s, a = F().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"), l = F().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"), c = o.shape, u = c[c.length - 1];
  if (e.shouldExecuteOnCPU([o]) || u < a || r > l) {
    const R = e.readSync(o.dataId), [M6, V] = $O(R, c, o.dtype, r, i6);
    return [
      e.makeTensorInfo(M6.shape, M6.dtype, M6.values),
      e.makeTensorInfo(V.shape, V.dtype, V.values)
    ];
  }
  if (r === 0)
    return c[c.length - 1] = 0, [
      e.makeTensorInfo(c, o.dtype, []),
      e.makeTensorInfo(c, "int32", [])
    ];
  if (u === 1)
    return [
      o,
      Xa({ attrs: { shape: c, dtype: "int32", value: 0 }, backend: e })
    ];
  const d = e.texData.get(o.dataId), h = d !== null && d.isPacked, p = h ? e.unpackTensor(o) : o, m = X(c) / u, g = et({ inputs: { x: p }, attrs: { shape: [m, u] }, backend: e });
  h && lo(e, p);
  const b = Xg(r), x6 = Xg(u);
  let w = null;
  const y6 = () => w === null ? [g, g] : [g, w], I = (R, M6, V) => {
    const z = y6(), P = new k5(V), O = [[u], [w === null ? 1 : 0], [Number.NEGATIVE_INFINITY], [R], [M6]], B6 = w;
    w = e.runWebGLProgram(P, z, "int32", O), lo(e, B6);
  };
  for (let R = 1; R < b; R *= 2) {
    const M6 = R * 2;
    for (let V = R; V >= 1; V /= 2)
      I(M6, V, [m, x6]);
  }
  for (let R = x6; R > b; R /= 2) {
    const M6 = y6(), V = new T5([m, R / 2]), P = [[u], [w === null ? 1 : 0], [b]], A = w;
    w = e.runWebGLProgram(V, M6, "int32", P), lo(e, A);
    const O = b / 2, B6 = O * 2;
    for (let Z = O; Z >= 1; Z /= 2)
      I(B6, Z, w.shape);
  }
  let v = w;
  w = zr({ inputs: { x: w }, backend: e, attrs: { begin: 0, size: [m, r] } }), lo(e, v);
  let k6 = hC({ inputs: { x: g, indices: w }, backend: e, attrs: { axis: 1, batchDims: 1 } });
  lo(e, g);
  const S = c.slice(0, -1);
  S.push(r), v = w, w = et({ inputs: { x: w }, attrs: { shape: S }, backend: e }), lo(e, v);
  const N = k6;
  return k6 = et({ inputs: { x: k6 }, attrs: { shape: S }, backend: e }), lo(e, N), [k6, w];
}
var R5 = {
  kernelName: Kh,
  backendName: "webgl",
  kernelFunc: N5
};
var $5 = class {
  constructor(t, e, s, o, r, i6) {
    this.variableNames = ["Image", "Transforms"], this.outputShape = i6;
    const a = s === "nearest" ? 1 : 2;
    let l;
    switch (o) {
      case "constant":
        l = 1;
        break;
      case "reflect":
        l = 2;
        break;
      case "wrap":
        l = 3;
        break;
      case "nearest":
        l = 4;
        break;
      default:
        l = 1;
        break;
    }
    this.userCode = `
            float mapCoord(float outCoord, float len) {
              float inCoord = outCoord;
              if(${l} == 2) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    if (inCoord < sz2) {
                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +
                      inCoord;
                    }
                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    inCoord -= sz2 * float(int(float(inCoord / sz2)));
                    if (inCoord >= len) {
                      inCoord = sz2 - inCoord - 1.0;
                    }
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${l} == 3) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord -= len * float(int(float(inCoord / sz)));
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${l} == 4) {
                return clamp(outCoord, 0.0, len - 1.0);
              } else {
                return outCoord;
              }
            }

            float readWithFillValue(int batch, int coordY, int coordX,
              int channel) {
              float outputValue;
              if (0 <= coordY && coordY < ${t} && 0 <= coordX && coordX < ${e}) {
                  outputValue = getImage(batch, coordY, coordX, channel);
              } else {
                outputValue = float(${r});
              }
              return outputValue;
            }

            void main() {
              ivec4 coords = getOutputCoords();
              float outputValue;
              int batch = coords[0];
              int x = coords[2];
              int y = coords[1];
              int channel = coords[3];
              float xf = float(x);
              float yf = float(y);
              float a1 = getTransforms(batch, 0);
              float a2 = getTransforms(batch, 1);
              float a3 = getTransforms(batch, 2);
              float b1 = getTransforms(batch, 3);
              float b2 = getTransforms(batch, 4);
              float b3 = getTransforms(batch, 5);
              float c1 = getTransforms(batch, 6);
              float c2 = getTransforms(batch, 7);
              float projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = float(${r});
              } else {
                float inX = (a1 * xf + a2 * yf + a3) / projection;
                float inY = (b1 * xf + b2 * yf + b3) / projection;
                float mapX = mapCoord(inX, float(${e}));
                float mapY = mapCoord(inY, float(${t}));

                if (${a} == 1) {
                  int coordY = int(round(mapY));
                  int coordX = int(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  float yFloor = floor(mapY);
                  float xFloor = floor(mapX);
                  float yCeil = yFloor + 1.0;
                  float xCeil = xFloor + 1.0;
                  float valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);
                  float valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutput(outputValue);
            }
        `;
  }
};
function G5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { image: o, transforms: r } = t, { interpolation: i6, fillMode: a, fillValue: l, outputShape: c } = s, [u, d, h, p] = o.shape, [f, m] = c ?? [d, h], g = [
    u,
    f,
    m,
    p
  ], b = new $5(d, h, i6, a, l, g);
  return e.runWebGLProgram(b, [o, r], "float32");
}
var E5 = {
  kernelName: Zh,
  backendName: "webgl",
  kernelFunc: G5
};
function L5(n) {
  const { inputs: t, attrs: e, backend: s } = n, { axis: o } = e, { x: r } = t;
  Er(r, "unique"), console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
  const i6 = s.readSync(r.dataId), { outputValues: a, outputShape: l, indices: c } = GO(i6, o, r.shape, r.dtype);
  return [
    s.makeTensorInfo(l, r.dtype, a),
    s.makeTensorInfo([c.length], "int32", c)
  ];
}
var M5 = {
  kernelName: Bh,
  backendName: "webgl",
  kernelFunc: L5
};
function W5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { value: o } = t;
  let { axis: r } = s;
  r < 0 && (r += o.shape.length);
  const i6 = o, a = i6.shape.length, l = o.shape[r], c = new Array(a - 1);
  let u = 0;
  for (let m = 0; m < a; m++)
    m !== r && (c[u++] = i6.shape[m]);
  const d = [], h = new Array(a).fill(0), p = i6.shape.slice();
  p[r] = 1;
  const f = new Array(l);
  for (let m = 0; m < f.length; m++) {
    h[r] = m;
    const g = zr({ inputs: { x: i6 }, backend: e, attrs: { begin: h, size: p } }), b = et({ inputs: { x: g }, backend: e, attrs: { shape: c } });
    f[m] = b, d.push(g);
  }
  return d.forEach((m) => e.disposeIntermediateTensorInfo(m)), f;
}
var D5 = {
  kernelName: Hc,
  backendName: "webgl",
  kernelFunc: W5
};
var F5 = class {
  constructor(t, e) {
    this.variableNames = ["x", "segmentIds"];
    const s = t.windowSize, o = t.batchSize, r = t.inSize, i6 = t.numSegments, a = i6 * Math.ceil(r / s);
    this.outputShape = [o, a];
    const l = "0.0", c = "sumValue", u = Math.floor(s / 4) * 4, d = s % 4, h = `
        sumValue += dot(values, segFilter);
    `;
    let p = "";
    r % s > 0 && (p = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return initializationValue;
        }
      `);
    let f = "";
    r % s > 0 && (f = `
        if (inIdx < 0 || inIdx >= ${r}) {
          return -1.0;
        }
      `), this.userCode = `
      const float initializationValue = ${l};

      float getValue(int batch, int inIdx) {
        ${p}
        return getX(batch, inIdx);
      }

      float getSegmentIdAtIndex(int inIdx) {
        ${f}
        return getSegmentIds(inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = int(floor(float(outIdx) / float(
          ${i6})) * float(${s}));
        int currentSeg = int(mod(float(outIdx), float(${i6})));

        float sumValue = 0.0;

        for (int i = 0; i < ${u}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0
          );

          ${h}
        }

        int inIdx = inOffset + ${u};
        if (${d === 1}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            0,
            0,
            0
          );

          ${h}
        } else if (${d === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
              0,
              0
          );

          ${h}
        } else if (${d === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            0
          );

          ${h}
        }
        setOutput(${c});
      }
    `;
  }
};
function V5(n) {
  const { inputs: t, backend: e, attrs: s } = n, { x: o, segmentIds: r } = t, { numSegments: i6 } = s, a = o.shape.length, l = [];
  let c = 0;
  const u = qt([c], a);
  let d = o;
  u != null && (d = ze({ inputs: { x: o }, backend: e, attrs: { perm: u } }), l.push(d), c = ie(1, a)[0]);
  const h = gx(d.shape, c, i6), p = X([d.shape[c]]), f = et({ inputs: { x: d }, backend: e, attrs: { shape: [-1, p] } });
  l.push(f);
  const m = Yh(o.dtype), g = (y6, I, v, k6, S) => {
    const N = y6.shape[0], R = y6.shape[1], M6 = mx(R, S), V = { windowSize: M6, inSize: R, batchSize: N, numSegments: S }, z = new F5(V, I), P = e.compileAndRun(z, [y6, v], k6);
    if (l.push(P), P.shape[1] === S)
      return P;
    const A = yC({
      backend: e,
      attrs: { start: 0, stop: S, step: 1, dtype: "float32" }
    }), O = wC({
      inputs: { x: A },
      backend: e,
      attrs: { reps: [R / M6] }
    });
    return l.push(A), l.push(O), g(P, I, O, k6, S);
  }, b = g(f, "unsortedSegmentSum", r, m, i6), x6 = et({ inputs: { x: b }, backend: e, attrs: { shape: h } });
  let w = x6;
  if (u != null) {
    l.push(x6);
    const y6 = js(u);
    w = ze({ inputs: { x: w }, backend: e, attrs: { perm: y6 } });
  }
  return l.forEach((y6) => e.disposeIntermediateTensorInfo(y6)), w;
}
var z5 = {
  kernelName: _c,
  backendName: "webgl",
  kernelFunc: V5
};
var P5 = [
  CX,
  SX,
  NX,
  GX,
  LX,
  DX,
  VX,
  PX,
  KX,
  BX,
  UX,
  JX,
  tK,
  oK,
  aK,
  cK,
  dK,
  mK,
  bK,
  yK,
  vK,
  GK,
  LK,
  FK,
  zK,
  ZK,
  HK,
  QK,
  rX,
  qK,
  oZ,
  lZ,
  fZ,
  bZ,
  yZ,
  IZ,
  vZ,
  NZ,
  GZ,
  MZ,
  DZ,
  VZ,
  PZ,
  XZ,
  ZZ,
  UZ,
  QZ,
  qZ,
  nB,
  oB,
  lB,
  hB,
  gB,
  yB,
  CB,
  vB,
  kB,
  NB,
  $B,
  EB,
  MB,
  VB,
  AB,
  KB,
  BB,
  UB,
  JB,
  eH,
  rH,
  oX,
  aH,
  nZ,
  uH,
  pH,
  gH,
  aX,
  wH,
  SH,
  TH,
  GH,
  MH,
  VH,
  AH,
  ZH,
  UH,
  JH,
  qH,
  s_,
  r_,
  a_,
  d_,
  p_,
  m_,
  b_,
  y_,
  v_,
  N_,
  E_,
  P_,
  uX,
  K_,
  H_,
  Y_,
  j_,
  AK,
  e9,
  s9,
  r9,
  l9,
  h9,
  cX,
  f9,
  g9,
  x9,
  w9,
  I9,
  OK,
  D_,
  S9,
  R9,
  L9,
  hX,
  F9,
  P9,
  K9,
  H9,
  Q9,
  j9,
  eU,
  oU,
  aU,
  uU,
  pU,
  gU,
  wU,
  vU,
  NU,
  GU,
  RK,
  V_,
  MU,
  DU,
  VU,
  PU,
  OU,
  KU,
  BU,
  _U,
  YU,
  jU,
  t5,
  n5,
  o5,
  a5,
  c5,
  d5,
  p5,
  F_,
  yX,
  g5,
  y5,
  I5,
  S5,
  R5,
  E5,
  wX,
  M5,
  D5,
  z5,
  n9
];
for (const n of P5)
  sn(n);
var IC = "(function(){"use strict";class Wt{constructor(n=[],e=Qt){if(this.data=n,this.length=this.data.length,this.compare=e,this.length>0)for(let t=(this.length>>1)-1;t>=0;t--)this._down(t)}push(n){this.data.push(n),this.length++,this._up(this.length-1)}pop(){if(this.length===0)return;const n=this.data[0],e=this.data.pop();return this.length--,this.length>0&&(this.data[0]=e,this._down(0)),n}peek(){return this.data[0]}_up(n){const{data:e,compare:t}=this,s=e[n];for(;n>0;){const r=n-1>>1,i=e[r];if(t(s,i)>=0)break;e[n]=i,n=r}e[n]=s}_down(n){const{data:e,compare:t}=this,s=this.length>>1,r=e[n];for(;n<s;){let i=(n<<1)+1,h=e[i];const l=i+1;if(l<this.length&&t(e[l],h)<0&&(i=l,h=e[l]),t(h,r)>=0)break;e[n]=h,n=i}e[n]=r}}function Qt(o,n){return o<n?-1:o>n?1:0}const yt=o=>{const{v1:n,v2:e}=o;let t=0;for(let s=0;s<n.length;s++){let r=(n[s]^e[s])>>>0;t+=Zt(r)}return t},Zt=o=>{var n=o-(o>>1&1431655765);return n=(n>>2&858993459)+(n&858993459),n=(n>>4)+n&252645135,n=(n>>8)+n&16711935,n=(n>>16)+n&65535,n},ct=1,vt=o=>{const{keywidth:n,keyheight:e,querywidth:t,queryheight:s,matches:r}=o,i=t*1.2,h=-i,l=s*1.2,u=-l,f=12,g=10,a=-1,j=1,y=1/Math.log(10),m=Math.max(n,e),M=Math.floor(n/2),T=Math.floor(e/2),E=[];for(let N=0;N<r.length;N++){const $=r[N].querypoint.scale,K=r[N].keypoint.scale;K==0&&console.log("ERROR divide zero");const v=$/K;E.push(v*m)}E.sort((N,$)=>N-$);const R=.25*E[Math.floor(E.length/2)-(E.length%2==0?1:0)-1],q=Math.max(5,Math.ceil((i-h)/R)),I=Math.max(5,Math.ceil((l-u)/R)),z=q*I,B=z*f,c=[],p=[],S={};for(let N=0;N<r.length;N++){const $=r[N].querypoint,K=r[N].keypoint,{x:v,y:V,scale:L,angle:C}=xt({querypoint:$,keypoint:K,keycenterX:M,keycenterY:T,scaleOneOverLogK:y});if(v<h||v>=i||V<u||V>=l||C<=-Math.PI||C>Math.PI||L<a||L>=j){c[N]=!1;continue}let X=q*(v-h)/(i-h),wt=I*(V-u)/(l-u),pt=f*(C+Math.PI)/(2*Math.PI),dt=g*(L-a)/(j-a);p[N]={binX:X,binY:wt,binAngle:pt,binScale:dt};let it=Math.floor(X-.5),lt=Math.floor(wt-.5),ht=Math.floor(dt-.5),jt=(Math.floor(pt-.5)+f)%f;if(it<0||it+1>=q||lt<0||lt+1>=I||ht<0||ht+1>=g){c[N]=!1;continue}for(let ut=0;ut<2;ut++){let kt=it+ut;for(let bt=0;bt<2;bt++){let un=lt+bt;for(let It=0;It<2;It++){let cn=(jt+It)%f;for(let Rt=0;Rt<2;Rt++){let fn=ht+Rt;const Nt=kt+un*q+cn*z+fn*B;S[Nt]===void 0&&(S[Nt]=0),S[Nt]+=1}}}}c[N]=!0}let d=0,D=-1;if(Object.keys(S).forEach(N=>{S[N]>d&&(d=S[N],D=N)}),d<3)return[];const U=Math.floor(D%B%z%q),F=Math.floor((D-U)%B%z/q),P=Math.floor((D-U-F*q)%B/z),Y=Math.floor((D-U-F*q-P*z)/B),G=[];for(let N=0;N<r.length;N++){if(!c[N])continue;const $=p[N];if(Math.abs($.binX-(U+.5))>=ct||Math.abs($.binY-(F+.5))>=ct||Math.abs($.binScale-(Y+.5))>=ct)continue;const L=Math.abs($.binAngle-(P+.5));Math.min(L,f-L)>=ct||G.push(r[N])}return G},xt=({querypoint:o,keypoint:n,keycenterX:e,keycenterY:t,scaleOneOverLogK:s})=>{let r=o.angle-n.angle;r<=-Math.PI?r+=2*Math.PI:r>Math.PI&&(r-=2*Math.PI);const i=o.scale/n.scale,h=i*Math.cos(r),l=i*Math.sin(r),u=[h,-l,l,h],f=[u[0]*n.x+u[1]*n.y,u[2]*n.x+u[3]*n.y],g=o.x-f[0],a=o.y-f[1];return{x:u[0]*e+u[1]*t+g,y:u[2]*e+u[3]*t+a,angle:r,scale:Math.log(i)*s}},At=Object.prototype.toString;function W(o){return At.call(o).endsWith("Array]")}function te(o){var n=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(!W(o))throw new TypeError("input must be an array");if(o.length===0)throw new TypeError("input must not be empty");var e=n.fromIndex,t=e===void 0?0:e,s=n.toIndex,r=s===void 0?o.length:s;if(t<0||t>=o.length||!Number.isInteger(t))throw new Error("fromIndex must be a positive integer smaller than length");if(r<=t||r>o.length||!Number.isInteger(r))throw new Error("toIndex must be an integer greater than fromIndex and at most equal to length");for(var i=o[t],h=t+1;h<r;h++)o[h]>i&&(i=o[h]);return i}function ee(o){var n=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(!W(o))throw new TypeError("input must be an array");if(o.length===0)throw new TypeError("input must not be empty");var e=n.fromIndex,t=e===void 0?0:e,s=n.toIndex,r=s===void 0?o.length:s;if(t<0||t>=o.length||!Number.isInteger(t))throw new Error("fromIndex must be a positive integer smaller than length");if(r<=t||r>o.length||!Number.isInteger(r))throw new Error("toIndex must be an integer greater than fromIndex and at most equal to length");for(var i=o[t],h=t+1;h<r;h++)o[h]<i&&(i=o[h]);return i}function qt(o){var n=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(W(o)){if(o.length===0)throw new TypeError("input must not be empty")}else throw new TypeError("input must be an array");var e;if(n.output!==void 0){if(!W(n.output))throw new TypeError("output option must be an array if specified");e=n.output}else e=new Array(o.length);var t=ee(o),s=te(o);if(t===s)throw new RangeError("minimum and maximum input values are equal. Cannot rescale a constant array");var r=n.min,i=r===void 0?n.autoMinMax?t:0:r,h=n.max,l=h===void 0?n.autoMinMax?s:1:h;if(i>=l)throw new RangeError("min option must be smaller than max option");for(var u=(l-i)/(s-t),f=0;f<o.length;f++)e[f]=(o[f]-t)*u+i;return e}const ft=" ".repeat(2),_t=" ".repeat(4);function ne(){return Tt(this)}function Tt(o,n={}){const{maxRows:e=15,maxColumns:t=10,maxNumSize:s=8,padMinus:r="auto"}=n;return`${o.constructor.name} {
${ft}[
${_t}${se(o,e,t,s,r)}
${ft}]
${ft}rows: ${o.rows}
${ft}columns: ${o.columns}
}`}function se(o,n,e,t,s){const{rows:r,columns:i}=o,h=Math.min(r,n),l=Math.min(i,e),u=[];if(s==="auto"){s=!1;t:for(let f=0;f<h;f++)for(let g=0;g<l;g++)if(o.get(f,g)<0){s=!0;break t}}for(let f=0;f<h;f++){let g=[];for(let a=0;a<l;a++)g.push(oe(o.get(f,a),t,s));u.push(`${g.join(" ")}`)}return l!==i&&(u[u.length-1]+=` ... ${i-e} more columns`),h!==r&&u.push(`... ${r-n} more rows`),u.join(`
${_t}`)}function oe(o,n,e){return(o>=0&&e?` ${zt(o,n-1)}`:zt(o,n)).padEnd(n)}function zt(o,n){let e=o.toString();if(e.length<=n)return e;let t=o.toFixed(n);if(t.length>n&&(t=o.toFixed(Math.max(0,n-(t.length-n)))),t.length<=n&&!t.startsWith("0.000")&&!t.startsWith("-0.000"))return t;let s=o.toExponential(n);return s.length>n&&(s=o.toExponential(Math.max(0,n-(s.length-n)))),s.slice(0)}function re(o,n){o.prototype.add=function(t){return typeof t=="number"?this.addS(t):this.addM(t)},o.prototype.addS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)+t);return this},o.prototype.addM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)+t.get(s,r));return this},o.add=function(t,s){return new n(t).add(s)},o.prototype.sub=function(t){return typeof t=="number"?this.subS(t):this.subM(t)},o.prototype.subS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)-t);return this},o.prototype.subM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)-t.get(s,r));return this},o.sub=function(t,s){return new n(t).sub(s)},o.prototype.subtract=o.prototype.sub,o.prototype.subtractS=o.prototype.subS,o.prototype.subtractM=o.prototype.subM,o.subtract=o.sub,o.prototype.mul=function(t){return typeof t=="number"?this.mulS(t):this.mulM(t)},o.prototype.mulS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)*t);return this},o.prototype.mulM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)*t.get(s,r));return this},o.mul=function(t,s){return new n(t).mul(s)},o.prototype.multiply=o.prototype.mul,o.prototype.multiplyS=o.prototype.mulS,o.prototype.multiplyM=o.prototype.mulM,o.multiply=o.mul,o.prototype.div=function(t){return typeof t=="number"?this.divS(t):this.divM(t)},o.prototype.divS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)/t);return this},o.prototype.divM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)/t.get(s,r));return this},o.div=function(t,s){return new n(t).div(s)},o.prototype.divide=o.prototype.div,o.prototype.divideS=o.prototype.divS,o.prototype.divideM=o.prototype.divM,o.divide=o.div,o.prototype.mod=function(t){return typeof t=="number"?this.modS(t):this.modM(t)},o.prototype.modS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)%t);return this},o.prototype.modM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)%t.get(s,r));return this},o.mod=function(t,s){return new n(t).mod(s)},o.prototype.modulus=o.prototype.mod,o.prototype.modulusS=o.prototype.modS,o.prototype.modulusM=o.prototype.modM,o.modulus=o.mod,o.prototype.and=function(t){return typeof t=="number"?this.andS(t):this.andM(t)},o.prototype.andS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)&t);return this},o.prototype.andM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)&t.get(s,r));return this},o.and=function(t,s){return new n(t).and(s)},o.prototype.or=function(t){return typeof t=="number"?this.orS(t):this.orM(t)},o.prototype.orS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)|t);return this},o.prototype.orM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)|t.get(s,r));return this},o.or=function(t,s){return new n(t).or(s)},o.prototype.xor=function(t){return typeof t=="number"?this.xorS(t):this.xorM(t)},o.prototype.xorS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)^t);return this},o.prototype.xorM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)^t.get(s,r));return this},o.xor=function(t,s){return new n(t).xor(s)},o.prototype.leftShift=function(t){return typeof t=="number"?this.leftShiftS(t):this.leftShiftM(t)},o.prototype.leftShiftS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)<<t);return this},o.prototype.leftShiftM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)<<t.get(s,r));return this},o.leftShift=function(t,s){return new n(t).leftShift(s)},o.prototype.signPropagatingRightShift=function(t){return typeof t=="number"?this.signPropagatingRightShiftS(t):this.signPropagatingRightShiftM(t)},o.prototype.signPropagatingRightShiftS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>t);return this},o.prototype.signPropagatingRightShiftM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>t.get(s,r));return this},o.signPropagatingRightShift=function(t,s){return new n(t).signPropagatingRightShift(s)},o.prototype.rightShift=function(t){return typeof t=="number"?this.rightShiftS(t):this.rightShiftM(t)},o.prototype.rightShiftS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>>t);return this},o.prototype.rightShiftM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,this.get(s,r)>>>t.get(s,r));return this},o.rightShift=function(t,s){return new n(t).rightShift(s)},o.prototype.zeroFillRightShift=o.prototype.rightShift,o.prototype.zeroFillRightShiftS=o.prototype.rightShiftS,o.prototype.zeroFillRightShiftM=o.prototype.rightShiftM,o.zeroFillRightShift=o.rightShift,o.prototype.not=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,~this.get(t,s));return this},o.not=function(t){return new n(t).not()},o.prototype.abs=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.abs(this.get(t,s)));return this},o.abs=function(t){return new n(t).abs()},o.prototype.acos=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.acos(this.get(t,s)));return this},o.acos=function(t){return new n(t).acos()},o.prototype.acosh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.acosh(this.get(t,s)));return this},o.acosh=function(t){return new n(t).acosh()},o.prototype.asin=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.asin(this.get(t,s)));return this},o.asin=function(t){return new n(t).asin()},o.prototype.asinh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.asinh(this.get(t,s)));return this},o.asinh=function(t){return new n(t).asinh()},o.prototype.atan=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.atan(this.get(t,s)));return this},o.atan=function(t){return new n(t).atan()},o.prototype.atanh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.atanh(this.get(t,s)));return this},o.atanh=function(t){return new n(t).atanh()},o.prototype.cbrt=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.cbrt(this.get(t,s)));return this},o.cbrt=function(t){return new n(t).cbrt()},o.prototype.ceil=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.ceil(this.get(t,s)));return this},o.ceil=function(t){return new n(t).ceil()},o.prototype.clz32=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.clz32(this.get(t,s)));return this},o.clz32=function(t){return new n(t).clz32()},o.prototype.cos=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.cos(this.get(t,s)));return this},o.cos=function(t){return new n(t).cos()},o.prototype.cosh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.cosh(this.get(t,s)));return this},o.cosh=function(t){return new n(t).cosh()},o.prototype.exp=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.exp(this.get(t,s)));return this},o.exp=function(t){return new n(t).exp()},o.prototype.expm1=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.expm1(this.get(t,s)));return this},o.expm1=function(t){return new n(t).expm1()},o.prototype.floor=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.floor(this.get(t,s)));return this},o.floor=function(t){return new n(t).floor()},o.prototype.fround=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.fround(this.get(t,s)));return this},o.fround=function(t){return new n(t).fround()},o.prototype.log=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log(this.get(t,s)));return this},o.log=function(t){return new n(t).log()},o.prototype.log1p=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log1p(this.get(t,s)));return this},o.log1p=function(t){return new n(t).log1p()},o.prototype.log10=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log10(this.get(t,s)));return this},o.log10=function(t){return new n(t).log10()},o.prototype.log2=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.log2(this.get(t,s)));return this},o.log2=function(t){return new n(t).log2()},o.prototype.round=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.round(this.get(t,s)));return this},o.round=function(t){return new n(t).round()},o.prototype.sign=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sign(this.get(t,s)));return this},o.sign=function(t){return new n(t).sign()},o.prototype.sin=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sin(this.get(t,s)));return this},o.sin=function(t){return new n(t).sin()},o.prototype.sinh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sinh(this.get(t,s)));return this},o.sinh=function(t){return new n(t).sinh()},o.prototype.sqrt=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.sqrt(this.get(t,s)));return this},o.sqrt=function(t){return new n(t).sqrt()},o.prototype.tan=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.tan(this.get(t,s)));return this},o.tan=function(t){return new n(t).tan()},o.prototype.tanh=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.tanh(this.get(t,s)));return this},o.tanh=function(t){return new n(t).tanh()},o.prototype.trunc=function(){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.set(t,s,Math.trunc(this.get(t,s)));return this},o.trunc=function(t){return new n(t).trunc()},o.pow=function(t,s){return new n(t).pow(s)},o.prototype.pow=function(t){return typeof t=="number"?this.powS(t):this.powM(t)},o.prototype.powS=function(t){for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,Math.pow(this.get(s,r),t));return this},o.prototype.powM=function(t){if(t=n.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let s=0;s<this.rows;s++)for(let r=0;r<this.columns;r++)this.set(s,r,Math.pow(this.get(s,r),t.get(s,r)));return this}}function Q(o,n,e){let t=e?o.rows:o.rows-1;if(n<0||n>t)throw new RangeError("Row index out of range")}function Z(o,n,e){let t=e?o.columns:o.columns-1;if(n<0||n>t)throw new RangeError("Column index out of range")}function tt(o,n){if(n.to1DArray&&(n=n.to1DArray()),n.length!==o.columns)throw new RangeError("vector size must be the same as the number of columns");return n}function et(o,n){if(n.to1DArray&&(n=n.to1DArray()),n.length!==o.rows)throw new RangeError("vector size must be the same as the number of rows");return n}function ie(o,n){if(!W(n))throw new TypeError("row indices must be an array");for(let e=0;e<n.length;e++)if(n[e]<0||n[e]>=o.rows)throw new RangeError("row indices are out of range")}function le(o,n){if(!W(n))throw new TypeError("column indices must be an array");for(let e=0;e<n.length;e++)if(n[e]<0||n[e]>=o.columns)throw new RangeError("column indices are out of range")}function Ft(o,n,e,t,s){if(arguments.length!==5)throw new RangeError("expected 4 arguments");if(at("startRow",n),at("endRow",e),at("startColumn",t),at("endColumn",s),n>e||t>s||n<0||n>=o.rows||e<0||e>=o.rows||t<0||t>=o.columns||s<0||s>=o.columns)throw new RangeError("Submatrix indices are out of range")}function gt(o,n=0){let e=[];for(let t=0;t<o;t++)e.push(n);return e}function at(o,n){if(typeof n!="number")throw new TypeError(`${o} must be a number`)}function nt(o){if(o.isEmpty())throw new Error("Empty matrix has no elements to index")}function he(o){let n=gt(o.rows);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[e]+=o.get(e,t);return n}function ue(o){let n=gt(o.columns);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[t]+=o.get(e,t);return n}function ce(o){let n=0;for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)n+=o.get(e,t);return n}function fe(o){let n=gt(o.rows,1);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[e]*=o.get(e,t);return n}function ge(o){let n=gt(o.columns,1);for(let e=0;e<o.rows;++e)for(let t=0;t<o.columns;++t)n[t]*=o.get(e,t);return n}function ae(o){let n=1;for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)n*=o.get(e,t);return n}function me(o,n,e){const t=o.rows,s=o.columns,r=[];for(let i=0;i<t;i++){let h=0,l=0,u=0;for(let f=0;f<s;f++)u=o.get(i,f)-e[i],h+=u,l+=u*u;n?r.push((l-h*h/s)/(s-1)):r.push((l-h*h/s)/s)}return r}function we(o,n,e){const t=o.rows,s=o.columns,r=[];for(let i=0;i<s;i++){let h=0,l=0,u=0;for(let f=0;f<t;f++)u=o.get(f,i)-e[i],h+=u,l+=u*u;n?r.push((l-h*h/t)/(t-1)):r.push((l-h*h/t)/t)}return r}function pe(o,n,e){const t=o.rows,s=o.columns,r=t*s;let i=0,h=0,l=0;for(let u=0;u<t;u++)for(let f=0;f<s;f++)l=o.get(u,f)-e,i+=l,h+=l*l;return n?(h-i*i/r)/(r-1):(h-i*i/r)/r}function de(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)-n[e])}function ye(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)-n[t])}function Me(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)-n)}function Ee(o){const n=[];for(let e=0;e<o.rows;e++){let t=0;for(let s=0;s<o.columns;s++)t+=Math.pow(o.get(e,s),2)/(o.columns-1);n.push(Math.sqrt(t))}return n}function Se(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)/n[e])}function je(o){const n=[];for(let e=0;e<o.columns;e++){let t=0;for(let s=0;s<o.rows;s++)t+=Math.pow(o.get(s,e),2)/(o.rows-1);n.push(Math.sqrt(t))}return n}function ke(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)/n[t])}function be(o){const n=o.size-1;let e=0;for(let t=0;t<o.columns;t++)for(let s=0;s<o.rows;s++)e+=Math.pow(o.get(s,t),2)/n;return Math.sqrt(e)}function Ie(o,n){for(let e=0;e<o.rows;e++)for(let t=0;t<o.columns;t++)o.set(e,t,o.get(e,t)/n)}class _{static from1DArray(n,e,t){if(n*e!==t.length)throw new RangeError("data length does not match given dimensions");let r=new b(n,e);for(let i=0;i<n;i++)for(let h=0;h<e;h++)r.set(i,h,t[i*e+h]);return r}static rowVector(n){let e=new b(1,n.length);for(let t=0;t<n.length;t++)e.set(0,t,n[t]);return e}static columnVector(n){let e=new b(n.length,1);for(let t=0;t<n.length;t++)e.set(t,0,n[t]);return e}static zeros(n,e){return new b(n,e)}static ones(n,e){return new b(n,e).fill(1)}static rand(n,e,t={}){if(typeof t!="object")throw new TypeError("options must be an object");const{random:s=Math.random}=t;let r=new b(n,e);for(let i=0;i<n;i++)for(let h=0;h<e;h++)r.set(i,h,s());return r}static randInt(n,e,t={}){if(typeof t!="object")throw new TypeError("options must be an object");const{min:s=0,max:r=1e3,random:i=Math.random}=t;if(!Number.isInteger(s))throw new TypeError("min must be an integer");if(!Number.isInteger(r))throw new TypeError("max must be an integer");if(s>=r)throw new RangeError("min must be smaller than max");let h=r-s,l=new b(n,e);for(let u=0;u<n;u++)for(let f=0;f<e;f++){let g=s+Math.round(i()*h);l.set(u,f,g)}return l}static eye(n,e,t){e===void 0&&(e=n),t===void 0&&(t=1);let s=Math.min(n,e),r=this.zeros(n,e);for(let i=0;i<s;i++)r.set(i,i,t);return r}static diag(n,e,t){let s=n.length;e===void 0&&(e=s),t===void 0&&(t=e);let r=Math.min(s,e,t),i=this.zeros(e,t);for(let h=0;h<r;h++)i.set(h,h,n[h]);return i}static min(n,e){n=this.checkMatrix(n),e=this.checkMatrix(e);let t=n.rows,s=n.columns,r=new b(t,s);for(let i=0;i<t;i++)for(let h=0;h<s;h++)r.set(i,h,Math.min(n.get(i,h),e.get(i,h)));return r}static max(n,e){n=this.checkMatrix(n),e=this.checkMatrix(e);let t=n.rows,s=n.columns,r=new this(t,s);for(let i=0;i<t;i++)for(let h=0;h<s;h++)r.set(i,h,Math.max(n.get(i,h),e.get(i,h)));return r}static checkMatrix(n){return _.isMatrix(n)?n:new b(n)}static isMatrix(n){return n!=null&&n.klass==="Matrix"}get size(){return this.rows*this.columns}apply(n){if(typeof n!="function")throw new TypeError("callback must be a function");for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.call(this,e,t);return this}to1DArray(){let n=[];for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.push(this.get(e,t));return n}to2DArray(){let n=[];for(let e=0;e<this.rows;e++){n.push([]);for(let t=0;t<this.columns;t++)n[e].push(this.get(e,t))}return n}toJSON(){return this.to2DArray()}isRowVector(){return this.rows===1}isColumnVector(){return this.columns===1}isVector(){return this.rows===1||this.columns===1}isSquare(){return this.rows===this.columns}isEmpty(){return this.rows===0||this.columns===0}isSymmetric(){if(this.isSquare()){for(let n=0;n<this.rows;n++)for(let e=0;e<=n;e++)if(this.get(n,e)!==this.get(e,n))return!1;return!0}return!1}isEchelonForm(){let n=0,e=0,t=-1,s=!0,r=!1;for(;n<this.rows&&s;){for(e=0,r=!1;e<this.columns&&r===!1;)this.get(n,e)===0?e++:this.get(n,e)===1&&e>t?(r=!0,t=e):(s=!1,r=!0);n++}return s}isReducedEchelonForm(){let n=0,e=0,t=-1,s=!0,r=!1;for(;n<this.rows&&s;){for(e=0,r=!1;e<this.columns&&r===!1;)this.get(n,e)===0?e++:this.get(n,e)===1&&e>t?(r=!0,t=e):(s=!1,r=!0);for(let i=e+1;i<this.rows;i++)this.get(n,i)!==0&&(s=!1);n++}return s}echelonForm(){let n=this.clone(),e=0,t=0;for(;e<n.rows&&t<n.columns;){let s=e;for(let r=e;r<n.rows;r++)n.get(r,t)>n.get(s,t)&&(s=r);if(n.get(s,t)===0)t++;else{n.swapRows(e,s);let r=n.get(e,t);for(let i=t;i<n.columns;i++)n.set(e,i,n.get(e,i)/r);for(let i=e+1;i<n.rows;i++){let h=n.get(i,t)/n.get(e,t);n.set(i,t,0);for(let l=t+1;l<n.columns;l++)n.set(i,l,n.get(i,l)-n.get(e,l)*h)}e++,t++}}return n}reducedEchelonForm(){let n=this.echelonForm(),e=n.columns,t=n.rows,s=t-1;for(;s>=0;)if(n.maxRow(s)===0)s--;else{let r=0,i=!1;for(;r<t&&i===!1;)n.get(s,r)===1?i=!0:r++;for(let h=0;h<s;h++){let l=n.get(h,r);for(let u=r;u<e;u++){let f=n.get(h,u)-l*n.get(s,u);n.set(h,u,f)}}s--}return n}set(){throw new Error("set method is unimplemented")}get(){throw new Error("get method is unimplemented")}repeat(n={}){if(typeof n!="object")throw new TypeError("options must be an object");const{rows:e=1,columns:t=1}=n;if(!Number.isInteger(e)||e<=0)throw new TypeError("rows must be a positive integer");if(!Number.isInteger(t)||t<=0)throw new TypeError("columns must be a positive integer");let s=new b(this.rows*e,this.columns*t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)s.setSubMatrix(this,this.rows*r,this.columns*i);return s}fill(n){for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,n);return this}neg(){return this.mulS(-1)}getRow(n){Q(this,n);let e=[];for(let t=0;t<this.columns;t++)e.push(this.get(n,t));return e}getRowVector(n){return b.rowVector(this.getRow(n))}setRow(n,e){Q(this,n),e=tt(this,e);for(let t=0;t<this.columns;t++)this.set(n,t,e[t]);return this}swapRows(n,e){Q(this,n),Q(this,e);for(let t=0;t<this.columns;t++){let s=this.get(n,t);this.set(n,t,this.get(e,t)),this.set(e,t,s)}return this}getColumn(n){Z(this,n);let e=[];for(let t=0;t<this.rows;t++)e.push(this.get(t,n));return e}getColumnVector(n){return b.columnVector(this.getColumn(n))}setColumn(n,e){Z(this,n),e=et(this,e);for(let t=0;t<this.rows;t++)this.set(t,n,e[t]);return this}swapColumns(n,e){Z(this,n),Z(this,e);for(let t=0;t<this.rows;t++){let s=this.get(t,n);this.set(t,n,this.get(t,e)),this.set(t,e,s)}return this}addRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)+n[t]);return this}subRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)-n[t]);return this}mulRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)*n[t]);return this}divRowVector(n){n=tt(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)/n[t]);return this}addColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)+n[e]);return this}subColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)-n[e]);return this}mulColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)*n[e]);return this}divColumnVector(n){n=et(this,n);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)/n[e]);return this}mulRow(n,e){Q(this,n);for(let t=0;t<this.columns;t++)this.set(n,t,this.get(n,t)*e);return this}mulColumn(n,e){Z(this,n);for(let t=0;t<this.rows;t++)this.set(t,n,this.get(t,n)*e);return this}max(n){if(this.isEmpty())return NaN;switch(n){case"row":{const e=new Array(this.rows).fill(Number.NEGATIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>e[t]&&(e[t]=this.get(t,s));return e}case"column":{const e=new Array(this.columns).fill(Number.NEGATIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>e[s]&&(e[s]=this.get(t,s));return e}case void 0:{let e=this.get(0,0);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>e&&(e=this.get(t,s));return e}default:throw new Error(`invalid option: ${n}`)}}maxIndex(){nt(this);let n=this.get(0,0),e=[0,0];for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)>n&&(n=this.get(t,s),e[0]=t,e[1]=s);return e}min(n){if(this.isEmpty())return NaN;switch(n){case"row":{const e=new Array(this.rows).fill(Number.POSITIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<e[t]&&(e[t]=this.get(t,s));return e}case"column":{const e=new Array(this.columns).fill(Number.POSITIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<e[s]&&(e[s]=this.get(t,s));return e}case void 0:{let e=this.get(0,0);for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<e&&(e=this.get(t,s));return e}default:throw new Error(`invalid option: ${n}`)}}minIndex(){nt(this);let n=this.get(0,0),e=[0,0];for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)this.get(t,s)<n&&(n=this.get(t,s),e[0]=t,e[1]=s);return e}maxRow(n){if(Q(this,n),this.isEmpty())return NaN;let e=this.get(n,0);for(let t=1;t<this.columns;t++)this.get(n,t)>e&&(e=this.get(n,t));return e}maxRowIndex(n){Q(this,n),nt(this);let e=this.get(n,0),t=[n,0];for(let s=1;s<this.columns;s++)this.get(n,s)>e&&(e=this.get(n,s),t[1]=s);return t}minRow(n){if(Q(this,n),this.isEmpty())return NaN;let e=this.get(n,0);for(let t=1;t<this.columns;t++)this.get(n,t)<e&&(e=this.get(n,t));return e}minRowIndex(n){Q(this,n),nt(this);let e=this.get(n,0),t=[n,0];for(let s=1;s<this.columns;s++)this.get(n,s)<e&&(e=this.get(n,s),t[1]=s);return t}maxColumn(n){if(Z(this,n),this.isEmpty())return NaN;let e=this.get(0,n);for(let t=1;t<this.rows;t++)this.get(t,n)>e&&(e=this.get(t,n));return e}maxColumnIndex(n){Z(this,n),nt(this);let e=this.get(0,n),t=[0,n];for(let s=1;s<this.rows;s++)this.get(s,n)>e&&(e=this.get(s,n),t[0]=s);return t}minColumn(n){if(Z(this,n),this.isEmpty())return NaN;let e=this.get(0,n);for(let t=1;t<this.rows;t++)this.get(t,n)<e&&(e=this.get(t,n));return e}minColumnIndex(n){Z(this,n),nt(this);let e=this.get(0,n),t=[0,n];for(let s=1;s<this.rows;s++)this.get(s,n)<e&&(e=this.get(s,n),t[0]=s);return t}diag(){let n=Math.min(this.rows,this.columns),e=[];for(let t=0;t<n;t++)e.push(this.get(t,t));return e}norm(n="frobenius"){let e=0;if(n==="max")return this.max();if(n==="frobenius"){for(let t=0;t<this.rows;t++)for(let s=0;s<this.columns;s++)e=e+this.get(t,s)*this.get(t,s);return Math.sqrt(e)}else throw new RangeError(`unknown norm type: ${n}`)}cumulativeSum(){let n=0;for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n+=this.get(e,t),this.set(e,t,n);return this}dot(n){_.isMatrix(n)&&(n=n.to1DArray());let e=this.to1DArray();if(e.length!==n.length)throw new RangeError("vectors do not have the same size");let t=0;for(let s=0;s<e.length;s++)t+=e[s]*n[s];return t}mmul(n){n=b.checkMatrix(n);let e=this.rows,t=this.columns,s=n.columns,r=new b(e,s),i=new Float64Array(t);for(let h=0;h<s;h++){for(let l=0;l<t;l++)i[l]=n.get(l,h);for(let l=0;l<e;l++){let u=0;for(let f=0;f<t;f++)u+=this.get(l,f)*i[f];r.set(l,h,u)}}return r}strassen2x2(n){n=b.checkMatrix(n);let e=new b(2,2);const t=this.get(0,0),s=n.get(0,0),r=this.get(0,1),i=n.get(0,1),h=this.get(1,0),l=n.get(1,0),u=this.get(1,1),f=n.get(1,1),g=(t+u)*(s+f),a=(h+u)*s,j=t*(i-f),w=u*(l-s),y=(t+r)*f,m=(h-t)*(s+i),M=(r-u)*(l+f),T=g+w-y+M,E=j+y,k=a+w,R=g-a+j+m;return e.set(0,0,T),e.set(0,1,E),e.set(1,0,k),e.set(1,1,R),e}strassen3x3(n){n=b.checkMatrix(n);let e=new b(3,3);const t=this.get(0,0),s=this.get(0,1),r=this.get(0,2),i=this.get(1,0),h=this.get(1,1),l=this.get(1,2),u=this.get(2,0),f=this.get(2,1),g=this.get(2,2),a=n.get(0,0),j=n.get(0,1),w=n.get(0,2),y=n.get(1,0),m=n.get(1,1),M=n.get(1,2),T=n.get(2,0),E=n.get(2,1),k=n.get(2,2),R=(t+s+r-i-h-f-g)*m,q=(t-i)*(-j+m),I=h*(-a+j+y-m-M-T+k),z=(-t+i+h)*(a-j+m),B=(i+h)*(-a+j),c=t*a,p=(-t+u+f)*(a-w+M),S=(-t+u)*(w-M),d=(u+f)*(-a+w),D=(t+s+r-h-l-u-f)*M,U=f*(-a+w+y-m-M-T+E),F=(-r+f+g)*(m+T-E),P=(r-g)*(m-E),Y=r*T,G=(f+g)*(-T+E),N=(-r+h+l)*(M+T-k),$=(r-l)*(M-k),K=(h+l)*(-T+k),v=s*y,V=l*E,L=i*w,C=u*j,X=g*k,wt=c+Y+v,pt=R+z+B+c+F+Y+G,dt=c+p+d+D+Y+N+K,it=q+I+z+c+Y+N+$,lt=q+z+B+c+V,ht=Y+N+$+K+L,jt=c+p+S+U+F+P+Y,ut=F+P+Y+G+C,kt=c+p+S+d+X;return e.set(0,0,wt),e.set(0,1,pt),e.set(0,2,dt),e.set(1,0,it),e.set(1,1,lt),e.set(1,2,ht),e.set(2,0,jt),e.set(2,1,ut),e.set(2,2,kt),e}mmulStrassen(n){n=b.checkMatrix(n);let e=this.clone(),t=e.rows,s=e.columns,r=n.rows,i=n.columns;s!==r&&console.warn(`Multiplying ${t} x ${s} and ${r} x ${i} matrix: dimensions do not match.`);function h(g,a,j){let w=g.rows,y=g.columns;if(w===a&&y===j)return g;{let m=_.zeros(a,j);return m=m.setSubMatrix(g,0,0),m}}let l=Math.max(t,r),u=Math.max(s,i);e=h(e,l,u),n=h(n,l,u);function f(g,a,j,w){if(j<=512||w<=512)return g.mmul(a);j%2===1&&w%2===1?(g=h(g,j+1,w+1),a=h(a,j+1,w+1)):j%2===1?(g=h(g,j+1,w),a=h(a,j+1,w)):w%2===1&&(g=h(g,j,w+1),a=h(a,j,w+1));let y=parseInt(g.rows/2,10),m=parseInt(g.columns/2,10),M=g.subMatrix(0,y-1,0,m-1),T=a.subMatrix(0,y-1,0,m-1),E=g.subMatrix(0,y-1,m,g.columns-1),k=a.subMatrix(0,y-1,m,a.columns-1),R=g.subMatrix(y,g.rows-1,0,m-1),q=a.subMatrix(y,a.rows-1,0,m-1),I=g.subMatrix(y,g.rows-1,m,g.columns-1),z=a.subMatrix(y,a.rows-1,m,a.columns-1),B=f(_.add(M,I),_.add(T,z),y,m),c=f(_.add(R,I),T,y,m),p=f(M,_.sub(k,z),y,m),S=f(I,_.sub(q,T),y,m),d=f(_.add(M,E),z,y,m),D=f(_.sub(R,M),_.add(T,k),y,m),U=f(_.sub(E,I),_.add(q,z),y,m),F=_.add(B,S);F.sub(d),F.add(U);let P=_.add(p,d),Y=_.add(c,S),G=_.sub(B,c);G.add(p),G.add(D);let N=_.zeros(2*F.rows,2*F.columns);return N=N.setSubMatrix(F,0,0),N=N.setSubMatrix(P,F.rows,0),N=N.setSubMatrix(Y,0,F.columns),N=N.setSubMatrix(G,F.rows,F.columns),N.subMatrix(0,j-1,0,w-1)}return f(e,n,l,u)}scaleRows(n={}){if(typeof n!="object")throw new TypeError("options must be an object");const{min:e=0,max:t=1}=n;if(!Number.isFinite(e))throw new TypeError("min must be a number");if(!Number.isFinite(t))throw new TypeError("max must be a number");if(e>=t)throw new RangeError("min must be smaller than max");let s=new b(this.rows,this.columns);for(let r=0;r<this.rows;r++){const i=this.getRow(r);i.length>0&&qt(i,{min:e,max:t,output:i}),s.setRow(r,i)}return s}scaleColumns(n={}){if(typeof n!="object")throw new TypeError("options must be an object");const{min:e=0,max:t=1}=n;if(!Number.isFinite(e))throw new TypeError("min must be a number");if(!Number.isFinite(t))throw new TypeError("max must be a number");if(e>=t)throw new RangeError("min must be smaller than max");let s=new b(this.rows,this.columns);for(let r=0;r<this.columns;r++){const i=this.getColumn(r);i.length&&qt(i,{min:e,max:t,output:i}),s.setColumn(r,i)}return s}flipRows(){const n=Math.ceil(this.columns/2);for(let e=0;e<this.rows;e++)for(let t=0;t<n;t++){let s=this.get(e,t),r=this.get(e,this.columns-1-t);this.set(e,t,r),this.set(e,this.columns-1-t,s)}return this}flipColumns(){const n=Math.ceil(this.rows/2);for(let e=0;e<this.columns;e++)for(let t=0;t<n;t++){let s=this.get(t,e),r=this.get(this.rows-1-t,e);this.set(t,e,r),this.set(this.rows-1-t,e,s)}return this}kroneckerProduct(n){n=b.checkMatrix(n);let e=this.rows,t=this.columns,s=n.rows,r=n.columns,i=new b(e*s,t*r);for(let h=0;h<e;h++)for(let l=0;l<t;l++)for(let u=0;u<s;u++)for(let f=0;f<r;f++)i.set(s*h+u,r*l+f,this.get(h,l)*n.get(u,f));return i}kroneckerSum(n){if(n=b.checkMatrix(n),!this.isSquare()||!n.isSquare())throw new Error("Kronecker Sum needs two Square Matrices");let e=this.rows,t=n.rows,s=this.kroneckerProduct(b.eye(t,t)),r=b.eye(e,e).kroneckerProduct(n);return s.add(r)}transpose(){let n=new b(this.columns,this.rows);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.set(t,e,this.get(e,t));return n}sortRows(n=Pt){for(let e=0;e<this.rows;e++)this.setRow(e,this.getRow(e).sort(n));return this}sortColumns(n=Pt){for(let e=0;e<this.columns;e++)this.setColumn(e,this.getColumn(e).sort(n));return this}subMatrix(n,e,t,s){Ft(this,n,e,t,s);let r=new b(e-n+1,s-t+1);for(let i=n;i<=e;i++)for(let h=t;h<=s;h++)r.set(i-n,h-t,this.get(i,h));return r}subMatrixRow(n,e,t){if(e===void 0&&(e=0),t===void 0&&(t=this.columns-1),e>t||e<0||e>=this.columns||t<0||t>=this.columns)throw new RangeError("Argument out of range");let s=new b(n.length,t-e+1);for(let r=0;r<n.length;r++)for(let i=e;i<=t;i++){if(n[r]<0||n[r]>=this.rows)throw new RangeError(`Row index out of range: ${n[r]}`);s.set(r,i-e,this.get(n[r],i))}return s}subMatrixColumn(n,e,t){if(e===void 0&&(e=0),t===void 0&&(t=this.rows-1),e>t||e<0||e>=this.rows||t<0||t>=this.rows)throw new RangeError("Argument out of range");let s=new b(t-e+1,n.length);for(let r=0;r<n.length;r++)for(let i=e;i<=t;i++){if(n[r]<0||n[r]>=this.columns)throw new RangeError(`Column index out of range: ${n[r]}`);s.set(i-e,r,this.get(i,n[r]))}return s}setSubMatrix(n,e,t){if(n=b.checkMatrix(n),n.isEmpty())return this;let s=e+n.rows-1,r=t+n.columns-1;Ft(this,e,s,t,r);for(let i=0;i<n.rows;i++)for(let h=0;h<n.columns;h++)this.set(e+i,t+h,n.get(i,h));return this}selection(n,e){ie(this,n),le(this,e);let t=new b(n.length,e.length);for(let s=0;s<n.length;s++){let r=n[s];for(let i=0;i<e.length;i++){let h=e[i];t.set(s,i,this.get(r,h))}}return t}trace(){let n=Math.min(this.rows,this.columns),e=0;for(let t=0;t<n;t++)e+=this.get(t,t);return e}clone(){let n=new b(this.rows,this.columns);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)n.set(e,t,this.get(e,t));return n}sum(n){switch(n){case"row":return he(this);case"column":return ue(this);case void 0:return ce(this);default:throw new Error(`invalid option: ${n}`)}}product(n){switch(n){case"row":return fe(this);case"column":return ge(this);case void 0:return ae(this);default:throw new Error(`invalid option: ${n}`)}}mean(n){const e=this.sum(n);switch(n){case"row":{for(let t=0;t<this.rows;t++)e[t]/=this.columns;return e}case"column":{for(let t=0;t<this.columns;t++)e[t]/=this.rows;return e}case void 0:return e/this.size;default:throw new Error(`invalid option: ${n}`)}}variance(n,e={}){if(typeof n=="object"&&(e=n,n=void 0),typeof e!="object")throw new TypeError("options must be an object");const{unbiased:t=!0,mean:s=this.mean(n)}=e;if(typeof t!="boolean")throw new TypeError("unbiased must be a boolean");switch(n){case"row":{if(!W(s))throw new TypeError("mean must be an array");return me(this,t,s)}case"column":{if(!W(s))throw new TypeError("mean must be an array");return we(this,t,s)}case void 0:{if(typeof s!="number")throw new TypeError("mean must be a number");return pe(this,t,s)}default:throw new Error(`invalid option: ${n}`)}}standardDeviation(n,e){typeof n=="object"&&(e=n,n=void 0);const t=this.variance(n,e);if(n===void 0)return Math.sqrt(t);for(let s=0;s<t.length;s++)t[s]=Math.sqrt(t[s]);return t}center(n,e={}){if(typeof n=="object"&&(e=n,n=void 0),typeof e!="object")throw new TypeError("options must be an object");const{center:t=this.mean(n)}=e;switch(n){case"row":{if(!W(t))throw new TypeError("center must be an array");return de(this,t),this}case"column":{if(!W(t))throw new TypeError("center must be an array");return ye(this,t),this}case void 0:{if(typeof t!="number")throw new TypeError("center must be a number");return Me(this,t),this}default:throw new Error(`invalid option: ${n}`)}}scale(n,e={}){if(typeof n=="object"&&(e=n,n=void 0),typeof e!="object")throw new TypeError("options must be an object");let t=e.scale;switch(n){case"row":{if(t===void 0)t=Ee(this);else if(!W(t))throw new TypeError("scale must be an array");return Se(this,t),this}case"column":{if(t===void 0)t=je(this);else if(!W(t))throw new TypeError("scale must be an array");return ke(this,t),this}case void 0:{if(t===void 0)t=be(this);else if(typeof t!="number")throw new TypeError("scale must be a number");return Ie(this,t),this}default:throw new Error(`invalid option: ${n}`)}}toString(n){return Tt(this,n)}}_.prototype.klass="Matrix",typeof Symbol<"u"&&(_.prototype[Symbol.for("nodejs.util.inspect.custom")]=ne);function Pt(o,n){return o-n}function Re(o){return o.every(n=>typeof n=="number")}_.random=_.rand,_.randomInt=_.randInt,_.diagonal=_.diag,_.prototype.diagonal=_.prototype.diag,_.identity=_.eye,_.prototype.negate=_.prototype.neg,_.prototype.tensorProduct=_.prototype.kroneckerProduct;class b extends _{constructor(n,e){if(super(),b.isMatrix(n))return n.clone();if(Number.isInteger(n)&&n>=0)if(this.data=[],Number.isInteger(e)&&e>=0)for(let t=0;t<n;t++)this.data.push(new Float64Array(e));else throw new TypeError("nColumns must be a positive integer");else if(W(n)){const t=n;if(n=t.length,e=n?t[0].length:0,typeof e!="number")throw new TypeError("Data must be a 2D array with at least one element");this.data=[];for(let s=0;s<n;s++){if(t[s].length!==e)throw new RangeError("Inconsistent array dimensions");if(!Re(t[s]))throw new TypeError("Input data contains non-numeric values");this.data.push(Float64Array.from(t[s]))}}else throw new TypeError("First argument must be a positive number or an array");this.rows=n,this.columns=e}set(n,e,t){return this.data[n][e]=t,this}get(n,e){return this.data[n][e]}removeRow(n){return Q(this,n),this.data.splice(n,1),this.rows-=1,this}addRow(n,e){return e===void 0&&(e=n,n=this.rows),Q(this,n,!0),e=Float64Array.from(tt(this,e)),this.data.splice(n,0,e),this.rows+=1,this}removeColumn(n){Z(this,n);for(let e=0;e<this.rows;e++){const t=new Float64Array(this.columns-1);for(let s=0;s<n;s++)t[s]=this.data[e][s];for(let s=n+1;s<this.columns;s++)t[s-1]=this.data[e][s];this.data[e]=t}return this.columns-=1,this}addColumn(n,e){typeof e>"u"&&(e=n,n=this.columns),Z(this,n,!0),e=et(this,e);for(let t=0;t<this.rows;t++){const s=new Float64Array(this.columns+1);let r=0;for(;r<n;r++)s[r]=this.data[t][r];for(s[r++]=e[t];r<this.columns+1;r++)s[r]=this.data[t][r-1];this.data[t]=s}return this.columns+=1,this}}re(_,b);class st extends _{constructor(n){super(),this.data=n,this.rows=n.length,this.columns=n[0].length}set(n,e,t){return this.data[n][e]=t,this}get(n,e){return this.data[n][e]}}class Ne{constructor(n){n=st.checkMatrix(n);let e=n.clone(),t=e.rows,s=e.columns,r=new Float64Array(t),i=1,h,l,u,f,g,a,j,w,y;for(h=0;h<t;h++)r[h]=h;for(w=new Float64Array(t),l=0;l<s;l++){for(h=0;h<t;h++)w[h]=e.get(h,l);for(h=0;h<t;h++){for(y=Math.min(h,l),g=0,u=0;u<y;u++)g+=e.get(h,u)*w[u];w[h]-=g,e.set(h,l,w[h])}for(f=l,h=l+1;h<t;h++)Math.abs(w[h])>Math.abs(w[f])&&(f=h);if(f!==l){for(u=0;u<s;u++)a=e.get(f,u),e.set(f,u,e.get(l,u)),e.set(l,u,a);j=r[f],r[f]=r[l],r[l]=j,i=-i}if(l<t&&e.get(l,l)!==0)for(h=l+1;h<t;h++)e.set(h,l,e.get(h,l)/e.get(l,l))}this.LU=e,this.pivotVector=r,this.pivotSign=i}isSingular(){let n=this.LU,e=n.columns;for(let t=0;t<e;t++)if(n.get(t,t)===0)return!0;return!1}solve(n){n=b.checkMatrix(n);let e=this.LU;if(e.rows!==n.rows)throw new Error("Invalid matrix dimensions");if(this.isSingular())throw new Error("LU matrix is singular");let s=n.columns,r=n.subMatrixRow(this.pivotVector,0,s-1),i=e.columns,h,l,u;for(u=0;u<i;u++)for(h=u+1;h<i;h++)for(l=0;l<s;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u));for(u=i-1;u>=0;u--){for(l=0;l<s;l++)r.set(u,l,r.get(u,l)/e.get(u,u));for(h=0;h<u;h++)for(l=0;l<s;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u))}return r}get determinant(){let n=this.LU;if(!n.isSquare())throw new Error("Matrix must be square");let e=this.pivotSign,t=n.columns;for(let s=0;s<t;s++)e*=n.get(s,s);return e}get lowerTriangularMatrix(){let n=this.LU,e=n.rows,t=n.columns,s=new b(e,t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)r>i?s.set(r,i,n.get(r,i)):r===i?s.set(r,i,1):s.set(r,i,0);return s}get upperTriangularMatrix(){let n=this.LU,e=n.rows,t=n.columns,s=new b(e,t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)r<=i?s.set(r,i,n.get(r,i)):s.set(r,i,0);return s}get pivotPermutationVector(){return Array.from(this.pivotVector)}}function x(o,n){let e=0;return Math.abs(o)>Math.abs(n)?(e=n/o,Math.abs(o)*Math.sqrt(1+e*e)):n!==0?(e=o/n,Math.abs(n)*Math.sqrt(1+e*e)):0}class ve{constructor(n){n=st.checkMatrix(n);let e=n.clone(),t=n.rows,s=n.columns,r=new Float64Array(s),i,h,l,u;for(l=0;l<s;l++){let f=0;for(i=l;i<t;i++)f=x(f,e.get(i,l));if(f!==0){for(e.get(l,l)<0&&(f=-f),i=l;i<t;i++)e.set(i,l,e.get(i,l)/f);for(e.set(l,l,e.get(l,l)+1),h=l+1;h<s;h++){for(u=0,i=l;i<t;i++)u+=e.get(i,l)*e.get(i,h);for(u=-u/e.get(l,l),i=l;i<t;i++)e.set(i,h,e.get(i,h)+u*e.get(i,l))}}r[l]=-f}this.QR=e,this.Rdiag=r}solve(n){n=b.checkMatrix(n);let e=this.QR,t=e.rows;if(n.rows!==t)throw new Error("Matrix row dimensions must agree");if(!this.isFullRank())throw new Error("Matrix is rank deficient");let s=n.columns,r=n.clone(),i=e.columns,h,l,u,f;for(u=0;u<i;u++)for(l=0;l<s;l++){for(f=0,h=u;h<t;h++)f+=e.get(h,u)*r.get(h,l);for(f=-f/e.get(u,u),h=u;h<t;h++)r.set(h,l,r.get(h,l)+f*e.get(h,u))}for(u=i-1;u>=0;u--){for(l=0;l<s;l++)r.set(u,l,r.get(u,l)/this.Rdiag[u]);for(h=0;h<u;h++)for(l=0;l<s;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u))}return r.subMatrix(0,i-1,0,s-1)}isFullRank(){let n=this.QR.columns;for(let e=0;e<n;e++)if(this.Rdiag[e]===0)return!1;return!0}get upperTriangularMatrix(){let n=this.QR,e=n.columns,t=new b(e,e),s,r;for(s=0;s<e;s++)for(r=0;r<e;r++)s<r?t.set(s,r,n.get(s,r)):s===r?t.set(s,r,this.Rdiag[s]):t.set(s,r,0);return t}get orthogonalMatrix(){let n=this.QR,e=n.rows,t=n.columns,s=new b(e,t),r,i,h,l;for(h=t-1;h>=0;h--){for(r=0;r<e;r++)s.set(r,h,0);for(s.set(h,h,1),i=h;i<t;i++)if(n.get(h,h)!==0){for(l=0,r=h;r<e;r++)l+=n.get(r,h)*s.get(r,i);for(l=-l/n.get(h,h),r=h;r<e;r++)s.set(r,i,s.get(r,i)+l*n.get(r,h))}}return s}}class Dt{constructor(n,e={}){if(n=st.checkMatrix(n),n.isEmpty())throw new Error("Matrix must be non-empty");let t=n.rows,s=n.columns;const{computeLeftSingularVectors:r=!0,computeRightSingularVectors:i=!0,autoTranspose:h=!1}=e;let l=!!r,u=!!i,f=!1,g;if(t<s)if(!h)g=n.clone(),console.warn("Computing SVD on a matrix with more columns than rows. Consider enabling autoTranspose");else{g=n.transpose(),t=g.rows,s=g.columns,f=!0;let c=l;l=u,u=c}else g=n.clone();let a=Math.min(t,s),j=Math.min(t+1,s),w=new Float64Array(j),y=new b(t,a),m=new b(s,s),M=new Float64Array(s),T=new Float64Array(t),E=new Float64Array(j);for(let c=0;c<j;c++)E[c]=c;let k=Math.min(t-1,s),R=Math.max(0,Math.min(s-2,t)),q=Math.max(k,R);for(let c=0;c<q;c++){if(c<k){w[c]=0;for(let p=c;p<t;p++)w[c]=x(w[c],g.get(p,c));if(w[c]!==0){g.get(c,c)<0&&(w[c]=-w[c]);for(let p=c;p<t;p++)g.set(p,c,g.get(p,c)/w[c]);g.set(c,c,g.get(c,c)+1)}w[c]=-w[c]}for(let p=c+1;p<s;p++){if(c<k&&w[c]!==0){let S=0;for(let d=c;d<t;d++)S+=g.get(d,c)*g.get(d,p);S=-S/g.get(c,c);for(let d=c;d<t;d++)g.set(d,p,g.get(d,p)+S*g.get(d,c))}M[p]=g.get(c,p)}if(l&&c<k)for(let p=c;p<t;p++)y.set(p,c,g.get(p,c));if(c<R){M[c]=0;for(let p=c+1;p<s;p++)M[c]=x(M[c],M[p]);if(M[c]!==0){M[c+1]<0&&(M[c]=0-M[c]);for(let p=c+1;p<s;p++)M[p]/=M[c];M[c+1]+=1}if(M[c]=-M[c],c+1<t&&M[c]!==0){for(let p=c+1;p<t;p++)T[p]=0;for(let p=c+1;p<t;p++)for(let S=c+1;S<s;S++)T[p]+=M[S]*g.get(p,S);for(let p=c+1;p<s;p++){let S=-M[p]/M[c+1];for(let d=c+1;d<t;d++)g.set(d,p,g.get(d,p)+S*T[d])}}if(u)for(let p=c+1;p<s;p++)m.set(p,c,M[p])}}let I=Math.min(s,t+1);if(k<s&&(w[k]=g.get(k,k)),t<I&&(w[I-1]=0),R+1<I&&(M[R]=g.get(R,I-1)),M[I-1]=0,l){for(let c=k;c<a;c++){for(let p=0;p<t;p++)y.set(p,c,0);y.set(c,c,1)}for(let c=k-1;c>=0;c--)if(w[c]!==0){for(let p=c+1;p<a;p++){let S=0;for(let d=c;d<t;d++)S+=y.get(d,c)*y.get(d,p);S=-S/y.get(c,c);for(let d=c;d<t;d++)y.set(d,p,y.get(d,p)+S*y.get(d,c))}for(let p=c;p<t;p++)y.set(p,c,-y.get(p,c));y.set(c,c,1+y.get(c,c));for(let p=0;p<c-1;p++)y.set(p,c,0)}else{for(let p=0;p<t;p++)y.set(p,c,0);y.set(c,c,1)}}if(u)for(let c=s-1;c>=0;c--){if(c<R&&M[c]!==0)for(let p=c+1;p<s;p++){let S=0;for(let d=c+1;d<s;d++)S+=m.get(d,c)*m.get(d,p);S=-S/m.get(c+1,c);for(let d=c+1;d<s;d++)m.set(d,p,m.get(d,p)+S*m.get(d,c))}for(let p=0;p<s;p++)m.set(p,c,0);m.set(c,c,1)}let z=I-1,B=Number.EPSILON;for(;I>0;){let c,p;for(c=I-2;c>=-1&&c!==-1;c--){const S=Number.MIN_VALUE+B*Math.abs(w[c]+Math.abs(w[c+1]));if(Math.abs(M[c])<=S||Number.isNaN(M[c])){M[c]=0;break}}if(c===I-2)p=4;else{let S;for(S=I-1;S>=c&&S!==c;S--){let d=(S!==I?Math.abs(M[S]):0)+(S!==c+1?Math.abs(M[S-1]):0);if(Math.abs(w[S])<=B*d){w[S]=0;break}}S===c?p=3:S===I-1?p=1:(p=2,c=S)}switch(c++,p){case 1:{let S=M[I-2];M[I-2]=0;for(let d=I-2;d>=c;d--){let D=x(w[d],S),U=w[d]/D,F=S/D;if(w[d]=D,d!==c&&(S=-F*M[d-1],M[d-1]=U*M[d-1]),u)for(let P=0;P<s;P++)D=U*m.get(P,d)+F*m.get(P,I-1),m.set(P,I-1,-F*m.get(P,d)+U*m.get(P,I-1)),m.set(P,d,D)}break}case 2:{let S=M[c-1];M[c-1]=0;for(let d=c;d<I;d++){let D=x(w[d],S),U=w[d]/D,F=S/D;if(w[d]=D,S=-F*M[d],M[d]=U*M[d],l)for(let P=0;P<t;P++)D=U*y.get(P,d)+F*y.get(P,c-1),y.set(P,c-1,-F*y.get(P,d)+U*y.get(P,c-1)),y.set(P,d,D)}break}case 3:{const S=Math.max(Math.abs(w[I-1]),Math.abs(w[I-2]),Math.abs(M[I-2]),Math.abs(w[c]),Math.abs(M[c])),d=w[I-1]/S,D=w[I-2]/S,U=M[I-2]/S,F=w[c]/S,P=M[c]/S,Y=((D+d)*(D-d)+U*U)/2,G=d*U*(d*U);let N=0;(Y!==0||G!==0)&&(Y<0?N=0-Math.sqrt(Y*Y+G):N=Math.sqrt(Y*Y+G),N=G/(Y+N));let $=(F+d)*(F-d)+N,K=F*P;for(let v=c;v<I-1;v++){let V=x($,K);V===0&&(V=Number.MIN_VALUE);let L=$/V,C=K/V;if(v!==c&&(M[v-1]=V),$=L*w[v]+C*M[v],M[v]=L*M[v]-C*w[v],K=C*w[v+1],w[v+1]=L*w[v+1],u)for(let X=0;X<s;X++)V=L*m.get(X,v)+C*m.get(X,v+1),m.set(X,v+1,-C*m.get(X,v)+L*m.get(X,v+1)),m.set(X,v,V);if(V=x($,K),V===0&&(V=Number.MIN_VALUE),L=$/V,C=K/V,w[v]=V,$=L*M[v]+C*w[v+1],w[v+1]=-C*M[v]+L*w[v+1],K=C*M[v+1],M[v+1]=L*M[v+1],l&&v<t-1)for(let X=0;X<t;X++)V=L*y.get(X,v)+C*y.get(X,v+1),y.set(X,v+1,-C*y.get(X,v)+L*y.get(X,v+1)),y.set(X,v,V)}M[I-2]=$;break}case 4:{if(w[c]<=0&&(w[c]=w[c]<0?-w[c]:0,u))for(let S=0;S<=z;S++)m.set(S,c,-m.get(S,c));for(;c<z&&!(w[c]>=w[c+1]);){let S=w[c];if(w[c]=w[c+1],w[c+1]=S,u&&c<s-1)for(let d=0;d<s;d++)S=m.get(d,c+1),m.set(d,c+1,m.get(d,c)),m.set(d,c,S);if(l&&c<t-1)for(let d=0;d<t;d++)S=y.get(d,c+1),y.set(d,c+1,y.get(d,c)),y.set(d,c,S);c++}I--;break}}}if(f){let c=m;m=y,y=c}this.m=t,this.n=s,this.s=w,this.U=y,this.V=m}solve(n){let e=n,t=this.threshold,s=this.s.length,r=b.zeros(s,s);for(let a=0;a<s;a++)Math.abs(this.s[a])<=t?r.set(a,a,0):r.set(a,a,1/this.s[a]);let i=this.U,h=this.rightSingularVectors,l=h.mmul(r),u=h.rows,f=i.rows,g=b.zeros(u,f);for(let a=0;a<u;a++)for(let j=0;j<f;j++){let w=0;for(let y=0;y<s;y++)w+=l.get(a,y)*i.get(j,y);g.set(a,j,w)}return g.mmul(e)}solveForDiagonal(n){return this.solve(b.diag(n))}inverse(){let n=this.V,e=this.threshold,t=n.rows,s=n.columns,r=new b(t,this.s.length);for(let f=0;f<t;f++)for(let g=0;g<s;g++)Math.abs(this.s[g])>e&&r.set(f,g,n.get(f,g)/this.s[g]);let i=this.U,h=i.rows,l=i.columns,u=new b(t,h);for(let f=0;f<t;f++)for(let g=0;g<h;g++){let a=0;for(let j=0;j<l;j++)a+=r.get(f,j)*i.get(g,j);u.set(f,g,a)}return u}get condition(){return this.s[0]/this.s[Math.min(this.m,this.n)-1]}get norm2(){return this.s[0]}get rank(){let n=Math.max(this.m,this.n)*this.s[0]*Number.EPSILON,e=0,t=this.s;for(let s=0,r=t.length;s<r;s++)t[s]>n&&e++;return e}get diagonal(){return Array.from(this.s)}get threshold(){return Number.EPSILON/2*Math.max(this.m,this.n)*this.s[0]}get leftSingularVectors(){return this.U}get rightSingularVectors(){return this.V}get diagonalMatrix(){return b.diag(this.s)}}function Mt(o,n=!1){return o=st.checkMatrix(o),n?new Dt(o).inverse():qe(o,b.eye(o.rows))}function qe(o,n,e=!1){return o=st.checkMatrix(o),n=st.checkMatrix(n),e?new Dt(o).solve(n):o.isSquare()?new Ne(o).solve(n):new ve(o).solve(n)}const _e=1234,Te=()=>({seed:_e,arrayShuffle(n){const{arr:e,sampleSize:t}=n;for(let s=0;s<t;s++){this.seed=(214013*this.seed+2531011)%-2147483648;let r=this.seed>>16&32767;r=r%e.length;let i=e[s];e[s]=e[r],e[r]=i}},nextInt(n){this.seed=(214013*this.seed+2531011)%-2147483648;let e=this.seed>>16&32767;return e=e%n,e}}),J=(o,n,e)=>(n[0]-o[0])*(e[1]-o[1])-(n[1]-o[1])*(e[0]-o[0]),ze=(o,n,e,t,s,r,i,h)=>!(J(o,n,e)>0!=J(s,r,i)>0||J(n,e,t)>0!=J(r,i,h)>0||J(e,t,o)>0!=J(i,h,s)>0||J(t,o,n)>0!=J(h,s,r)>0),Fe=(o,n,e,t,s,r)=>J(o,n,e)>0==J(t,s,r)>0,Pe=o=>{const n=o[4]*o[8]-o[5]*o[7],e=o[3]*o[8]-o[5]*o[6],t=o[3]*o[7]-o[4]*o[6];return o[0]*n-o[1]*e+o[2]*t},Bt=(o,n)=>{const e=Pe(o);if(Math.abs(e)<=n)return null;const t=1/e;return[(o[4]*o[8]-o[5]*o[7])*t,(o[2]*o[7]-o[1]*o[8])*t,(o[1]*o[5]-o[2]*o[4])*t,(o[5]*o[6]-o[3]*o[8])*t,(o[0]*o[8]-o[2]*o[6])*t,(o[2]*o[3]-o[0]*o[5])*t,(o[3]*o[7]-o[4]*o[6])*t,(o[1]*o[6]-o[0]*o[7])*t,(o[0]*o[4]-o[1]*o[3])*t]},ot=(o,n)=>{const e=n[6]*o[0]+n[7]*o[1]+n[8],t=[];return t[0]=(n[0]*o[0]+n[1]*o[1]+n[2])/e,t[1]=(n[3]*o[0]+n[4]*o[1]+n[5])/e,t},De=(o,n,e,t)=>{const s=rt(n,o),r=rt(e,o),i=rt(t,o),h=rt(n,e),l=rt(t,e),u=mt(s,r),f=mt(r,i),g=mt(s,i),a=mt(h,l);return Math.min(Math.min(Math.min(u,f),g),a)},Be=(o,n,e,t)=>{const s=J(o,n,e)<=0;return!(J(n,e,t)<=0!==s||J(e,t,o)<=0!==s||J(t,o,n)<=0!==s)},rt=(o,n)=>[o[0]-n[0],o[1]-n[1]],mt=(o,n)=>{const e=o[0]*n[1]-o[1]*n[0];return Math.abs(e)*.5},Vt=(o,n)=>{const{normPoints:e,param:t}=Xt(o),{normPoints:s,param:r}=Xt(n),i=s.length,h=[],l=[];for(let u=0;u<i;u++){const f=[e[u][0],e[u][1],1,0,0,0,-(e[u][0]*s[u][0]),-(e[u][1]*s[u][0])],g=[0,0,0,e[u][0],e[u][1],1,-(e[u][0]*s[u][1]),-(e[u][1]*s[u][1])];h.push(f),h.push(g),l.push([s[u][0]]),l.push([s[u][1]])}try{const u=new b(h),f=new b(l),g=u.transpose(),a=g.mmul(u),j=g.mmul(f),y=Mt(a).mmul(j).to1DArray();return Ve(y,t,r)}catch{return null}},Xt=o=>{let n=0,e=0;for(let l=0;l<o.length;l++)n+=o[l][0],e+=o[l][1];let t=n/o.length,s=e/o.length,r=0;for(let l=0;l<o.length;l++){const u=o[l][0]-t,f=o[l][1]-s;r+=Math.sqrt(u*u+f*f)}let i=Math.sqrt(2)*o.length/r;const h=[];for(let l=0;l<o.length;l++)h.push([(o[l][0]-t)*i,(o[l][1]-s)*i]);return{normPoints:h,param:{meanX:t,meanY:s,s:i}}},Ve=(o,n,e)=>{const t=e.s*e.meanX,s=e.s*e.meanY,r=[o[0]+t*o[6],o[1]+t*o[7],(o[0]+t*o[6])*-n.meanX+(o[1]+t*o[7])*-n.meanY+(o[2]+t)/n.s,o[3]+s*o[6],o[4]+s*o[7],(o[3]+s*o[6])*-n.meanX+(o[4]+s*o[7])*-n.meanY+(o[5]+s)/n.s,e.s*o[6],e.s*o[7],e.s*o[6]*-n.meanX+e.s*o[7]*-n.meanY+e.s/n.s];for(let i=0;i<9;i++)r[i]=r[i]/r[8];return r},Xe=.01,Ue=10,$e=20,Le=10,Ut=o=>{const{srcPoints:n,dstPoints:e,keyframe:t,quickMode:s}=o,r=[[0,0],[t.width,0],[t.width,t.height],[0,t.height]],i=4;if(n.length<i)return null;const h=Xe,l=1/(h*h),u=Math.min(Ue,n.length),f=Te(),g=[];for(let E=0;E<n.length;E++)g[E]=E;f.arrayShuffle({arr:g,sampleSize:g.length});const a=s?Le:$e,j=a*2;let w=0;const y=[];for(;w<j&&y.length<a;){if(w+=1,f.arrayShuffle({arr:g,sampleSize:i}),!ze(n[g[0]],n[g[1]],n[g[2]],n[g[3]],e[g[0]],e[g[1]],e[g[2]],e[g[3]]))continue;const E=Vt([n[g[0]],n[g[1]],n[g[2]],n[g[3]]],[e[g[0]],e[g[1]],e[g[2]],e[g[3]]]);E!==null&&He({H:E,testPoints:r})&&y.push(E)}if(y.length===0)return null;const m=[];for(let E=0;E<y.length;E++)m.push({H:y[E],cost:0});let M=u;for(let E=0;E<n.length&&m.length>2;E+=M){M=Math.min(u,n.length-E);let k=E+M;for(let R=0;R<m.length;R++)for(let q=E;q<k;q++){const I=Ce({H:m[R].H,srcPoint:n[q],dstPoint:e[q],oneOverScale2:l});m[R].cost+=I}m.sort((R,q)=>R.cost-q.cost),m.splice(-Math.floor((m.length+1)/2))}let T=null;for(let E=0;E<m.length;E++){const k=Ye({inH:m[E].H});if(Oe({H:k,testPoints:r,keyframe:t})){T=k;break}}return T},Oe=({H:o,testPoints:n,keyframe:e})=>{const t=Bt(o,1e-5);if(t===null)return!1;const s=[];for(let i=0;i<n.length;i++)s.push(ot(n[i],t));return!(De(s[0],s[1],s[2],s[3])<e.width*e.height*1e-4||!Be(s[0],s[1],s[2],s[3]))},Ye=({inH:o})=>{const n=1/o[8],e=[];for(let t=0;t<8;t++)e[t]=o[t]*n;return e[8]=1,e},Ce=({H:o,srcPoint:n,dstPoint:e,oneOverScale2:t})=>{const s=ot(n,o),r=[s[0]-e[0],s[1]-e[1]];return Math.log(1+(r[0]*r[0]+r[1]*r[1])*t)},He=({H:o,testPoints:n})=>{const e=[];for(let t=0;t<n.length;t++)e[t]=ot(n[t],o);for(let t=0;t<n.length;t++){const s=t,r=(t+1)%n.length,i=(t+2)%n.length;if(!Fe(n[s],n[r],n[i],e[s],e[r],e[i]))return!1}return!0},$t=3,Lt=6,Ke=8,Ot=.7,Je=({keyframe:o,querypoints:n,querywidth:e,queryheight:t,debugMode:s})=>{let r={};const i=[];for(let m=0;m<n.length;m++){const M=n[m],T=M.maxima?o.maximaPoints:o.minimaPoints;if(T.length===0)continue;const E=M.maxima?o.maximaPointsCluster.rootNode:o.minimaPointsCluster.rootNode,k=[],R=new Wt([],(B,c)=>B.d-c.d);Et({node:E,keypoints:T,querypoint:M,queue:R,keypointIndexes:k,numPop:0});let q=-1,I=Number.MAX_SAFE_INTEGER,z=Number.MAX_SAFE_INTEGER;for(let B=0;B<k.length;B++){const c=T[k[B]],p=yt({v1:c.descriptors,v2:M.descriptors});p<I?(z=I,I=p,q=k[B]):p<z&&(z=p)}q!==-1&&(z===Number.MAX_SAFE_INTEGER||1*I/z<Ot)&&i.push({querypoint:M,keypoint:T[q]})}if(s&&(r.matches=i),i.length<Lt)return{debugExtra:r};const h=vt({keywidth:o.width,keyheight:o.height,querywidth:e,queryheight:t,matches:i});s&&(r.houghMatches=h);const l=Ut({srcPoints:h.map(m=>[m.keypoint.x,m.keypoint.y]),dstPoints:h.map(m=>[m.querypoint.x,m.querypoint.y]),keyframe:o});if(l===null)return{debugExtra:r};const u=Yt({H:l,matches:h,threshold:$t});if(s&&(r.inlierMatches=u),u.length<Lt)return{debugExtra:r};const f=Bt(l,1e-5),g=10*10,a=[];for(let m=0;m<n.length;m++){const M=n[m],T=ot([M.x,M.y],f);let E=-1,k=Number.MAX_SAFE_INTEGER,R=Number.MAX_SAFE_INTEGER;const q=M.maxima?o.maximaPoints:o.minimaPoints;for(let I=0;I<q.length;I++){const z=q[I];if((z.x-T[0])*(z.x-T[0])+(z.y-T[1])*(z.y-T[1])>g)continue;const c=yt({v1:z.descriptors,v2:M.descriptors});c<k?(R=k,k=c,E=I):c<R&&(R=c)}E!==-1&&(R===Number.MAX_SAFE_INTEGER||1*k/R<Ot)&&a.push({querypoint:M,keypoint:q[E]})}s&&(r.matches2=a);const j=vt({keywidth:o.width,keyheight:o.height,querywidth:e,queryheight:t,matches:a});s&&(r.houghMatches2=j);const w=Ut({srcPoints:j.map(m=>[m.keypoint.x,m.keypoint.y]),dstPoints:j.map(m=>[m.querypoint.x,m.querypoint.y]),keyframe:o});if(w===null)return{debugExtra:r};const y=Yt({H:w,matches:j,threshold:$t});return s&&(r.inlierMatches2=y),{H:w,matches:y,debugExtra:r}},Et=({node:o,keypoints:n,querypoint:e,queue:t,keypointIndexes:s,numPop:r})=>{if(o.leaf){for(let l=0;l<o.pointIndexes.length;l++)s.push(o.pointIndexes[l]);return}const i=[];for(let l=0;l<o.children.length;l++){const f=o.children[l].centerPointIndex,g=yt({v1:n[f].descriptors,v2:e.descriptors});i.push(g)}let h=Number.MAX_SAFE_INTEGER;for(let l=0;l<o.children.length;l++)h=Math.min(h,i[l]);for(let l=0;l<o.children.length;l++)i[l]!==h&&t.push({node:o.children[l],d:i[l]});for(let l=0;l<o.children.length;l++)i[l]===h&&Et({node:o.children[l],keypoints:n,querypoint:e,queue:t,keypointIndexes:s,numPop:r});if(r<Ke&&t.length>0){const{node:l,d:u}=t.pop();r+=1,Et({node:l,keypoints:n,querypoint:e,queue:t,keypointIndexes:s,numPop:r})}},Yt=o=>{const{H:n,matches:e,threshold:t}=o,s=t*t,r=[];for(let i=0;i<e.length;i++){const h=e[i].querypoint,l=e[i].keypoint,u=ot([l.x,l.y],n);(u[0]-h.x)*(u[0]-h.x)+(u[1]-h.y)*(u[1]-h.y)<=s&&r.push(e[i])}return r};class Ge{constructor(n,e,t=!1){this.queryWidth=n,this.queryHeight=e,this.debugMode=t}matchDetection(n,e){let t={frames:[]},s=null;for(let l=0;l<n.length;l++){const{H:u,matches:f,debugExtra:g}=Je({keyframe:n[l],querypoints:e,querywidth:this.queryWidth,queryheight:this.queryHeight,debugMode:this.debugMode});t.frames.push(g),u&&(s===null||s.matches.length<f.length)&&(s={keyframeIndex:l,H:u,matches:f})}if(s===null)return{keyframeIndex:-1,debugExtra:t};const r=[],i=[],h=n[s.keyframeIndex];for(let l=0;l<s.matches.length;l++){const u=s.matches[l].querypoint,f=s.matches[l].keypoint;r.push({x:u.x,y:u.y}),i.push({x:(f.x+.5)/h.scale,y:(f.y+.5)/h.scale,z:0})}return{screenCoords:r,worldCoords:i,keyframeIndex:s.keyframeIndex,debugExtra:t}}}const We=({screenCoords:o,worldCoords:n,projectionTransform:e})=>{const t=Vt(n.map(m=>[m.x,m.y]),o.map(m=>[m.x,m.y])),s=new b([[t[0],t[1],t[2]],[t[3],t[4],t[5]],[t[6],t[7],t[8]]]),r=new b(e),l=Mt(r).mmul(s).to1DArray(),u=Math.sqrt(l[0]*l[0]+l[3]*l[3]+l[6]*l[6]),f=Math.sqrt(l[1]*l[1]+l[4]*l[4]+l[7]*l[7]),g=(u+f)/2,a=[];a[0]=l[0]/u,a[3]=l[3]/u,a[6]=l[6]/u,a[1]=l[1]/f,a[4]=l[4]/f,a[7]=l[7]/f,a[2]=a[3]*a[7]-a[6]*a[4],a[5]=a[6]*a[1]-a[0]*a[7],a[8]=a[0]*a[4]-a[1]*a[3];const j=Math.sqrt(a[2]*a[2]+a[5]*a[5]+a[8]*a[8]);a[2]/=j,a[5]/=j,a[8]/=j;const w=[];return w[0]=l[2]/g,w[1]=l[5]/g,w[2]=l[8]/g,[[a[0],a[1],a[2],w[0]],[a[3],a[4],a[5],w[1]],[a[6],a[7],a[8],w[2]]]},Qe=(o,n)=>[[o[0][0]*n[0][0]+o[0][2]*n[2][0],o[0][0]*n[0][1]+o[0][2]*n[2][1],o[0][0]*n[0][2]+o[0][2]*n[2][2],o[0][0]*n[0][3]+o[0][2]*n[2][3]],[o[1][1]*n[1][0]+o[1][2]*n[2][0],o[1][1]*n[1][1]+o[1][2]*n[2][1],o[1][1]*n[1][2]+o[1][2]*n[2][2],o[1][1]*n[1][3]+o[1][2]*n[2][3]],[n[2][0],n[2][1],n[2][2],n[2][3]]],Ct=(o,n,e,t)=>{const s=o[0][0]*n+o[0][1]*e+o[0][3],r=o[1][0]*n+o[1][1]*e+o[1][3],i=o[2][0]*n+o[2][1]*e+o[2][3];return{x:s,y:r,z:i}},Ze=(o,n,e,t)=>{const{x:s,y:r,z:i}=Ct(o,n,e);return{x:s/i,y:r/i}},xe=5,Ae=4,Ht=10,tn=.1,en=.99;let H=[[],[],[]],A=[[],[]],O=[[],[],[]];const nn=({initialModelViewTransform:o,projectionTransform:n,worldCoords:e,screenCoords:t})=>{let s=0,r=0;for(let g=0;g<e.length;g++)s+=e[g].x,r+=e[g].y;s/=e.length,r/=e.length;const i=[];for(let g=0;g<e.length;g++)i.push({x:e[g].x-s,y:e[g].y-r,z:e[g].z});const h=[[],[],[]];for(let g=0;g<3;g++)for(let a=0;a<3;a++)h[g][a]=o[g][a];h[0][3]=o[0][0]*s+o[0][1]*r+o[0][3],h[1][3]=o[1][0]*s+o[1][1]*r+o[1][3],h[2][3]=o[2][0]*s+o[2][1]*r+o[2][3];const l=[1,.8,.6,.4,0];let u=h,f=null;for(let g=0;g<l.length;g++){const a=sn({initialModelViewTransform:u,projectionTransform:n,worldCoords:i,screenCoords:t,inlierProb:l[g]});if(u=a.modelViewTransform,a.err<xe){f=u;break}}return f===null?null:(f[0][3]=f[0][3]-f[0][0]*s-f[0][1]*r,f[1][3]=f[1][3]-f[1][0]*s-f[1][1]*r,f[2][3]=f[2][3]-f[2][0]*s-f[2][1]*r,f)},sn=({initialModelViewTransform:o,projectionTransform:n,worldCoords:e,screenCoords:t,inlierProb:s})=>{const r=s<1;let i=o,h=0,l=0,u=new Array(e.length),f=new Array(e.length),g=new Array(e.length),a=new Array(e.length);for(let j=0;j<=Ht;j++){const w=Qe(n,i);for(let E=0;E<e.length;E++){const k=Ze(w,e[E].x,e[E].y,e[E].z),R=t[E].x-k.x,q=t[E].y-k.y;g[E]=R,a[E]=q,u[E]=R*R+q*q}let y;if(l=0,r){const E=Math.max(3,Math.floor(e.length*s)-1);for(let k=0;k<e.length;k++)f[k]=u[k];f.sort((k,R)=>k-R),y=Math.max(f[E]*Ae,16);for(let k=0;k<e.length;k++)f[k]>y?l+=y/6:l+=y/6*(1-(1-f[k]/y)*(1-f[k]/y)*(1-f[k]/y))}else for(let E=0;E<e.length;E++)l+=u[E];if(l/=e.length,l<tn||j>0&&l/h>en||j===Ht)break;h=l;const m=[],M=[];for(let E=0;E<e.length;E++){if(r&&u[E]>y)continue;const k=ln({modelViewProjectionTransform:w,modelViewTransform:i,projectionTransform:n,worldCoord:e[E]});if(r){const R=(1-u[E]/y)*(1-u[E]/y);for(let q=0;q<2;q++)for(let I=0;I<6;I++)k[q][I]*=R;m.push([g[E]*R]),m.push([a[E]*R])}else m.push([g[E]]),m.push([a[E]]);for(let R=0;R<k.length;R++)M.push(k[R])}const T=rn({dU:m,J_U_S:M});if(T===null)break;i=on({modelViewTransform:i,dS:T})}return{modelViewTransform:i,err:l}},on=({modelViewTransform:o,dS:n})=>{let e=n[0]*n[0]+n[1]*n[1]+n[2]*n[2],t,s,r;e<1e-6?(t=1,s=0,r=0,e=0):(e=Math.sqrt(e),t=n[0]/e,s=n[1]/e,r=n[2]/e);const i=Math.cos(e),h=Math.sin(e),l=1-i;H[0][0]=t*t*l+i,H[0][1]=t*s*l-r*h,H[0][2]=t*r*l+s*h,H[0][3]=n[3],H[1][0]=s*t*l+r*h,H[1][1]=s*s*l+i,H[1][2]=s*r*l-t*h,H[1][3]=n[4],H[2][0]=r*t*l-s*h,H[2][1]=r*s*l+t*h,H[2][2]=r*r*l+i,H[2][3]=n[5];const u=[[],[],[]];for(let f=0;f<3;f++){for(let g=0;g<4;g++)u[f][g]=o[f][0]*H[0][g]+o[f][1]*H[1][g]+o[f][2]*H[2][g];u[f][3]+=o[f][3]}return u},rn=({dU:o,J_U_S:n})=>{const e=new b(n),t=new b(o),s=e.transpose(),r=s.mmul(e),i=s.mmul(t);let h;try{h=Mt(r)}catch{return null}return h.mmul(i).to1DArray()},ln=({modelViewProjectionTransform:o,modelViewTransform:n,projectionTransform:e,worldCoord:t})=>{const s=n,{x:r,y:i,z:h}=t,l=Ct(o,r,i),u=l.z*l.z;A[0][0]=e[0][0]*l.z/u,A[0][1]=e[0][1]*l.z/u,A[0][2]=(e[0][2]*l.z-e[2][2]*l.x)/u,A[1][0]=e[1][0]*l.z/u,A[1][1]=e[1][1]*l.z/u,A[1][2]=(e[1][2]*l.z-e[2][2]*l.y)/u,O[0][0]=s[0][2]*i,O[0][1]=-s[0][2]*r,O[0][2]=s[0][1]*r-s[0][0]*i,O[0][3]=s[0][0],O[0][4]=s[0][1],O[0][5]=s[0][2],O[1][0]=s[1][2]*i,O[1][1]=-s[1][2]*r,O[1][2]=s[1][1]*r-s[1][0]*i,O[1][3]=s[1][0],O[1][4]=s[1][1],O[1][5]=s[1][2],O[2][0]=s[2][2]*i,O[2][1]=-s[2][2]*r,O[2][2]=s[2][1]*r-s[2][0]*i,O[2][3]=s[2][0],O[2][4]=s[2][1],O[2][5]=s[2][2];const f=[[],[]];for(let g=0;g<2;g++)for(let a=0;a<6;a++){f[g][a]=0;for(let j=0;j<3;j++)f[g][a]+=A[g][j]*O[j][a]}return f};class hn{constructor(n){this.projectionTransform=n}estimate({screenCoords:n,worldCoords:e}){return We({screenCoords:n,worldCoords:e,projectionTransform:this.projectionTransform})}refineEstimate({initialModelViewTransform:n,worldCoords:e,screenCoords:t}){return nn({initialModelViewTransform:n,worldCoords:e,screenCoords:t,projectionTransform:this.projectionTransform})}}let Kt=null,Jt=!1,Gt=null,St=null;onmessage=o=>{const{data:n}=o;switch(n.type){case"setup":n.projectionTransform,Kt=n.matchingDataList,Jt=n.debugMode,Gt=new Ge(n.inputWidth,n.inputHeight,Jt),St=new hn(n.projectionTransform);break;case"match":const e=n.targetIndexes;let t=-1,s=null,r=null;for(let f=0;f<e.length;f++){const g=e[f],{keyframeIndex:a,screenCoords:j,worldCoords:w,debugExtra:y}=Gt.matchDetection(Kt[g],n.featurePoints);if(r=y,a!==-1){const m=St.estimate({screenCoords:j,worldCoords:w});m&&(t=g,s=m);break}}postMessage({type:"matchDone",targetIndex:t,modelViewTransform:s,debugExtra:r});break;case"trackUpdate":const{modelViewTransform:i,worldCoords:h,screenCoords:l}=n,u=St.refineEstimate({initialModelViewTransform:i,worldCoords:h,screenCoords:l});postMessage({type:"trackUpdateDone",modelViewTransform:u});break;case"dispose":close();break;default:throw new Error(`Invalid message type '${n.type}'`)}}})();
";
var Kg = typeof window < "u" && window.Blob && new Blob([atob(IC)], { type: "text/javascript;charset=utf-8" });
function A5(n) {
  let t;
  try {
    if (t = Kg && (window.URL || window.webkitURL).createObjectURL(Kg), !t)
      throw "";
    const e = new Worker(t, {
      name: n == null ? void 0 : n.name
    });
    return e.addEventListener("error", () => {
      (window.URL || window.webkitURL).revokeObjectURL(t);
    }), e;
  } catch {
    return new Worker(
      "data:application/javascript;base64," + IC,
      {
        name: n == null ? void 0 : n.name
      }
    );
  } finally {
    t && (window.URL || window.webkitURL).revokeObjectURL(t);
  }
}
var O5 = (n, t) => [
  [
    n[0][0] * t[0][0] + n[0][2] * t[2][0],
    n[0][0] * t[0][1] + n[0][2] * t[2][1],
    n[0][0] * t[0][2] + n[0][2] * t[2][2],
    n[0][0] * t[0][3] + n[0][2] * t[2][3]
  ],
  [
    n[1][1] * t[1][0] + n[1][2] * t[2][0],
    n[1][1] * t[1][1] + n[1][2] * t[2][1],
    n[1][1] * t[1][2] + n[1][2] * t[2][2],
    n[1][1] * t[1][3] + n[1][2] * t[2][3]
  ],
  [
    t[2][0],
    t[2][1],
    t[2][2],
    t[2][3]
  ]
];
var X5 = (n, t, e, s) => {
  const o = n[0][0] * t + n[0][1] * e + n[0][3], r = n[1][0] * t + n[1][1] * e + n[1][3], i6 = n[2][0] * t + n[2][1] * e + n[2][3];
  return { x: o, y: r, z: i6 };
};
var K5 = (n, t, e, s) => {
  const { x: o, y: r, z: i6 } = X5(n, t, e);
  return { x: o / i6, y: r / i6 };
};
var Z5 = 6;
var B5 = 1;
var H5 = 10;
var _5 = 1;
var U5 = 0.8;
var Y5 = 1;
var Un = 1e3;
var Q5 = class {
  constructor(t, e, s, o, r, i6 = false) {
    this.markerDimensions = t, this.trackingDataList = e, this.projectionTransform = s, this.debugMode = i6, this.trackingKeyframeList = [];
    for (let l = 0; l < e.length; l++)
      this.trackingKeyframeList.push(e[l][Y5]);
    let a = 0;
    for (let l = 0; l < this.trackingKeyframeList.length; l++)
      a = Math.max(a, this.trackingKeyframeList[l].points.length);
    this.featurePointsListT = [], this.imagePixelsListT = [], this.imagePropertiesListT = [];
    for (let l = 0; l < this.trackingKeyframeList.length; l++) {
      const { featurePoints: c, imagePixels: u, imageProperties: d } = this._prebuild(this.trackingKeyframeList[l], a);
      this.featurePointsListT[l] = c, this.imagePixelsListT[l] = u, this.imagePropertiesListT[l] = d;
    }
    this.kernelCaches = {};
  }
  dummyRun(t) {
    let e = [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]];
    for (let s = 0; s < this.featurePointsListT.length; s++)
      this.track(t, e, s);
  }
  track(t, e, s) {
    let o = {};
    const r = O5(this.projectionTransform, e), i6 = this._buildAdjustedModelViewTransform(r);
    this.markerDimensions[s][0], this.markerDimensions[s][1], this.trackingKeyframeList[s].width, this.trackingKeyframeList[s].height;
    const a = this.featurePointsListT[s], l = this.imagePixelsListT[s], c = this.imagePropertiesListT[s], u = this._computeProjection(i6, t, s), { matchingPointsT: d, simT: h } = this._computeMatching(a, l, c, u), p = d.arraySync(), f = h.arraySync(), m = this.trackingKeyframeList[s], g = [], b = [], x6 = [];
    for (let w = 0; w < p.length; w++)
      if (f[w] > U5 && w < m.points.length) {
        x6.push(w);
        const y6 = K5(r, p[w][0], p[w][1]);
        b.push(y6), g.push({ x: m.points[w].x / m.scale, y: m.points[w].y / m.scale, z: 0 });
      }
    return this.debugMode && (o = {
      projectedImage: u.arraySync(),
      matchingPoints: d.arraySync(),
      goodTrack: x6,
      trackedPoints: b
    }), i6.dispose(), u.dispose(), d.dispose(), h.dispose(), { worldCoords: g, screenCoords: b, debugExtra: o };
  }
  _computeMatching(t, e, s, o) {
    const r = Z5, i6 = r * 2 + 1, l = H5 * B5, c = _5, u = l * 2 + 1, d = o.shape[0], h = o.shape[1], p = t.shape[0];
    if (!this.kernelCaches.computeMatching) {
      const f = {
        variableNames: ["features", "markerPixels", "markerProperties", "targetPixels"],
        outputShape: [p, u * u],
        userCode: `
	  void main() {
	    ivec2 coords = getOutputCoords();

	    int featureIndex = coords[0];
	    int searchOffsetIndex = coords[1];

	    int markerWidth = int(getMarkerProperties(0));
	    int markerHeight = int(getMarkerProperties(1));
	    float markerScale = getMarkerProperties(2);

	    int searchOffsetX = imod(searchOffsetIndex, ${u}) * ${c};
	    int searchOffsetY = searchOffsetIndex / ${u} * ${c};

	    int sCenterX = int(getFeatures(featureIndex, 0) * markerScale);
	    int sCenterY = int(getFeatures(featureIndex, 1) * markerScale);

	    int sx = sCenterX + searchOffsetX - ${l};
	    int sy = sCenterY + searchOffsetY - ${l};

	    if (sx < ${r} || sx >= (${h} - ${r}) || sy < ${r} || sy >= (${d} - ${r})) {
	      setOutput(-2.);
	    } 
	    else {
	      float sumPoint = 0.;
	      float sumPointSquare = 0.;
	      float sumTemplate = 0.;
	      float sumTemplateSquare = 0.;
	      float sumPointTemplate = 0.;

	      for (int templateOffsetY = 0; templateOffsetY < ${i6}; templateOffsetY++) {
		for (int templateOffsetX = 0; templateOffsetX < ${i6}; templateOffsetX++) {
		  int fx2 = sCenterX + templateOffsetX - ${r};
		  int fy2 = sCenterY + templateOffsetY - ${r};

		  int sx2 = sx + templateOffsetX - ${r};
		  int sy2 = sy + templateOffsetY - ${r};

		  int markerPixelIndex = fy2 * markerWidth + fx2;
		  float markerPixel = getMarkerPixels(markerPixelIndex);
		  float targetPixel = getTargetPixels(sy2, sx2);

		  sumTemplate += markerPixel;
		  sumTemplateSquare += markerPixel * markerPixel;
		  sumPoint += targetPixel;
		  sumPointSquare += targetPixel * targetPixel;
		  sumPointTemplate += targetPixel * markerPixel;
		}
	      }

	      // Normalized cross-correlation
	      // !important divide first avoid overflow (e.g. sumPoint / count * sumPoint)
	      float count = float(${i6} * ${i6});
	      float pointVariance = sqrt(sumPointSquare - sumPoint / count * sumPoint);
	      float templateVariance = sqrt(sumTemplateSquare - sumTemplate / count * sumTemplate);

	      if (pointVariance < 0.0000001) {
		setOutput(-3.);
	      } else if (templateVariance < 0.0000001) {
		//setOutput(sumTemplate);
		setOutput(-4.);
	      } else {
		sumPointTemplate -= sumPoint / count * sumTemplate;
		float sim = sumPointTemplate / pointVariance / templateVariance;  
		setOutput(sim);
	      }
	    }
	  }
	`
      }, m = {
        variableNames: ["featurePoints", "markerProperties", "maxIndex"],
        outputShape: [p, 2],
        // [x, y]
        userCode: `
	  void main() {
	    ivec2 coords = getOutputCoords();

	    float markerScale = getMarkerProperties(2);

	    int featureIndex = coords[0];

	    int maxIndex = int(getMaxIndex(featureIndex));
	    int searchLocationIndex = maxIndex / ${u * u};
	    int searchOffsetIndex = imod(maxIndex, ${u * u});

	    if (coords[1] == 0) {
	      int searchOffsetX = imod(searchOffsetIndex, ${u}) * ${c};
	      setOutput(getFeaturePoints(featureIndex, 0) + float(searchOffsetX - ${l}) / markerScale);
	    }
	    else if (coords[1] == 1) {
	      int searchOffsetY = searchOffsetIndex / ${u} * ${c};
	      setOutput(getFeaturePoints(featureIndex, 1) + float(searchOffsetY - ${l}) / markerScale);
	    }
	  }
	`
      }, g = {
        variableNames: ["sims", "maxIndex"],
        outputShape: [p],
        userCode: `
	  void main() {
	    int featureIndex = getOutputCoords();
	    int maxIndex = int(getMaxIndex(featureIndex));
	    setOutput(getSims(featureIndex, maxIndex));
	  }
	`
      };
      this.kernelCaches.computeMatching = [f, m, g];
    }
    return D(() => {
      const f = this.kernelCaches.computeMatching, m = this._compileAndRun(f[0], [t, e, s, o]), g = m.argMax(1), b = this._compileAndRun(f[1], [t, s, g]), x6 = this._compileAndRun(f[2], [m, g]);
      return { matchingPointsT: b, simT: x6 };
    });
  }
  _computeProjection(t, e, s) {
    const o = this.trackingKeyframeList[s].width, r = this.trackingKeyframeList[s].height, i6 = this.trackingKeyframeList[s].scale, a = o + "-" + r + "-" + i6;
    if (this.kernelCaches.computeProjection || (this.kernelCaches.computeProjection = {}), !this.kernelCaches.computeProjection[a]) {
      const l = {
        variableNames: ["M", "pixel"],
        outputShape: [r, o],
        userCode: `
	  void main() {
	      ivec2 coords = getOutputCoords();

	      float m00 = getM(0, 0) * ${Un}.;
	      float m01 = getM(0, 1) * ${Un}.;
	      float m03 = getM(0, 3) * ${Un}.;
	      float m10 = getM(1, 0) * ${Un}.;
	      float m11 = getM(1, 1) * ${Un}.;
	      float m13 = getM(1, 3) * ${Un}.;
	      float m20 = getM(2, 0) * ${Un}.;
	      float m21 = getM(2, 1) * ${Un}.;
	      float m23 = getM(2, 3) * ${Un}.;

	      float y = float(coords[0]) / float(${i6});
	      float x = float(coords[1]) / float(${i6});
	      float uz = (x * m20) + (y * m21) + m23;
	      float oneOverUz = 1. / uz;

	      float ux = (x * m00) + (y * m01) + m03;
	      float uy = (x * m10) + (y * m11) + m13;

	      ux = floor(ux * oneOverUz + 0.5);
	      uy = floor(uy * oneOverUz + 0.5);
	      setOutput(getPixel(int(uy), int(ux)));
	    }
	`
      };
      this.kernelCaches.computeProjection[a] = l;
    }
    return D(() => {
      const l = this.kernelCaches.computeProjection[a];
      return this._compileAndRun(l, [t, e]);
    });
  }
  _buildAdjustedModelViewTransform(t) {
    return D(() => {
      let e = [];
      for (let o = 0; o < t.length; o++) {
        e.push([]);
        for (let r = 0; r < t[o].length; r++)
          e[o].push(t[o][r] / Un);
      }
      return $e(e, [3, 4]);
    });
  }
  _prebuild(t, e) {
    return D(() => {
      const s = t.scale, o = [];
      for (let l = 0; l < e; l++)
        l < t.points.length ? o.push([t.points[l].x / s, t.points[l].y / s]) : o.push([-1, -1]);
      const r = $e(t.data, [t.width * t.height]), i6 = $e([t.width, t.height, t.scale], [3]);
      return {
        featurePoints: $e(o, [o.length, 2], "float32"),
        imagePixels: r,
        imageProperties: i6
      };
    });
  }
  _compileAndRun(t, e) {
    const s = ps().compileAndRun(t, e);
    return Ot().makeTensorFromDataId(s.dataId, s.shape, s.dtype);
  }
};
var tl = [
  // ring 5
  {
    sigma: 0.55,
    points: [
      [-1, 0],
      [-0.5, -0.866025],
      [0.5, -0.866025],
      [1, -0],
      [0.5, 0.866025],
      [-0.5, 0.866025]
    ]
  },
  // ring 4
  {
    sigma: 0.475,
    points: [
      [0, 0.930969],
      [-0.806243, 0.465485],
      [-0.806243, -0.465485],
      [-0, -0.930969],
      [0.806243, -0.465485],
      [0.806243, 0.465485]
    ]
  },
  // ring 3
  {
    sigma: 0.4,
    points: [
      [0.847306, -0],
      [0.423653, 0.733789],
      [-0.423653, 0.733789],
      [-0.847306, 0],
      [-0.423653, -0.733789],
      [0.423653, -0.733789]
    ]
  },
  // ring 2
  {
    sigma: 0.325,
    points: [
      [-0, -0.741094],
      [0.641806, -0.370547],
      [0.641806, 0.370547],
      [0, 0.741094],
      [-0.641806, 0.370547],
      [-0.641806, -0.370547]
    ]
  },
  // ring 1
  {
    sigma: 0.25,
    points: [
      [-0.595502, 0],
      [-0.297751, -0.51572],
      [0.297751, -0.51572],
      [0.595502, -0],
      [0.297751, 0.51572],
      [-0.297751, 0.51572]
    ]
  },
  // ring 0
  {
    sigma: 0.175,
    points: [
      [0, 0.362783],
      [-0.314179, 0.181391],
      [-0.314179, -0.181391],
      [-0, -0.362783],
      [0.314179, -0.181391],
      [0.314179, 0.181391]
    ]
  },
  // center
  {
    sigma: 0.1,
    points: [
      [0, 0]
    ]
  }
];
var Ao = [];
for (let n = 0; n < tl.length; n++) {
  const t = tl[n].sigma;
  for (let e = 0; e < tl[n].points.length; e++) {
    const s = tl[n].points[e];
    Ao.push([t, s[0], s[1]]);
  }
}
var Xu = {};
function J5(n) {
  const t = n.shape[1], e = n.shape[0], s = "w" + t + "h" + e;
  if (!Xu.hasOwnProperty(s)) {
    const o = {
      variableNames: ["p"],
      outputShape: [e, t],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();

          float sum = getP(coords[0], coords[1]-2);
          sum += getP(coords[0], coords[1]-1) * 4.;
          sum += getP(coords[0], coords[1]) * 6.;
          sum += getP(coords[0], coords[1]+1) * 4.;
          sum += getP(coords[0], coords[1]+2);
          setOutput(sum);
        }
      `
    }, r = {
      variableNames: ["p"],
      outputShape: [e, t],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();

          float sum = getP(coords[0]-2, coords[1]);
          sum += getP(coords[0]-1, coords[1]) * 4.;
          sum += getP(coords[0], coords[1]) * 6.;
          sum += getP(coords[0]+1, coords[1]) * 4.;
          sum += getP(coords[0]+2, coords[1]);
          sum /= 256.;
          setOutput(sum);
        }
      `
    };
    Xu[s] = [o, r];
  }
  return Xu[s];
}
var j5 = (n) => {
  const t = n.inputs.image, e = n.backend, [s, o] = J5(t), r = e.runWebGLProgram(s, [t], t.dtype), i6 = e.runWebGLProgram(o, [r], t.dtype);
  return e.disposeIntermediateTensorInfo(r), i6;
};
var q5 = {
  //: KernelConfig
  kernelName: "BinomialFilter",
  backendName: "webgl",
  kernelFunc: j5
  // as {} as KernelFunc,
};
var el = 7;
var Zg = 3;
var t4 = Zg * Zg;
var Ku = 4;
var e4 = (Ku + 1) * (Ku + 1) / Ku;
var Zu = {};
function n4(n) {
  const t = n.shape[1], e = n.shape[0], s = "w" + t + "h" + e;
  if (!Zu.hasOwnProperty(s)) {
    const o = {
      variableNames: ["image0", "image1", "image2"],
      outputShape: [e, t],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();
    
          int y = coords[0];
          int x = coords[1];
    
          float value = getImage1(y, x);
    
          // Step 1: find local maxima/minima
          if (value * value < ${t4}.) {
            setOutput(0.);
            return;
          }
          if (y < ${el} || y > ${e - 1 - el}) {
            setOutput(0.);
            return;
          }
          if (x < ${el} || x > ${t - 1 - el}) {
            setOutput(0.);
            return;
          }
    
          bool isMax = true;
          bool isMin = true;
          for (int dy = -1; dy <= 1; dy++) {
            for (int dx = -1; dx <= 1; dx++) {
              float value0 = getImage0(y+dy, x+dx);
              float value1 = getImage1(y+dy, x+dx);
              float value2 = getImage2(y+dy, x+dx);
    
        if (value < value0 || value < value1 || value < value2) {
          isMax = false;
        }
        if (value > value0 || value > value1 || value > value2) {
          isMin = false;
        }
            }
          }
    
          if (!isMax && !isMin) {
            setOutput(0.);
            return;
          }
    
          // compute edge score and reject based on threshold
          float dxx = getImage1(y, x+1) + getImage1(y, x-1) - 2. * getImage1(y, x);
          float dyy = getImage1(y+1, x) + getImage1(y-1, x) - 2. * getImage1(y, x);
          float dxy = 0.25 * (getImage1(y-1,x-1) + getImage1(y+1,x+1) - getImage1(y-1,x+1) - getImage1(y+1,x-1));
    
          float det = (dxx * dyy) - (dxy * dxy);
    
          if (abs(det) < 0.0001) { // determinant undefined. no solution
            setOutput(0.);
            return;
          }
    
          float edgeScore = (dxx + dyy) * (dxx + dyy) / det;
    
          if (abs(edgeScore) >= ${e4} ) {
            setOutput(0.);
            return;
          }
          setOutput(getImage1(y,x));
        }
      `
    };
    Zu[s] = o;
  }
  return Zu[s];
}
var s4 = (n) => {
  let { image0: t, image1: e, image2: s } = n.inputs;
  const o = n.backend, r = n4(e);
  return t = Ot().runKernel("DownsampleBilinear", { image: t }), s = Ot().runKernel("UpsampleBilinear", { image: s, targetImage: e }), o.runWebGLProgram(r, [t, e, s], e.dtype);
};
var o4 = {
  //: KernelConfig
  kernelName: "BuildExtremas",
  backendName: "webgl",
  kernelFunc: s4
  // as {} as KernelFunc,
};
var Zr = 36;
var Bu = {};
function r4(n) {
  const t = n.shape[0];
  if (!Bu.hasOwnProperty(t)) {
    const e = {
      variableNames: ["histogram"],
      outputShape: [n.shape[0]],
      userCode: `
            void main() {
                int featureIndex = getOutputCoords();

                int maxIndex = 0;
                for (int i = 1; i < ${Zr}; i++) {
                    if (getHistogram(featureIndex, i) > getHistogram(featureIndex, maxIndex)) {
                        maxIndex = i;
                    }
                }

                int prev = imod(maxIndex - 1 + ${Zr}, ${Zr});
                int next = imod(maxIndex + 1, ${Zr});

                /**
                 * Fit a quatratic to 3 points. The system of equations is:
                 *
                 * y0 = A*x0^2 + B*x0 + C
                 * y1 = A*x1^2 + B*x1 + C
                 * y2 = A*x2^2 + B*x2 + C
                 *
                 * This system of equations is solved for A,B,C.
                 */
                float p10 = float(maxIndex - 1);
                float p11 = getHistogram(featureIndex, prev); 
                float p20 = float(maxIndex);
                float p21 = getHistogram(featureIndex, maxIndex); 
                float p30 = float(maxIndex + 1);
                float p31 = getHistogram(featureIndex, next); 

                float d1 = (p30-p20)*(p30-p10);
                float d2 = (p10-p20)*(p30-p10);
                float d3 = p10-p20;

                // If any of the denominators are zero then, just use maxIndex.
                    float fbin = float(maxIndex);
                if ( abs(d1) > 0.00001 && abs(d2) > 0.00001 && abs(d3) > 0.00001) {
                float a = p10*p10;
                float b = p20*p20;

                // Solve for the coefficients A,B,C
                float A = ((p31-p21)/d1)-((p11-p21)/d2);
                float B = ((p11-p21)+(A*(b-a)))/d3;
                float C = p11-(A*a)-(B*p10);
                fbin = -B / (2. * A);
                }

                float an = 2.0 *${Math.PI} * (fbin + 0.5) / ${Zr}. - ${Math.PI};
                setOutput(an);
            }
            `
    };
    Bu[t] = e;
  }
  return Bu[t];
}
var i4 = (n) => {
  const { histograms: t } = n.inputs, e = n.backend, s = r4(t);
  return e.runWebGLProgram(s, [t], t.dtype);
};
var a4 = {
  //: KernelConfig
  kernelName: "ComputeExtremaAngles",
  backendName: "webgl",
  kernelFunc: i4
  // as {} as KernelFunc,
};
var Bg = 7;
var Hu = {};
function l4(n, t) {
  const e = `${n}|${t.shape[0]}`;
  if (!Hu.hasOwnProperty(e)) {
    const s = [];
    for (let i6 = 1; i6 < n; i6++)
      s.push("image" + i6);
    let o = "float getPixel(int octave, int y, int x) {";
    for (let i6 = 1; i6 < n; i6++)
      o += `
  if (octave == ${i6}) {
	return getImage${i6}(y, x);
  }
`;
    o += "}";
    const r = {
      variableNames: [...s, "extrema", "angles", "freakPoints"],
      outputShape: [t.shape[0], Ao.length],
      userCode: `
  ${o}
  void main() {
	ivec2 coords = getOutputCoords();
	int featureIndex = coords[0];
	int freakIndex = coords[1];

	float freakSigma = getFreakPoints(freakIndex, 0);
	float freakX = getFreakPoints(freakIndex, 1);
	float freakY = getFreakPoints(freakIndex, 2);

	int octave = int(getExtrema(featureIndex, 1));
	float inputY = getExtrema(featureIndex, 2);
	float inputX = getExtrema(featureIndex, 3);
	float inputAngle = getAngles(featureIndex);
	float cos = ${Bg}. * cos(inputAngle);
	float sin = ${Bg}. * sin(inputAngle);

	float yp = inputY + freakX * sin + freakY * cos;
	float xp = inputX + freakX * cos + freakY * -sin;

	int x0 = int(floor(xp));
	int x1 = x0 + 1;
	int y0 = int(floor(yp));
	int y1 = y0 + 1;

	float f1 = getPixel(octave, y0, x0);
	float f2 = getPixel(octave, y0, x1);
	float f3 = getPixel(octave, y1, x0);
	float f4 = getPixel(octave, y1, x1);

	float x1f = float(x1);
	float y1f = float(y1);
	float x0f = float(x0);
	float y0f = float(y0);

	// ratio for interpolation between four neighbouring points
	float value = (x1f - xp) * (y1f - yp) * f1
		+ (xp - x0f) * (y1f - yp) * f2
		+ (x1f - xp) * (yp - y0f) * f3
		+ (xp - x0f) * (yp - y0f) * f4;

	setOutput(value);
  }
`
    };
    Hu[e] = r;
  }
  return Hu[e];
}
var c4 = (n) => {
  const { gaussianImagesT: t, prunedExtremas: e, prunedExtremasAngles: s, freakPointsT: o, pyramidImagesLength: r } = n.inputs, i6 = n.backend, a = l4(r, e);
  return i6.runWebGLProgram(a, [...t, e, s, o], "float32");
};
var u4 = {
  //: KernelConfig
  kernelName: "ComputeExtremaFreak",
  backendName: "webgl",
  kernelFunc: c4
  // as {} as KernelFunc,
};
var CC = (Ao.length - 1) * Ao.length / 2;
var d4 = Math.ceil(CC / 8);
var _u = {};
function h4(n) {
  const t = `${n.shape[0]}`;
  if (!_u.hasOwnProperty(t)) {
    const e = {
      variableNames: ["freak", "p"],
      outputShape: [n.shape[0], d4],
      userCode: `
  void main() {
    ivec2 coords = getOutputCoords();
    int featureIndex = coords[0];
    int descIndex = coords[1] * 8;

    int sum = 0;
    for (int i = 0; i < 8; i++) {
      if (descIndex + i >= ${CC}) {
        continue;
      }

      int p1 = int(getP(descIndex + i, 0));
      int p2 = int(getP(descIndex + i, 1));

      float v1 = getFreak(featureIndex, p1);
      float v2 = getFreak(featureIndex, p2);

      if (v1 < v2 + 0.01) {
        sum += int(pow(2.0, float(7 - i)));
      }
    }
    setOutput(float(sum));
  }
`
    };
    _u[t] = e;
  }
  return _u[t];
}
var p4 = (n) => {
  const { extremaFreaks: t, positionT: e } = n.inputs, { backend: s } = n, o = h4(t);
  return s.runWebGLProgram(o, [t, e], "int32");
};
var f4 = {
  //: KernelConfig
  kernelName: "ComputeFreakDescriptors",
  backendName: "webgl",
  kernelFunc: p4
  // as {} as KernelFunc,
};
var Uu = {};
function m4(n, t) {
  const e = `${n}|${t}`;
  if (!Uu.hasOwnProperty(e)) {
    const s = [];
    let o = "float getPixel(int octave, int y, int x) {";
    for (let r = 1; r < n; r++)
      s.push("image" + r), o += `
				if (octave == ${r}) {
					return getImage${r}(y, x);
				}
			`;
    o += "}", Uu[e] = {
      variableNames: [...s, "extrema"],
      outputShape: [t, 3, 3],
      // 3x3 pixels around the extrema
      userCode: `
			${o}
		
			void main() {
				ivec3 coords = getOutputCoords();
				int featureIndex = coords[0];
				float score = getExtrema(featureIndex, 0);
				if (score == 0.0) {
					return;
				}
		
				int dy = coords[1]-1;
				int dx = coords[2]-1;
				int octave = int(getExtrema(featureIndex, 1));
				int y = int(getExtrema(featureIndex, 2));
				int x = int(getExtrema(featureIndex, 3));
				setOutput(getPixel(octave, y+dy, x+dx));
			}
			`
    };
  }
  return Uu[e];
}
var g4 = (n) => {
  const { prunedExtremasList: t, dogPyramidImagesT: e } = n.inputs, s = n.backend, o = m4(e.length, t.length), r = $e(t, [t.length, t[0].length], "int32");
  return s.runWebGLProgram(o, [...e.slice(1), r], e[0].dtype);
};
var b4 = {
  //: KernelConfig
  kernelName: "ComputeLocalization",
  backendName: "webgl",
  kernelFunc: g4
  // as {} as KernelFunc,
};
var x4 = 0.159154943091895;
var sr = 36;
var Yu = {};
function y4(n, t, e) {
  const s = `${e}|${n.shape[0]}|${t.shape[0]}`;
  if (!Yu.hasOwnProperty(s)) {
    const o = [];
    for (let l = 1; l < e; l++)
      o.push("image" + l);
    let r = "float getPixel(int octave, int y, int x) {";
    for (let l = 1; l < e; l++)
      r += `
            if (octave == ${l}) {
                return getImage${l}(y, x);
            }
            `;
    r += "}";
    const i6 = {
      variableNames: [...o, "extrema", "radial"],
      outputShape: [n.shape[0], t.shape[0], 2],
      // last dimension: [fbin, magnitude]
      userCode: `
                ${r}

                void main() {
                    ivec3 coords = getOutputCoords();
                    int featureIndex = coords[0];
                    int radialIndex = coords[1];
                    int propertyIndex = coords[2];

                    int radialY = int(getRadial(radialIndex, 0));
                    int radialX = int(getRadial(radialIndex, 1));
                    float radialW = getRadial(radialIndex, 2);

                    int octave = int(getExtrema(featureIndex, 1));
                    int y = int(getExtrema(featureIndex, 2));
                    int x = int(getExtrema(featureIndex, 3));

                    int xp = x + radialX;
                    int yp = y + radialY;

                    float dy = getPixel(octave, yp+1, xp) - getPixel(octave, yp-1, xp);
                    float dx = getPixel(octave, yp, xp+1) - getPixel(octave, yp, xp-1);

                    if (propertyIndex == 0) {
                    // be careful that atan(0, 0) gives 1.57 instead of 0 (different from js), but doesn't matter here, coz magnitude is 0
                    
                    float angle = atan(dy, dx) + ${Math.PI};
                    float fbin = angle * ${sr}. * ${x4};
                    setOutput(fbin);
                    return;
                    }

                    if (propertyIndex == 1) {
                        float mag = sqrt(dx * dx + dy * dy);
                        float magnitude = radialW * mag;
                        setOutput(magnitude);
                        return;
                    }
                }

                `
    }, a = {
      variableNames: ["fbinMag"],
      outputShape: [n.shape[0], sr],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();
                int featureIndex = coords[0];
                int binIndex = coords[1];

                float sum = 0.;
                for (int i = 0; i < ${t.shape[0]}; i++) {
                    float fbin = getFbinMag(featureIndex, i, 0);
                    int bin = int(floor(fbin - 0.5));
                    int b1 = imod(bin + ${sr}, ${sr});
                    int b2 = imod(bin + 1 + ${sr}, ${sr});

                    if (b1 == binIndex || b2 == binIndex) {
                        float magnitude = getFbinMag(featureIndex, i, 1);
                        float w2 = fbin - float(bin) - 0.5;
                        float w1 = w2 * -1. + 1.;

                        if (b1 == binIndex) {
                            sum += w1 * magnitude;
                        }
                        if (b2 == binIndex) {
                            sum += w2 * magnitude;
                        }
                    }
                }
                setOutput(sum);
            }
            `
    };
    Yu[s] = [i6, a];
  }
  return Yu[s];
}
var w4 = (n) => {
  const { gaussianImagesT: t, prunedExtremasT: e, radialPropertiesT: s, pyramidImagesLength: o } = n.inputs, r = n.backend, [i6, a] = y4(e, s, o), l = r.runWebGLProgram(i6, [...t, e, s], s.dtype), c = r.runWebGLProgram(a, [l], s.dtype);
  return r.disposeIntermediateTensorInfo(l), c;
};
var I4 = {
  kernelName: "ComputeOrientationHistograms",
  backendName: "webgl",
  kernelFunc: w4
  // as {} as KernelFunc,
};
var Qu = {};
function C4(n) {
  const t = n.shape[1], e = n.shape[0], s = "w" + t + "h" + e;
  if (!Qu.hasOwnProperty(s)) {
    const o = {
      variableNames: ["p"],
      outputShape: [Math.floor(e / 2), Math.floor(t / 2)],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();
                int y = coords[0] * 2;
                int x = coords[1] * 2;
        
                float sum = getP(y, x) * 0.25;
                sum += getP(y+1,x) * 0.25; 
                sum += getP(y, x+1) * 0.25; 
                sum += getP(y+1,x+1) * 0.25;
                setOutput(sum);
            }
            `
    };
    Qu[s] = o;
  }
  return Qu[s];
}
var v4 = (n) => {
  const t = n.inputs.image, e = n.backend, s = C4(t);
  return e.runWebGLProgram(s, [t], t.dtype);
};
var S4 = {
  //: KernelConfig
  kernelName: "DownsampleBilinear",
  backendName: "webgl",
  kernelFunc: v4
  // as {} as KernelFunc,
};
var k4 = (n) => {
  const { extremasResultT: t } = n.inputs, e = n.backend, s = t.shape[0], o = t.shape[1], r = {
    variableNames: ["extrema"],
    outputShape: [Math.floor(s / 2), Math.floor(o / 2)],
    userCode: `
		  void main() {
			ivec2 coords = getOutputCoords();
			int y = coords[0] * 2;
			int x = coords[1] * 2;
  
			float location = 0.0;
			float values = getExtrema(y, x);
  
			if (getExtrema(y+1, x) != 0.0) {
			  location = 1.0;
		  values = getExtrema(y+1, x);
			}
			else if (getExtrema(y, x+1) != 0.0) {
			  location = 2.0;
		  values = getExtrema(y, x+1);
			}
			else if (getExtrema(y+1, x+1) != 0.0) {
			  location = 3.0;
		  values = getExtrema(y+1, x+1);
			}
  
			if (values < 0.0) {
			  setOutput(location * -1000.0 + values);
			} else {
			  setOutput(location * 1000.0 + values);
			}
		  }
		`
  };
  return e.runWebGLProgram(r, [t], t.dtype);
};
var T4 = {
  //: KernelConfig
  kernelName: "ExtremaReduction",
  backendName: "webgl",
  kernelFunc: k4
  // as {} as KernelFunc,
};
var nl = 36;
var N4 = 5;
var Ju = {};
function R4(n) {
  const t = `h${n.shape[0]}`;
  if (!Ju.hasOwnProperty(t)) {
    const e = {
      variableNames: ["histogram"],
      outputShape: [n.shape[0], nl],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();

                int featureIndex = coords[0];
                int binIndex = coords[1];

                int prevBin = imod(binIndex - 1 + ${nl}, ${nl});
                int nextBin = imod(binIndex + 1, ${nl});
                float result = 0.274068619061197 * getHistogram(featureIndex, prevBin) + 0.451862761877606 * getHistogram(featureIndex, binIndex) + 0.274068619061197 * getHistogram(featureIndex, nextBin);

                setOutput(result);
            }
            `
    };
    Ju[t] = e;
  }
  return Ju[t];
}
var $4 = (n) => {
  let { histograms: t } = n.inputs;
  const e = n.backend, s = R4(t);
  for (let o = 0; o < N4; o++) {
    const r = t;
    t = e.runWebGLProgram(s, [t], t.dtype), o > 0 && e.disposeIntermediateTensorInfo(r);
  }
  return t;
};
var G4 = {
  //: KernelConfig
  kernelName: "SmoothHistograms",
  backendName: "webgl",
  kernelFunc: $4
  // as {} as KernelFunc,
};
var ju = {};
function E4(n, t) {
  const e = t.shape[1], s = t.shape[0], o = "w" + e + "h" + s;
  if (!ju.hasOwnProperty(o)) {
    const r = {
      variableNames: ["p"],
      outputShape: [s, e],
      userCode: `
              void main() {
                ivec2 coords = getOutputCoords();
                int j = coords[0];
                int i = coords[1];
        
                float sj = 0.5 * float(j) - 0.25; 
                float si = 0.5 * float(i) - 0.25;
        
                float sj0 = floor(sj);
                float sj1 = ceil(sj);
                float si0 = floor(si);
                float si1 = ceil(si);
        
                int sj0I = int(sj0);
                int sj1I = int(sj1);
                int si0I = int(si0);
                int si1I = int(si1);
        
                float sum = 0.0;
                sum += getP(sj0I, si0I) * (si1 - si) * (sj1 - sj);
                sum += getP(sj1I, si0I) * (si1 - si) * (sj - sj0);
                sum += getP(sj0I, si1I) * (si - si0) * (sj1 - sj);
                sum += getP(sj1I, si1I) * (si - si0) * (sj - sj0);
                setOutput(sum);
              }
            `
    };
    ju[o] = r;
  }
  return ju[o];
}
var L4 = (n) => {
  const { image: t, targetImage: e } = n.inputs, s = n.backend, o = E4(t, e);
  return s.runWebGLProgram(o, [t], t.dtype);
};
var M4 = {
  //: KernelConfig
  kernelName: "UpsampleBilinear",
  backendName: "webgl",
  kernelFunc: L4
  // as {} as KernelFunc,
};
sn(q5);
sn(o4);
sn(a4);
sn(u4);
sn(f4);
sn(b4);
sn(I4);
sn(S4);
sn(T4);
sn(G4);
sn(M4);
var Hg = 8;
var W4 = 5;
var Br = 10;
var D4 = 5;
var qu = 3;
var F4 = 1.5;
(Ao.length - 1) * Ao.length / 2;
var vC = class {
  constructor(t, e, s = false) {
    this.debugMode = s, this.width = t, this.height = e;
    let o = 0;
    for (; t >= Hg && e >= Hg && (t /= 2, e /= 2, o++, o !== W4); )
      ;
    this.numOctaves = o, this.tensorCaches = {}, this.kernelCaches = {};
  }
  // used in compiler
  detectImageData(t) {
    const e = new Uint8ClampedArray(4 * t.length);
    for (let o = 0; o < t.length; o++)
      e[4 * o] = t[o], e[4 * o + 1] = t[o], e[4 * o + 2] = t[o], e[4 * o + 3] = 255;
    const s = new ImageData(e, this.width, this.height);
    return this.detect(s);
  }
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} inputImageT 
   * @returns 
   */
  detect(t) {
    let e = null;
    const s = [];
    for (let b = 0; b < this.numOctaves; b++) {
      let x6, w;
      b === 0 ? x6 = this._applyFilter(t) : x6 = this._downsampleBilinear(s[b - 1][s[b - 1].length - 1]), w = this._applyFilter(x6), s.push([x6, w]);
    }
    const o = [];
    for (let b = 0; b < this.numOctaves; b++) {
      let x6 = this._differenceImageBinomial(s[b][0], s[b][1]);
      o.push(x6);
    }
    const r = [];
    for (let b = 1; b < this.numOctaves - 1; b++) {
      const x6 = this._buildExtremas(o[b - 1], o[b], o[b + 1]);
      r.push(x6);
    }
    const i6 = this._applyPrune(r), a = this._computeLocalization(i6, o), l = this._computeOrientationHistograms(a, s), c = this._smoothHistograms(l), u = this._computeExtremaAngles(c), d = this._computeExtremaFreak(s, a, u), h = this._computeFreakDescriptors(d), p = a.arraySync(), f = u.arraySync(), m = h.arraySync();
    this.debugMode && (e = {
      pyramidImages: s.map((b) => b.map((x6) => x6.arraySync())),
      dogPyramidImages: o.map((b) => b ? b.arraySync() : null),
      extremasResults: r.map((b) => b.arraySync()),
      extremaAngles: u.arraySync(),
      prunedExtremas: i6,
      localizedExtremas: a.arraySync()
    }), s.forEach((b) => b.forEach((x6) => x6.dispose())), o.forEach((b) => b && b.dispose()), r.forEach((b) => b.dispose()), a.dispose(), l.dispose(), c.dispose(), u.dispose(), d.dispose(), h.dispose();
    const g = [];
    for (let b = 0; b < p.length; b++) {
      if (p[b][0] == 0)
        continue;
      const x6 = [];
      for (let N = 0; N < m[b].length; N += 4) {
        const R = m[b][N], M6 = m[b][N + 1], V = m[b][N + 2], z = m[b][N + 3];
        let P = R * 16777216 + M6 * 65536 + V * 256 + z;
        x6.push(P);
      }
      const w = p[b][1], y6 = p[b][2], v = p[b][3] * Math.pow(2, w) + Math.pow(2, w - 1) - 0.5, k6 = y6 * Math.pow(2, w) + Math.pow(2, w - 1) - 0.5, S = Math.pow(2, w);
      g.push({
        maxima: p[b][0] > 0,
        x: v,
        y: k6,
        scale: S,
        angle: f[b],
        descriptors: x6
      });
    }
    return { featurePoints: g, debugExtra: e };
  }
  _computeFreakDescriptors(t) {
    if (!this.tensorCaches.computeFreakDescriptors) {
      const s = [], o = [];
      for (let a = 0; a < t.shape[1]; a++)
        for (let l = a + 1; l < t.shape[1]; l++)
          s.push(a), o.push(l);
      const r = $e(s, [s.length]).cast("int32"), i6 = $e(o, [o.length]).cast("int32");
      this.tensorCaches.computeFreakDescriptors = {
        positionT: hn(Xn([r, i6], 1))
      };
    }
    const { positionT: e } = this.tensorCaches.computeFreakDescriptors;
    return D(() => Ot().runKernel("ComputeFreakDescriptors", { extremaFreaks: t, positionT: e }));
  }
  _computeExtremaFreak(t, e, s) {
    this.tensorCaches._computeExtremaFreak || D(() => {
      const i6 = $e(Ao);
      this.tensorCaches._computeExtremaFreak = {
        freakPointsT: hn(i6)
      };
    });
    const { freakPointsT: o } = this.tensorCaches._computeExtremaFreak, r = [];
    for (let i6 = 1; i6 < t.length; i6++)
      r.push(t[i6][1]);
    return D(() => Ot().runKernel("ComputeExtremaFreak", { gaussianImagesT: r, prunedExtremas: e, prunedExtremasAngles: s, freakPointsT: o, pyramidImagesLength: t.length }));
  }
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} histograms 
   * @returns 
   */
  _computeExtremaAngles(t) {
    return D(() => Ot().runKernel("ComputeExtremaAngles", { histograms: t }));
  }
  // TODO: maybe can try just using average momentum, instead of histogram method. histogram might be overcomplicated
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} prunedExtremasT 
   * @param {tf.Tensor<tf.Rank>[]} pyramidImagesT 
   * @returns 
   */
  _computeOrientationHistograms(t, e) {
    const s = [];
    for (let r = 1; r < e.length; r++)
      s.push(e[r][1]);
    this.tensorCaches.orientationHistograms || D(() => {
      const r = -1 / (2 * qu * qu), i6 = qu * F4, a = Math.ceil(i6), l = [];
      for (let c = -a; c <= a; c++)
        for (let u = -a; u <= a; u++) {
          const d = u * u + c * c;
          if (d <= i6 * i6) {
            const h = d * r;
            let p = (720 + h * (720 + h * (360 + h * (120 + h * (30 + h * (6 + h)))))) * 0.0013888888;
            l.push([c, u, p]);
          }
        }
      this.tensorCaches.orientationHistograms = {
        radialPropertiesT: hn($e(l, [l.length, 3]))
      };
    });
    const { radialPropertiesT: o } = this.tensorCaches.orientationHistograms;
    return D(() => Ot().runKernel("ComputeOrientationHistograms", { gaussianImagesT: s, prunedExtremasT: t, radialPropertiesT: o, pyramidImagesLength: e.length }));
  }
  // The histogram is smoothed with a Gaussian, with sigma = 1
  _smoothHistograms(t) {
    return D(() => Ot().runKernel("SmoothHistograms", { histograms: t }));
  }
  /**
   * 
   * @param {number[][]} prunedExtremasList 
   * @param {tf.Tensor<tf.Rank>[]} dogPyramidImagesT 
   * @returns 
   */
  _computeLocalization(t, e) {
    return D(() => {
      const o = Ot().runKernel("ComputeLocalization", { prunedExtremasList: t, dogPyramidImagesT: e }).arraySync(), r = [];
      for (let a = 0; a < o.length; a++) {
        r.push([]);
        for (let l = 0; l < o[a].length; l++)
          r[a].push([]);
      }
      const i6 = [];
      for (let a = 0; a < t.length; a++)
        i6[a] = [
          t[a][0],
          t[a][1],
          t[a][2],
          t[a][3]
        ];
      for (let a = 0; a < i6.length; a++) {
        if (i6[a][0] === 0)
          continue;
        const l = o[a], c = 0.5 * (l[1][2] - l[1][0]), u = 0.5 * (l[2][1] - l[0][1]), d = l[1][2] + l[1][0] - 2 * l[1][1], h = l[2][1] + l[0][1] - 2 * l[1][1], p = 0.25 * (l[0][0] + l[2][2] - l[0][2] - l[2][0]), f = d * h - p * p, m = (h * -c + -p * -u) / f, g = (-p * -c + d * -u) / f, b = i6[a][2] + g, x6 = i6[a][3] + m;
        Math.abs(f) < 1e-4 || (i6[a][2] = b, i6[a][3] = x6);
      }
      return $e(i6, [i6.length, i6[0].length], "float32");
    });
  }
  // faster to do it in CPU
  // if we do in gpu, we probably need to use tf.topk(), which seems to be run in CPU anyway (no gpu operation for that)
  //  TODO: research adapative maximum supression method
  /**
   * 
   * @param {tf.Tensor<tf.Rank>[]} extremasResultsT 
   * @returns 
   */
  _applyPrune(t) {
    const e = Br * Br, s = D4, o = [], r = [];
    for (let a = 0; a < e; a++) {
      r.push([]), o.push([]);
      for (let l = 0; l < s; l++)
        r[a].push([0, 0, 0, 0]), o[a].push(0);
    }
    D(() => {
      for (let a = 0; a < t.length; a++) {
        const l = Ot().runKernel("ExtremaReduction", { extremasResultT: t[a] }), c = a + 1, u = l.arraySync(), d = l.shape[0], h = l.shape[1], p = h * 2 / Br, f = d * 2 / Br;
        for (let m = 0; m < d; m++)
          for (let g = 0; g < h; g++) {
            const b = u[m][g];
            if (b == 0)
              continue;
            const x6 = b % 1e3, w = Math.floor(Math.abs(b) / 1e3), y6 = g * 2 + (w === 2 || w === 3 ? 1 : 0), I = m * 2 + (w === 1 || w === 3 ? 1 : 0), v = Math.floor(y6 / p), S = Math.floor(I / f) * Br + v, N = Math.abs(x6);
            let R = s;
            for (; R >= 1 && N > o[S][R - 1]; )
              R -= 1;
            if (R < s) {
              for (let M6 = s - 1; M6 >= R + 1; M6--)
                o[S][M6] = o[S][M6 - 1], r[S][M6][0] = r[S][M6 - 1][0], r[S][M6][1] = r[S][M6 - 1][1], r[S][M6][2] = r[S][M6 - 1][2], r[S][M6][3] = r[S][M6 - 1][3];
              o[S][R] = N, r[S][R][0] = x6, r[S][R][1] = c, r[S][R][2] = I, r[S][R][3] = y6;
            }
          }
      }
    });
    const i6 = [];
    for (let a = 0; a < e; a++)
      for (let l = 0; l < s; l++)
        i6.push(r[a][l]);
    return i6;
  }
  _buildExtremas(t, e, s) {
    return D(() => Ot().runKernel("BuildExtremas", { image0: t, image1: e, image2: s }));
  }
  /**
   * 
   * @param {tf.Tensor<tf.Rank>} image1 
   * @param {tf.Tensor<tf.Rank>} image2 
   * @returns 
   */
  _differenceImageBinomial(t, e) {
    return D(() => t.sub(e));
  }
  // 4th order binomail filter [1,4,6,4,1] X [1,4,6,4,1]
  _applyFilter(t) {
    return D(() => Ot().runKernel("BinomialFilter", { image: t }));
  }
  /* _upsampleBilinear(image, targetImage) {
  		const imageHeight = image.shape[0];
  		const imageWidth = image.shape[1];
  
  		const kernelKey = 'w' + imageWidth;
  		if (!this.kernelCaches.upsampleBilinear) {
  			this.kernelCaches.upsampleBilinear = {};
  		}
  
  		if (!this.kernelCaches.upsampleBilinear[kernelKey]) {
  			const kernel = {
  				variableNames: ['p'],
  				outputShape: [targetImage.shape[0], targetImage.shape[1]],
  				userCode: `
  	  void main() {
  		ivec2 coords = getOutputCoords();
  		int j = coords[0];
  		int i = coords[1];
  
  		float sj = 0.5 * float(j) - 0.25; 
  		float si = 0.5 * float(i) - 0.25;
  
  		float sj0 = floor(sj);
  		float sj1 = ceil(sj);
  		float si0 = floor(si);
  		float si1 = ceil(si);
  
  		int sj0I = int(sj0);
  		int sj1I = int(sj1);
  		int si0I = int(si0);
  		int si1I = int(si1);
  
  		float sum = 0.0;
  		sum += getP(sj0I, si0I) * (si1 - si) * (sj1 - sj);
  		sum += getP(sj1I, si0I) * (si1 - si) * (sj - sj0);
  		sum += getP(sj0I, si1I) * (si - si0) * (sj1 - sj);
  		sum += getP(sj1I, si1I) * (si - si0) * (sj - sj0);
  		setOutput(sum);
  	  }
  	`
  			};
  			this.kernelCaches.upsampleBilinear[kernelKey] = kernel;
  		}
  
  		return tf.tidy(() => {
  			const program = this.kernelCaches.upsampleBilinear[kernelKey];
  			return tf.engine().runKernel("UpsampleBilinear", { x: image, width: image.shape[1], height: image.shape[0] });//this._compileAndRun(program, [image]);
  		});
  	} */
  _downsampleBilinear(t) {
    return D(() => Ot().runKernel("DownsampleBilinear", { image: t }));
  }
  /**
   * 
   * @param {tf.MathBackendWebGL.GPGPUProgram} program 
   * @param {*} inputs 
   * @returns 
   */
  _compileAndRun(t, e) {
    const s = ps().compileAndRun(t, e);
    return Ot().makeTensorFromDataId(s.dataId, s.shape, s.dtype);
  }
  _runWebGLProgram(t, e, s) {
    const o = ps().runWebGLProgram(t, e, s);
    return Ot().makeTensorFromDataId(o.dataId, o.shape, o.dtype);
  }
};
var V4 = class {
  constructor(t, e, s = false) {
    this.debugMode = s, this.width = t, this.height = e;
    let o = Math.min(t, e) / 2, r = Math.pow(2, Math.round(Math.log(o) / Math.log(2)));
    this.cropSize = r, this.detector = new vC(r, r, s), this.kernelCaches = {}, this.lastRandomIndex = 4;
  }
  detect(t) {
    const e = Math.floor(this.height / 2 - this.cropSize / 2), s = Math.floor(this.width / 2 - this.cropSize / 2), o = this._detect(t, s, e);
    return this.debugMode && (o.debugExtra.crop = { startX: s, startY: e, cropSize: this.cropSize }), o;
  }
  detectMoving(t) {
    const e = this.lastRandomIndex % 3, s = Math.floor(this.lastRandomIndex / 3);
    let o = Math.floor(this.height / 2 - this.cropSize + s * this.cropSize / 2), r = Math.floor(this.width / 2 - this.cropSize + e * this.cropSize / 2);
    return r < 0 && (r = 0), o < 0 && (o = 0), r >= this.width - this.cropSize && (r = this.width - this.cropSize - 1), o >= this.height - this.cropSize && (o = this.height - this.cropSize - 1), this.lastRandomIndex = (this.lastRandomIndex + 1) % 9, this._detect(t, r, o);
  }
  _detect(t, e, s) {
    const o = t.slice([s, e], [this.cropSize, this.cropSize]), { featurePoints: r, debugExtra: i6 } = this.detector.detect(o);
    return r.forEach((a) => {
      a.x += e, a.y += s;
    }), this.debugMode && (i6.projectedImage = o.arraySync()), o.dispose(), { featurePoints: r, debugExtra: i6 };
  }
};
var SC = ({ image: n, ratio: t }) => {
  const e = Math.round(n.width * t), s = Math.round(n.height * t), o = new Uint8Array(e * s);
  for (let r = 0; r < e; r++) {
    let i6 = Math.round(1 * r / t), a = Math.round(1 * (r + 1) / t) - 1;
    a >= n.width && (a = n.width - 1);
    for (let l = 0; l < s; l++) {
      let c = Math.round(1 * l / t), u = Math.round(1 * (l + 1) / t) - 1;
      u >= n.height && (u = n.height - 1);
      let d = 0, h = 0;
      for (let p = i6; p <= a; p++)
        for (let f = c; f <= u; f++)
          d += 1 * n.data[f * n.width + p], h += 1;
      o[l * e + r] = Math.floor(d / h);
    }
  }
  return { data: o, width: e, height: s };
};
var z4 = 100;
var P4 = (n) => {
  const t = z4 / Math.min(n.width, n.height), e = [];
  let s = t;
  for (; ; )
    if (e.push(s), s *= Math.pow(2, 1 / 3), s >= 0.95) {
      s = 1;
      break;
    }
  e.push(s), e.reverse();
  const o = [];
  for (let r = 0; r < e.length; r++)
    n.width * e[r], n.height * e[r], o.push(Object.assign(SC({ image: n, ratio: e[r] }), { scale: e[r] }));
  return o;
};
var A4 = (n) => {
  const t = Math.min(n.width, n.height), e = [], s = [];
  e.push(256 / t), e.push(128 / t);
  for (let o = 0; o < e.length; o++)
    s.push(Object.assign(SC({ image: n, ratio: e[o] }), { scale: e[o] }));
  return s;
};
var O4 = (n) => {
  const { v1: t, v2: e } = n;
  let s = 0;
  for (let o = 0; o < t.length; o++) {
    let r = (t[o] ^ e[o]) >>> 0;
    s += X4(r);
  }
  return s;
};
var X4 = (n) => {
  var t = n - (n >> 1 & 1431655765);
  return t = (t >> 2 & 858993459) + (t & 858993459), t = (t >> 4) + t & 252645135, t = (t >> 8) + t & 16711935, t = (t >> 16) + t & 65535, t;
};
var K4 = 1234;
var Z4 = () => ({
  seed: K4,
  arrayShuffle(t) {
    const { arr: e, sampleSize: s } = t;
    for (let o = 0; o < s; o++) {
      this.seed = (214013 * this.seed + 2531011) % -2147483648;
      let r = this.seed >> 16 & 32767;
      r = r % e.length;
      let i6 = e[o];
      e[o] = e[r], e[r] = i6;
    }
  },
  nextInt(t) {
    this.seed = (214013 * this.seed + 2531011) % -2147483648;
    let e = this.seed >> 16 & 32767;
    return e = e % t, e;
  }
});
var B4 = 16;
var H4 = 128;
var Bd = 8;
var _4 = (n) => {
  const { points: t, pointIndexes: e, randomizer: s } = n, o = [];
  for (let l = 0; l < e.length; l++)
    o.push(l);
  let r = Number.MAX_SAFE_INTEGER, i6 = -1;
  const a = [];
  for (let l = 0; l < H4; l++) {
    s.arrayShuffle({ arr: o, sampleSize: Bd });
    let c = 0;
    const u = [];
    for (let d = 0; d < e.length; d++) {
      let h = Number.MAX_SAFE_INTEGER;
      for (let p = 0; p < Bd; p++) {
        const f = e[o[p]], m = O4({ v1: t[e[d]].descriptors, v2: t[f].descriptors });
        m < h && (u[d] = o[p], h = m);
      }
      c += h;
    }
    a.push(u), c < r && (r = c, i6 = l);
  }
  return a[i6];
};
var _g = ({ points: n }) => {
  const t = [];
  for (let o = 0; o < n.length; o++)
    t.push(o);
  const e = Z4();
  return { rootNode: kC({ points: n, pointIndexes: t, centerPointIndex: null, randomizer: e }) };
};
var kC = (n) => {
  const { points: t, pointIndexes: e, centerPointIndex: s, randomizer: o } = n;
  let r = false;
  (e.length <= Bd || e.length <= B4) && (r = true);
  const i6 = {};
  if (!r) {
    const l = _4({ points: t, pointIndexes: e, randomizer: o });
    for (let c = 0; c < l.length; c++)
      i6[e[l[c]]] === void 0 && (i6[e[l[c]]] = []), i6[e[l[c]]].push(e[c]);
  }
  Object.keys(i6).length === 1 && (r = true);
  const a = {
    centerPointIndex: s
  };
  if (r) {
    a.leaf = true, a.pointIndexes = [];
    for (let l = 0; l < e.length; l++)
      a.pointIndexes.push(e[l]);
    return a;
  }
  return a.leaf = false, a.children = [], Object.keys(i6).forEach((l) => {
    a.children.push(kC({ points: t, pointIndexes: i6[l], centerPointIndex: l, randomizer: o }));
  }), a;
};
var fo = 4294967295;
function U4(n, t, e) {
  var s = e / 4294967296, o = e;
  n.setUint32(t, s), n.setUint32(t + 4, o);
}
function TC(n, t, e) {
  var s = Math.floor(e / 4294967296), o = e;
  n.setUint32(t, s), n.setUint32(t + 4, o);
}
function NC(n, t) {
  var e = n.getInt32(t), s = n.getUint32(t + 4);
  return e * 4294967296 + s;
}
function Y4(n, t) {
  var e = n.getUint32(t), s = n.getUint32(t + 4);
  return e * 4294967296 + s;
}
var td;
var ed;
var nd;
var Tu = (typeof process > "u" || ((td = process == null ? void 0 : process.env) === null || td === void 0 ? void 0 : td.TEXT_ENCODING) !== "never") && typeof TextEncoder < "u" && typeof TextDecoder < "u";
function Ug(n) {
  for (var t = n.length, e = 0, s = 0; s < t; ) {
    var o = n.charCodeAt(s++);
    if (o & 4294967168)
      if (!(o & 4294965248))
        e += 2;
      else {
        if (o >= 55296 && o <= 56319 && s < t) {
          var r = n.charCodeAt(s);
          (r & 64512) === 56320 && (++s, o = ((o & 1023) << 10) + (r & 1023) + 65536);
        }
        o & 4294901760 ? e += 4 : e += 3;
      }
    else {
      e++;
      continue;
    }
  }
  return e;
}
function Q4(n, t, e) {
  for (var s = n.length, o = e, r = 0; r < s; ) {
    var i6 = n.charCodeAt(r++);
    if (i6 & 4294967168)
      if (!(i6 & 4294965248))
        t[o++] = i6 >> 6 & 31 | 192;
      else {
        if (i6 >= 55296 && i6 <= 56319 && r < s) {
          var a = n.charCodeAt(r);
          (a & 64512) === 56320 && (++r, i6 = ((i6 & 1023) << 10) + (a & 1023) + 65536);
        }
        i6 & 4294901760 ? (t[o++] = i6 >> 18 & 7 | 240, t[o++] = i6 >> 12 & 63 | 128, t[o++] = i6 >> 6 & 63 | 128) : (t[o++] = i6 >> 12 & 15 | 224, t[o++] = i6 >> 6 & 63 | 128);
      }
    else {
      t[o++] = i6;
      continue;
    }
    t[o++] = i6 & 63 | 128;
  }
}
var oi = Tu ? new TextEncoder() : void 0;
var J4 = Tu ? typeof process < "u" && ((ed = process == null ? void 0 : process.env) === null || ed === void 0 ? void 0 : ed.TEXT_ENCODING) !== "force" ? 200 : 0 : fo;
function j4(n, t, e) {
  t.set(oi.encode(n), e);
}
function q4(n, t, e) {
  oi.encodeInto(n, t.subarray(e));
}
var tY = oi != null && oi.encodeInto ? q4 : j4;
var eY = 4096;
function RC(n, t, e) {
  for (var s = t, o = s + e, r = [], i6 = ""; s < o; ) {
    var a = n[s++];
    if (!(a & 128))
      r.push(a);
    else if ((a & 224) === 192) {
      var l = n[s++] & 63;
      r.push((a & 31) << 6 | l);
    } else if ((a & 240) === 224) {
      var l = n[s++] & 63, c = n[s++] & 63;
      r.push((a & 31) << 12 | l << 6 | c);
    } else if ((a & 248) === 240) {
      var l = n[s++] & 63, c = n[s++] & 63, u = n[s++] & 63, d = (a & 7) << 18 | l << 12 | c << 6 | u;
      d > 65535 && (d -= 65536, r.push(d >>> 10 & 1023 | 55296), d = 56320 | d & 1023), r.push(d);
    } else
      r.push(a);
    r.length >= eY && (i6 += String.fromCharCode.apply(String, r), r.length = 0);
  }
  return r.length > 0 && (i6 += String.fromCharCode.apply(String, r)), i6;
}
var nY = Tu ? new TextDecoder() : null;
var sY = Tu ? typeof process < "u" && ((nd = process == null ? void 0 : process.env) === null || nd === void 0 ? void 0 : nd.TEXT_DECODER) !== "force" ? 200 : 0 : fo;
function oY(n, t, e) {
  var s = n.subarray(t, t + e);
  return nY.decode(s);
}
var sl = (
  /** @class */
  /* @__PURE__ */ function() {
    function n(t, e) {
      this.type = t, this.data = e;
    }
    return n;
  }()
);
var rY = /* @__PURE__ */ function() {
  var n = function(t, e) {
    return n = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(s, o) {
      s.__proto__ = o;
    } || function(s, o) {
      for (var r in o)
        Object.prototype.hasOwnProperty.call(o, r) && (s[r] = o[r]);
    }, n(t, e);
  };
  return function(t, e) {
    if (typeof e != "function" && e !== null)
      throw new TypeError("Class extends value " + String(e) + " is not a constructor or null");
    n(t, e);
    function s() {
      this.constructor = t;
    }
    t.prototype = e === null ? Object.create(e) : (s.prototype = e.prototype, new s());
  };
}();
var Yn = (
  /** @class */
  function(n) {
    rY(t, n);
    function t(e) {
      var s = n.call(this, e) || this, o = Object.create(t.prototype);
      return Object.setPrototypeOf(s, o), Object.defineProperty(s, "name", {
        configurable: true,
        enumerable: false,
        value: t.name
      }), s;
    }
    return t;
  }(Error)
);
var iY = -1;
var aY = 4294967296 - 1;
var lY = 17179869184 - 1;
function cY(n) {
  var t = n.sec, e = n.nsec;
  if (t >= 0 && e >= 0 && t <= lY)
    if (e === 0 && t <= aY) {
      var s = new Uint8Array(4), o = new DataView(s.buffer);
      return o.setUint32(0, t), s;
    } else {
      var r = t / 4294967296, i6 = t & 4294967295, s = new Uint8Array(8), o = new DataView(s.buffer);
      return o.setUint32(0, e << 2 | r & 3), o.setUint32(4, i6), s;
    }
  else {
    var s = new Uint8Array(12), o = new DataView(s.buffer);
    return o.setUint32(0, e), TC(o, 4, t), s;
  }
}
function uY(n) {
  var t = n.getTime(), e = Math.floor(t / 1e3), s = (t - e * 1e3) * 1e6, o = Math.floor(s / 1e9);
  return {
    sec: e + o,
    nsec: s - o * 1e9
  };
}
function dY(n) {
  if (n instanceof Date) {
    var t = uY(n);
    return cY(t);
  } else
    return null;
}
function hY(n) {
  var t = new DataView(n.buffer, n.byteOffset, n.byteLength);
  switch (n.byteLength) {
    case 4: {
      var e = t.getUint32(0), s = 0;
      return { sec: e, nsec: s };
    }
    case 8: {
      var o = t.getUint32(0), r = t.getUint32(4), e = (o & 3) * 4294967296 + r, s = o >>> 2;
      return { sec: e, nsec: s };
    }
    case 12: {
      var e = NC(t, 4), s = t.getUint32(0);
      return { sec: e, nsec: s };
    }
    default:
      throw new Yn("Unrecognized data size for timestamp (expected 4, 8, or 12): ".concat(n.length));
  }
}
function pY(n) {
  var t = hY(n);
  return new Date(t.sec * 1e3 + t.nsec / 1e6);
}
var fY = {
  type: iY,
  encode: dY,
  decode: pY
};
var $C = (
  /** @class */
  function() {
    function n() {
      this.builtInEncoders = [], this.builtInDecoders = [], this.encoders = [], this.decoders = [], this.register(fY);
    }
    return n.prototype.register = function(t) {
      var e = t.type, s = t.encode, o = t.decode;
      if (e >= 0)
        this.encoders[e] = s, this.decoders[e] = o;
      else {
        var r = 1 + e;
        this.builtInEncoders[r] = s, this.builtInDecoders[r] = o;
      }
    }, n.prototype.tryToEncode = function(t, e) {
      for (var s = 0; s < this.builtInEncoders.length; s++) {
        var o = this.builtInEncoders[s];
        if (o != null) {
          var r = o(t, e);
          if (r != null) {
            var i6 = -1 - s;
            return new sl(i6, r);
          }
        }
      }
      for (var s = 0; s < this.encoders.length; s++) {
        var o = this.encoders[s];
        if (o != null) {
          var r = o(t, e);
          if (r != null) {
            var i6 = s;
            return new sl(i6, r);
          }
        }
      }
      return t instanceof sl ? t : null;
    }, n.prototype.decode = function(t, e, s) {
      var o = e < 0 ? this.builtInDecoders[-1 - e] : this.decoders[e];
      return o ? o(t, e, s) : new sl(e, t);
    }, n.defaultCodec = new n(), n;
  }()
);
function Zl(n) {
  return n instanceof Uint8Array ? n : ArrayBuffer.isView(n) ? new Uint8Array(n.buffer, n.byteOffset, n.byteLength) : n instanceof ArrayBuffer ? new Uint8Array(n) : Uint8Array.from(n);
}
function mY(n) {
  if (n instanceof ArrayBuffer)
    return new DataView(n);
  var t = Zl(n);
  return new DataView(t.buffer, t.byteOffset, t.byteLength);
}
var gY = 100;
var bY = 2048;
var xY = (
  /** @class */
  function() {
    function n(t, e, s, o, r, i6, a, l) {
      t === void 0 && (t = $C.defaultCodec), e === void 0 && (e = void 0), s === void 0 && (s = gY), o === void 0 && (o = bY), r === void 0 && (r = false), i6 === void 0 && (i6 = false), a === void 0 && (a = false), l === void 0 && (l = false), this.extensionCodec = t, this.context = e, this.maxDepth = s, this.initialBufferSize = o, this.sortKeys = r, this.forceFloat32 = i6, this.ignoreUndefined = a, this.forceIntegerToFloat = l, this.pos = 0, this.view = new DataView(new ArrayBuffer(this.initialBufferSize)), this.bytes = new Uint8Array(this.view.buffer);
    }
    return n.prototype.reinitializeState = function() {
      this.pos = 0;
    }, n.prototype.encodeSharedRef = function(t) {
      return this.reinitializeState(), this.doEncode(t, 1), this.bytes.subarray(0, this.pos);
    }, n.prototype.encode = function(t) {
      return this.reinitializeState(), this.doEncode(t, 1), this.bytes.slice(0, this.pos);
    }, n.prototype.doEncode = function(t, e) {
      if (e > this.maxDepth)
        throw new Error("Too deep objects in depth ".concat(e));
      t == null ? this.encodeNil() : typeof t == "boolean" ? this.encodeBoolean(t) : typeof t == "number" ? this.encodeNumber(t) : typeof t == "string" ? this.encodeString(t) : this.encodeObject(t, e);
    }, n.prototype.ensureBufferSizeToWrite = function(t) {
      var e = this.pos + t;
      this.view.byteLength < e && this.resizeBuffer(e * 2);
    }, n.prototype.resizeBuffer = function(t) {
      var e = new ArrayBuffer(t), s = new Uint8Array(e), o = new DataView(e);
      s.set(this.bytes), this.view = o, this.bytes = s;
    }, n.prototype.encodeNil = function() {
      this.writeU8(192);
    }, n.prototype.encodeBoolean = function(t) {
      t === false ? this.writeU8(194) : this.writeU8(195);
    }, n.prototype.encodeNumber = function(t) {
      Number.isSafeInteger(t) && !this.forceIntegerToFloat ? t >= 0 ? t < 128 ? this.writeU8(t) : t < 256 ? (this.writeU8(204), this.writeU8(t)) : t < 65536 ? (this.writeU8(205), this.writeU16(t)) : t < 4294967296 ? (this.writeU8(206), this.writeU32(t)) : (this.writeU8(207), this.writeU64(t)) : t >= -32 ? this.writeU8(224 | t + 32) : t >= -128 ? (this.writeU8(208), this.writeI8(t)) : t >= -32768 ? (this.writeU8(209), this.writeI16(t)) : t >= -2147483648 ? (this.writeU8(210), this.writeI32(t)) : (this.writeU8(211), this.writeI64(t)) : this.forceFloat32 ? (this.writeU8(202), this.writeF32(t)) : (this.writeU8(203), this.writeF64(t));
    }, n.prototype.writeStringHeader = function(t) {
      if (t < 32)
        this.writeU8(160 + t);
      else if (t < 256)
        this.writeU8(217), this.writeU8(t);
      else if (t < 65536)
        this.writeU8(218), this.writeU16(t);
      else if (t < 4294967296)
        this.writeU8(219), this.writeU32(t);
      else
        throw new Error("Too long string: ".concat(t, " bytes in UTF-8"));
    }, n.prototype.encodeString = function(t) {
      var e = 5, s = t.length;
      if (s > J4) {
        var o = Ug(t);
        this.ensureBufferSizeToWrite(e + o), this.writeStringHeader(o), tY(t, this.bytes, this.pos), this.pos += o;
      } else {
        var o = Ug(t);
        this.ensureBufferSizeToWrite(e + o), this.writeStringHeader(o), Q4(t, this.bytes, this.pos), this.pos += o;
      }
    }, n.prototype.encodeObject = function(t, e) {
      var s = this.extensionCodec.tryToEncode(t, this.context);
      if (s != null)
        this.encodeExtension(s);
      else if (Array.isArray(t))
        this.encodeArray(t, e);
      else if (ArrayBuffer.isView(t))
        this.encodeBinary(t);
      else if (typeof t == "object")
        this.encodeMap(t, e);
      else
        throw new Error("Unrecognized object: ".concat(Object.prototype.toString.apply(t)));
    }, n.prototype.encodeBinary = function(t) {
      var e = t.byteLength;
      if (e < 256)
        this.writeU8(196), this.writeU8(e);
      else if (e < 65536)
        this.writeU8(197), this.writeU16(e);
      else if (e < 4294967296)
        this.writeU8(198), this.writeU32(e);
      else
        throw new Error("Too large binary: ".concat(e));
      var s = Zl(t);
      this.writeU8a(s);
    }, n.prototype.encodeArray = function(t, e) {
      var s = t.length;
      if (s < 16)
        this.writeU8(144 + s);
      else if (s < 65536)
        this.writeU8(220), this.writeU16(s);
      else if (s < 4294967296)
        this.writeU8(221), this.writeU32(s);
      else
        throw new Error("Too large array: ".concat(s));
      for (var o = 0, r = t; o < r.length; o++) {
        var i6 = r[o];
        this.doEncode(i6, e + 1);
      }
    }, n.prototype.countWithoutUndefined = function(t, e) {
      for (var s = 0, o = 0, r = e; o < r.length; o++) {
        var i6 = r[o];
        t[i6] !== void 0 && s++;
      }
      return s;
    }, n.prototype.encodeMap = function(t, e) {
      var s = Object.keys(t);
      this.sortKeys && s.sort();
      var o = this.ignoreUndefined ? this.countWithoutUndefined(t, s) : s.length;
      if (o < 16)
        this.writeU8(128 + o);
      else if (o < 65536)
        this.writeU8(222), this.writeU16(o);
      else if (o < 4294967296)
        this.writeU8(223), this.writeU32(o);
      else
        throw new Error("Too large map object: ".concat(o));
      for (var r = 0, i6 = s; r < i6.length; r++) {
        var a = i6[r], l = t[a];
        this.ignoreUndefined && l === void 0 || (this.encodeString(a), this.doEncode(l, e + 1));
      }
    }, n.prototype.encodeExtension = function(t) {
      var e = t.data.length;
      if (e === 1)
        this.writeU8(212);
      else if (e === 2)
        this.writeU8(213);
      else if (e === 4)
        this.writeU8(214);
      else if (e === 8)
        this.writeU8(215);
      else if (e === 16)
        this.writeU8(216);
      else if (e < 256)
        this.writeU8(199), this.writeU8(e);
      else if (e < 65536)
        this.writeU8(200), this.writeU16(e);
      else if (e < 4294967296)
        this.writeU8(201), this.writeU32(e);
      else
        throw new Error("Too large extension object: ".concat(e));
      this.writeI8(t.type), this.writeU8a(t.data);
    }, n.prototype.writeU8 = function(t) {
      this.ensureBufferSizeToWrite(1), this.view.setUint8(this.pos, t), this.pos++;
    }, n.prototype.writeU8a = function(t) {
      var e = t.length;
      this.ensureBufferSizeToWrite(e), this.bytes.set(t, this.pos), this.pos += e;
    }, n.prototype.writeI8 = function(t) {
      this.ensureBufferSizeToWrite(1), this.view.setInt8(this.pos, t), this.pos++;
    }, n.prototype.writeU16 = function(t) {
      this.ensureBufferSizeToWrite(2), this.view.setUint16(this.pos, t), this.pos += 2;
    }, n.prototype.writeI16 = function(t) {
      this.ensureBufferSizeToWrite(2), this.view.setInt16(this.pos, t), this.pos += 2;
    }, n.prototype.writeU32 = function(t) {
      this.ensureBufferSizeToWrite(4), this.view.setUint32(this.pos, t), this.pos += 4;
    }, n.prototype.writeI32 = function(t) {
      this.ensureBufferSizeToWrite(4), this.view.setInt32(this.pos, t), this.pos += 4;
    }, n.prototype.writeF32 = function(t) {
      this.ensureBufferSizeToWrite(4), this.view.setFloat32(this.pos, t), this.pos += 4;
    }, n.prototype.writeF64 = function(t) {
      this.ensureBufferSizeToWrite(8), this.view.setFloat64(this.pos, t), this.pos += 8;
    }, n.prototype.writeU64 = function(t) {
      this.ensureBufferSizeToWrite(8), U4(this.view, this.pos, t), this.pos += 8;
    }, n.prototype.writeI64 = function(t) {
      this.ensureBufferSizeToWrite(8), TC(this.view, this.pos, t), this.pos += 8;
    }, n;
  }()
);
var yY = {};
function wY(n, t) {
  t === void 0 && (t = yY);
  var e = new xY(t.extensionCodec, t.context, t.maxDepth, t.initialBufferSize, t.sortKeys, t.forceFloat32, t.ignoreUndefined, t.forceIntegerToFloat);
  return e.encodeSharedRef(n);
}
function sd(n) {
  return "".concat(n < 0 ? "-" : "", "0x").concat(Math.abs(n).toString(16).padStart(2, "0"));
}
var IY = 16;
var CY = 16;
var vY = (
  /** @class */
  function() {
    function n(t, e) {
      t === void 0 && (t = IY), e === void 0 && (e = CY), this.maxKeyLength = t, this.maxLengthPerKey = e, this.hit = 0, this.miss = 0, this.caches = [];
      for (var s = 0; s < this.maxKeyLength; s++)
        this.caches.push([]);
    }
    return n.prototype.canBeCached = function(t) {
      return t > 0 && t <= this.maxKeyLength;
    }, n.prototype.find = function(t, e, s) {
      var o = this.caches[s - 1];
      t:
        for (var r = 0, i6 = o; r < i6.length; r++) {
          for (var a = i6[r], l = a.bytes, c = 0; c < s; c++)
            if (l[c] !== t[e + c])
              continue t;
          return a.str;
        }
      return null;
    }, n.prototype.store = function(t, e) {
      var s = this.caches[t.length - 1], o = { bytes: t, str: e };
      s.length >= this.maxLengthPerKey ? s[Math.random() * s.length | 0] = o : s.push(o);
    }, n.prototype.decode = function(t, e, s) {
      var o = this.find(t, e, s);
      if (o != null)
        return this.hit++, o;
      this.miss++;
      var r = RC(t, e, s), i6 = Uint8Array.prototype.slice.call(t, e, e + s);
      return this.store(i6, r), r;
    }, n;
  }()
);
var SY = function(n, t, e, s) {
  function o(r) {
    return r instanceof e ? r : new e(function(i6) {
      i6(r);
    });
  }
  return new (e || (e = Promise))(function(r, i6) {
    function a(u) {
      try {
        c(s.next(u));
      } catch (d) {
        i6(d);
      }
    }
    function l(u) {
      try {
        c(s.throw(u));
      } catch (d) {
        i6(d);
      }
    }
    function c(u) {
      u.done ? r(u.value) : o(u.value).then(a, l);
    }
    c((s = s.apply(n, t || [])).next());
  });
};
var od = function(n, t) {
  var e = { label: 0, sent: function() {
    if (r[0] & 1)
      throw r[1];
    return r[1];
  }, trys: [], ops: [] }, s, o, r, i6;
  return i6 = { next: a(0), throw: a(1), return: a(2) }, typeof Symbol == "function" && (i6[Symbol.iterator] = function() {
    return this;
  }), i6;
  function a(c) {
    return function(u) {
      return l([c, u]);
    };
  }
  function l(c) {
    if (s)
      throw new TypeError("Generator is already executing.");
    for (; e; )
      try {
        if (s = 1, o && (r = c[0] & 2 ? o.return : c[0] ? o.throw || ((r = o.return) && r.call(o), 0) : o.next) && !(r = r.call(o, c[1])).done)
          return r;
        switch (o = 0, r && (c = [c[0] & 2, r.value]), c[0]) {
          case 0:
          case 1:
            r = c;
            break;
          case 4:
            return e.label++, { value: c[1], done: false };
          case 5:
            e.label++, o = c[1], c = [0];
            continue;
          case 7:
            c = e.ops.pop(), e.trys.pop();
            continue;
          default:
            if (r = e.trys, !(r = r.length > 0 && r[r.length - 1]) && (c[0] === 6 || c[0] === 2)) {
              e = 0;
              continue;
            }
            if (c[0] === 3 && (!r || c[1] > r[0] && c[1] < r[3])) {
              e.label = c[1];
              break;
            }
            if (c[0] === 6 && e.label < r[1]) {
              e.label = r[1], r = c;
              break;
            }
            if (r && e.label < r[2]) {
              e.label = r[2], e.ops.push(c);
              break;
            }
            r[2] && e.ops.pop(), e.trys.pop();
            continue;
        }
        c = t.call(n, e);
      } catch (u) {
        c = [6, u], o = 0;
      } finally {
        s = r = 0;
      }
    if (c[0] & 5)
      throw c[1];
    return { value: c[0] ? c[1] : void 0, done: true };
  }
};
var Yg = function(n) {
  if (!Symbol.asyncIterator)
    throw new TypeError("Symbol.asyncIterator is not defined.");
  var t = n[Symbol.asyncIterator], e;
  return t ? t.call(n) : (n = typeof __values == "function" ? __values(n) : n[Symbol.iterator](), e = {}, s("next"), s("throw"), s("return"), e[Symbol.asyncIterator] = function() {
    return this;
  }, e);
  function s(r) {
    e[r] = n[r] && function(i6) {
      return new Promise(function(a, l) {
        i6 = n[r](i6), o(a, l, i6.done, i6.value);
      });
    };
  }
  function o(r, i6, a, l) {
    Promise.resolve(l).then(function(c) {
      r({ value: c, done: a });
    }, i6);
  }
};
var hr = function(n) {
  return this instanceof hr ? (this.v = n, this) : new hr(n);
};
var kY = function(n, t, e) {
  if (!Symbol.asyncIterator)
    throw new TypeError("Symbol.asyncIterator is not defined.");
  var s = e.apply(n, t || []), o, r = [];
  return o = {}, i6("next"), i6("throw"), i6("return"), o[Symbol.asyncIterator] = function() {
    return this;
  }, o;
  function i6(h) {
    s[h] && (o[h] = function(p) {
      return new Promise(function(f, m) {
        r.push([h, p, f, m]) > 1 || a(h, p);
      });
    });
  }
  function a(h, p) {
    try {
      l(s[h](p));
    } catch (f) {
      d(r[0][3], f);
    }
  }
  function l(h) {
    h.value instanceof hr ? Promise.resolve(h.value.v).then(c, u) : d(r[0][2], h);
  }
  function c(h) {
    a("next", h);
  }
  function u(h) {
    a("throw", h);
  }
  function d(h, p) {
    h(p), r.shift(), r.length && a(r[0][0], r[0][1]);
  }
};
var TY = function(n) {
  var t = typeof n;
  return t === "string" || t === "number";
};
var Hr = -1;
var cm = new DataView(new ArrayBuffer(0));
var NY = new Uint8Array(cm.buffer);
var Hd = function() {
  try {
    cm.getInt8(0);
  } catch (n) {
    return n.constructor;
  }
  throw new Error("never reached");
}();
var Qg = new Hd("Insufficient data");
var RY = new vY();
var $Y = (
  /** @class */
  function() {
    function n(t, e, s, o, r, i6, a, l) {
      t === void 0 && (t = $C.defaultCodec), e === void 0 && (e = void 0), s === void 0 && (s = fo), o === void 0 && (o = fo), r === void 0 && (r = fo), i6 === void 0 && (i6 = fo), a === void 0 && (a = fo), l === void 0 && (l = RY), this.extensionCodec = t, this.context = e, this.maxStrLength = s, this.maxBinLength = o, this.maxArrayLength = r, this.maxMapLength = i6, this.maxExtLength = a, this.keyDecoder = l, this.totalPos = 0, this.pos = 0, this.view = cm, this.bytes = NY, this.headByte = Hr, this.stack = [];
    }
    return n.prototype.reinitializeState = function() {
      this.totalPos = 0, this.headByte = Hr, this.stack.length = 0;
    }, n.prototype.setBuffer = function(t) {
      this.bytes = Zl(t), this.view = mY(this.bytes), this.pos = 0;
    }, n.prototype.appendBuffer = function(t) {
      if (this.headByte === Hr && !this.hasRemaining(1))
        this.setBuffer(t);
      else {
        var e = this.bytes.subarray(this.pos), s = Zl(t), o = new Uint8Array(e.length + s.length);
        o.set(e), o.set(s, e.length), this.setBuffer(o);
      }
    }, n.prototype.hasRemaining = function(t) {
      return this.view.byteLength - this.pos >= t;
    }, n.prototype.createExtraByteError = function(t) {
      var e = this, s = e.view, o = e.pos;
      return new RangeError("Extra ".concat(s.byteLength - o, " of ").concat(s.byteLength, " byte(s) found at buffer[").concat(t, "]"));
    }, n.prototype.decode = function(t) {
      this.reinitializeState(), this.setBuffer(t);
      var e = this.doDecodeSync();
      if (this.hasRemaining(1))
        throw this.createExtraByteError(this.pos);
      return e;
    }, n.prototype.decodeMulti = function(t) {
      return od(this, function(e) {
        switch (e.label) {
          case 0:
            this.reinitializeState(), this.setBuffer(t), e.label = 1;
          case 1:
            return this.hasRemaining(1) ? [4, this.doDecodeSync()] : [3, 3];
          case 2:
            return e.sent(), [3, 1];
          case 3:
            return [
              2
              /*return*/
            ];
        }
      });
    }, n.prototype.decodeAsync = function(t) {
      var e, s, o, r;
      return SY(this, void 0, void 0, function() {
        var i6, a, l, c, u, d, h, p;
        return od(this, function(f) {
          switch (f.label) {
            case 0:
              i6 = false, f.label = 1;
            case 1:
              f.trys.push([1, 6, 7, 12]), e = Yg(t), f.label = 2;
            case 2:
              return [4, e.next()];
            case 3:
              if (s = f.sent(), !!s.done)
                return [3, 5];
              if (l = s.value, i6)
                throw this.createExtraByteError(this.totalPos);
              this.appendBuffer(l);
              try {
                a = this.doDecodeSync(), i6 = true;
              } catch (m) {
                if (!(m instanceof Hd))
                  throw m;
              }
              this.totalPos += this.pos, f.label = 4;
            case 4:
              return [3, 2];
            case 5:
              return [3, 12];
            case 6:
              return c = f.sent(), o = { error: c }, [3, 12];
            case 7:
              return f.trys.push([7, , 10, 11]), s && !s.done && (r = e.return) ? [4, r.call(e)] : [3, 9];
            case 8:
              f.sent(), f.label = 9;
            case 9:
              return [3, 11];
            case 10:
              if (o)
                throw o.error;
              return [
                7
                /*endfinally*/
              ];
            case 11:
              return [
                7
                /*endfinally*/
              ];
            case 12:
              if (i6) {
                if (this.hasRemaining(1))
                  throw this.createExtraByteError(this.totalPos);
                return [2, a];
              }
              throw u = this, d = u.headByte, h = u.pos, p = u.totalPos, new RangeError("Insufficient data in parsing ".concat(sd(d), " at ").concat(p, " (").concat(h, " in the current buffer)"));
          }
        });
      });
    }, n.prototype.decodeArrayStream = function(t) {
      return this.decodeMultiAsync(t, true);
    }, n.prototype.decodeStream = function(t) {
      return this.decodeMultiAsync(t, false);
    }, n.prototype.decodeMultiAsync = function(t, e) {
      return kY(this, arguments, function() {
        var o, r, i6, a, l, c, u, d, h;
        return od(this, function(p) {
          switch (p.label) {
            case 0:
              o = e, r = -1, p.label = 1;
            case 1:
              p.trys.push([1, 13, 14, 19]), i6 = Yg(t), p.label = 2;
            case 2:
              return [4, hr(i6.next())];
            case 3:
              if (a = p.sent(), !!a.done)
                return [3, 12];
              if (l = a.value, e && r === 0)
                throw this.createExtraByteError(this.totalPos);
              this.appendBuffer(l), o && (r = this.readArraySize(), o = false, this.complete()), p.label = 4;
            case 4:
              p.trys.push([4, 9, , 10]), p.label = 5;
            case 5:
              return [4, hr(this.doDecodeSync())];
            case 6:
              return [4, p.sent()];
            case 7:
              return p.sent(), --r === 0 ? [3, 8] : [3, 5];
            case 8:
              return [3, 10];
            case 9:
              if (c = p.sent(), !(c instanceof Hd))
                throw c;
              return [3, 10];
            case 10:
              this.totalPos += this.pos, p.label = 11;
            case 11:
              return [3, 2];
            case 12:
              return [3, 19];
            case 13:
              return u = p.sent(), d = { error: u }, [3, 19];
            case 14:
              return p.trys.push([14, , 17, 18]), a && !a.done && (h = i6.return) ? [4, hr(h.call(i6))] : [3, 16];
            case 15:
              p.sent(), p.label = 16;
            case 16:
              return [3, 18];
            case 17:
              if (d)
                throw d.error;
              return [
                7
                /*endfinally*/
              ];
            case 18:
              return [
                7
                /*endfinally*/
              ];
            case 19:
              return [
                2
                /*return*/
              ];
          }
        });
      });
    }, n.prototype.doDecodeSync = function() {
      t:
        for (; ; ) {
          var t = this.readHeadByte(), e = void 0;
          if (t >= 224)
            e = t - 256;
          else if (t < 192)
            if (t < 128)
              e = t;
            else if (t < 144) {
              var s = t - 128;
              if (s !== 0) {
                this.pushMapState(s), this.complete();
                continue t;
              } else
                e = {};
            } else if (t < 160) {
              var s = t - 144;
              if (s !== 0) {
                this.pushArrayState(s), this.complete();
                continue t;
              } else
                e = [];
            } else {
              var o = t - 160;
              e = this.decodeUtf8String(o, 0);
            }
          else if (t === 192)
            e = null;
          else if (t === 194)
            e = false;
          else if (t === 195)
            e = true;
          else if (t === 202)
            e = this.readF32();
          else if (t === 203)
            e = this.readF64();
          else if (t === 204)
            e = this.readU8();
          else if (t === 205)
            e = this.readU16();
          else if (t === 206)
            e = this.readU32();
          else if (t === 207)
            e = this.readU64();
          else if (t === 208)
            e = this.readI8();
          else if (t === 209)
            e = this.readI16();
          else if (t === 210)
            e = this.readI32();
          else if (t === 211)
            e = this.readI64();
          else if (t === 217) {
            var o = this.lookU8();
            e = this.decodeUtf8String(o, 1);
          } else if (t === 218) {
            var o = this.lookU16();
            e = this.decodeUtf8String(o, 2);
          } else if (t === 219) {
            var o = this.lookU32();
            e = this.decodeUtf8String(o, 4);
          } else if (t === 220) {
            var s = this.readU16();
            if (s !== 0) {
              this.pushArrayState(s), this.complete();
              continue t;
            } else
              e = [];
          } else if (t === 221) {
            var s = this.readU32();
            if (s !== 0) {
              this.pushArrayState(s), this.complete();
              continue t;
            } else
              e = [];
          } else if (t === 222) {
            var s = this.readU16();
            if (s !== 0) {
              this.pushMapState(s), this.complete();
              continue t;
            } else
              e = {};
          } else if (t === 223) {
            var s = this.readU32();
            if (s !== 0) {
              this.pushMapState(s), this.complete();
              continue t;
            } else
              e = {};
          } else if (t === 196) {
            var s = this.lookU8();
            e = this.decodeBinary(s, 1);
          } else if (t === 197) {
            var s = this.lookU16();
            e = this.decodeBinary(s, 2);
          } else if (t === 198) {
            var s = this.lookU32();
            e = this.decodeBinary(s, 4);
          } else if (t === 212)
            e = this.decodeExtension(1, 0);
          else if (t === 213)
            e = this.decodeExtension(2, 0);
          else if (t === 214)
            e = this.decodeExtension(4, 0);
          else if (t === 215)
            e = this.decodeExtension(8, 0);
          else if (t === 216)
            e = this.decodeExtension(16, 0);
          else if (t === 199) {
            var s = this.lookU8();
            e = this.decodeExtension(s, 1);
          } else if (t === 200) {
            var s = this.lookU16();
            e = this.decodeExtension(s, 2);
          } else if (t === 201) {
            var s = this.lookU32();
            e = this.decodeExtension(s, 4);
          } else
            throw new Yn("Unrecognized type byte: ".concat(sd(t)));
          this.complete();
          for (var r = this.stack; r.length > 0; ) {
            var i6 = r[r.length - 1];
            if (i6.type === 0)
              if (i6.array[i6.position] = e, i6.position++, i6.position === i6.size)
                r.pop(), e = i6.array;
              else
                continue t;
            else if (i6.type === 1) {
              if (!TY(e))
                throw new Yn("The type of key must be string or number but " + typeof e);
              if (e === "__proto__")
                throw new Yn("The key __proto__ is not allowed");
              i6.key = e, i6.type = 2;
              continue t;
            } else if (i6.map[i6.key] = e, i6.readCount++, i6.readCount === i6.size)
              r.pop(), e = i6.map;
            else {
              i6.key = null, i6.type = 1;
              continue t;
            }
          }
          return e;
        }
    }, n.prototype.readHeadByte = function() {
      return this.headByte === Hr && (this.headByte = this.readU8()), this.headByte;
    }, n.prototype.complete = function() {
      this.headByte = Hr;
    }, n.prototype.readArraySize = function() {
      var t = this.readHeadByte();
      switch (t) {
        case 220:
          return this.readU16();
        case 221:
          return this.readU32();
        default: {
          if (t < 160)
            return t - 144;
          throw new Yn("Unrecognized array type byte: ".concat(sd(t)));
        }
      }
    }, n.prototype.pushMapState = function(t) {
      if (t > this.maxMapLength)
        throw new Yn("Max length exceeded: map length (".concat(t, ") > maxMapLengthLength (").concat(this.maxMapLength, ")"));
      this.stack.push({
        type: 1,
        size: t,
        key: null,
        readCount: 0,
        map: {}
      });
    }, n.prototype.pushArrayState = function(t) {
      if (t > this.maxArrayLength)
        throw new Yn("Max length exceeded: array length (".concat(t, ") > maxArrayLength (").concat(this.maxArrayLength, ")"));
      this.stack.push({
        type: 0,
        size: t,
        array: new Array(t),
        position: 0
      });
    }, n.prototype.decodeUtf8String = function(t, e) {
      var s;
      if (t > this.maxStrLength)
        throw new Yn("Max length exceeded: UTF-8 byte length (".concat(t, ") > maxStrLength (").concat(this.maxStrLength, ")"));
      if (this.bytes.byteLength < this.pos + e + t)
        throw Qg;
      var o = this.pos + e, r;
      return this.stateIsMapKey() && (!((s = this.keyDecoder) === null || s === void 0) && s.canBeCached(t)) ? r = this.keyDecoder.decode(this.bytes, o, t) : t > sY ? r = oY(this.bytes, o, t) : r = RC(this.bytes, o, t), this.pos += e + t, r;
    }, n.prototype.stateIsMapKey = function() {
      if (this.stack.length > 0) {
        var t = this.stack[this.stack.length - 1];
        return t.type === 1;
      }
      return false;
    }, n.prototype.decodeBinary = function(t, e) {
      if (t > this.maxBinLength)
        throw new Yn("Max length exceeded: bin length (".concat(t, ") > maxBinLength (").concat(this.maxBinLength, ")"));
      if (!this.hasRemaining(t + e))
        throw Qg;
      var s = this.pos + e, o = this.bytes.subarray(s, s + t);
      return this.pos += e + t, o;
    }, n.prototype.decodeExtension = function(t, e) {
      if (t > this.maxExtLength)
        throw new Yn("Max length exceeded: ext length (".concat(t, ") > maxExtLength (").concat(this.maxExtLength, ")"));
      var s = this.view.getInt8(this.pos + e), o = this.decodeBinary(
        t,
        e + 1
        /* extType */
      );
      return this.extensionCodec.decode(o, s, this.context);
    }, n.prototype.lookU8 = function() {
      return this.view.getUint8(this.pos);
    }, n.prototype.lookU16 = function() {
      return this.view.getUint16(this.pos);
    }, n.prototype.lookU32 = function() {
      return this.view.getUint32(this.pos);
    }, n.prototype.readU8 = function() {
      var t = this.view.getUint8(this.pos);
      return this.pos++, t;
    }, n.prototype.readI8 = function() {
      var t = this.view.getInt8(this.pos);
      return this.pos++, t;
    }, n.prototype.readU16 = function() {
      var t = this.view.getUint16(this.pos);
      return this.pos += 2, t;
    }, n.prototype.readI16 = function() {
      var t = this.view.getInt16(this.pos);
      return this.pos += 2, t;
    }, n.prototype.readU32 = function() {
      var t = this.view.getUint32(this.pos);
      return this.pos += 4, t;
    }, n.prototype.readI32 = function() {
      var t = this.view.getInt32(this.pos);
      return this.pos += 4, t;
    }, n.prototype.readU64 = function() {
      var t = Y4(this.view, this.pos);
      return this.pos += 8, t;
    }, n.prototype.readI64 = function() {
      var t = NC(this.view, this.pos);
      return this.pos += 8, t;
    }, n.prototype.readF32 = function() {
      var t = this.view.getFloat32(this.pos);
      return this.pos += 4, t;
    }, n.prototype.readF64 = function() {
      var t = this.view.getFloat64(this.pos);
      return this.pos += 8, t;
    }, n;
  }()
);
var GY = {};
function EY(n, t) {
  t === void 0 && (t = GY);
  var e = new $Y(t.extensionCodec, t.context, t.maxStrLength, t.maxBinLength, t.maxArrayLength, t.maxMapLength, t.maxExtLength);
  return e.decode(n);
}
var Jg = 2;
var LY = class {
  constructor() {
    this.data = null;
  }
  // input html Images
  compileImageTargets(t, e) {
    return new Promise(async (s, o) => {
      const r = [];
      for (let c = 0; c < t.length; c++) {
        const u = t[c], h = this.createProcessCanvas(u).getContext("2d");
        h.drawImage(u, 0, 0, u.width, u.height);
        const p = h.getImageData(0, 0, u.width, u.height), f = new Uint8Array(u.width * u.height);
        for (let g = 0; g < f.length; g++) {
          const b = g * 4;
          f[g] = Math.floor((p.data[b] + p.data[b + 1] + p.data[b + 2]) / 3);
        }
        const m = { data: f, height: u.height, width: u.width };
        r.push(m);
      }
      const i6 = 50 / r.length;
      let a = 0;
      this.data = [];
      for (let c = 0; c < r.length; c++) {
        const u = r[c], d = P4(u), h = i6 / d.length, p = await MY(d, () => {
          a += h, e(a);
        });
        this.data.push({
          targetImage: u,
          imageList: d,
          matchingData: p
        });
      }
      for (let c = 0; c < r.length; c++) {
        const u = A4(r[c]);
        this.data[c].trackingImageList = u;
      }
      const l = await this.compileTrack({ progressCallback: e, targetImages: r, basePercent: 50 });
      for (let c = 0; c < r.length; c++)
        this.data[c].trackingData = l[c];
      s(this.data);
    });
  }
  // not exporting imageList because too large. rebuild this using targetImage
  exportData() {
    const t = [];
    for (let s = 0; s < this.data.length; s++)
      t.push({
        //targetImage: this.data[i].targetImage,
        targetImage: {
          width: this.data[s].targetImage.width,
          height: this.data[s].targetImage.height
        },
        trackingData: this.data[s].trackingData,
        matchingData: this.data[s].matchingData
      });
    return wY({
      v: Jg,
      dataList: t
    });
  }
  importData(t) {
    const e = EY(new Uint8Array(t));
    if (!e.v || e.v !== Jg)
      return console.error("Your compiled .mind might be outdated. Please recompile"), [];
    const { dataList: s } = e;
    this.data = [];
    for (let o = 0; o < s.length; o++)
      this.data.push({
        targetImage: s[o].targetImage,
        trackingData: s[o].trackingData,
        matchingData: s[o].matchingData
      });
    return this.data;
  }
  createProcessCanvas(t) {
    console.warn("missing createProcessCanvas implementation");
  }
  compileTrack({ progressCallback: t, targetImages: e, basePercent: s }) {
    console.warn("missing compileTrack implementation");
  }
};
var MY = async (n, t) => {
  const e = [];
  for (let s = 0; s < n.length; s++) {
    const o = n[s], r = new vC(o.width, o.height);
    await su(), D(() => {
      const i6 = $e(o.data, [o.data.length], "float32").reshape([o.height, o.width]), { featurePoints: a } = r.detect(i6), l = a.filter((h) => h.maxima), c = a.filter((h) => !h.maxima), u = _g({ points: l }), d = _g({ points: c });
      e.push({
        maximaPoints: l,
        minimaPoints: c,
        maximaPointsCluster: u,
        minimaPointsCluster: d,
        width: o.width,
        height: o.height,
        scale: o.scale
      }), t(s);
    });
  }
  return e;
};
var GC = "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";
var jg = typeof window < "u" && window.Blob && new Blob([atob(GC)], { type: "text/javascript;charset=utf-8" });
function WY(n) {
  let t;
  try {
    if (t = jg && (window.URL || window.webkitURL).createObjectURL(jg), !t)
      throw "";
    const e = new Worker(t, {
      name: n == null ? void 0 : n.name
    });
    return e.addEventListener("error", () => {
      (window.URL || window.webkitURL).revokeObjectURL(t);
    }), e;
  } catch {
    return new Worker(
      "data:application/javascript;base64," + GC,
      {
        name: n == null ? void 0 : n.name
      }
    );
  } finally {
    t && (window.URL || window.webkitURL).revokeObjectURL(t);
  }
}
var DY = class extends LY {
  createProcessCanvas(t) {
    const e = document.createElement("canvas");
    return e.width = t.width, e.height = t.height, e;
  }
  compileTrack({ progressCallback: t, targetImages: e, basePercent: s }) {
    return new Promise((o, r) => {
      const i6 = new WY();
      i6.onmessage = (a) => {
        a.data.type === "progress" ? t(s + a.data.percent * s / 100) : a.data.type === "compileDone" && o(a.data.list);
      }, i6.postMessage({ type: "compile", targetImages: e });
    });
  }
};
var FY = class {
  constructor(t, e) {
    this.width = t, this.height = e, this.texShape = [e, t];
    const s = document.createElement("canvas").getContext("2d");
    s.canvas.width = t, s.canvas.height = e, this.context = s, this.program = this.buildProgram(t, e);
    const o = ps();
    this.tempPixelHandle = o.makeTensorInfo(this.texShape, "float32"), o.texData.get(this.tempPixelHandle.dataId).usage = 2;
  }
  // old method
  _loadInput(t) {
    return D(() => {
      let e = P0(t);
      return e = e.mean(2), e;
    });
  }
  // input is instance of HTMLVideoElement or HTMLImageElement
  loadInput(t) {
    const e = this.context;
    if (e.clearRect(0, 0, this.context.canvas.width, this.context.canvas.height), t.width === this.height && t.height === this.width) {
      let i6 = this.context.canvas.width / 2, a = this.context.canvas.height / 2, l = 90;
      e.save(), e.translate(i6, a), e.rotate(l * Math.PI / 180), e.drawImage(t, -t.width / 2, -t.height / 2), e.restore();
    } else
      this.context.drawImage(t, 0, 0, t.width, t.height);
    const o = ps();
    return o.gpgpu.uploadPixelDataToTexture(o.getTexture(this.tempPixelHandle.dataId), this.context.canvas), this._compileAndRun(this.program, [this.tempPixelHandle]);
  }
  buildProgram(t, e) {
    const s = F().getNumber("WEBGL_VERSION") === 2 ? "texture" : "texture2D";
    return {
      variableNames: ["A"],
      outputShape: this.texShape,
      userCode: `
	void main() {
	  ivec2 coords = getOutputCoords();
	  int texR = coords[0];
	  int texC = coords[1];
	  vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${t}.0, ${e}.0);

	  vec4 values = ${s}(A, uv);
	  setOutput((0.299 * values.r + 0.587 * values.g + 0.114 * values.b) * 255.0);
	}
      `
    };
  }
  _compileAndRun(t, e) {
    const s = ps().compileAndRun(t, e);
    return Ot().makeTensorFromDataId(s.dataId, s.shape, s.dtype);
  }
  _runWebGLProgram(t, e, s) {
    const o = ps().runWebGLProgram(t, e, s);
    return Ot().makeTensorFromDataId(o.dataId, o.shape, o.dtype);
  }
};
var rd = { memory: wl, nextFrame: su };
var VY = 1e-3;
var zY = 1e3;
var PY = 5;
var AY = 5;
var QQ = class {
  constructor({
    inputWidth: t,
    inputHeight: e,
    onUpdate: s = null,
    debugMode: o = false,
    maxTrack: r = 1,
    warmupTolerance: i6 = null,
    missTolerance: a = null,
    filterMinCF: l = null,
    filterBeta: c = null
  }) {
    this.inputWidth = t, this.inputHeight = e, this.maxTrack = r, this.filterMinCF = l === null ? VY : l, this.filterBeta = c === null ? zY : c, this.warmupTolerance = i6 === null ? PY : i6, this.missTolerance = a === null ? AY : a, this.cropDetector = new V4(this.inputWidth, this.inputHeight, o), this.inputLoader = new FY(this.inputWidth, this.inputHeight), this.markerDimensions = null, this.onUpdate = s, this.debugMode = o, this.processingVideo = false, this.interestedTargetIndex = -1, this.trackingStates = [];
    const u = 10, d = 1e5, h = 45 * Math.PI / 180, p = this.inputHeight / 2 / Math.tan(h / 2);
    this.projectionTransform = [
      [p, 0, this.inputWidth / 2],
      [0, p, this.inputHeight / 2],
      [0, 0, 1]
    ], this.projectionMatrix = this._glProjectionMatrix({
      projectionTransform: this.projectionTransform,
      width: this.inputWidth,
      height: this.inputHeight,
      near: u,
      far: d
    }), this.worker = new A5(), this.workerMatchDone = null, this.workerTrackDone = null, this.worker.onmessage = (f) => {
      f.data.type === "matchDone" && this.workerMatchDone !== null && this.workerMatchDone(f.data), f.data.type === "trackUpdateDone" && this.workerTrackDone !== null && this.workerTrackDone(f.data);
    };
  }
  showTFStats() {
    console.log(rd.memory().numTensors), console.table(rd.memory());
  }
  addImageTargets(t) {
    return new Promise(async (e, s) => {
      const r = await (await fetch(t)).arrayBuffer(), i6 = this.addImageTargetsFromBuffer(r);
      e(i6);
    });
  }
  addImageTargetsFromBuffer(t) {
    const s = new DY().importData(t), o = [], r = [], i6 = [];
    for (let a = 0; a < s.length; a++)
      r.push(s[a].matchingData), o.push(s[a].trackingData), i6.push([s[a].targetImage.width, s[a].targetImage.height]);
    return this.tracker = new Q5(i6, o, this.projectionTransform, this.inputWidth, this.inputHeight, this.debugMode), this.worker.postMessage({
      type: "setup",
      inputWidth: this.inputWidth,
      inputHeight: this.inputHeight,
      projectionTransform: this.projectionTransform,
      debugMode: this.debugMode,
      matchingDataList: r
    }), this.markerDimensions = i6, { dimensions: i6, matchingDataList: r, trackingDataList: o };
  }
  dispose() {
    this.stopProcessVideo(), this.worker.postMessage({
      type: "dispose"
    });
  }
  // warm up gpu - build kernels is slow
  dummyRun(t) {
    const e = this.inputLoader.loadInput(t);
    this.cropDetector.detect(e), this.tracker.dummyRun(e), e.dispose();
  }
  getProjectionMatrix() {
    return this.projectionMatrix;
  }
  getRotatedZ90Matrix(t) {
    return [
      -t[1],
      t[0],
      t[2],
      t[3],
      -t[5],
      t[4],
      t[6],
      t[7],
      -t[9],
      t[8],
      t[10],
      t[11],
      -t[13],
      t[12],
      t[14],
      t[15]
    ];
  }
  getWorldMatrix(t, e) {
    return this._glModelViewMatrix(t, e);
  }
  async _detectAndMatch(t, e) {
    const { featurePoints: s } = this.cropDetector.detectMoving(t), { targetIndex: o, modelViewTransform: r } = await this._workerMatch(s, e);
    return { targetIndex: o, modelViewTransform: r };
  }
  async _trackAndUpdate(t, e, s) {
    const { worldCoords: o, screenCoords: r } = this.tracker.track(t, e, s);
    return o.length < 4 ? null : await this._workerTrackUpdate(e, { worldCoords: o, screenCoords: r });
  }
  processVideo(t) {
    if (this.processingVideo)
      return;
    this.processingVideo = true, this.trackingStates = [];
    for (let s = 0; s < this.markerDimensions.length; s++)
      this.trackingStates.push({
        showing: false,
        isTracking: false,
        currentModelViewTransform: null,
        trackCount: 0,
        trackMiss: 0,
        filter: new y({ minCutOff: this.filterMinCF, beta: this.filterBeta })
      });
    (async () => {
      for (; this.processingVideo; ) {
        const s = this.inputLoader.loadInput(t);
        if (this.trackingStates.reduce((r, i6) => r + (i6.isTracking ? 1 : 0), 0) < this.maxTrack) {
          const r = [];
          for (let l = 0; l < this.trackingStates.length; l++)
            this.trackingStates[l].isTracking !== true && (this.interestedTargetIndex !== -1 && this.interestedTargetIndex !== l || r.push(l));
          const { targetIndex: i6, modelViewTransform: a } = await this._detectAndMatch(s, r);
          i6 !== -1 && (this.trackingStates[i6].isTracking = true, this.trackingStates[i6].currentModelViewTransform = a);
        }
        for (let r = 0; r < this.trackingStates.length; r++) {
          const i6 = this.trackingStates[r];
          if (i6.isTracking) {
            let a = await this._trackAndUpdate(s, i6.currentModelViewTransform, r);
            a === null ? i6.isTracking = false : i6.currentModelViewTransform = a;
          }
          if (i6.showing || i6.isTracking && (i6.trackMiss = 0, i6.trackCount += 1, i6.trackCount > this.warmupTolerance && (i6.showing = true, i6.trackingMatrix = null, i6.filter.reset())), i6.showing && (i6.isTracking ? i6.trackMiss = 0 : (i6.trackCount = 0, i6.trackMiss += 1, i6.trackMiss > this.missTolerance && (i6.showing = false, i6.trackingMatrix = null, this.onUpdate && this.onUpdate({ type: "updateMatrix", targetIndex: r, worldMatrix: null })))), i6.showing) {
            const a = this._glModelViewMatrix(i6.currentModelViewTransform, r);
            i6.trackingMatrix = i6.filter.filter(Date.now(), a);
            let l = [];
            for (let u = 0; u < i6.trackingMatrix.length; u++)
              l[u] = i6.trackingMatrix[u];
            t.width === this.inputHeight && t.height === this.inputWidth && (l = this.getRotatedZ90Matrix(l)), this.onUpdate && this.onUpdate({ type: "updateMatrix", targetIndex: r, worldMatrix: l });
          }
        }
        s.dispose(), this.onUpdate && this.onUpdate({ type: "processDone" }), await rd.nextFrame();
      }
    })();
  }
  stopProcessVideo() {
    this.processingVideo = false;
  }
  async detect(t) {
    const e = this.inputLoader.loadInput(t), { featurePoints: s, debugExtra: o } = await this.cropDetector.detect(e);
    return e.dispose(), { featurePoints: s, debugExtra: o };
  }
  async match(t, e) {
    const { modelViewTransform: s, debugExtra: o } = await this._workerMatch(t, [e]);
    return { modelViewTransform: s, debugExtra: o };
  }
  async track(t, e, s) {
    const o = this.inputLoader.loadInput(t), r = this.tracker.track(o, e, s);
    return o.dispose(), r;
  }
  async trackUpdate(t, e) {
    return e.worldCoords.length < 4 ? null : await this._workerTrackUpdate(t, e);
  }
  _workerMatch(t, e) {
    return new Promise(async (s, o) => {
      this.workerMatchDone = (r) => {
        s({ targetIndex: r.targetIndex, modelViewTransform: r.modelViewTransform, debugExtra: r.debugExtra });
      }, this.worker.postMessage({ type: "match", featurePoints: t, targetIndexes: e });
    });
  }
  _workerTrackUpdate(t, e) {
    return new Promise(async (s, o) => {
      this.workerTrackDone = (a) => {
        s(a.modelViewTransform);
      };
      const { worldCoords: r, screenCoords: i6 } = e;
      this.worker.postMessage({ type: "trackUpdate", modelViewTransform: t, worldCoords: r, screenCoords: i6 });
    });
  }
  _glModelViewMatrix(t, e) {
    const s = this.markerDimensions[e][1];
    return [
      t[0][0],
      -t[1][0],
      -t[2][0],
      0,
      -t[0][1],
      t[1][1],
      t[2][1],
      0,
      -t[0][2],
      t[1][2],
      t[2][2],
      0,
      t[0][1] * s + t[0][3],
      -(t[1][1] * s + t[1][3]),
      -(t[2][1] * s + t[2][3]),
      1
    ];
  }
  // build openGL projection matrix
  // ref: https://strawlab.org/2011/11/05/augmented-reality-with-OpenGL/
  _glProjectionMatrix({ projectionTransform: t, width: e, height: s, near: o, far: r }) {
    const i6 = [
      [2 * t[0][0] / e, 0, -(2 * t[0][2] / e - 1), 0],
      [0, 2 * t[1][1] / s, -(2 * t[1][2] / s - 1), 0],
      [0, 0, -(r + o) / (r - o), -2 * r * o / (r - o)],
      [0, 0, -1, 0]
    ], a = [];
    for (let l = 0; l < 4; l++)
      for (let c = 0; c < 4; c++)
        a.push(i6[c][l]);
    return a;
  }
};

// node_modules/mind-ar/dist/mindar-image-three.prod.js
function jd2(s) {
  C(Array.isArray(s), () => "The argument passed to tf.addN() must be a list of tensors"), C(s.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ${s.length}`);
  const e = s.map((r, n) => T(r, `tensors${n}`, "addN")), t = e[0];
  e.forEach((r) => {
    if (r.dtype !== t.dtype)
      throw new Error("All tensors passed to tf.addN() must have the same dtype");
  }), e.forEach((r) => {
    if (!$t(r.shape, t.shape))
      throw new Error("All tensors passed to tf.addN() must have the same shape");
  });
  const a = e;
  return $.runKernel(qd, a);
}
var nn2 = L({ addN_: jd2 });
function Bd2(s, e, t, a, r, n) {
  const u = T(s, "forgetBias", "basicLSTMCell"), o = T(e, "lstmKernel", "basicLSTMCell"), l = T(t, "lstmBias", "basicLSTMCell"), p = T(a, "data", "basicLSTMCell"), m = T(r, "c", "basicLSTMCell"), c = T(n, "h", "basicLSTMCell"), d = Ge([p, c], 1), h = Gt(d, o), N = U(h, l), g = N.shape[0], f = N.shape[1] / 4, b = [g, f], O = Ft(N, [0, 0], b), _6 = Ft(N, [0, f], b), T6 = Ft(N, [0, f * 2], b), I = Ft(N, [0, f * 3], b), D6 = U(G(kr(O), sp(_6)), G(m, kr(U(u, T6)))), C6 = G(sp(D6), kr(I));
  return [D6, C6];
}
var on2 = L({ basicLSTMCell_: Bd2 });
function Hd2(s, e) {
  const t = T(s, "x", "bitwiseAnd"), a = T(e, "y", "bitwiseAnd");
  if (!$t(t.shape, a.shape))
    throw new Error(`BitwiseAnd: Tensors must have the same shape. x: ${t.shape}, y: ${a.shape}`);
  if (t.dtype !== "int32" || a.dtype !== "int32")
    throw new Error(`BitwiseAnd: Only supports 'int32' values in tensor, found type of x: ${t.dtype} and type of y: ${a.dtype}`);
  const r = { a: t, b: a };
  return $.runKernel(rh, r);
}
var un2 = L({ bitwiseAnd_: Hd2 });
function Wd2(s, e) {
  const t = T(s, "s0", "broadcastArgs", "int32"), a = T(e, "s1", "broadcastArgs", "int32");
  if (t.rank !== 1)
    throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${t.rank}`);
  if (a.rank !== 1)
    throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${a.rank}`);
  const r = { s0: t, s1: a };
  return $.runKernel(cb, r);
}
var ln2 = L({ broadcastArgs_: Wd2 });
function Ud2(s) {
  const t = { x: T(s, "x", "diag") };
  return $.runKernel(ub, t);
}
var pn2 = L({ diag_: Ud2 });
function qd2(s, e) {
  const t = T(s, "x", "ensureShape", "string_or_numeric");
  if (!XC(t.shape, e))
    throw new Error(`EnsureShape: Shape of tensor ${t.shape} is not compatible with expected shape ${e}`);
  return s;
}
var mn2 = L({ ensureShape_: qd2 });
function cn2(s, e, t) {
  if (t <= 0)
    throw new Error("The number of values should be positive.");
  const a = { start: s, stop: e, num: t };
  return $.runKernel(hb, {}, a);
}
var fe2 = 2147483648;
function Gd2(s, e, t = "left") {
  const a = T(s, "sortedSequence", "searchSorted"), r = T(e, "values", "searchSorted"), n = a.shape[a.shape.length - 1], u = r.shape[r.shape.length - 1], o = W(a, [-1, n]), l = W(r, [-1, u]);
  if (o.rank < 2)
    throw new Error("Sorted input argument must be at least 2-dimensional");
  if (o.shape[0] !== l.shape[0])
    throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
  if (X(l.shape) >= fe2)
    throw new Error(`values tensor size must less than ${fe2}`);
  if (o.shape[1] >= fe2)
    throw new Error(`trailing dim_size must less than ${fe2} for int32 output type, was ${o.shape[1]}`);
  const p = {
    sortedSequence: o,
    values: l
  }, m = { side: t };
  return $.runKernel(wb, p, m);
}
var Ce2 = L({ searchSorted_: Gd2 });
function dn2(s, e) {
  return Ce2(s, e, "left");
}
function Kd2(s, e, t, a, r = false) {
  const u = { x: T(s, "x", "maxPoolWithArgmax") }, o = { filterSize: e, strides: t, pad: a, includeBatchInIndex: r }, l = $.runKernel(pb, u, o);
  return { result: l[0], indexes: l[1] };
}
var hn2 = L({ maxPoolWithArgmax_: Kd2 });
function fn2(s, e, { indexing: t = "xy" } = {}) {
  if (t !== "xy" && t !== "ij")
    throw new TypeError(`${t} is not a valid third argument to meshgrid`);
  if (s === void 0)
    return [];
  let a = T(s, "x", "meshgrid", s instanceof Mt ? s.dtype : "float32");
  if (e === void 0)
    return [a];
  let r = T(e, "y", "meshgrid", e instanceof Mt ? e.dtype : "float32");
  const n = X(a.shape), u = X(r.shape);
  return t === "xy" ? (a = W(a, [1, -1]), r = W(r, [-1, 1]), [
    Gt(ks([u, 1], a.dtype), a),
    Gt(r, ks([1, n], r.dtype))
  ]) : (a = W(a, [-1, 1]), r = W(r, [1, -1]), [
    Gt(a, ks([1, u], a.dtype)),
    Gt(ks([n, 1], r.dtype), r)
  ]);
}
function Jd2(s, e, t, a) {
  const r = T(e, "data", "multiRNNCell"), n = jh(t, "c", "multiRNNCell"), u = jh(a, "h", "multiRNNCell");
  let o = r;
  const l = [];
  for (let c = 0; c < s.length; c++) {
    const d = s[c](o, n[c], u[c]);
    l.push(d[0]), l.push(d[1]), o = d[1];
  }
  const p = [], m = [];
  for (let c = 0; c < l.length; c += 2)
    p.push(l[c]), m.push(l[c + 1]);
  return [p, m];
}
var yn2 = L({ multiRNNCell_: Jd2 });
function Qd2(s, e, t, a = false) {
  const r = T(s, "logits", "multinomial"), n = r.size, u = r.rank;
  if (n < 2)
    throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${n}.`);
  if (u > 2)
    throw new Error(`Rank of probabilities must be 1 or 2, but is ${u}`);
  t = t || Math.random();
  const l = { logits: u === 1 ? W(r, [1, -1]) : r }, p = { numSamples: e, seed: t, normalized: a }, m = $.runKernel(fb, l, p);
  return u === 1 ? W(m, [m.size]) : m;
}
var gn2 = L({ multinomial_: Qd2 });
function Xd2(s, e) {
  const t = T(s, "v1", "outerProduct"), a = T(e, "v2", "outerProduct");
  C(t.rank === 1 && a.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ${t.rank} and ${a.rank}.`);
  const r = W(t, [-1, 1]), n = W(a, [1, -1]);
  return Gt(r, n);
}
var bn2 = L({ outerProduct_: Xd2 });
function Zd2(s, e, t = 0) {
  return C(e.length === 2, () => "Invalid number of paddings. Must be length of 2."), bp(s, [e], t);
}
var Nn2 = L({ pad1d_: Zd2 });
function Yd2(s, e, t = 0) {
  return C(e.length === 2 && e[0].length === 2 && e[1].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), bp(s, e, t);
}
var wn2 = L({ pad2d_: Yd2 });
function Md2(s, e, t = 0) {
  return C(e.length === 3 && e[0].length === 2 && e[1].length === 2 && e[2].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), bp(s, e, t);
}
var Tn2 = L({ pad3d_: Md2 });
function eh2(s, e, t = 0) {
  return C(e.length === 4 && e[0].length === 2 && e[1].length === 2 && e[2].length === 2 && e[3].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), bp(s, e, t);
}
var Sn2 = L({ pad4d_: eh2 });
function th2(s, e, t, a) {
  const r = s.map((m, c) => T(m, `tensors${c}`, "raggedGather", "int32")), n = T(e, "paramsDenseValues", "raggedGather"), u = T(t, "indices", "raggedGather", "int32"), o = {
    paramsNestedSplits: r,
    paramsDenseValues: n,
    indices: u
  }, l = { outputRaggedRank: a }, p = $.runKernel(mb, o, l);
  return {
    outputNestedSplits: p.slice(0, p.length - 1),
    outputDenseValues: p[p.length - 1]
  };
}
var vn2 = L({ raggedGather_: th2 });
function sh2(s, e, t) {
  const a = T(s, "starts", "raggedRange"), r = T(e, "limits", "raggedRange", a.dtype), n = T(t, "deltas", "raggedRange", a.dtype), u = {
    starts: a,
    limits: r,
    deltas: n
  }, o = $.runKernel(gb, u);
  return {
    rtNestedSplits: o[0],
    rtDenseValues: o[1]
  };
}
var On2 = L({ raggedRange_: sh2 });
function ah2(s, e, t, a, r) {
  const n = T(s, "shape", "raggedTensorToTensor", "int32"), u = T(e, "values", "raggedTensorToTensor"), o = T(t, "defaultValue", "raggedTensorToTensor", u.dtype), l = a.map((c, d) => T(c, `tensors${d}`, "raggedTensorToTensor", "int32")), p = {
    shape: n,
    values: u,
    defaultValue: o,
    rowPartitionTensors: l
  }, m = { rowPartitionTypes: r };
  return $.runKernel(bb, p, m);
}
var _n2 = L({ raggedTensorToTensor_: ah2 });
function rh2(s, e, t) {
  is(s);
  const a = X(s);
  let r = null;
  if (t == null || t === "float32")
    r = new Float32Array(a);
  else if (t === "int32")
    r = new Int32Array(a);
  else if (t === "bool")
    r = new Uint8Array(a);
  else
    throw new Error(`Unknown data type ${t}`);
  for (let n = 0; n < a; n++)
    r[n] = e();
  return $.makeTensor(r, s, t);
}
var An2 = L({ rand_: rh2 });
var nh2 = 1e-3;
var En2 = 0.1;
function ih2(s, e, t) {
  return t == null && (t = bt2()), je2(s, e, (a, r) => Nt2(a, r, t));
}
function bt2() {
  return $.backend.floatPrecision() === 32 ? nh2 : En2;
}
function je2(s, e, t) {
  let a = true;
  if ((qe(s) || qe(e)) && (a = false), qe(s) && qe(e) && (a = true), a) {
    const u = s.constructor.name, o = e.constructor.name;
    if (u !== o)
      throw new Error(`Arrays are of different type. Actual: ${u}. Expected: ${o}`);
  }
  if (Array.isArray(s) && Array.isArray(e)) {
    const u = ya(s), o = ya(e);
    if (!$t(u, o))
      throw new Error(`Arrays have different shapes. Actual: [${u}]. Expected: [${o}]`);
  }
  const r = qe(s) ? s : Ks(s), n = qe(e) ? e : Ks(e);
  if (r.length !== n.length)
    throw new Error(`Arrays have different lengths actual: ${r.length} vs expected: ${n.length}.
Actual:   ${r}.
Expected: ${n}.`);
  for (let u = 0; u < n.length; ++u) {
    const o = r[u], l = n[u];
    if (!t(o, l))
      throw new Error(`Arrays differ: actual[${u}] = ${o}, expected[${u}] = ${l}.
Actual:   ${r}.
Expected: ${n}.`);
  }
  typeof expect < "u" && expect().nothing();
}
function oh2(s, e) {
  s().then(() => e.fail(), () => e()), typeof expect < "u" && expect().nothing();
}
function uh2(s, e) {
  const t = typeof e == "string" || typeof e == "number" || typeof e == "boolean" ? [e] : e;
  return vr(s) || vr(s[0]) || vr(e) || vr(e[0]) ? je2(s, t, (a, r) => a == r) : je2(s, e, (a, r) => Nt2(a, r, 0));
}
function lh2(s, e, t) {
  if (t == null && (t = bt2()), !Nt2(s, e, t))
    throw new Error(`Numbers differ: actual === ${s}, expected === ${e}`);
  typeof expect < "u" && expect().nothing();
}
function Nt2(s, e, t) {
  return !isFinite(s) && !isFinite(e) ? true : !(isNaN(s) || isNaN(e) || Math.abs(s - e) > t);
}
function ph2(s, e, t) {
  for (let a = 0; a < s.length; a++)
    if (s[a] < e || s[a] > t)
      throw new Error(`Value out of range:${s[a]} low: ${e}, high: ${t}`);
}
function mh2(s, e) {
  const t = new Float32Array(s), a = new Float32Array(e);
  if (t.length !== a.length)
    throw new Error(`Expected ArrayBuffer to be of length ${a.length}, but it was ${t.length}`);
  for (let r = 0; r < a.length; r++)
    if (t[r] !== a[r])
      throw new Error(`Expected ArrayBuffer value at ${r} to be ${a[r]} but got ${t[r]} instead`);
}
function kn2(s) {
  for (let e = 0; e < s.length; e++) {
    const t = s[e];
    Array.isArray(t) ? kn2(t) : s[e] = ms(t);
  }
  return s;
}
function ch2(s) {
  const e = document.createElement("video");
  return "playsInline" in e && (e.playsInline = true), e.muted = true, e.loop = true, e.style.position = "fixed", e.style.left = "0px", e.style.top = "0px", e.preload = "auto", e.appendChild(s), new Promise((t) => {
    e.addEventListener("loadeddata", (a) => t(e)), e.load();
  });
}
async function dh2(s) {
  await s.play(), "requestVideoFrameCallback" in s && await new Promise((e) => {
    s.requestVideoFrameCallback(e);
  });
}
var hh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  TEST_EPSILON_FLOAT16: En2,
  createVideoElement: ch2,
  encodeStrings: kn2,
  expectArrayBuffersEqual: mh2,
  expectArraysClose: ih2,
  expectArraysEqual: uh2,
  expectNumbersClose: lh2,
  expectPromiseToFail: oh2,
  expectValuesInRange: ph2,
  play: dh2,
  testEpsilon: bt2
}, Symbol.toStringTag, { value: "Module" }));
function fh2(s, e, t = 1, a = "float32", r) {
  if (is(s), t == null && (t = 1), a == null && (a = "float32"), a !== "float32" && a !== "int32")
    throw new Error(`Unsupported data type ${a}`);
  const n = new kQ(e, t, a, r), u = vt(s, a);
  for (let o = 0; o < u.values.length; o++)
    u.values[o] = n.nextValue();
  return u.toTensor();
}
var In2 = L({ randomGamma_: fh2 });
function yh2(s, e, t) {
  if (e != null && e === "bool")
    throw new Error(`Unsupported data type ${e}`);
  return kT(s, 0, 1, e, t);
}
var $n2 = L({ randomStandardNormal_: yh2 });
function gh2(s, e, t, a) {
  return Sa(s, e, t, "int32", a);
}
var Dn2 = L({ randomUniformInt_: gh2 });
function bh2(s) {
  const e = T(s, "x", "reverse");
  return C(e.rank === 1, () => `Error in reverse1D: x must be rank 1 but got rank ${e.rank}.`), Lo(e, 0);
}
var Cn2 = L({ reverse1d_: bh2 });
function Nh2(s, e) {
  const t = T(s, "x", "reverse");
  return C(t.rank === 2, () => `Error in reverse2D: x must be rank 2 but got rank ${t.rank}.`), Lo(t, e);
}
var zn2 = L({ reverse2d_: Nh2 });
function wh2(s, e) {
  const t = T(s, "x", "reverse");
  return C(t.rank === 3, () => `Error in reverse3D: x must be rank 3 but got rank ${t.rank}.`), Lo(t, e);
}
var xn2 = L({ reverse3d_: wh2 });
function Th2(s, e) {
  const t = T(s, "x", "reverse");
  return C(t.rank === 4, () => `Error in reverse4D: x must be rank 4 but got rank ${t.rank}.`), Lo(t, e);
}
var Ln = L({ reverse4d_: Th2 });
async function Sh2(s, e) {
  const t = T(s, "x", "setdiff1d"), a = T(e, "y", "setdiff1d");
  C(t.dtype === a.dtype, () => `x and y should have the same dtype, but got x (${t.dtype}) and y (${a.dtype}).`), C(t.rank === 1, () => `x should be 1D tensor, but got x (${t.shape}).`), C(a.rank === 1, () => `y should be 1D tensor, but got y (${a.shape}).`);
  const r = await t.data(), n = await a.data(), u = new Set(n);
  let o = 0;
  for (let m = 0; m < r.length; m++)
    u.has(r[m]) || o++;
  const l = new ve([o], t.dtype), p = new ve([o], "int32");
  for (let m = 0, c = 0; m < r.length; m++)
    u.has(r[m]) || (l.values[c] = r[m], p.values[c] = m, c++);
  return [l.toTensor(), p.toTensor()];
}
var Pn2 = Sh2;
function Fn2(s, e, t) {
  if (Hl(s), e != null && e.length !== 4)
    throw new Error("tensor4d() requires shape to have four numbers");
  const a = ya(s, t);
  if (a.length !== 4 && a.length !== 1)
    throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
  if (a.length === 1 && e == null)
    throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
  return wa(s, e, a, t);
}
function Vn2(s, e, t) {
  if (Hl(s), e != null && e.length !== 5)
    throw new Error("tensor5d() requires shape to have five numbers");
  const a = ya(s, t);
  if (a.length !== 5 && a.length !== 1)
    throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
  if (a.length === 1 && e == null)
    throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
  return wa(s, e, a, t);
}
function Rn2(s, e, t) {
  if (Hl(s), e != null && e.length !== 6)
    throw new Error("tensor6d() requires shape to have six numbers");
  const a = ya(s, t);
  if (a.length !== 6 && a.length !== 1)
    throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
  if (a.length === 1 && e == null)
    throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
  return e = e || a, wa(s, e, a, t);
}
function vh2(s, e, t) {
  const a = T(s, "tensor", "tensorScatterupdate"), r = T(e, "indices", "tensorScatterupdate", "int32"), n = T(t, "updates", "tensorScatterupdate");
  if (y0(n, r, a.shape), a.dtype !== n.dtype)
    throw new Error(`tensor and updates must have the same dtype, instead they are ${a.dtype} and ${n.dtype}.`);
  const u = {
    tensor: a,
    indices: r,
    updates: n
  }, o = {};
  return $.runKernel(yb, u, o);
}
var jn2 = L({ tensorScatterUpdate_: vh2 });
function Bn2(s, e) {
  return Ce2(s, e, "right");
}
async function Oh2(s) {
  const e = T(s, "condition", "whereAsync", "bool"), t = await e.data(), a = C0(e.shape, t);
  return s !== e && e.dispose(), a;
}
var wt = Oh2;
async function _h2(s, e, t) {
  const a = T(s, "tensor", "boolMask"), r = T(e, "mask", "boolMask", "bool"), n = t ?? 0, u = r.rank, o = a.shape;
  C(u > 0, () => "mask cannot be scalar"), Pe(o.slice(n, n + u), r.shape, "mask's shape must match the first K dimensions of tensor's shape,");
  let l = 1;
  for (let g = n; g < n + u; g++)
    l *= o[g];
  const p = o.slice(0, n).concat([l], o.slice(n + u)), m = W(a, p), c = W(r, [-1]), d = await wt(c), h = ka(d, [1]), N = cp(m, h, n);
  return s !== a && a.dispose(), e !== r && r.dispose(), h.dispose(), m.dispose(), c.dispose(), d.dispose(), N;
}
var Hn2 = _h2;
function Ah2(s, e, t, a, r = true) {
  const n = T(s, "v", "movingAverage"), u = T(e, "x", "movingAverage"), o = T(t, "decay", "movingAverage");
  I2(n, u), C($t(n.shape, u.shape), () => "Shape mismatch in v and x");
  const l = gt(1), p = it(l, o);
  let m = G(it(u, n), p);
  if (r) {
    C(a != null, () => "When using zeroDebias: true, step is required.");
    const c = T(a, "step", "movingAverage");
    m = ut(m, it(l, gr(o, c)));
  }
  return U(n, m);
}
var Wn2 = L({ movingAverage_: Ah2 });
function Eh2(s, e, t) {
  is(t);
  const a = T(s, "indices", "scatterND", "int32"), r = T(e, "updates", "scatterND");
  y0(r, a, t);
  const n = { indices: a, updates: r }, u = { shape: t };
  return $.runKernel(xb, n, u);
}
var Un2 = L({ scatterND_: Eh2 });
function kh2(s, e, t, a) {
  if (s.dtype !== "int32")
    throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${s.dtype}.`);
  if (s.rank > 2)
    throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${s.shape}.`);
  const r = s.rank > 0 ? s.shape[0] : 1, n = s.rank > 1 ? s.shape[1] : 1;
  if (t.length !== n)
    throw new Error(`outputShape has incorrect number of elements:, ${t.length}, should be: ${n}.`);
  const u = e.size;
  if (!(e.rank === 0 || e.rank === 1 && u === r))
    throw new Error(`sparseValues has incorrect shape ${e.shape}, should be [] or [${r}]`);
  if (e.dtype !== a.dtype)
    throw new Error("sparseValues.dtype must match defaultValues.dtype");
}
function Ih2(s, e, t, a = 0) {
  is(t);
  const r = T(s, "sparseIndices", "sparseToDense", "int32"), n = T(e, "sparseValues", "sparseToDense", "string_or_numeric"), u = T(a, "defaultValue", "sparseToDense", n.dtype);
  kh2(r, n, t, u);
  const o = {
    sparseIndices: r,
    sparseValues: n,
    defaultValue: u
  }, l = { outputShape: t };
  return $.runKernel(Ib, o, l);
}
var qn2 = L({ sparseToDense_: Ih2 });
function $h2(s, e) {
  const t = T(e, "indices", "gatherND", "int32"), r = { params: T(s, "x", "gatherND", "string_or_numeric"), indices: t };
  return $.runKernel(db, r);
}
var Gn2 = L({ gatherND_: $h2 });
async function Dh2(s, e, t = 1) {
  const a = T(s, "predictions", "inTopK"), r = T(e, "targets", "inTopK");
  C(a.rank > 1, () => `inTopK() expects the predictions to be of rank 2 or higher, but got ${a.rank}`), C(a.rank - 1 === r.rank, () => `predictions rank should be 1 larger than targets rank, but got predictions rank ${a.rank} and targets rank ${r.rank}`), Pe(a.shape.slice(0, a.shape.length - 1), r.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
  const n = a.shape[a.shape.length - 1];
  C(t > 0 && t <= n, () => `'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${n}), but got ${t}`);
  const u = await a.data(), o = await r.data(), [l, p] = [u.length / n, n], m = Se("bool", l);
  for (let c = 0; c < l; c++) {
    const d = c * p, h = u.subarray(d, d + p), N = [];
    for (let g = 0; g < h.length; g++)
      N.push({ value: h[g], index: g });
    N.sort((g, f) => f.value - g.value), m[c] = 0;
    for (let g = 0; g < t; g++)
      if (N[g].index === o[c]) {
        m[c] = 1;
        break;
      }
  }
  return s !== a && a.dispose(), e !== r && r.dispose(), $e(m, r.shape, "bool");
}
var Kn2 = Dh2;
function Ch2({ x: s, filter: e, strides: t, pad: a, dataFormat: r = "NHWC", dilations: n = [1, 1], dimRoundingMode: u, bias: o, activation: l = "linear", preluActivationWeights: p, leakyreluAlpha: m }) {
  if (Vp($.state.gradientDepth, l) === false) {
    let I = ap(s, e, t, a, r, n, u);
    return o != null && (I = U(I, o)), Fp(I, l, p, m);
  }
  const c = T(s, "x", "depthwiseConv2d", "float32"), d = T(e, "filter", "depthwiseConv2d", "float32");
  let h = c, N = false;
  c.rank === 3 && (N = true, h = W(c, [1, c.shape[0], c.shape[1], c.shape[2]])), C(h.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${h.rank}.`), C(d.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${d.rank}.`), C(h.shape[3] === d.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${h.shape[3]}) must match the inChannels dimension in filter ${d.shape[2]}.`), n == null && (n = [1, 1]), C(Le(t, n), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${t} and dilations '${n}'`), Ue("fused depthwiseConv2d", a, u);
  const g = Te(
    h.shape,
    d.shape,
    t,
    n,
    a,
    u,
    true
    /* depthwise */
  );
  let f;
  o != null && (f = T(o, "bias", "fused conv2d"), [f] = se(f, c), bt(g.outShape, f.shape));
  let b;
  p != null && (b = T(p, "prelu weights", "fused depthwiseConv2d"));
  const O = (I, D6) => {
    C(No(n), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${n}'`);
    const [C6, X6, F6, j] = D6, ze2 = Wp(I, F6, l), $t2 = kN(X6.shape, ze2, C6, t, a, n, u), Dt = vN(X6, ze2, C6.shape, t, a, n, u);
    if (j != null) {
      const wi2 = Dp(f, ze2);
      return [$t2, Dt, wi2];
    }
    return [$t2, Dt];
  }, _6 = {
    x: h,
    filter: d,
    bias: f,
    preluActivationWeights: b
  }, T6 = {
    strides: t,
    pad: a,
    dataFormat: r,
    dilations: n,
    dimRoundingMode: u,
    activation: l,
    leakyreluAlpha: m
  };
  return o == null ? Eo((D6, C6, X6) => {
    let F6 = $.runKernel(Cb, _6, T6);
    return X6([C6, D6, F6]), N && (F6 = W(F6, [F6.shape[1], F6.shape[2], F6.shape[3]])), { value: F6, gradFunc: O };
  })(h, d) : Eo((D6, C6, X6, F6) => {
    let j = $.runKernel(Cb, _6, T6);
    return F6([C6, D6, j, X6]), N && (j = W(j, [j.shape[1], j.shape[2], j.shape[3]])), { value: j, gradFunc: O };
  })(h, d, f);
}
var zh2 = L({ fusedDepthwiseConv2d_: Ch2 });
var Jn2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  conv2d: IN,
  depthwiseConv2d: zh2,
  matMul: Nm
}, Symbol.toStringTag, { value: "Module" }));
var xh2 = "model";
var Lh2 = ".json";
var Ph2 = ".weights.bin";
function Ft2(s) {
  return new Promise((e) => setTimeout(e)).then(s);
}
var J = class _J {
  constructor(e) {
    if (!F().getBool("IS_BROWSER"))
      throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
    e.startsWith(_J.URL_SCHEME) && (e = e.slice(_J.URL_SCHEME.length)), (e == null || e.length === 0) && (e = xh2), this.modelJsonFileName = e + Lh2, this.weightDataFileName = e + Ph2;
  }
  async save(e) {
    if (typeof document > "u")
      throw new Error("Browser downloads are not supported in this environment since `document` is not present");
    const t = Cs.join(e.weightData), a = window.URL.createObjectURL(new Blob([t], { type: "application/octet-stream" }));
    if (e.modelTopology instanceof ArrayBuffer)
      throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
    {
      const r = [{
        paths: ["./" + this.weightDataFileName],
        weights: e.weightSpecs
      }], n = V2(e, r), u = window.URL.createObjectURL(new Blob([JSON.stringify(n)], { type: "application/json" })), o = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
      if (o.download = this.modelJsonFileName, o.href = u, await Ft2(() => o.dispatchEvent(new MouseEvent("click"))), e.weightData != null) {
        const l = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
        l.download = this.weightDataFileName, l.href = a, await Ft2(() => l.dispatchEvent(new MouseEvent("click")));
      }
      return { modelArtifactsInfo: tp(e) };
    }
  }
};
J.URL_SCHEME = "downloads://";
var Fh2 = class {
  constructor(e) {
    if (e == null || e.length < 1)
      throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e}`);
    this.jsonFile = e[0], this.weightsFiles = e.slice(1);
  }
  async load() {
    return new Promise((e, t) => {
      const a = new FileReader();
      a.onload = (r) => {
        const n = JSON.parse(r.target.result), u = n.modelTopology;
        if (u == null) {
          t(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
          return;
        }
        if (n.weightsManifest == null) {
          t(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
          return;
        }
        if (this.weightsFiles.length === 0) {
          e({ modelTopology: u });
          return;
        }
        const l = P2(n, (p) => this.loadWeights(p));
        e(l);
      }, a.onerror = (r) => t(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`), a.readAsText(this.jsonFile);
    });
  }
  loadWeights(e) {
    const t = [], a = [];
    for (const u of e)
      t.push(...u.weights), a.push(...u.paths);
    const r = this.checkManifestAndWeightFiles(e), n = a.map((u) => this.loadWeightsFile(u, r[u]));
    return Promise.all(n).then((u) => [t, u]);
  }
  loadWeightsFile(e, t) {
    return new Promise((a, r) => {
      const n = new FileReader();
      n.onload = (u) => {
        const o = u.target.result;
        a(o);
      }, n.onerror = (u) => r(`Failed to weights data from file of path '${e}'.`), n.readAsArrayBuffer(t);
    });
  }
  /**
   * Check the compatibility between weights manifest and weight files.
   */
  checkManifestAndWeightFiles(e) {
    const t = [], a = this.weightsFiles.map((n) => pQ(n.name)), r = {};
    for (const n of e)
      n.paths.forEach((u) => {
        const o = pQ(u);
        if (t.indexOf(o) !== -1)
          throw new Error(`Duplicate file basename found in weights manifest: '${o}'`);
        if (t.push(o), a.indexOf(o) === -1)
          throw new Error(`Weight file with basename '${o}' is not provided.`);
        r[u] = this.weightsFiles[a.indexOf(o)];
      });
    if (t.length !== this.weightsFiles.length)
      throw new Error(`Mismatch in the number of files in weights manifest (${t.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
    return r;
  }
};
var Vh2 = (s) => F().getBool("IS_BROWSER") && !Array.isArray(s) && s.startsWith(J.URL_SCHEME) ? Rh2(s.slice(J.URL_SCHEME.length)) : null;
ee.registerSaveRouter(Vh2);
function Rh2(s = "model") {
  return new J(s);
}
function jh2(s) {
  return new Fh2(s);
}
var xe2 = class {
  constructor(e) {
    this.modelArtifacts = e;
  }
  load() {
    return this.modelArtifacts;
  }
};
var Qn2 = class {
  constructor(e) {
    this.saveHandler = e;
  }
  save(e) {
    return this.saveHandler(e);
  }
};
var Bh2 = class {
  constructor(e) {
    e.load && (this.load = () => Promise.resolve(e.load())), e.save && (this.save = (t) => Promise.resolve(e.save(t)));
  }
};
function Hh2(s, e, t, a) {
  const r = arguments;
  return new Bh2(Ee2(...r));
}
function Ee2(s, e, t, a) {
  return arguments.length === 1 ? s.modelTopology != null || s.weightSpecs != null ? new xe2(s) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new xe2({ modelTopology: s })) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new xe2({
    modelTopology: s,
    weightSpecs: e,
    weightData: t,
    trainingConfig: a
  }));
}
function Wh2(s) {
  return new Qn2(s);
}
function Uh2(s) {
  return new Qn2(s);
}
var Tt2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  CompositeArrayBuffer: Cs,
  browserFiles: jh2,
  browserHTTPRequest: h$,
  concatenateArrayBuffers: F2,
  copyModel: xQ,
  decodeWeights: Ab,
  decodeWeightsStream: hQ,
  encodeWeights: Cm,
  fromMemory: Hh2,
  fromMemorySync: Ee2,
  getLoadHandlers: B2,
  getModelArtifactsForJSON: P2,
  getModelArtifactsForJSONSync: z2,
  getModelArtifactsInfoForJSON: tp,
  getSaveHandlers: Z2,
  getWeightSpecs: km,
  http: F0,
  isHTTPScheme: Em,
  listModels: gQ,
  loadWeights: a$,
  moveModel: yQ,
  registerLoadRouter: mQ,
  registerSaveRouter: fQ,
  removeModel: bQ,
  weightsLoaderFactory: l$,
  withSaveHandler: Wh2,
  withSaveHandlerSync: Uh2
}, Symbol.toStringTag, { value: "Module" }));
function qh2(s, e, t) {
  const a = T(s, "labels", "confusionMatrix"), r = T(e, "predictions", "confusionMatrix");
  C(t == null || t > 0 && Number.isInteger(t), () => `If provided, numClasses must be a positive integer, but got ${t}`), C(a.rank === 1, () => `Expected the rank of labels to be 1, but got ${a.rank}`), C(r.rank === 1, () => `Expected the rank of predictions to be 1, but got ${r.rank}`), C(a.shape[0] === r.shape[0], () => `Mismatch in the number of examples: ${a.shape[0]} vs. ${r.shape[0]}. Labels and predictions should have the same number of elements.`), C(t > 0 && Number.isInteger(t), () => `numClasses is required to be a positive integer, but got ${t}`);
  const n = a0(tt(a, "int32"), t), u = a0(tt(r, "int32"), t), o = kt(n), l = Gt(o, u);
  return tt(l, "int32");
}
var Gh2 = L({ confusionMatrix_: qh2 });
var Kh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  confusionMatrix: Gh2
}, Symbol.toStringTag, { value: "Module" }));
var Xn2 = "4.16.0";
var Jh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  nonMaxSuppressionV3Impl: zp,
  nonMaxSuppressionV4Impl: Pp,
  nonMaxSuppressionV5Impl: Ap,
  whereImpl: C0
}, Symbol.toStringTag, { value: "Module" }));
function Qh2(s) {
  return new zx(s);
}
function Xh2(s) {
  return new Px(s);
}
function Zh2() {
  return new Ax();
}
function Yh2(s) {
  return new Ox(s);
}
var Mh2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  maxNorm: Qh2,
  minMaxNorm: Yh2,
  nonNeg: Zh2,
  unitNorm: Xh2
}, Symbol.toStringTag, { value: "Module" }));
function ef2() {
  return new Gx();
}
function tf2() {
  return new yf();
}
function sf2(s) {
  return new Ex(s);
}
function af2(s) {
  return new Lx(s);
}
function rf2(s) {
  return new Mx(s);
}
function nf2(s) {
  return new Wx(s);
}
function of2(s) {
  return new Dx(s);
}
function uf2(s) {
  return new en(s);
}
function lf2(s) {
  return new wf(s);
}
function pf2(s) {
  return new If(s);
}
function mf2(s) {
  return new Cf(s);
}
function cf2(s) {
  return new vf(s);
}
function df2(s) {
  return new Sf(s);
}
function hf2(s) {
  return new kf(s);
}
function ff2(s) {
  return new Fx(s);
}
var yf2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  constant: sf2,
  glorotNormal: pf2,
  glorotUniform: lf2,
  heNormal: mf2,
  heUniform: cf2,
  identity: of2,
  leCunNormal: df2,
  leCunUniform: hf2,
  ones: tf2,
  orthogonal: ff2,
  randomNormal: rf2,
  randomUniform: af2,
  truncatedNormal: nf2,
  varianceScaling: uf2,
  zeros: ef2
}, Symbol.toStringTag, { value: "Module" }));
function gf2(s) {
  return new ur(s);
}
function bf2(s) {
  return new mi(s);
}
function Zn2(s) {
  return fL(s);
}
function Nf2(s, e) {
  wn.registerCallbackConstructor(s, e);
}
function wf2(s) {
  return new Wa(s);
}
function Tf2(s) {
  return new Iy(s);
}
function Sf2(s) {
  return new xy(s);
}
function vf2(s) {
  return new yy(s);
}
function Of2(s) {
  return new wy(s);
}
function _f2(s) {
  return new vy(s);
}
function Af2(s) {
  return new Cy(s);
}
function Ef2(s) {
  return new fu(s);
}
function kf2(s) {
  return new Fa(s);
}
function If2(s) {
  return new ky(s);
}
function $f2(s) {
  return new Va(s);
}
function Df2(s) {
  return new Ty(s);
}
function Cf2(s) {
  return new Ry(s);
}
function zf2(s) {
  return new $y(s);
}
function xf2(s) {
  return new Gy(s);
}
function Lf2(s) {
  return new Ey(s);
}
function Pf2(s) {
  return new Xy(s);
}
function Ff2(s) {
  return new Ay(s);
}
function Vf2(s) {
  return new Vf(s);
}
function Rf2(s) {
  return new Py(s);
}
function jf2(s) {
  return new Oy(s);
}
function Bf2(s) {
  return new Ky(s);
}
function Hf2(s) {
  return new Zy(s);
}
function Wf2(s) {
  return new By(s);
}
function Uf2(s) {
  return new _y(s);
}
function qf2(s) {
  return new Uy(s);
}
function Gf2(s) {
  return new Qy(s);
}
function Kf2(s) {
  return new qy(s);
}
function Jf2(s) {
  return new Jy(s);
}
function Qf2(s) {
  return new jy(s);
}
function Xf2(s) {
  return new Yy(s);
}
function Zf2(s) {
  return new t1(s);
}
function Yf2(s) {
  return new o1(s);
}
function Mf2(s) {
  return new r1(s);
}
function ey2(s) {
  return new i1(s);
}
function St2(s) {
  return new u1(s);
}
function ty2(s) {
  return St2(s);
}
function sy2(s) {
  return St2(s);
}
function vt2(s) {
  return new p1(s);
}
function ay2(s) {
  return vt2(s);
}
function ry2(s) {
  return vt2(s);
}
function Ot2(s) {
  return new g1(s);
}
function ny2(s) {
  return Ot2(s);
}
function iy2(s) {
  return Ot2(s);
}
function oy2(s) {
  return new x1(s);
}
function uy2(s) {
  return new I1(s);
}
function Yn2(s) {
  return new y1(s);
}
function Mn2(s) {
  return new C1(s);
}
function ei2(s) {
  return new c1(s);
}
function ti2(s) {
  return new h1(s);
}
function ly2(s) {
  return new m1(s);
}
function py2(s) {
  return new Dy(s);
}
function my2(s) {
  return new Wf(s);
}
function cy2(s) {
  return new Fy(s);
}
function dy2(s) {
  return new gu(s);
}
function hy2(s) {
  return new Wy(s);
}
function fy2(s) {
  return new Mf(s);
}
function yy2(s) {
  return new zy(s);
}
function gy2(s) {
  return new Ff(s);
}
function by2(s) {
  return new no(s);
}
function Ny2(s) {
  return new Df(s);
}
function wy2(s) {
  return new k1(s);
}
function Ty2(s) {
  return new S1(s);
}
var Sy2 = Yn2;
var vy2 = Mn2;
var Oy2 = ei2;
var _y2 = ti2;
function Ay2(s) {
  return new e1(s);
}
function Ey2(s) {
  return new n1(s);
}
function ky2(s) {
  return new s1(s);
}
function Iy2(s) {
  return new Hy(s);
}
function $y2(s) {
  return new T1(s);
}
function Dy2(s) {
  return new N1(s);
}
function Cy2(s) {
  return new $1(s);
}
function zy2(s) {
  return new R1(s);
}
function xy2(s) {
  return new L1(s);
}
var Ly2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  Layer: St,
  RNN: no,
  RNNCell: mu,
  activation: Pf2,
  add: qf2,
  alphaDropout: ky2,
  average: Gf2,
  averagePooling1d: St2,
  averagePooling2d: vt2,
  averagePooling3d: Ot2,
  avgPool1d: ty2,
  avgPool2d: ay2,
  avgPool3d: ny2,
  avgPooling1d: sy2,
  avgPooling2d: ry2,
  avgPooling3d: iy2,
  batchNormalization: Yf2,
  bidirectional: wy2,
  categoryEncoding: zy2,
  centerCrop: Dy2,
  concatenate: Kf2,
  conv1d: Ef2,
  conv2d: kf2,
  conv2dTranspose: If2,
  conv3d: $f2,
  conv3dTranspose: Df2,
  convLstm2d: yy2,
  convLstm2dCell: gy2,
  cropping2D: zf2,
  dense: Ff2,
  depthwiseConv2d: Lf2,
  dot: Zf2,
  dropout: Vf2,
  elu: Tf2,
  embedding: Uf2,
  flatten: jf2,
  gaussianDropout: Ey2,
  gaussianNoise: Ay2,
  globalAveragePooling1d: oy2,
  globalAveragePooling2d: uy2,
  globalMaxPool1d: Sy2,
  globalMaxPool2d: vy2,
  globalMaxPooling1d: Yn2,
  globalMaxPooling2d: Mn2,
  gru: py2,
  gruCell: my2,
  input: Zn2,
  inputLayer: wf2,
  layerNormalization: Mf2,
  leakyReLU: vf2,
  lstm: cy2,
  lstmCell: dy2,
  masking: Iy2,
  maxPool1d: Oy2,
  maxPool2d: _y2,
  maxPooling1d: ei2,
  maxPooling2d: ti2,
  maxPooling3d: ly2,
  maximum: Jf2,
  minimum: Qf2,
  multiply: Xf2,
  permute: Wf2,
  prelu: Of2,
  randomWidth: xy2,
  reLU: Sf2,
  repeatVector: Bf2,
  rescaling: $y2,
  reshape: Hf2,
  resizing: Cy2,
  rnn: by2,
  separableConv2d: Cf2,
  simpleRNN: hy2,
  simpleRNNCell: fy2,
  softmax: _f2,
  spatialDropout1d: Rf2,
  stackedRNNCells: Ny2,
  thresholdedReLU: Af2,
  timeDistributed: Ty2,
  upSampling2d: xf2,
  zeroPadding2d: ey2
}, Symbol.toStringTag, { value: "Module" }));
function Py2(s, e) {
  return Hx(s, e);
}
function Fy2(s, e) {
  return VL(s, e);
}
function Vy2(s, e) {
  return zL(s, e);
}
function Ry2(s, e) {
  return _x(s, e);
}
function jy2(s, e) {
  return Yx(s, e);
}
function By2(s, e) {
  return FL(s, e);
}
function Hy2(s, e) {
  return DQ(s, e);
}
function Wy2(s, e) {
  return Bx(s, e);
}
function Uy2(s, e) {
  return Rf(s, e);
}
function qy2(s, e) {
  return $f(s, e);
}
function Gy2(s, e) {
  return $f(s, e);
}
function Ky2(s, e) {
  return $f(s, e);
}
function Jy2(s, e) {
  return uu(s, e);
}
function Qy2(s, e) {
  return uu(s, e);
}
function Xy2(s, e) {
  return uu(s, e);
}
var Zy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  MAPE: Gy2,
  MSE: Qy2,
  binaryAccuracy: Py2,
  binaryCrossentropy: Fy2,
  categoricalAccuracy: Ry2,
  categoricalCrossentropy: jy2,
  cosineProximity: Wy2,
  mape: Ky2,
  meanAbsoluteError: Uy2,
  meanAbsolutePercentageError: qy2,
  meanSquaredError: Jy2,
  mse: Xy2,
  precision: By2,
  recall: Hy2,
  sparseCategoricalAccuracy: Vy2
}, Symbol.toStringTag, { value: "Module" }));
var Yy2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  modelFromJSON: FQ
}, Symbol.toStringTag, { value: "Module" }));
function My2(s) {
  return new hu(s);
}
function eg2(s) {
  return AQ(s);
}
function tg2(s) {
  return OQ(s);
}
var sg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  l1: eg2,
  l1l2: My2,
  l2: tg2
}, Symbol.toStringTag, { value: "Module" }));
var si2 = class extends hi {
  constructor() {
    super(...arguments), this.model = null;
  }
  setModel(e) {
    if (!(e instanceof ur))
      throw new Error("model must be a LayersModel, not some other Container");
    this.model = e;
  }
};
function ye2(s, e) {
  return s < e;
}
function Vt2(s, e) {
  return s > e;
}
var ai2 = class extends si2 {
  constructor(e) {
    if (super(), e == null && (e = {}), e.restoreBestWeights)
      throw new yt("restoreBestWeights = True is not implemented in EarlyStopping yet.");
    this.monitor = e.monitor || "val_loss", this.minDelta = Math.abs(e.minDelta || 0), this.patience = e.patience || 0, this.verbose = e.verbose || 0, this.mode = e.mode || "auto", this.baseline = e.baseline, ["auto", "min", "max"].indexOf(this.mode) === -1 && (console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`), this.mode = "auto"), this.mode === "min" ? this.monitorFunc = ye2 : this.mode === "max" ? this.monitorFunc = Vt2 : this.monitor.indexOf("acc") !== -1 ? this.monitorFunc = Vt2 : this.monitorFunc = ye2, this.monitorFunc === ye2 && (this.minDelta *= -1);
  }
  async onTrainBegin(e) {
    this.wait = 0, this.stoppedEpoch = 0, this.baseline != null ? this.best = this.baseline : this.best = this.monitorFunc === ye2 ? 1 / 0 : -1 / 0;
  }
  async onEpochEnd(e, t) {
    await ao(t);
    const a = this.getMonitorValue(t);
    a != null && (this.monitorFunc(a - this.minDelta, this.best) ? (this.best = a, this.wait = 0) : (this.wait++, this.wait >= this.patience && (this.stoppedEpoch = e, this.model.stopTraining = true)));
  }
  async onTrainEnd(e) {
    this.stoppedEpoch > 0 && this.verbose && console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);
  }
  getMonitorValue(e) {
    e == null && (e = {});
    const t = e[this.monitor];
    return t == null && console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(e)}`), t;
  }
};
function ag2(s) {
  return new ai2(s);
}
var rg2 = { earlyStopping: ag2 };
var _t = {};
function ng2(s, e) {
  const t = {
    tfOpName: s,
    category: "custom",
    inputs: [],
    attrs: [],
    customExecutor: e
  };
  _t[s] = t;
}
function ri2(s) {
  return _t[s];
}
function ig2(s) {
  delete _t[s];
}
function i(s, e, t, a, r) {
  const n = e.inputParams[s];
  if (n && n.inputIndexStart !== void 0) {
    const o = n.inputIndexStart, l = n.inputIndexEnd === 0 ? void 0 : n.inputIndexEnd === void 0 ? o + 1 : n.inputIndexEnd, p = o < 0 ? e.inputNames.length + o : o;
    if (n.type === "tensor")
      return E6(e.inputNames[p], t, a, r);
    if (n.type === "tensors") {
      const d = e.inputs.slice(o, l);
      return e.inputNames.slice(o, l).filter((N, g) => {
        var f;
        return ((f = d[g]) === null || f === void 0 ? void 0 : f.op) !== "NoOp";
      }).map((N) => E6(N, t, a, r));
    }
    const m = E6(e.inputNames[p], t, a, r), c = m.dataSync();
    return n.type === "number" ? c[0] : kn(m.shape, c);
  }
  const u = e.attrParams[s];
  return u && u.value;
}
function E6(s, e, t, a) {
  const [r, n] = $6(s, t);
  if (a != null) {
    const o = a.getHashTableHandleByName(r);
    if (o != null)
      return o;
  }
  const u = t.currentContextIds.find((o) => !!e[ke2(r, o)]);
  return u !== void 0 ? e[ke2(r, u)][n] : void 0;
}
function Rt2(s, e, t) {
  return e[ke2(s, t.currentContextId)];
}
function B(s, e) {
  const [t, a, r] = $6(s, e);
  return [
    ke2(t, e && e.currentContextId),
    a,
    r
  ];
}
function ke2(s, e) {
  return e ? `${s}-${e}` : s;
}
function $6(s, e) {
  if (s === "")
    return ["", 0, void 0];
  const t = e != null && e.parseNodeNameCache != null;
  if (t) {
    const n = e.parseNodeNameCache.get(s);
    if (n != null)
      return n;
  }
  const a = s.split(":");
  let r;
  if (a.length === 1)
    r = [s, 0, void 0];
  else {
    const n = a[0], u = a.length === 3 ? a[1] : void 0, o = Number(a[a.length - 1]);
    r = [n, o, u];
  }
  return t && e.parseNodeNameCache.set(s, r), r;
}
function we(s, e, t) {
  let a = i("pad", s, e, t);
  if (a === "explicit") {
    a = i("explicitPaddings", s, e, t);
    const r = [[0, 0], [0, 0], [0, 0], [0, 0]];
    for (let n = 0; n < 4; n++)
      r[n][0] = a[n * 2], r[n][1] = a[n * 2 + 1];
    return r;
  }
  return a;
}
function H(s) {
  return s.kept ? s : yo(s);
}
var og2 = [
  {
    tfOpName: "Add",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "AddV2",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "AddN",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "BiasAdd",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sub",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "RealDiv",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Div",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "DivNoNan",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FloorDiv",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Mul",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Maximum",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Minimum",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Pow",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "SquaredDifference",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Mod",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FloorMod",
    category: "arithmetic",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  }
];
var ug2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: og2
}, Symbol.toStringTag, { value: "Module" }));
var lg2 = [
  {
    tfOpName: "Abs",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Acos",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Asin",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Atan",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Atan2",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "y",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Ceil",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ClipByValue",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "clipValueMin",
        type: "number"
      },
      {
        start: 2,
        name: "clipValueMax",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Complex",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "real",
        type: "tensor"
      },
      {
        start: 1,
        name: "imag",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ComplexAbs",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Cos",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Cosh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Elu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Exp",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Floor",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Log",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Imag",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "outputType",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Neg",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Real",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "outputType",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Prelu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "alpha",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Relu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Relu6",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Selu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sigmoid",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sin",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sinh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sqrt",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Rsqrt",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Square",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Tan",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Tanh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Sign",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Round",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Expm1",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Log1p",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Reciprocal",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Softplus",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Asinh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Acosh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Atanh",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Erf",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LeakyRelu",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "alpha",
        name: "alpha",
        type: "number",
        defaultValue: 0.2
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "IsNan",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "IsFinite",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "IsInf",
    category: "basic_math",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  }
];
var pg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: lg2
}, Symbol.toStringTag, { value: "Module" }));
var mg2 = [
  {
    tfOpName: "EmptyTensorList",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 1,
        name: "maxNumElements",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "LoopCond",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "pred",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Switch",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "pred",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Merge",
    category: "control",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "Enter",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "frame_name",
        name: "frameName",
        type: "string"
      },
      {
        tfName: "is_constant",
        name: "isConstant",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Exit",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "NextIteration",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArrayV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "size",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      },
      {
        tfName: "dynamic_size",
        name: "dynamicSize",
        type: "bool"
      },
      {
        tfName: "clear_after_read",
        name: "clearAfterRead",
        type: "bool"
      },
      {
        tfName: "identical_element_shapes",
        name: "identicalElementShapes",
        type: "bool"
      },
      {
        tfName: "tensor_array_name",
        name: "name",
        type: "string"
      }
    ]
  },
  {
    tfOpName: "TensorArrayWriteV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 3,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArrayReadV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArrayGatherV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      }
    ]
  },
  {
    tfOpName: "TensorArrayScatterV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 3,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorArrayConcatV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "element_shape_except0",
        name: "elementShapeExcept0",
        type: "shape",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorArraySplitV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 2,
        name: "lengths",
        type: "number[]"
      },
      {
        start: 3,
        name: "flowIn",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorArraySizeV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      },
      {
        start: 1,
        name: "flowIn",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "TensorArrayCloseV3",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorArrayId",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "StatelessIf",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "cond",
        type: "tensor"
      },
      {
        start: 1,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "then_branch",
        name: "thenBranch",
        type: "func"
      },
      {
        tfName: "else_branch",
        name: "elseBranch",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "If",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "cond",
        type: "tensor"
      },
      {
        start: 1,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "then_branch",
        name: "thenBranch",
        type: "func"
      },
      {
        tfName: "else_branch",
        name: "elseBranch",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "StatelessWhile",
    category: "control",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "cond",
        name: "cond",
        type: "func"
      },
      {
        tfName: "body",
        name: "body",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "While",
    category: "control",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "cond",
        name: "cond",
        type: "func"
      },
      {
        tfName: "body",
        name: "body",
        type: "func"
      }
    ]
  },
  {
    tfOpName: "TensorListScatter",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListScatterV2",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 3,
        name: "numElements",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListGather",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "number[]"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListGetItem",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListSetItem",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "index",
        type: "number"
      },
      {
        start: 2,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListReserve",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 1,
        name: "numElements",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListFromTensor",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListStack",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      },
      {
        tfName: "num_elements",
        name: "numElements",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListSplit",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      },
      {
        start: 2,
        name: "lengths",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListConcat",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      },
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListConcatV2",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_shape",
        name: "elementShape",
        type: "shape"
      },
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListPopBack",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "elementShape",
        type: "shape"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListPushBack",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "element_dtype",
        name: "elementDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TensorListLength",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "TensorListResize",
    category: "control",
    inputs: [
      {
        start: 0,
        name: "tensorListId",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number"
      }
    ]
  }
];
var cg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: mg2
}, Symbol.toStringTag, { value: "Module" }));
var dg2 = [
  {
    tfOpName: "AvgPool",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MaxPool",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: [],
        notSupported: true
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MaxPoolWithArgmax",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "include_batch_in_index",
        name: "includeBatchInIndex",
        type: "bool"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "AvgPool3D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MaxPool3D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "ksize",
        name: "kernelSize",
        type: "number[]"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Conv1D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "stride",
        name: "stride",
        type: "number"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NWC"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "dilation",
        name: "dilation",
        type: "number",
        defaultValue: 1
      }
    ]
  },
  {
    tfOpName: "Conv2D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "useCudnnOnGpu",
        name: "useCudnnOnGpu",
        type: "bool"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "_FusedConv2D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      },
      {
        start: 2,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "num_args",
        name: "numArgs",
        type: "number"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "use_cudnn_on_gpu",
        name: "useCudnnOnGpu",
        type: "bool",
        defaultValue: true
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]",
        defaultValue: [
          1,
          1,
          1,
          1
        ]
      },
      {
        tfName: "fused_ops",
        name: "fusedOps",
        type: "string[]",
        defaultValue: []
      },
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-4
      },
      {
        tfName: "leakyrelu_alpha",
        name: "leakyreluAlpha",
        type: "number",
        defaultValue: 0.2
      }
    ]
  },
  {
    tfOpName: "Conv2DBackpropInput",
    category: "convolution",
    inputs: [
      {
        start: 2,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      },
      {
        start: 0,
        name: "outputShape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "DepthwiseConv2d",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "DepthwiseConv2dNative",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "FusedDepthwiseConv2dNative",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      },
      {
        start: 2,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "num_args",
        name: "numArgs",
        type: "number"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]",
        defaultValue: [
          1,
          1,
          1,
          1
        ]
      },
      {
        tfName: "fused_ops",
        name: "fusedOps",
        type: "string[]",
        defaultValue: []
      },
      {
        tfName: "explicit_paddings",
        name: "explicitPaddings",
        type: "number[]",
        defaultValue: []
      }
    ]
  },
  {
    tfOpName: "Conv3D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        defaultValue: "NHWC"
      },
      {
        tfName: "dilations",
        name: "dilations",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Dilation2D",
    category: "convolution",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "filter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "strides",
        name: "strides",
        type: "number[]"
      },
      {
        tfName: "rates",
        name: "dilations",
        type: "number[]"
      },
      {
        tfName: "padding",
        name: "pad",
        type: "string"
      }
    ]
  }
];
var hg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: dg2
}, Symbol.toStringTag, { value: "Module" }));
var fg2 = [
  {
    tfOpName: "Fill",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      },
      {
        start: 1,
        name: "value",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "LinSpace",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "start",
        type: "number"
      },
      {
        start: 1,
        name: "stop",
        type: "number"
      },
      {
        start: 2,
        name: "num",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "OneHot",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "indices",
        type: "tensor"
      },
      {
        start: 1,
        name: "depth",
        type: "number"
      },
      {
        start: 2,
        name: "onValue",
        type: "number",
        defaultValue: 1
      },
      {
        start: 3,
        name: "offValue",
        type: "number",
        defaultValue: 0
      }
    ],
    attrs: [
      {
        tfName: "axis",
        name: "axis",
        type: "number",
        notSupported: true
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Ones",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "OnesLike",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "RandomStandardNormal",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "seed",
        name: "seed",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number",
        defaultValue: 0,
        notSupported: true
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "T",
        name: "T",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "RandomUniform",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "minval",
        name: "minval",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "maxval",
        name: "maxval",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "seed",
        name: "seed",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number",
        defaultValue: 0,
        notSupported: true
      },
      {
        tfName: "T",
        name: "T",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "RandomUniformInt",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "minval",
        name: "minval",
        type: "number"
      },
      {
        tfName: "maxval",
        name: "maxval",
        type: "number"
      },
      {
        tfName: "seed",
        name: "seed",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number",
        defaultValue: 0,
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Range",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "start",
        type: "number"
      },
      {
        start: 1,
        name: "stop",
        type: "number"
      },
      {
        start: 2,
        name: "step",
        type: "number",
        defaultValue: 0
      }
    ],
    attrs: [
      {
        tfName: "Tidx",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "TruncatedNormal",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "means",
        name: "mean",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "stddev",
        name: "stdDev",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "seed",
        name: "seed",
        type: "number"
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number",
        defaultValue: 0,
        notSupported: true
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "T",
        name: "T",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Zeros",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "ZerosLike",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Multinomial",
    category: "creation",
    inputs: [
      {
        start: 0,
        name: "logits",
        type: "tensor"
      },
      {
        start: 1,
        name: "numSamples",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "seed",
        name: "seed",
        type: "number"
      },
      {
        tfName: "seed2",
        name: "seed2",
        type: "number"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      },
      {
        tfName: "output_dtype",
        name: "output_dtype",
        type: "dtype"
      }
    ]
  }
];
var yg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: fg2
}, Symbol.toStringTag, { value: "Module" }));
var gg2 = [
  {
    tfOpName: "NonMaxSuppressionV2",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "NonMaxSuppressionV3",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      },
      {
        start: 4,
        name: "scoreThreshold",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "NonMaxSuppressionV4",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      },
      {
        start: 4,
        name: "scoreThreshold",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "T_threshold",
        name: "threshold",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "pad_to_max_output_size",
        name: "padToMaxOutputSize",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "NonMaxSuppressionV5",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 1,
        name: "scores",
        type: "tensor"
      },
      {
        start: 2,
        name: "maxOutputSize",
        type: "number"
      },
      {
        start: 3,
        name: "iouThreshold",
        type: "number"
      },
      {
        start: 4,
        name: "scoreThreshold",
        type: "number"
      },
      {
        start: 5,
        name: "softNmsSigma",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "Where",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "condition",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ListDiff",
    category: "dynamic",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "y",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  }
];
var bg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: gg2
}, Symbol.toStringTag, { value: "Module" }));
var Ng2 = [
  {
    tfOpName: "LowerBound",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "sortedSequence",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "TopKV2",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "k",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "sorted",
        name: "sorted",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "UpperBound",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "sortedSequence",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Unique",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "UniqueV2",
    category: "evaluation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  }
];
var wg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Ng2
}, Symbol.toStringTag, { value: "Module" }));
var Tg2 = [
  {
    tfOpName: "PlaceholderWithDefault",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "default",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "shape",
        name: "shape",
        type: "shape"
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Placeholder",
    category: "graph",
    attrs: [
      {
        tfName: "shape",
        name: "shape",
        type: "shape"
      },
      {
        tfName: "dtype",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "Const",
    category: "graph"
  },
  {
    tfOpName: "Identity",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "IdentityN",
    category: "graph",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "x",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "Snapshot",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Rank",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Size",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "Shape",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "ShapeN",
    category: "graph",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "x",
        type: "tensors"
      }
    ]
  },
  {
    tfOpName: "Print",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "data",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "message",
        name: "message",
        type: "string"
      },
      {
        tfName: "first_n",
        name: "firstN",
        type: "number",
        notSupported: true
      },
      {
        tfName: "summarize",
        name: "summarize",
        type: "number",
        defaultValue: 3
      }
    ]
  },
  {
    tfOpName: "NoOp",
    category: "graph",
    inputs: []
  },
  {
    tfOpName: "StopGradient",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "FakeQuantWithMinMaxVars",
    category: "graph",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "min",
        name: "min",
        type: "number"
      },
      {
        tfName: "max",
        name: "max",
        type: "number"
      }
    ]
  }
];
var Sg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Tg2
}, Symbol.toStringTag, { value: "Module" }));
var vg2 = [
  {
    tfOpName: "HashTable",
    category: "hash_table",
    inputs: [],
    attrs: [
      {
        tfName: "shared_name",
        name: "sharedName",
        type: "string"
      },
      {
        tfName: "use_node_name_sharing",
        name: "useNodeNameSharing",
        type: "bool"
      },
      {
        tfName: "key_dtype",
        name: "keyDType",
        type: "dtype"
      },
      {
        tfName: "value_dtype",
        name: "valueDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "HashTableV2",
    category: "hash_table",
    inputs: [],
    attrs: [
      {
        tfName: "shared_name",
        name: "sharedName",
        type: "string"
      },
      {
        tfName: "use_node_name_sharing",
        name: "useNodeNameSharing",
        type: "bool"
      },
      {
        tfName: "key_dtype",
        name: "keyDType",
        type: "dtype"
      },
      {
        tfName: "value_dtype",
        name: "valueDType",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "LookupTableImport",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableImportV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableFind",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "defaultValue",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableFindV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "defaultValue",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "Tin",
        name: "tIn",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "Tout",
        name: "tOut",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LookupTableSize",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "LookupTableSizeV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "InitializeTable",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "InitializeTableV2",
    category: "hash_table",
    inputs: [
      {
        start: 0,
        name: "tableHandle",
        type: "tensor"
      },
      {
        start: 1,
        name: "keys",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ]
  }
];
var Og2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: vg2
}, Symbol.toStringTag, { value: "Module" }));
var _g2 = [
  {
    tfOpName: "ResizeBilinear",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "images",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "align_corners",
        name: "alignCorners",
        type: "bool"
      },
      {
        tfName: "half_pixel_centers",
        name: "halfPixelCenters",
        type: "bool"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "ResizeNearestNeighbor",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "images",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "align_corners",
        name: "alignCorners",
        type: "bool"
      },
      {
        tfName: "half_pixel_centers",
        name: "halfPixelCenters",
        type: "bool"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "CropAndResize",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "image",
        type: "tensor"
      },
      {
        start: 1,
        name: "boxes",
        type: "tensor"
      },
      {
        start: 2,
        name: "boxInd",
        type: "tensor"
      },
      {
        start: 3,
        name: "cropSize",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "method",
        name: "method",
        type: "string"
      },
      {
        tfName: "extrapolation_value",
        name: "extrapolationValue",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "ImageProjectiveTransformV3",
    category: "image",
    inputs: [
      {
        start: 0,
        name: "images",
        type: "tensor"
      },
      {
        start: 1,
        name: "transforms",
        type: "tensor"
      },
      {
        start: 2,
        name: "outputShape",
        type: "number[]"
      },
      {
        start: 3,
        name: "fillValue",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "interpolation",
        name: "interpolation",
        type: "string"
      },
      {
        tfName: "fill_mode",
        name: "fillMode",
        type: "string"
      }
    ]
  }
];
var Ag2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: _g2
}, Symbol.toStringTag, { value: "Module" }));
var Eg2 = [
  {
    tfOpName: "Equal",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "NotEqual",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Greater",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "GreaterEqual",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Less",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LessEqual",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LogicalAnd",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LogicalNot",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LogicalOr",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Select",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "condition",
        type: "tensor"
      },
      {
        start: 1,
        name: "a",
        type: "tensor"
      },
      {
        start: 2,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "SelectV2",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "condition",
        type: "tensor"
      },
      {
        start: 1,
        name: "a",
        type: "tensor"
      },
      {
        start: 2,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "BitwiseAnd",
    category: "logical",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "y",
        type: "tensor"
      }
    ]
  }
];
var kg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Eg2
}, Symbol.toStringTag, { value: "Module" }));
var Ig2 = [
  {
    tfOpName: "_FusedMatMul",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      },
      {
        start: 2,
        end: 0,
        name: "args",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "num_args",
        name: "numArgs",
        type: "number"
      },
      {
        tfName: "fused_ops",
        name: "fusedOps",
        type: "string[]",
        defaultValue: []
      },
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-4
      },
      {
        tfName: "transpose_a",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "transpose_b",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "leakyrelu_alpha",
        name: "leakyreluAlpha",
        type: "number",
        defaultValue: 0.2
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "MatMul",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "transpose_a",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "transpose_b",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "BatchMatMul",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "adj_x",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "adj_y",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "BatchMatMulV2",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "b",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "adj_x",
        name: "transposeA",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "adj_y",
        name: "transposeB",
        type: "bool",
        defaultValue: false
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Transpose",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "perm",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Einsum",
    category: "matrices",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "equation",
        name: "equation",
        type: "string"
      },
      {
        tfName: "N",
        name: "n",
        type: "number",
        defaultValue: 2
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "MatrixBandPart",
    category: "matrices",
    inputs: [
      {
        start: 0,
        name: "a",
        type: "tensor"
      },
      {
        start: 1,
        name: "numLower",
        type: "tensor"
      },
      {
        start: 1,
        name: "numUpper",
        type: "tensor"
      }
    ]
  }
];
var $g2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Ig2
}, Symbol.toStringTag, { value: "Module" }));
var Dg2 = [
  {
    tfOpName: "EuclideanNorm",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool",
        defaultValue: false
      }
    ]
  },
  {
    tfOpName: "FusedBatchNorm",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "scale",
        type: "tensor"
      },
      {
        start: 2,
        name: "offset",
        type: "tensor"
      },
      {
        start: 3,
        name: "mean",
        type: "tensor"
      },
      {
        start: 4,
        name: "variance",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-3
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FusedBatchNormV2",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "scale",
        type: "tensor"
      },
      {
        start: 2,
        name: "offset",
        type: "tensor"
      },
      {
        start: 3,
        name: "mean",
        type: "tensor"
      },
      {
        start: 4,
        name: "variance",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-3
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "FusedBatchNormV3",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "scale",
        type: "tensor"
      },
      {
        start: 2,
        name: "offset",
        type: "tensor"
      },
      {
        start: 3,
        name: "mean",
        type: "tensor"
      },
      {
        start: 4,
        name: "variance",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "epsilon",
        name: "epsilon",
        type: "number",
        defaultValue: 1e-3
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "LRN",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "depth_radius",
        name: "radius",
        type: "number",
        defaultValue: 5
      },
      {
        tfName: "bias",
        name: "bias",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "alpha",
        name: "alpha",
        type: "number",
        defaultValue: 1
      },
      {
        tfName: "beta",
        name: "beta",
        type: "number",
        defaultValue: 0.5
      }
    ]
  },
  {
    tfOpName: "Softmax",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "LogSoftmax",
    category: "normalization",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  }
];
var Cg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Dg2
}, Symbol.toStringTag, { value: "Module" }));
var zg2 = [
  {
    tfOpName: "Bincount",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number"
      },
      {
        start: 2,
        name: "weights",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "DenseBincount",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "size",
        type: "number"
      },
      {
        start: 2,
        name: "weights",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "binary_output",
        name: "binaryOutput",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Max",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Mean",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Min",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Sum",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "All",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Any",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "ArgMax",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "ArgMin",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "Prod",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "keep_dims",
        name: "keepDims",
        type: "bool"
      },
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Cumprod",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "exclusive",
        name: "exclusive",
        type: "bool"
      },
      {
        tfName: "reverse",
        name: "reverse",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "Cumsum",
    category: "reduction",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "exclusive",
        name: "exclusive",
        type: "bool"
      },
      {
        tfName: "reverse",
        name: "reverse",
        type: "bool"
      }
    ]
  }
];
var xg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: zg2
}, Symbol.toStringTag, { value: "Module" }));
var Lg2 = [
  {
    tfOpName: "ConcatV2",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        end: -1,
        name: "tensors",
        type: "tensors"
      },
      {
        start: -1,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "N",
        name: "n",
        type: "number",
        defaultValue: 2
      }
    ]
  },
  {
    tfOpName: "Concat",
    category: "slice_join",
    inputs: [
      {
        start: 1,
        end: 0,
        name: "tensors",
        type: "tensors"
      },
      {
        start: 0,
        name: "axis",
        type: "number"
      }
    ],
    attrs: [
      {
        tfName: "N",
        name: "n",
        type: "number",
        defaultValue: 2
      }
    ]
  },
  {
    tfOpName: "GatherV2",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      },
      {
        start: 2,
        name: "axis",
        type: "number",
        defaultValue: 0
      }
    ],
    attrs: [
      {
        tfName: "batch_dims",
        name: "batchDims",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Gather",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "validate_indices",
        name: "validateIndices",
        type: "bool",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Reverse",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "dims",
        type: "bool[]"
      }
    ]
  },
  {
    tfOpName: "ReverseV2",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Slice",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "begin",
        type: "number[]"
      },
      {
        start: 2,
        name: "size",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "StridedSlice",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "begin",
        type: "number[]"
      },
      {
        start: 2,
        name: "end",
        type: "number[]"
      },
      {
        start: 3,
        name: "strides",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "begin_mask",
        name: "beginMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "end_mask",
        name: "endMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "new_axis_mask",
        name: "newAxisMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "ellipsis_mask",
        name: "ellipsisMask",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "shrink_axis_mask",
        name: "shrinkAxisMask",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Pack",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        end: 0,
        name: "tensors",
        type: "tensors"
      }
    ],
    attrs: [
      {
        tfName: "axis",
        name: "axis",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Unpack",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "axis",
        name: "axis",
        type: "number",
        defaultValue: 0
      },
      {
        tfName: "num",
        name: "num",
        type: "number",
        defaultValue: 0,
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "Tile",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "reps",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Split",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "axis",
        type: "number",
        defaultValue: 0
      },
      {
        start: 1,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "num_split",
        name: "numOrSizeSplits",
        type: "number",
        defaultValue: 1
      }
    ]
  },
  {
    tfOpName: "SplitV",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "numOrSizeSplits",
        type: "number[]"
      },
      {
        start: 2,
        name: "axis",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "ScatterNd",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "indices",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      },
      {
        start: 2,
        name: "shape",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "GatherNd",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "SparseToDense",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "sparseIndices",
        type: "tensor"
      },
      {
        start: 1,
        name: "outputShape",
        type: "number[]"
      },
      {
        start: 2,
        name: "sparseValues",
        type: "tensor"
      },
      {
        start: 3,
        name: "defaultValue",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "validate_indices",
        name: "validateIndices",
        type: "bool",
        defaultValue: false,
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "TensorScatterUpdate",
    category: "slice_join",
    inputs: [
      {
        start: 0,
        name: "tensor",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      },
      {
        start: 2,
        name: "values",
        type: "tensor"
      }
    ]
  }
];
var Pg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Lg2
}, Symbol.toStringTag, { value: "Module" }));
var Fg2 = [
  {
    tfOpName: "SparseFillEmptyRows",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "indices",
        type: "tensor"
      },
      {
        start: 1,
        name: "values",
        type: "tensor"
      },
      {
        start: 2,
        name: "denseShape",
        type: "tensor"
      },
      {
        start: 3,
        name: "defaultValue",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "SparseReshape",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "inputIndices",
        type: "tensor"
      },
      {
        start: 1,
        name: "inputShape",
        type: "tensor"
      },
      {
        start: 2,
        name: "newShape",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "T",
        name: "dtype",
        type: "dtype",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "SparseSegmentMean",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      },
      {
        start: 2,
        name: "segmentIds",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "SparseSegmentSum",
    category: "sparse",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "indices",
        type: "tensor"
      },
      {
        start: 2,
        name: "segmentIds",
        type: "tensor"
      }
    ]
  }
];
var Vg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Fg2
}, Symbol.toStringTag, { value: "Module" }));
var Rg2 = [
  {
    tfOpName: "FFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "IFFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ]
  },
  {
    tfOpName: "RFFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "fft_length",
        type: "number",
        notSupported: true
      }
    ]
  },
  {
    tfOpName: "IRFFT",
    category: "spectral",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "fft_length",
        type: "number",
        notSupported: true
      }
    ]
  }
];
var jg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Rg2
}, Symbol.toStringTag, { value: "Module" }));
var Bg2 = [
  {
    tfOpName: "StaticRegexReplace",
    category: "string",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "pattern",
        name: "pattern",
        type: "string"
      },
      {
        tfName: "rewrite",
        name: "rewrite",
        type: "string"
      },
      {
        tfName: "replace_global",
        name: "replaceGlobal",
        type: "bool"
      }
    ]
  },
  {
    tfOpName: "StringNGrams",
    category: "string",
    inputs: [
      {
        start: 0,
        name: "data",
        type: "tensor"
      },
      {
        start: 1,
        name: "dataSplits",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "separator",
        name: "separator",
        type: "string"
      },
      {
        tfName: "ngram_widths",
        name: "nGramWidths",
        type: "number[]"
      },
      {
        tfName: "left_pad",
        name: "leftPad",
        type: "string"
      },
      {
        tfName: "right_pad",
        name: "rightPad",
        type: "string"
      },
      {
        tfName: "pad_width",
        name: "padWidth",
        type: "number"
      },
      {
        tfName: "preserve_short_sequences",
        name: "preserveShortSequences",
        type: "bool"
      }
    ],
    outputs: [
      "ngrams",
      "ngrams_splits"
    ]
  },
  {
    tfOpName: "StringSplit",
    category: "string",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      },
      {
        start: 1,
        name: "delimiter",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "skip_empty",
        name: "skipEmpty",
        type: "bool"
      }
    ],
    outputs: [
      "indices",
      "values",
      "shape"
    ]
  },
  {
    tfOpName: "StringToHashBucketFast",
    category: "string",
    inputs: [
      {
        start: 0,
        name: "input",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "num_buckets",
        name: "numBuckets",
        type: "number"
      }
    ]
  }
];
var Hg2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Bg2
}, Symbol.toStringTag, { value: "Module" }));
var Wg2 = [
  {
    tfOpName: "Cast",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "SrcT",
        name: "sdtype",
        type: "dtype",
        notSupported: true
      },
      {
        tfName: "DstT",
        name: "dtype",
        type: "dtype"
      }
    ]
  },
  {
    tfOpName: "ExpandDims",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "axis",
        type: "number"
      }
    ]
  },
  {
    tfOpName: "MirrorPad",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "padding",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "mode",
        name: "mode",
        type: "string"
      }
    ]
  },
  {
    tfOpName: "Pad",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "padding",
        type: "number[]"
      }
    ],
    attrs: [
      {
        tfName: "constant_value",
        name: "constantValue",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "PadV2",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "padding",
        type: "number[]"
      },
      {
        start: 2,
        name: "constantValue",
        type: "number",
        defaultValue: 0
      }
    ]
  },
  {
    tfOpName: "Reshape",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "shape",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "EnsureShape",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "shape",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "Squeeze",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "axis",
        tfDeprecatedName: "squeeze_dims",
        name: "axis",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "SpaceToBatchND",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "blockShape",
        type: "number[]"
      },
      {
        start: 2,
        name: "paddings",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "BatchToSpaceND",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "blockShape",
        type: "number[]"
      },
      {
        start: 2,
        name: "crops",
        type: "number[]"
      }
    ]
  },
  {
    tfOpName: "DepthToSpace",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      }
    ],
    attrs: [
      {
        tfName: "block_size",
        name: "blockSize",
        type: "number"
      },
      {
        tfName: "data_format",
        name: "dataFormat",
        type: "string"
      }
    ]
  },
  {
    tfOpName: "BroadcastTo",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "x",
        type: "tensor"
      },
      {
        start: 1,
        name: "shape",
        type: "number[]"
      }
    ],
    attrs: []
  },
  {
    tfOpName: "BroadcastArgs",
    category: "transformation",
    inputs: [
      {
        start: 0,
        name: "s0",
        type: "tensor"
      },
      {
        start: 1,
        name: "s1",
        type: "tensor"
      }
    ],
    attrs: []
  }
];
var Ug2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  json: Wg2
}, Symbol.toStringTag, { value: "Module" }));
var jt2 = class {
  // Singleton instance for the mapper
  static get Instance() {
    return this._instance || (this._instance = new this());
  }
  // Loads the op mapping from the JSON file.
  constructor() {
    const e = [
      ug2,
      pg2,
      cg2,
      hg2,
      yg2,
      bg2,
      wg2,
      Sg2,
      Og2,
      Ag2,
      kg2,
      $g2,
      Cg2,
      xg2,
      Pg2,
      Vg2,
      jg2,
      Hg2,
      Ug2
    ], t = [].concat(...e.map((a) => a.json));
    this.opMappers = t.reduce((a, r) => (a[r.tfOpName] = r, a), {});
  }
  // Converts the model inference graph from Tensorflow GraphDef to local
  // representation for TensorFlow.js API
  transformGraph(e, t = {}) {
    const a = e.node, r = [], n = [], u = [], o = a.reduce((g, f) => (g[f.name] = this.mapNode(f), f.op.startsWith("Placeholder") ? r.push(g[f.name]) : f.op === "Const" ? n.push(g[f.name]) : (f.input == null || f.input.length === 0) && u.push(g[f.name]), g), {});
    let l = [];
    const p = [];
    let m = {}, c = {};
    t != null && (m = this.mapSignatureEntries(t.inputs), c = this.mapSignatureEntries(t.outputs));
    const d = Object.keys(o);
    d.forEach((g) => {
      const f = o[g];
      f.inputNames.forEach((b, O) => {
        const [_6, , T6] = B(b), I = o[_6];
        if (I.outputs != null) {
          const D6 = I.outputs.indexOf(T6);
          if (D6 !== -1) {
            const C6 = `${_6}:${D6}`;
            f.inputNames[O] = C6;
          }
        }
        f.inputs.push(I), I.children.push(f);
      });
    }), Object.keys(c).length === 0 ? d.forEach((g) => {
      const f = o[g];
      f.children.length === 0 && p.push(f);
    }) : Object.keys(c).forEach((g) => {
      const [f] = B(g), b = o[f];
      b != null && (b.signatureKey = c[g], p.push(b));
    }), Object.keys(m).length > 0 ? Object.keys(m).forEach((g) => {
      const [f] = B(g), b = o[f];
      b && (b.signatureKey = m[g], l.push(b));
    }) : l = r;
    let h = {};
    e.library != null && e.library.function != null && (h = e.library.function.reduce((g, f) => (g[f.signature.name] = this.mapFunction(f), g), {}));
    const N = { nodes: o, inputs: l, outputs: p, weights: n, placeholders: r, signature: t, functions: h };
    return u.length > 0 && (N.initNodes = u), N;
  }
  mapSignatureEntries(e) {
    return Object.keys(e || {}).reduce((t, a) => (t[e[a].name] = a, t), {});
  }
  mapNode(e) {
    const t = ri2(e.op) || this.opMappers[e.op] || {};
    e.attr == null && (e.attr = {});
    const a = {
      name: e.name,
      op: e.op,
      category: t.category,
      inputNames: (e.input || []).map((r) => r.startsWith("^") ? r.slice(1) : r),
      inputs: [],
      children: [],
      inputParams: {},
      attrParams: {},
      rawAttrs: e.attr,
      outputs: t.outputs
    };
    return t.inputs != null && (a.inputParams = t.inputs.reduce((r, n) => (r[n.name] = {
      type: n.type,
      inputIndexStart: n.start,
      inputIndexEnd: n.end
    }, r), {})), t.attrs != null && (a.attrParams = t.attrs.reduce((r, n) => {
      const u = n.type;
      let o;
      switch (n.type) {
        case "string":
          o = Be2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Be2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "string[]":
          o = Je2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Je2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "number":
          o = We2(e.attr, n.tfName, n.defaultValue || 0), o === void 0 && n.tfDeprecatedName && (o = We2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "number[]":
          o = Ke2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Ke2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "bool":
          o = He2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = He2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "bool[]":
          o = Xe2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Xe2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "shape":
          o = Ge2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Ge2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "shape[]":
          o = Qe2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Qe2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "dtype":
          o = Ue2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Ue2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "dtype[]":
          o = qe2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = qe2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "func":
          o = Bt2(e.attr, n.tfName, n.defaultValue), o === void 0 && n.tfDeprecatedName && (o = Bt2(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;
        case "tensor":
        case "tensors":
          break;
        default:
          throw new Error(`Unsupported param type: ${n.type} for op: ${e.op}`);
      }
      return r[n.name] = { value: o, type: u }, r;
    }, {})), a;
  }
  // map the TFunctionDef to TFJS graph object
  mapFunction(e) {
    const t = e.nodeDef, a = [], r = [];
    let n = {};
    t != null && (n = t.reduce((c, d) => (c[d.name] = this.mapNode(d), d.op === "Const" && r.push(c[d.name]), c), {}));
    const u = [], o = [];
    e.signature.inputArg.forEach((c) => {
      const [d] = B(c.name), h = {
        name: d,
        op: "Placeholder",
        inputs: [],
        inputNames: [],
        category: "graph",
        inputParams: {},
        attrParams: { dtype: { value: At(c.type), type: "dtype" } },
        children: []
      };
      h.signatureKey = c.name, u.push(h), n[d] = h;
    }), Object.keys(n).forEach((c) => {
      const d = n[c];
      d.inputNames.forEach((h, N) => {
        const [g, , f] = B(h), b = n[g];
        if (b.outputs != null) {
          const O = b.outputs.indexOf(f);
          if (O !== -1) {
            const _6 = `${g}:${O}`;
            d.inputNames[N] = _6;
          }
        }
        d.inputs.push(b), b.children.push(d);
      });
    });
    const p = e.ret;
    e.signature.outputArg.forEach((c) => {
      const [d, h] = B(p[c.name]), N = n[d];
      N != null && (N.defaultOutput = h, o.push(N));
    });
    const m = this.mapArgsToSignature(e);
    return { nodes: n, inputs: u, outputs: o, weights: r, placeholders: a, signature: m };
  }
  mapArgsToSignature(e) {
    return {
      methodName: e.signature.name,
      inputs: e.signature.inputArg.reduce((t, a) => (t[a.name] = this.mapArgToTensorInfo(a), t), {}),
      outputs: e.signature.outputArg.reduce((t, a) => (t[a.name] = this.mapArgToTensorInfo(a, e.ret), t), {})
    };
  }
  mapArgToTensorInfo(e, t) {
    let a = e.name;
    return t != null && (a = t[a]), { name: a, dtype: e.type };
  }
};
function qg2(s) {
  const e = F().global;
  if (typeof e.atob < "u")
    return e.atob(s);
  if (typeof Buffer < "u")
    return new Buffer(s, "base64").toString();
  throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
}
function ni2(s, e) {
  const t = Array.isArray(s) ? String.fromCharCode.apply(null, s) : qg2(s);
  return e ? t : t.toLowerCase();
}
function Be2(s, e, t, a = false) {
  const r = s[e];
  return r != null ? ni2(r.s, a) : t;
}
function He2(s, e, t) {
  const a = s[e];
  return a ? a.b : t;
}
function We2(s, e, t) {
  const a = s[e] || {}, r = a.i != null ? a.i : a.f != null ? a.f : t;
  return typeof r == "number" ? r : parseInt(r, 10);
}
function At(s) {
  switch (typeof s == "string" && (s = ug[s]), s) {
    case ug.DT_FLOAT:
    case ug.DT_HALF:
      return "float32";
    case ug.DT_INT32:
    case ug.DT_INT64:
    case ug.DT_INT8:
    case ug.DT_UINT8:
      return "int32";
    case ug.DT_BOOL:
      return "bool";
    case ug.DT_DOUBLE:
      return "float32";
    case ug.DT_STRING:
      return "string";
    case ug.DT_COMPLEX64:
    case ug.DT_COMPLEX128:
      return "complex64";
    default:
      return null;
  }
}
function Bt2(s, e, t) {
  const a = s[e];
  return a && a.func ? a.func.name : t;
}
function Ue2(s, e, t) {
  const a = s[e];
  return a && a.type ? At(a.type) : t;
}
function qe2(s, e, t) {
  const a = s[e];
  return a && a.list && a.list.type ? a.list.type.map((r) => At(r)) : t;
}
function ii2(s) {
  if (!s.unknownRank)
    return s.dim != null ? s.dim.map((e) => typeof e.size == "number" ? e.size : parseInt(e.size, 10)) : [];
}
function Ge2(s, e, t) {
  const a = s[e];
  return a && a.shape ? ii2(a.shape) : t;
}
function Ke2(s, e, t) {
  const a = s[e];
  return a ? ((a.list.f && a.list.f.length ? a.list.f : a.list.i) || []).map((r) => typeof r == "number" ? r : parseInt(r, 10)) : t;
}
function Je2(s, e, t, a = false) {
  const r = s[e];
  return r && r.list && r.list.s ? r.list.s.map((n) => ni2(n, a)) : t;
}
function Qe2(s, e, t) {
  const a = s[e];
  return a && a.list && a.list.shape ? a.list.shape.map((r) => ii2(r)) : t;
}
function Xe2(s, e, t) {
  const a = s[e];
  return a && a.list && a.list.b ? a.list.b : t;
}
var Gg2 = class {
  constructor(e, t, a) {
    this.node = e, this.tensorMap = t, this.context = a, this.inputs = [], this.attrs = {}, this.inputs = e.inputNames.map((r) => this.getInput(r)), e.rawAttrs != null && (this.attrs = Object.keys(e.rawAttrs).reduce((r, n) => (r[n] = this.getAttr(n), r), {}));
  }
  /**
   * Return the value of the attribute or input param.
   * @param name String: name of attribute or input param.
   */
  getInput(e) {
    return E6(e, this.tensorMap, this.context);
  }
  /**
   * Return the value of the attribute or input param.
   * @param name String: name of attribute or input param.
   */
  getAttr(e, t) {
    const a = this.node.rawAttrs[e];
    if (a.tensor != null)
      return E6(e, this.tensorMap, this.context);
    if (a.i != null || a.f != null)
      return We2(this.node.rawAttrs, e, t);
    if (a.s != null)
      return Be2(this.node.rawAttrs, e, t);
    if (a.b != null)
      return He2(this.node.rawAttrs, e, t);
    if (a.shape != null)
      return Ge2(this.node.rawAttrs, e, t);
    if (a.type != null)
      return Ue2(this.node.rawAttrs, e, t);
    if (a.list != null) {
      if (a.list.i != null || a.list.f != null)
        return Ke2(this.node.rawAttrs, e, t);
      if (a.list.s != null)
        return Je2(this.node.rawAttrs, e, t);
      if (a.list.shape != null)
        return Qe2(this.node.rawAttrs, e, t);
      if (a.list.b != null)
        return Xe2(this.node.rawAttrs, e, t);
      if (a.list.type != null)
        return qe2(this.node.rawAttrs, e, t);
    }
    return t;
  }
};
var k = Object.freeze(Object.defineProperty({
  __proto__: null,
  OP_SCOPE_SUFFIX: N2,
  abs: me,
  acos: gv,
  acosh: xv,
  add: U,
  addN: nn2,
  all: Qb,
  any: Id,
  argMax: ai,
  argMin: vv,
  asin: kv,
  asinh: Nv,
  atan: $v,
  atan2: Ev,
  atanh: Mv,
  avgPool: np,
  avgPool3d: Ov,
  basicLSTMCell: on2,
  batchNorm: Qc,
  batchNorm2d: Jv,
  batchNorm3d: qv,
  batchNorm4d: eS,
  batchToSpaceND: op,
  bincount: sS,
  bitwiseAnd: un2,
  booleanMaskAsync: Hn2,
  broadcastArgs: ln2,
  broadcastTo: ni,
  buffer: vt,
  cast: tt,
  ceil: iS,
  clipByValue: fn,
  clone: yo,
  complex: vo,
  concat: Ge,
  concat1d: cS,
  concat2d: dS,
  concat3d: pS,
  concat4d: mS,
  conv1d: Jb,
  conv2d: $o,
  conv2dTranspose: jb,
  conv3d: IS,
  conv3dTranspose: SS,
  cos: ip,
  cosh: t0,
  cosineWindow: v0,
  cumprod: vd,
  cumsum: e0,
  denseBincount: Tm,
  depthToSpace: ES,
  depthwiseConv2d: ap,
  diag: pn2,
  dilation2d: WS,
  div: ut,
  divNoNan: PS,
  dot: OS,
  dropout: bN,
  einsum: Or,
  elu: Jc,
  enclosingPowerOfTwo: xN,
  ensureShape: mn2,
  equal: Tn,
  erf: BS,
  euclideanNorm: tk,
  exp: mn,
  expandDims: Oe,
  expm1: ok,
  eye: o0,
  fft: Gp,
  fill: Ca,
  floor: qc,
  floorDiv: Yb,
  fused: Jn2,
  gather: cp,
  gatherND: Gn2,
  greater: rn,
  greaterEqual: Bo,
  ifft: kl,
  imag: up,
  image: fs,
  inTopKAsync: Kn2,
  irfft: b0,
  isFinite: pk,
  isInf: mk,
  isNaN: bk,
  leakyRelu: dp,
  less: Cl,
  lessEqual: Tr,
  linalg: e$,
  linspace: cn2,
  localResponseNormalization: Ck,
  log: Nn,
  log1p: hp,
  logSigmoid: $k,
  logSoftmax: r0,
  logSumExp: pp,
  logicalAnd: ss,
  logicalNot: fp,
  logicalOr: i0,
  logicalXor: Vk,
  losses: $Q,
  lowerBound: dn2,
  matMul: Gt,
  max: Pn,
  maxPool: mp,
  maxPool3d: Ak,
  maxPoolWithArgmax: hn2,
  maximum: qs,
  mean: oe,
  meshgrid: fn2,
  min: Il,
  minimum: br,
  mirrorPad: Bk,
  mod: _k,
  moments: gp,
  movingAverage: Wn2,
  mul: G,
  multiRNNCell: yn2,
  multinomial: gn2,
  neg: Yt,
  norm: jc,
  notEqual: ui,
  oneHot: a0,
  ones: ks,
  onesLike: Rn,
  op: L,
  outerProduct: bn2,
  pad: bp,
  pad1d: Nn2,
  pad2d: wn2,
  pad3d: Tn2,
  pad4d: Sn2,
  pool: sT,
  pow: gr,
  prelu: yp,
  print: lv,
  prod: iT,
  raggedGather: vn2,
  raggedRange: On2,
  raggedTensorToTensor: _n2,
  rand: An2,
  randomGamma: In2,
  randomNormal: kT,
  randomStandardNormal: $n2,
  randomUniform: Sa,
  randomUniformInt: Dn2,
  range: di,
  real: vl,
  reciprocal: $T,
  relu: Ts,
  relu6: c0,
  reshape: W,
  reverse: Lo,
  reverse1d: Cn2,
  reverse2d: zn2,
  reverse3d: xn2,
  reverse4d: Ln,
  rfft: Ep,
  round: u0,
  rsqrt: d0,
  scalar: gt,
  scatterND: Un2,
  searchSorted: Ce2,
  selu: h0,
  separableConv2d: p0,
  setdiff1dAsync: Pn2,
  sigmoid: kr,
  sign: zT,
  signal: RQ,
  sin: f0,
  sinh: m0,
  slice: Ft,
  slice1d: Np,
  slice2d: g0,
  slice3d: Rp,
  slice4d: Sl,
  softmax: $p,
  softplus: va,
  spaceToBatchND: xp,
  sparse: GQ,
  sparseToDense: qn2,
  spectral: NQ,
  split: pn,
  sqrt: Ve,
  square: Kt,
  squaredDifference: x0,
  squeeze: ka,
  stack: Xn,
  step: Ta,
  stridedSlice: nN,
  string: EQ,
  sub: it,
  sum: at,
  tan: oN,
  tanh: sp,
  tensor: $e,
  tensor1d: Ze,
  tensor2d: il,
  tensor3d: rN,
  tensor4d: Fn2,
  tensor5d: Vn2,
  tensor6d: Rn2,
  tensorScatterUpdate: jn2,
  tile: Vn,
  topk: aN,
  transpose: kt,
  truncatedNormal: w0,
  unique: uN,
  unsortedSegmentSum: I0,
  unstack: Mo,
  upperBound: Bn2,
  variable: pN,
  where: Ee,
  whereAsync: wt,
  zeros: be,
  zerosLike: Tt
}, Symbol.toStringTag, { value: "Module" }));
var Kg2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "BiasAdd":
    case "AddV2":
    case "Add":
      return [a.add(i("a", s, e, t), i("b", s, e, t))];
    case "AddN":
      return [a.addN(i("tensors", s, e, t))];
    case "FloorMod":
    case "Mod":
      return [a.mod(i("a", s, e, t), i("b", s, e, t))];
    case "Mul":
      return [a.mul(i("a", s, e, t), i("b", s, e, t))];
    case "RealDiv":
    case "Div":
      return [a.div(i("a", s, e, t), i("b", s, e, t))];
    case "DivNoNan":
      return [a.divNoNan(i("a", s, e, t), i("b", s, e, t))];
    case "FloorDiv":
      return [a.floorDiv(i("a", s, e, t), i("b", s, e, t))];
    case "Sub":
      return [a.sub(i("a", s, e, t), i("b", s, e, t))];
    case "Minimum":
      return [a.minimum(i("a", s, e, t), i("b", s, e, t))];
    case "Maximum":
      return [a.maximum(i("a", s, e, t), i("b", s, e, t))];
    case "Pow":
      return [a.pow(i("a", s, e, t), i("b", s, e, t))];
    case "SquaredDifference":
      return [a.squaredDifference(i("a", s, e, t), i("b", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var Jg2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "Abs":
    case "ComplexAbs":
      return [a.abs(i("x", s, e, t))];
    case "Acos":
      return [a.acos(i("x", s, e, t))];
    case "Acosh":
      return [a.acosh(i("x", s, e, t))];
    case "Asin":
      return [a.asin(i("x", s, e, t))];
    case "Asinh":
      return [a.asinh(i("x", s, e, t))];
    case "Atan":
      return [a.atan(i("x", s, e, t))];
    case "Atan2":
      return [a.atan2(i("x", s, e, t), i("y", s, e, t))];
    case "Atanh":
      return [a.atanh(i("x", s, e, t))];
    case "Ceil":
      return [a.ceil(i("x", s, e, t))];
    case "Complex":
      return [a.complex(i("real", s, e, t), i("imag", s, e, t))];
    case "Cos":
      return [a.cos(i("x", s, e, t))];
    case "Cosh":
      return [a.cosh(i("x", s, e, t))];
    case "Elu":
      return [a.elu(i("x", s, e, t))];
    case "Erf":
      return [a.erf(i("x", s, e, t))];
    case "Exp":
      return [a.exp(i("x", s, e, t))];
    case "Expm1":
      return [a.expm1(i("x", s, e, t))];
    case "Floor":
      return [a.floor(i("x", s, e, t))];
    case "Log":
      return [a.log(i("x", s, e, t))];
    case "Log1p":
      return [a.log1p(i("x", s, e, t))];
    case "Imag":
      return [a.imag(i("x", s, e, t))];
    case "Neg":
      return [a.neg(i("x", s, e, t))];
    case "Reciprocal":
      return [a.reciprocal(i("x", s, e, t))];
    case "Real":
      return [a.real(i("x", s, e, t))];
    case "Relu":
      return [a.relu(i("x", s, e, t))];
    case "Round":
      return [a.round(i("x", s, e, t))];
    case "Selu":
      return [a.selu(i("x", s, e, t))];
    case "Sigmoid":
      return [a.sigmoid(i("x", s, e, t))];
    case "Sin":
      return [a.sin(i("x", s, e, t))];
    case "Sign":
      return [a.sign(i("x", s, e, t))];
    case "Sinh":
      return [a.sinh(i("x", s, e, t))];
    case "Softplus":
      return [a.softplus(i("x", s, e, t))];
    case "Sqrt":
      return [a.sqrt(i("x", s, e, t))];
    case "Square":
      return [a.square(i("x", s, e, t))];
    case "Tanh":
      return [a.tanh(i("x", s, e, t))];
    case "Tan":
      return [a.tan(i("x", s, e, t))];
    case "ClipByValue":
      return [a.clipByValue(i("x", s, e, t), i("clipValueMin", s, e, t), i("clipValueMax", s, e, t))];
    case "Relu6":
      return [a.relu6(i("x", s, e, t))];
    case "Rsqrt":
      return [a.rsqrt(E6(s.inputNames[0], e, t))];
    case "LeakyRelu":
      return [a.leakyRelu(i("x", s, e, t), i("alpha", s, e, t))];
    case "Prelu":
      return [a.prelu(i("x", s, e, t), i("alpha", s, e, t))];
    case "IsNan":
      return [a.isNaN(E6(s.inputNames[0], e, t))];
    case "IsInf":
      return [a.isInf(E6(s.inputNames[0], e, t))];
    case "IsFinite":
      return [a.isFinite(E6(s.inputNames[0], e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function x(s, e, t = "") {
  if (!(typeof s == "number" || typeof e == "number")) {
    C(s.length === e.length, () => t + ` Shapes ${s} and ${e} must match`);
    for (let a = 0; a < s.length; a++) {
      const r = s[a], n = e[a];
      C(r < 0 || n < 0 || r === n, () => t + ` Shapes ${s} and ${e} must match`);
    }
  }
}
function Ht2(s) {
  return !(typeof s == "number" || s.some((e) => e < 0));
}
function ie2(s, e, t) {
  let a = Ze2(s, t);
  const r = !Ht2(a);
  if (r && e.length === 0)
    throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${a}`);
  if (r && e.forEach((n) => {
    a = Ze2(n.shape, a);
  }), !Ht2(a))
    throw new Error(`Non-fully-defined elementShape: ${a}`);
  return a;
}
function Ze2(s, e) {
  if (typeof s == "number")
    return e;
  if (typeof e == "number")
    return s;
  if (s.length !== e.length)
    throw new Error(`Incompatible ranks during merge: ${s} vs. ${e}`);
  const t = [];
  for (let a = 0; a < s.length; ++a) {
    const r = s[a], n = e[a];
    if (r >= 0 && n >= 0 && r !== n)
      throw new Error(`Incompatible shape during merge: ${s} vs. ${e}`);
    t[a] = r >= 0 ? r : n;
  }
  return t;
}
var Qg2 = class {
  constructor(e, t, a, r, n, u, o) {
    this.name = e, this.dtype = t, this.maxSize = a, this.elementShape = r, this.identicalElementShapes = n, this.dynamicSize = u, this.clearAfterRead = o, this.tensors = [], this.closed_ = false, this.idTensor = gt(0), hn(this.idTensor);
  }
  get id() {
    return this.idTensor.id;
  }
  get closed() {
    return this.closed_;
  }
  /**
   * Dispose the tensors and idTensor and mark the TensoryArray as closed.
   */
  clearAndClose(e) {
    this.tensors.forEach((t) => {
      (e == null || !e.has(t.tensor.id)) && t.tensor.dispose();
    }), this.tensors = [], this.closed_ = true, this.idTensor.dispose();
  }
  size() {
    return this.tensors.length;
  }
  /**
   * Read the value at location index in the TensorArray.
   * @param index Number the index to read from.
   */
  read(e) {
    if (this.closed_)
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    if (e < 0 || e >= this.size())
      throw new Error(`Tried to read from index ${e}, but array size is: ${this.size()}`);
    const t = this.tensors[e];
    if (t.cleared)
      throw new Error(`TensorArray ${this.name}: Could not read index ${e} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);
    return this.clearAfterRead && (t.cleared = true), t.read = true, t.tensor;
  }
  /**
   * Helper method to read multiple tensors from the specified indices.
   */
  readMany(e) {
    return e.map((t) => this.read(t));
  }
  /**
   * Write value into the index of the TensorArray.
   * @param index number the index to write to.
   * @param tensor
   */
  write(e, t) {
    if (this.closed_)
      throw new Error(`TensorArray ${this.name} has already been closed.`);
    if (e < 0 || !this.dynamicSize && e >= this.maxSize)
      throw new Error(`Tried to write to index ${e}, but array is not resizeable and size is: ${this.maxSize}`);
    const a = this.tensors[e] || {};
    if (t.dtype !== this.dtype)
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e},
          because the value dtype is ${t.dtype}, but TensorArray dtype is ${this.dtype}.`);
    if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0) && (this.elementShape = t.shape), x(this.elementShape, t.shape, `TensorArray ${this.name}: Could not write to TensorArray index ${e}.`), a.read)
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been read.`);
    if (a.written)
      throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been written.`);
    a.tensor = t, hn(t), a.written = true, this.tensors[e] = a;
  }
  /**
   * Helper method to write multiple tensors to the specified indices.
   */
  writeMany(e, t) {
    if (e.length !== t.length)
      throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${e.length} is not the same as tensors size: ${t.length}.`);
    e.forEach((a, r) => this.write(a, t[r]));
  }
  /**
   * Return selected values in the TensorArray as a packed Tensor. All of
   * selected values must have been written and their shapes must all match.
   * @param [indices] number[] Optional. Taking values in [0, max_value). If the
   *    TensorArray is not dynamic, max_value=size(). If not specified returns
   *    all tensors in the original order.
   * @param [dtype]
   */
  gather(e, t) {
    if (t && t !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${t}`);
    if (e)
      e = e.slice(0, this.size());
    else {
      e = [];
      for (let r = 0; r < this.size(); r++)
        e.push(r);
    }
    if (e.length === 0)
      return $e([], [0].concat(this.elementShape));
    const a = this.readMany(e);
    return x(this.elementShape, a[0].shape, "TensorArray shape mismatch: "), Xn(a, 0);
  }
  /**
   * Return the values in the TensorArray as a concatenated Tensor.
   */
  concat(e) {
    if (e && e !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${e}`);
    if (this.size() === 0)
      return $e([], [0].concat(this.elementShape));
    const t = [];
    for (let r = 0; r < this.size(); r++)
      t.push(r);
    const a = this.readMany(t);
    return x(this.elementShape, a[0].shape, `TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${a[0].shape})`), Ge(a, 0);
  }
  /**
   * Scatter the values of a Tensor in specific indices of a TensorArray.
   * @param indices nummber[] values in [0, max_value). If the
   *    TensorArray is not dynamic, max_value=size().
   * @param tensor Tensor input tensor.
   */
  scatter(e, t) {
    if (t.dtype !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);
    if (e.length !== t.shape[0])
      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);
    const a = Math.max(...e);
    if (!this.dynamicSize && a >= this.maxSize)
      throw new Error(`Max index must be < array size (${a}  vs. ${this.maxSize})`);
    this.writeMany(e, Mo(t, 0));
  }
  /**
   * Split the values of a Tensor into the TensorArray.
   * @param length number[] with the lengths to use when splitting value along
   *    its first dimension.
   * @param tensor Tensor, the tensor to split.
   */
  split(e, t) {
    if (t.dtype !== this.dtype)
      throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);
    let a = 0;
    const r = e.map((l) => (a += l, a));
    if (a !== t.shape[0])
      throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${a}, and tensor's shape is: ${t.shape}`);
    if (!this.dynamicSize && e.length !== this.maxSize)
      throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${e.length}), and the TensorArray is not marked as dynamically resizeable`);
    const n = a === 0 ? 0 : t.size / a, u = [];
    D(() => {
      t = W(t, [1, a, n]);
      for (let l = 0; l < e.length; ++l) {
        const m = [0, l === 0 ? 0 : r[l - 1], 0], c = [1, e[l], n];
        u[l] = W(Ft(t, m, c), this.elementShape);
      }
      return u;
    });
    const o = [];
    for (let l = 0; l < e.length; l++)
      o[l] = l;
    this.writeMany(o, u);
  }
};
var Q = class _Q2 {
  get id() {
    return this.idTensor.id;
  }
  /**
   *
   * @param tensors list of tensors
   * @param elementShape shape of each tensor, this can be a single number (any
   * shape is allowed) or partial shape (dim = -1).
   * @param elementDtype data type of each tensor
   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1
   *   meaning that the size of `tensors` is unbounded.
   */
  constructor(e, t, a, r = -1) {
    this.tensors = e, this.elementShape = t, this.elementDtype = a, e != null && e.forEach((n) => {
      if (a !== n.dtype)
        throw new Error(`Invalid data types; op elements ${a}, but list elements ${n.dtype}`);
      x(t, n.shape, "TensorList shape mismatch: "), hn(n);
    }), this.idTensor = gt(0), this.maxNumElements = r, hn(this.idTensor);
  }
  /**
   * Get a new TensorList containing a copy of the underlying tensor container.
   */
  copy() {
    return new _Q2([...this.tensors], this.elementShape, this.elementDtype);
  }
  /**
   * Dispose the tensors and idTensor and clear the tensor list.
   */
  clearAndClose(e) {
    this.tensors.forEach((t) => {
      (e == null || !e.has(t.id)) && t.dispose();
    }), this.tensors.length = 0, this.idTensor.dispose();
  }
  /**
   * The size of the tensors in the tensor list.
   */
  size() {
    return this.tensors.length;
  }
  /**
   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)
   * tf.Tensor.
   * @param elementShape shape of each tensor
   * @param elementDtype data type of each tensor
   * @param numElements the number of elements to stack
   */
  stack(e, t, a = -1) {
    if (t !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);
    if (a !== -1 && this.tensors.length !== a)
      throw new Error(`Operation expected a list with ${a} elements but got a list with ${this.tensors.length} elements.`);
    x(e, this.elementShape, "TensorList shape mismatch: ");
    const r = ie2(this.elementShape, this.tensors, e);
    return D(() => {
      const n = this.tensors.map((u) => W(u, r));
      return Xn(n, 0);
    });
  }
  /**
   * Pop a tensor from the end of the list.
   * @param elementShape shape of the tensor
   * @param elementDtype data type of the tensor
   */
  popBack(e, t) {
    if (t !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);
    if (this.size() === 0)
      throw new Error("Trying to pop from an empty list.");
    const a = ie2(this.elementShape, this.tensors, e), r = this.tensors.pop();
    return r.kept = false, x(r.shape, e, "TensorList shape mismatch: "), W(r, a);
  }
  /**
   * Push a tensor to the end of the list.
   * @param tensor Tensor to be pushed.
   */
  pushBack(e) {
    if (e.dtype !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);
    if (x(e.shape, this.elementShape, "TensorList shape mismatch: "), this.maxNumElements === this.size())
      throw new Error("Trying to push element into a full list.");
    hn(e), this.tensors.push(e);
  }
  /**
   * Update the size of the list.
   * @param size the new size of the list.
   */
  resize(e) {
    if (e < 0)
      throw new Error(`TensorListResize expects size to be non-negative. Got: ${e}`);
    if (this.maxNumElements !== -1 && e > this.maxNumElements)
      throw new Error(`TensorListResize input size ${e} is greater maxNumElement ${this.maxNumElements}.`);
    const t = new _Q2([], this.elementShape, this.elementDtype, this.maxNumElements);
    t.tensors.length = e;
    for (let a = 0; a < Math.min(this.tensors.length, e); ++a)
      t.tensors[a] = this.tensors[a];
    return t;
  }
  /**
   * Retrieve the element at the provided index
   * @param elementShape shape of the tensor
   * @param elementDtype dtype of the tensor
   * @param elementIndex index of the tensor
   */
  getItem(e, t, a) {
    if (a !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${a}, but list elements ${this.elementDtype}`);
    if (e < 0 || e > this.tensors.length)
      throw new Error(`Trying to access element ${e} in a list with ${this.tensors.length} elements.`);
    if (this.tensors[e] == null)
      throw new Error(`element at index ${e} is null.`);
    x(this.tensors[e].shape, t, "TensorList shape mismatch: ");
    const r = ie2(this.elementShape, this.tensors, t);
    return W(this.tensors[e], r);
  }
  /**
   * Set the tensor at the index
   * @param elementIndex index of the tensor
   * @param tensor the tensor to be inserted into the list
   */
  setItem(e, t) {
    if (t.dtype !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);
    if (e < 0 || this.maxNumElements !== -1 && e >= this.maxNumElements)
      throw new Error(`Trying to set element ${e} in a list with max ${this.maxNumElements} elements.`);
    x(this.elementShape, t.shape, "TensorList shape mismatch: "), hn(t), this.tensors[e] != null && (this.tensors[e].kept = false), this.tensors[e] = t;
  }
  /**
   * Return selected values in the TensorList as a stacked Tensor. All of
   * selected values must have been written and their shapes must all match.
   * @param indices indices of tensors to gather
   * @param elementDtype output tensor dtype
   * @param elementShape output tensor element shape
   */
  gather(e, t, a) {
    if (t !== this.elementDtype)
      throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);
    x(this.elementShape, a, "TensorList shape mismatch: "), e = e.slice(0, this.size());
    const r = ie2(this.elementShape, this.tensors, a);
    return e.length === 0 ? $e([], [0].concat(r)) : D(() => {
      const n = e.map((u) => W(this.tensors[u], r));
      return Xn(n, 0);
    });
  }
  /**
   * Return the values in the TensorList as a concatenated Tensor.
   * @param elementDtype output tensor dtype
   * @param elementShape output tensor element shape
   */
  concat(e, t) {
    if (e && e !== this.elementDtype)
      throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${e}`);
    x(this.elementShape, t, "TensorList shape mismatch: ");
    const a = ie2(this.elementShape, this.tensors, t);
    return this.size() === 0 ? $e([], [0].concat(a)) : D(() => {
      const r = this.tensors.map((n) => W(n, a));
      return Ge(r, 0);
    });
  }
};
function Xg2(s, e, t) {
  const a = s.dtype;
  if (s.shape.length < 1)
    throw new Error(`Tensor must be at least a vector, but saw shape: ${s.shape}`);
  if (s.dtype !== t)
    throw new Error(`Invalid data types; op elements ${s.dtype}, but list elements ${t}`);
  const r = s.shape.slice(1);
  x(r, e, "TensorList shape mismatch: ");
  const n = Mo(s);
  return new Q(n, e, a);
}
function Zg2(s, e, t, a) {
  return new Q([], s, e, a);
}
function Yg2(s, e, t, a) {
  if (e.length !== s.shape[0])
    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${s.shape[0]}`);
  const r = Math.max(...e);
  if (a != null && a !== -1 && r >= a)
    throw new Error(`Max index must be < array size (${r}  vs. ${a})`);
  const n = new Q([], t, s.dtype, a), u = Mo(s, 0);
  return e.forEach((o, l) => {
    n.setItem(o, u[l]);
  }), n;
}
function Mg2(s, e, t) {
  let a = 0;
  const r = e.map((m) => (a += m, a));
  if (a !== s.shape[0])
    throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${a}, and tensor's shape is: ${s.shape}`);
  const n = s.shape.slice(1), u = Ze2(n, t), o = a === 0 ? 0 : s.size / a, l = D(() => {
    const m = [];
    s = W(s, [1, a, o]);
    for (let c = 0; c < e.length; ++c) {
      const h = [0, c === 0 ? 0 : r[c - 1], 0], N = [1, e[c], o];
      m[c] = W(Ft(s, h, N), u);
    }
    return s.dispose(), m;
  }), p = new Q([], t, s.dtype, e.length);
  for (let m = 0; m < l.length; m++)
    p.setItem(m, l[m]);
  return p;
}
var eb2 = async (s, e, t) => {
  switch (s.op) {
    case "If":
    case "StatelessIf": {
      const a = i("thenBranch", s, e, t), r = i("elseBranch", s, e, t), n = i("cond", s, e, t), u = i("args", s, e, t);
      return (await n.data())[0] ? t.functionMap[a].executeFunctionAsync(u, t.tensorArrayMap, t.tensorListMap) : t.functionMap[r].executeFunctionAsync(u, t.tensorArrayMap, t.tensorListMap);
    }
    case "While":
    case "StatelessWhile": {
      const a = i("body", s, e, t), r = i("cond", s, e, t), n = i("args", s, e, t), u = await t.functionMap[r].executeFunctionAsync(n, t.tensorArrayMap, t.tensorListMap), o = n.map((m) => m.id);
      let l = await u[0].data();
      u.forEach((m) => {
        !m.kept && o.indexOf(m.id) === -1 && m.dispose();
      });
      let p = n;
      for (; l[0]; ) {
        const m = p;
        p = await t.functionMap[a].executeFunctionAsync(p, t.tensorArrayMap, t.tensorListMap);
        const c = p.map((h) => h.id);
        m.forEach((h) => {
          !h.kept && o.indexOf(h.id) === -1 && c.indexOf(h.id) === -1 && h.dispose();
        });
        const d = await t.functionMap[r].executeFunctionAsync(p, t.tensorArrayMap, t.tensorListMap);
        l = await d[0].data(), d.forEach((h) => {
          !h.kept && o.indexOf(h.id) === -1 && c.indexOf(h.id) === -1 && h.dispose();
        });
      }
      return p;
    }
    case "LoopCond": {
      const a = i("pred", s, e, t);
      return [H(a)];
    }
    case "Switch": {
      const a = i("pred", s, e, t);
      let r = i("data", s, e, t);
      return r.kept || (r = H(r)), (await a.data())[0] ? [void 0, r] : [r, void 0];
    }
    case "Merge": {
      const a = s.inputNames.find((r) => E6(r, e, t) !== void 0);
      if (a) {
        const r = E6(a, e, t);
        return [H(r)];
      }
      return;
    }
    case "Enter": {
      const a = i("frameName", s, e, t), r = i("tensor", s, e, t);
      return t.enterFrame(a), [H(r)];
    }
    case "Exit": {
      const a = i("tensor", s, e, t);
      return t.exitFrame(), [H(a)];
    }
    case "NextIteration": {
      const a = i("tensor", s, e, t);
      return t.nextIteration(), [H(a)];
    }
    case "TensorArrayV3": {
      const a = i("size", s, e, t), r = i("dtype", s, e, t), n = i("elementShape", s, e, t), u = i("dynamicSize", s, e, t), o = i("clearAfterRead", s, e, t), l = i("identicalElementShapes", s, e, t), p = i("name", s, e, t), m = new Qg2(p, r, a, n, l, u, o);
      return t.addTensorArray(m), [m.idTensor, gt(1)];
    }
    case "TensorArrayWriteV3": {
      const a = i("tensorArrayId", s, e, t), r = i("index", s, e, t), n = i("tensor", s, e, t), u = t.getTensorArray(a.id);
      return u.write(r, n), [u.idTensor];
    }
    case "TensorArrayReadV3": {
      const a = i("tensorArrayId", s, e, t), r = i("index", s, e, t);
      return [t.getTensorArray(a.id).read(r)];
    }
    case "TensorArrayGatherV3": {
      const a = i("tensorArrayId", s, e, t), r = i("indices", s, e, t), n = i("dtype", s, e, t);
      return [t.getTensorArray(a.id).gather(r, n)];
    }
    case "TensorArrayScatterV3": {
      const a = i("tensorArrayId", s, e, t), r = i("indices", s, e, t), n = i("tensor", s, e, t), u = t.getTensorArray(a.id);
      return u.scatter(r, n), [u.idTensor];
    }
    case "TensorArrayConcatV3": {
      const a = i("tensorArrayId", s, e, t), r = t.getTensorArray(a.id), n = i("dtype", s, e, t);
      return [r.concat(n)];
    }
    case "TensorArraySplitV3": {
      const a = i("tensorArrayId", s, e, t), r = i("tensor", s, e, t), n = i("lengths", s, e, t), u = t.getTensorArray(a.id);
      return u.split(n, r), [u.idTensor];
    }
    case "TensorArraySizeV3": {
      const a = i("tensorArrayId", s, e, t), r = t.getTensorArray(a.id);
      return [gt(r.size(), "int32")];
    }
    case "TensorArrayCloseV3": {
      const a = i("tensorArrayId", s, e, t), r = t.getTensorArray(a.id);
      return r.clearAndClose(), [r.idTensor];
    }
    case "TensorListSetItem": {
      const a = i("tensorListId", s, e, t), r = i("index", s, e, t), n = i("tensor", s, e, t), u = t.getTensorList(a.id);
      return u.setItem(r, n), [u.idTensor];
    }
    case "TensorListGetItem": {
      const a = i("tensorListId", s, e, t), r = i("index", s, e, t), n = i("elementShape", s, e, t), u = i("elementDType", s, e, t);
      return [t.getTensorList(a.id).getItem(r, n, u)];
    }
    case "TensorListScatterV2":
    case "TensorListScatter": {
      const a = i("indices", s, e, t), r = i("tensor", s, e, t), n = i("elementShape", s, e, t), u = i("numElements", s, e, t), o = Yg2(r, a, n, u);
      return t.addTensorList(o), [o.idTensor];
    }
    case "TensorListReserve":
    case "EmptyTensorList": {
      const a = i("elementShape", s, e, t), r = i("elementDType", s, e, t);
      let n;
      s.op === "TensorListReserve" ? n = "numElements" : n = "maxNumElements";
      const u = i(n, s, e, t), o = s.op === "TensorListReserve" ? -1 : u, l = Zg2(a, r, u, o);
      return t.addTensorList(l), [l.idTensor];
    }
    case "TensorListGather": {
      const a = i("tensorListId", s, e, t), r = i("indices", s, e, t), n = i("elementShape", s, e, t), u = i("elementDType", s, e, t);
      return [t.getTensorList(a.id).gather(r, u, n)];
    }
    case "TensorListStack": {
      const a = i("tensorListId", s, e, t), r = i("elementShape", s, e, t), n = i("elementDType", s, e, t), u = i("numElements", s, e, t);
      return [t.getTensorList(a.id).stack(r, n, u)];
    }
    case "TensorListFromTensor": {
      const a = i("tensor", s, e, t), r = i("elementShape", s, e, t), n = i("elementDType", s, e, t), u = Xg2(a, r, n);
      return t.addTensorList(u), [u.idTensor];
    }
    case "TensorListConcat":
    case "TensorListConcatV2": {
      const a = i("tensorListId", s, e, t), r = t.getTensorList(a.id), n = i("dtype", s, e, t), u = i("elementShape", s, e, t);
      return [r.concat(n, u)];
    }
    case "TensorListPushBack": {
      const a = i("tensorListId", s, e, t), r = i("tensor", s, e, t), n = t.getTensorList(a.id);
      return n.pushBack(r), [n.idTensor];
    }
    case "TensorListPopBack": {
      const a = i("tensorListId", s, e, t), r = i("elementShape", s, e, t), n = i("elementDType", s, e, t);
      return [t.getTensorList(a.id).popBack(r, n)];
    }
    case "TensorListSplit": {
      const a = i("tensor", s, e, t), r = i("elementShape", s, e, t), n = i("lengths", s, e, t), u = Mg2(a, n, r);
      return t.addTensorList(u), [u.idTensor];
    }
    case "TensorListLength": {
      const a = i("tensorListId", s, e, t), r = t.getTensorList(a.id);
      return [gt(r.size(), "int32")];
    }
    case "TensorListResize": {
      const a = i("tensorListId", s, e, t), r = i("size", s, e, t), u = t.getTensorList(a.id).resize(r);
      return t.addTensorList(u), [u.idTensor];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function Wt2(s, e, t) {
  const [a, r] = i("fusedOps", s, e, t), n = a === "biasadd", u = !n, o = r === "prelu", l = a === "fusedbatchnorm", p = i("numArgs", s, e, t);
  if (n) {
    if (o && p !== 2)
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
    if (!o && n && p !== 1)
      throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
  }
  if (l)
    throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
  const m = i("strides", s, e, t), c = we(s, e, t), d = i("dataFormat", s, e, t).toUpperCase(), h = i("dilations", s, e, t);
  let [N, g] = i("args", s, e, t);
  u && (g = N, N = void 0);
  const f = i("leakyreluAlpha", s, e, t);
  return {
    stride: m,
    pad: c,
    dataFormat: d,
    dilations: h,
    biasArg: N,
    preluArg: g,
    activationFunc: r,
    leakyreluAlpha: f
  };
}
var tb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "Conv1D": {
      const r = i("stride", s, e, t), n = i("pad", s, e, t), u = i("dataFormat", s, e, t).toUpperCase(), o = i("dilation", s, e, t);
      return [a.conv1d(i("x", s, e, t), i("filter", s, e, t), r, n, u, o)];
    }
    case "Conv2D": {
      const r = i("strides", s, e, t), n = we(s, e, t), u = i("dataFormat", s, e, t).toUpperCase(), o = i("dilations", s, e, t);
      return [a.conv2d(i("x", s, e, t), i("filter", s, e, t), [r[1], r[2]], n, u, [o[1], o[2]])];
    }
    case "_FusedConv2D": {
      const { stride: r, pad: n, dataFormat: u, dilations: o, biasArg: l, preluArg: p, activationFunc: m, leakyreluAlpha: c } = Wt2(s, e, t);
      return [a.fused.conv2d({
        x: i("x", s, e, t),
        filter: i("filter", s, e, t),
        strides: [r[1], r[2]],
        pad: n,
        dataFormat: u,
        dilations: [o[1], o[2]],
        bias: l,
        activation: m,
        preluActivationWeights: p,
        leakyreluAlpha: c
      })];
    }
    case "FusedDepthwiseConv2dNative": {
      const { stride: r, pad: n, dataFormat: u, dilations: o, biasArg: l, preluArg: p, activationFunc: m, leakyreluAlpha: c } = Wt2(s, e, t);
      return [a.fused.depthwiseConv2d({
        x: i("x", s, e, t),
        filter: i("filter", s, e, t),
        strides: [r[1], r[2]],
        pad: n,
        dataFormat: u,
        dilations: [o[1], o[2]],
        bias: l,
        activation: m,
        preluActivationWeights: p,
        leakyreluAlpha: c
      })];
    }
    case "Conv2DBackpropInput":
    case "Conv2dTranspose": {
      const r = i("outputShape", s, e, t), n = i("strides", s, e, t), u = we(s, e, t);
      return [a.conv2dTranspose(i("x", s, e, t), i("filter", s, e, t), r, [n[1], n[2]], u)];
    }
    case "DepthwiseConv2dNative":
    case "DepthwiseConv2d": {
      const r = i("strides", s, e, t), n = we(s, e, t), u = i("dilations", s, e, t), o = i("dataFormat", s, e, t).toUpperCase();
      return [a.depthwiseConv2d(i("input", s, e, t), i("filter", s, e, t), [r[1], r[2]], n, o, [u[1], u[2]])];
    }
    case "Conv3D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), u = i("dataFormat", s, e, t).toUpperCase(), o = i("dilations", s, e, t);
      return [a.conv3d(i("x", s, e, t), i("filter", s, e, t), [r[1], r[2], r[3]], n, u, [o[1], o[2], o[3]])];
    }
    case "AvgPool": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), u = i("kernelSize", s, e, t);
      return [a.avgPool(i("x", s, e, t), [u[1], u[2]], [r[1], r[2]], n)];
    }
    case "MaxPool": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), u = i("kernelSize", s, e, t);
      return [a.maxPool(i("x", s, e, t), [u[1], u[2]], [r[1], r[2]], n)];
    }
    case "MaxPoolWithArgmax": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), u = i("kernelSize", s, e, t), o = i("includeBatchInIndex", s, e, t), { result: l, indexes: p } = a.maxPoolWithArgmax(i("x", s, e, t), [u[1], u[2]], [r[1], r[2]], n, o);
      return [l, p];
    }
    case "AvgPool3D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), u = i("kernelSize", s, e, t);
      return [a.avgPool3d(i("x", s, e, t), [u[1], u[2], u[3]], [r[1], r[2], r[3]], n)];
    }
    case "MaxPool3D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), u = i("kernelSize", s, e, t);
      return [a.maxPool3d(i("x", s, e, t), [u[1], u[2], u[3]], [r[1], r[2], r[3]], n)];
    }
    case "Dilation2D": {
      const r = i("strides", s, e, t), n = i("pad", s, e, t), u = i("dilations", s, e, t), o = r[1], l = r[2], p = u[1], m = u[2];
      return [a.dilation2d(
        i("x", s, e, t),
        i("filter", s, e, t),
        [o, l],
        n,
        [p, m],
        "NHWC"
        /* dataFormat */
      )];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var sb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "Fill": {
      const r = i("shape", s, e, t), n = i("dtype", s, e, t), u = i("value", s, e, t);
      return [a.fill(r, u, n)];
    }
    case "LinSpace": {
      const r = i("start", s, e, t), n = i("stop", s, e, t), u = i("num", s, e, t);
      return [a.linspace(r, n, u)];
    }
    case "Multinomial": {
      const r = i("logits", s, e, t), n = i("numSamples", s, e, t), u = i("seed", s, e, t);
      return [a.multinomial(r, n, u)];
    }
    case "OneHot": {
      const r = i("indices", s, e, t), n = i("depth", s, e, t), u = i("onValue", s, e, t), o = i("offValue", s, e, t), l = i("dtype", s, e, t);
      return [a.oneHot(r, n, u, o, l)];
    }
    case "Ones":
      return [a.ones(i("shape", s, e, t), i("dtype", s, e, t))];
    case "OnesLike":
      return [a.onesLike(i("x", s, e, t))];
    case "RandomStandardNormal":
      return [a.randomStandardNormal(i("shape", s, e, t), i("dtype", s, e, t), i("seed", s, e, t))];
    case "RandomUniform":
      return [a.randomUniform(
        // tslint:disable-next-line:no-any
        i("shape", s, e, t),
        i("minval", s, e, t),
        i("maxval", s, e, t),
        i("dtype", s, e, t)
      )];
    case "RandomUniformInt":
      return [a.randomUniformInt(i("shape", s, e, t), i("minval", s, e, t), i("maxval", s, e, t), i("seed", s, e, t))];
    case "Range": {
      const r = i("start", s, e, t), n = i("stop", s, e, t), u = i("step", s, e, t);
      return [a.range(r, n, u, i("dtype", s, e, t))];
    }
    case "TruncatedNormal": {
      const r = i("shape", s, e, t), n = i("mean", s, e, t), u = i("stdDev", s, e, t), o = i("seed", s, e, t);
      return [a.truncatedNormal(r, n, u, i("dtype", s, e, t), o)];
    }
    case "Zeros":
      return [a.zeros(i("shape", s, e, t), i("dtype", s, e, t))];
    case "ZerosLike":
      return [a.zerosLike(i("x", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function Le2(s, e, t) {
  const a = i("boxes", s, e, t), r = i("scores", s, e, t), n = i("maxOutputSize", s, e, t), u = i("iouThreshold", s, e, t), o = i("scoreThreshold", s, e, t), l = i("softNmsSigma", s, e, t);
  return {
    boxes: a,
    scores: r,
    maxOutputSize: n,
    iouThreshold: u,
    scoreThreshold: o,
    softNmsSigma: l
  };
}
var ab2 = async (s, e, t, a, r = k) => {
  switch (s.op) {
    case "NonMaxSuppressionV5": {
      const { boxes: n, scores: u, maxOutputSize: o, iouThreshold: l, scoreThreshold: p, softNmsSigma: m } = Le2(s, e, t), c = await r.image.nonMaxSuppressionWithScoreAsync(n, u, o, l, p, m);
      return [c.selectedIndices, c.selectedScores];
    }
    case "NonMaxSuppressionV4": {
      const { boxes: n, scores: u, maxOutputSize: o, iouThreshold: l, scoreThreshold: p } = Le2(s, e, t), m = i("padToMaxOutputSize", s, e, t), c = await r.image.nonMaxSuppressionPaddedAsync(n, u, o, l, p, m);
      return [c.selectedIndices, c.validOutputs];
    }
    case "NonMaxSuppressionV3":
    case "NonMaxSuppressionV2": {
      const { boxes: n, scores: u, maxOutputSize: o, iouThreshold: l, scoreThreshold: p } = Le2(s, e, t);
      return [await r.image.nonMaxSuppressionAsync(n, u, o, l, p)];
    }
    case "Where": {
      const n = r.cast(i("condition", s, e, t), "bool"), u = [await r.whereAsync(n)];
      return n.dispose(), u;
    }
    case "ListDiff":
      return r.setdiff1dAsync(i("x", s, e, t), i("y", s, e, t));
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var rb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "LowerBound": {
      const r = i("sortedSequence", s, e, t), n = i("values", s, e, t);
      return [a.lowerBound(r, n)];
    }
    case "TopKV2": {
      const r = i("x", s, e, t), n = i("k", s, e, t), u = i("sorted", s, e, t), o = a.topk(r, n, u);
      return [o.values, o.indices];
    }
    case "UpperBound": {
      const r = i("sortedSequence", s, e, t), n = i("values", s, e, t);
      return [a.upperBound(r, n)];
    }
    case "Unique": {
      const r = i("x", s, e, t), n = a.unique(r);
      return [n.values, n.indices];
    }
    case "UniqueV2": {
      const r = i("x", s, e, t), n = i("axis", s, e, t), u = a.unique(r, n);
      return [u.values, u.indices];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var nb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "Const":
      return e[s.name];
    case "PlaceholderWithDefault":
      const r = i("default", s, e, t);
      return [E6(s.name, e, t) || r];
    case "Placeholder":
      return [E6(s.name, e, t)];
    case "Identity":
    case "StopGradient":
    case "FakeQuantWithMinMaxVars": {
      const m = i("x", s, e, t);
      return [H(m)];
    }
    case "IdentityN":
      return i("x", s, e, t).map((m) => H(m));
    case "Snapshot":
      const n = i("x", s, e, t);
      return [H(n)];
    case "Shape":
      return [a.tensor1d(i("x", s, e, t).shape, "int32")];
    case "ShapeN":
      return i("x", s, e, t).map((m) => a.tensor1d(m.shape));
    case "Size":
      return [a.scalar(i("x", s, e, t).size, "int32")];
    case "Rank":
      return [a.scalar(i("x", s, e, t).rank, "int32")];
    case "NoOp":
      return [a.scalar(1)];
    case "Print":
      const u = i("x", s, e, t), o = i("data", s, e, t), l = i("message", s, e, t), p = i("summarize", s, e, t);
      console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."), console.log(l);
      for (let m = 0; m < o.length; m++)
        console.log(Array.prototype.slice.call(o[m].dataSync()).slice(0, p));
      return [u];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var ib2 = class {
  get id() {
    return this.handle.id;
  }
  /**
   * Constructor of HashTable. Creates a hash table.
   *
   * @param keyDType `dtype` of the table keys.
   * @param valueDType `dtype` of the table values.
   */
  constructor(e, t) {
    this.keyDType = e, this.valueDType = t, this.handle = gt(0), this.tensorMap = /* @__PURE__ */ new Map(), hn(this.handle);
  }
  /**
   * Dispose the tensors and handle and clear the hashtable.
   */
  clearAndClose() {
    this.tensorMap.forEach((e) => e.dispose()), this.tensorMap.clear(), this.handle.dispose();
  }
  /**
   * The number of items in the hash table.
   */
  size() {
    return this.tensorMap.size;
  }
  /**
   * The number of items in the hash table as a rank-0 tensor.
   */
  tensorSize() {
    return gt(this.size(), "int32");
  }
  /**
   * Replaces the contents of the table with the specified keys and values.
   * @param keys Keys to store in the hashtable.
   * @param values Values to store in the hashtable.
   */
  async import(e, t) {
    this.checkKeyAndValueTensor(e, t);
    const a = await e.data();
    return this.tensorMap.forEach((r) => r.dispose()), this.tensorMap.clear(), D(() => {
      const r = Mo(t), n = a.length, u = r.length;
      C(n === u, () => `The number of elements doesn't match, keys has ${n} elements, the values has ${u} elements.`);
      for (let o = 0; o < n; o++) {
        const l = a[o], p = r[o];
        hn(p), this.tensorMap.set(l, p);
      }
      return this.handle;
    });
  }
  /**
   * Looks up keys in a hash table, outputs the corresponding values.
   *
   * Performs batch lookups, for every element in the key tensor, `find`
   * stacks the corresponding value into the return tensor.
   *
   * If an element is not present in the table, the given `defaultValue` is
   * used.
   *
   * @param keys Keys to look up. Must have the same type as the keys of the
   *     table.
   * @param defaultValue The scalar `defaultValue` is the value output for keys
   *     not present in the table. It must also be of the same type as the
   *     table values.
   */
  async find(e, t) {
    this.checkKeyAndValueTensor(e, t);
    const a = await e.data();
    return D(() => {
      const r = [];
      for (let n = 0; n < a.length; n++) {
        const u = a[n], o = this.findWithDefault(u, t);
        r.push(o);
      }
      return Xn(r);
    });
  }
  // tslint:disable-next-line: no-any
  findWithDefault(e, t) {
    const a = this.tensorMap.get(e);
    return a ?? t;
  }
  checkKeyAndValueTensor(e, t) {
    if (e.dtype !== this.keyDType)
      throw new Error(`Expect key dtype ${this.keyDType}, but got ${e.dtype}`);
    if (t.dtype !== this.valueDType)
      throw new Error(`Expect value dtype ${this.valueDType}, but got ${t.dtype}`);
  }
};
var ob2 = async (s, e, t, a) => {
  switch (s.op) {
    case "HashTable":
    case "HashTableV2": {
      const r = a.getHashTableHandleByName(s.name);
      if (r != null)
        return [r];
      {
        const n = i("keyDType", s, e, t), u = i("valueDType", s, e, t), o = new ib2(n, u);
        return a.addHashTable(s.name, o), [o.handle];
      }
    }
    case "InitializeTable":
    case "InitializeTableV2":
    case "LookupTableImport":
    case "LookupTableImportV2": {
      const r = i("tableHandle", s, e, t, a), n = i("keys", s, e, t), u = i("values", s, e, t);
      return [await a.getHashTableById(r.id).import(n, u)];
    }
    case "LookupTableFind":
    case "LookupTableFindV2": {
      const r = i("tableHandle", s, e, t, a), n = i("keys", s, e, t), u = i("defaultValue", s, e, t);
      return [await a.getHashTableById(r.id).find(n, u)];
    }
    case "LookupTableSize":
    case "LookupTableSizeV2": {
      const r = i("tableHandle", s, e, t, a);
      return [a.getHashTableById(r.id).tensorSize()];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var ub2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "ResizeBilinear": {
      const r = i("images", s, e, t), n = i("size", s, e, t), u = i("alignCorners", s, e, t), o = i("halfPixelCenters", s, e, t);
      return [a.image.resizeBilinear(r, [n[0], n[1]], u, o)];
    }
    case "ResizeNearestNeighbor": {
      const r = i("images", s, e, t), n = i("size", s, e, t), u = i("alignCorners", s, e, t), o = i("halfPixelCenters", s, e, t);
      return [a.image.resizeNearestNeighbor(r, [n[0], n[1]], u, o)];
    }
    case "CropAndResize": {
      const r = i("image", s, e, t), n = i("boxes", s, e, t), u = i("boxInd", s, e, t), o = i("cropSize", s, e, t), l = i("method", s, e, t), p = i("extrapolationValue", s, e, t);
      return [a.image.cropAndResize(r, n, u, o, l, p)];
    }
    case "ImageProjectiveTransformV3": {
      const r = i("images", s, e, t), n = i("transforms", s, e, t), u = i("outputShape", s, e, t), o = i("fillValue", s, e, t), l = i("interpolation", s, e, t), p = i("fillMode", s, e, t);
      return [a.image.transform(r, n, l.toLowerCase(), p.toLowerCase(), o, u)];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var lb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "Equal":
      return [a.equal(i("a", s, e, t), i("b", s, e, t))];
    case "NotEqual":
      return [a.notEqual(i("a", s, e, t), i("b", s, e, t))];
    case "Greater":
      return [a.greater(i("a", s, e, t), i("b", s, e, t))];
    case "GreaterEqual":
      return [a.greaterEqual(i("a", s, e, t), i("b", s, e, t))];
    case "Less":
      return [a.less(i("a", s, e, t), i("b", s, e, t))];
    case "LessEqual":
      return [a.lessEqual(i("a", s, e, t), i("b", s, e, t))];
    case "LogicalAnd":
      return [a.logicalAnd(i("a", s, e, t), i("b", s, e, t))];
    case "LogicalNot":
      return [a.logicalNot(i("a", s, e, t))];
    case "LogicalOr":
      return [a.logicalOr(i("a", s, e, t), i("b", s, e, t))];
    case "Select":
    case "SelectV2":
      return [a.where(i("condition", s, e, t), i("a", s, e, t), i("b", s, e, t))];
    case "BitwiseAnd":
      return [a.bitwiseAnd(i("a", s, e, t), i("b", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var pb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "BatchMatMul":
    case "BatchMatMulV2":
    case "MatMul":
      return [a.matMul(i("a", s, e, t), i("b", s, e, t), i("transposeA", s, e, t), i("transposeB", s, e, t))];
    case "Einsum":
      return [a.einsum(i("equation", s, e, t), ...i("tensors", s, e, t))];
    case "Transpose":
      return [a.transpose(i("x", s, e, t), i("perm", s, e, t))];
    case "_FusedMatMul":
      const [r, n] = i("fusedOps", s, e, t), u = r === "biasadd", o = n === "prelu", l = i("numArgs", s, e, t), p = i("leakyreluAlpha", s, e, t);
      if (u) {
        if (o && l !== 2)
          throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        if (!o && l !== 1)
          throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
      }
      const [m, c] = i("args", s, e, t);
      return [a.fused.matMul({
        a: i("a", s, e, t),
        b: i("b", s, e, t),
        transposeA: i("transposeA", s, e, t),
        transposeB: i("transposeB", s, e, t),
        bias: m,
        activation: n,
        preluActivationWeights: c,
        leakyreluAlpha: p
      })];
    case "MatrixBandPart":
      return [a.linalg.bandPart(i("a", s, e, t), i("numLower", s, e, t), i("numUpper", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var mb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "EuclideanNorm":
      return [a.euclideanNorm(i("x", s, e, t), i("axis", s, e, t), i("keepDims", s, e, t))];
    case "FusedBatchNorm":
    case "FusedBatchNormV2":
      return [a.batchNorm(i("x", s, e, t), i("mean", s, e, t), i("variance", s, e, t), i("offset", s, e, t), i("scale", s, e, t), i("epsilon", s, e, t))];
    case "FusedBatchNormV3":
      return [a.batchNorm(i("x", s, e, t), i("mean", s, e, t), i("variance", s, e, t), i("offset", s, e, t), i("scale", s, e, t), i("epsilon", s, e, t))];
    case "LRN":
      return [a.localResponseNormalization(i("x", s, e, t), i("radius", s, e, t), i("bias", s, e, t), i("alpha", s, e, t), i("beta", s, e, t))];
    case "Softmax":
      return [a.softmax(i("x", s, e, t))];
    case "LogSoftmax":
      return [a.logSoftmax(i("x", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var cb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "RaggedGather": {
      const { outputNestedSplits: r, outputDenseValues: n } = a.raggedGather(i("paramsNestedSplits", s, e, t), i("paramsDenseValues", s, e, t), i("indices", s, e, t), i("outputRaggedRank", s, e, t));
      return r.concat(n);
    }
    case "RaggedRange": {
      const { rtNestedSplits: r, rtDenseValues: n } = a.raggedRange(i("starts", s, e, t), i("limits", s, e, t), i("splits", s, e, t));
      return [r, n];
    }
    case "RaggedTensorToTensor":
      return [a.raggedTensorToTensor(i("shape", s, e, t), i("values", s, e, t), i("defaultValue", s, e, t), i("rowPartitionTensors", s, e, t), i("rowPartitionTypes", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var db2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "Max": {
      const o = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.max(i("x", s, e, t), o, l)];
    }
    case "Mean": {
      const o = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.mean(i("x", s, e, t), o, l)];
    }
    case "Min": {
      const o = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.min(i("x", s, e, t), o, l)];
    }
    case "Sum": {
      const o = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.sum(i("x", s, e, t), o, l)];
    }
    case "All": {
      const o = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.all(i("x", s, e, t), o, l)];
    }
    case "Any": {
      const o = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.any(i("x", s, e, t), o, l)];
    }
    case "ArgMax": {
      const o = i("axis", s, e, t);
      return [a.argMax(i("x", s, e, t), o)];
    }
    case "ArgMin": {
      const o = i("axis", s, e, t);
      return [a.argMin(i("x", s, e, t), o)];
    }
    case "Prod": {
      const o = i("axis", s, e, t), l = i("keepDims", s, e, t);
      return [a.prod(i("x", s, e, t), o, l)];
    }
    case "Cumprod": {
      const o = i("axis", s, e, t), l = i("exclusive", s, e, t), p = i("reverse", s, e, t);
      return [a.cumprod(i("x", s, e, t), o, l, p)];
    }
    case "Cumsum": {
      const o = i("axis", s, e, t), l = i("exclusive", s, e, t), p = i("reverse", s, e, t);
      return [a.cumsum(i("x", s, e, t), o, l, p)];
    }
    case "Bincount":
      const r = i("x", s, e, t), n = i("weights", s, e, t), u = i("size", s, e, t);
      return [a.bincount(r, n, u)];
    case "DenseBincount": {
      const o = i("x", s, e, t), l = i("weights", s, e, t), p = i("size", s, e, t), m = i("binaryOutput", s, e, t);
      return [a.denseBincount(o, l, p, m)];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var hb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "ConcatV2":
    case "Concat": {
      const r = i("n", s, e, t), n = i("axis", s, e, t);
      let u = i("tensors", s, e, t);
      return u = u.slice(0, r), [a.concat(u, n)];
    }
    case "Gather": {
      const r = i("x", s, e, t), n = i("indices", s, e, t);
      return [a.gather(r, a.cast(n, "int32"), 0)];
    }
    case "GatherV2": {
      const r = i("axis", s, e, t), n = i("batchDims", s, e, t), u = i("x", s, e, t), o = i("indices", s, e, t);
      return [a.gather(u, a.cast(o, "int32"), r, n)];
    }
    case "Reverse": {
      const r = i("dims", s, e, t), n = [];
      for (let o = 0; o < r.length; o++)
        r[o] && n.push(o);
      const u = i("x", s, e, t);
      return [a.reverse(u, n)];
    }
    case "ReverseV2": {
      const r = i("axis", s, e, t), n = i("x", s, e, t);
      return [a.reverse(n, r)];
    }
    case "Slice": {
      const r = i("begin", s, e, t), n = i("size", s, e, t);
      return [a.slice(i("x", s, e, t), r, n)];
    }
    case "StridedSlice": {
      const r = i("begin", s, e, t), n = i("end", s, e, t), u = i("strides", s, e, t), o = i("beginMask", s, e, t), l = i("endMask", s, e, t), p = i("ellipsisMask", s, e, t), m = i("newAxisMask", s, e, t), c = i("shrinkAxisMask", s, e, t), d = i("x", s, e, t);
      return [a.stridedSlice(d, r, n, u, o, l, p, m, c)];
    }
    case "Pack":
      return D(() => {
        const r = i("axis", s, e, t), n = i("tensors", s, e, t), u = n[0].shape, o = a.squeeze(n[0]).shape, l = n.map((p) => {
          const m = $t(p.shape, u);
          if (!m && !$t(a.squeeze(p).shape, o))
            throw new Error("the input tensors shape does not match");
          return m ? p : a.reshape(p, u);
        });
        return [a.stack(l, r)];
      });
    case "Unpack": {
      const r = i("axis", s, e, t), n = i("tensor", s, e, t);
      return a.unstack(n, r);
    }
    case "Tile": {
      const r = i("reps", s, e, t);
      return [a.tile(i("x", s, e, t), r)];
    }
    case "Split":
    case "SplitV": {
      const r = i("axis", s, e, t), n = i("numOrSizeSplits", s, e, t), u = i("x", s, e, t);
      return a.split(u, n, r);
    }
    case "ScatterNd": {
      const r = i("indices", s, e, t), n = i("values", s, e, t), u = i("shape", s, e, t);
      return [a.scatterND(r, n, u)];
    }
    case "GatherNd": {
      const r = i("x", s, e, t), n = i("indices", s, e, t);
      return [a.gatherND(r, n)];
    }
    case "SparseToDense": {
      const r = i("sparseIndices", s, e, t), n = i("outputShape", s, e, t), u = i("sparseValues", s, e, t), o = i("defaultValue", s, e, t);
      return [a.sparseToDense(r, u, n, u.dtype === o.dtype ? o : a.cast(o, u.dtype))];
    }
    case "TensorScatterUpdate": {
      const r = i("indices", s, e, t), n = i("values", s, e, t), u = i("tensor", s, e, t);
      return [a.tensorScatterUpdate(u, r, n)];
    }
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var fb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "SparseFillEmptyRows": {
      const { outputIndices: r, outputValues: n, emptyRowIndicator: u, reverseIndexMap: o } = a.sparse.sparseFillEmptyRows(i("indices", s, e, t), i("values", s, e, t), i("denseShape", s, e, t), i("defaultValue", s, e, t));
      return [
        r,
        n,
        u,
        o
      ];
    }
    case "SparseReshape": {
      const { outputIndices: r, outputShape: n } = a.sparse.sparseReshape(i("inputIndices", s, e, t), i("inputShape", s, e, t), i("newShape", s, e, t));
      return [r, n];
    }
    case "SparseSegmentMean":
      return [a.sparse.sparseSegmentMean(i("data", s, e, t), i("indices", s, e, t), i("segmentIds", s, e, t))];
    case "SparseSegmentSum":
      return [a.sparse.sparseSegmentSum(i("data", s, e, t), i("indices", s, e, t), i("segmentIds", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var yb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "FFT":
      return [a.fft(i("x", s, e, t))];
    case "IFFT":
      return [a.ifft(i("x", s, e, t))];
    case "RFFT":
      return [a.rfft(i("x", s, e, t))];
    case "IRFFT":
      return [a.irfft(i("x", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var gb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "StaticRegexReplace":
      return [a.string.staticRegexReplace(i("input", s, e, t), i("pattern", s, e, t), i("rewrite", s, e, t), i("replaceGlobal", s, e, t))];
    case "StringNGrams": {
      const { nGrams: r, nGramsSplits: n } = a.string.stringNGrams(i("data", s, e, t), i("dataSplits", s, e, t), i("separator", s, e, t), i("nGramWidths", s, e, t), i("leftPad", s, e, t), i("rightPad", s, e, t), i("padWidth", s, e, t), i("preserveShortSequences", s, e, t));
      return [r, n];
    }
    case "StringSplit": {
      const { indices: r, values: n, shape: u } = a.string.stringSplit(i("input", s, e, t), i("delimiter", s, e, t), i("skipEmpty", s, e, t));
      return [r, n, u];
    }
    case "StringToHashBucketFast":
      return [a.string.stringToHashBucketFast(i("input", s, e, t), i("numBuckets", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
var bb2 = (s, e, t, a = k) => {
  switch (s.op) {
    case "Cast":
      return [a.cast(i("x", s, e, t), i("dtype", s, e, t))];
    case "ExpandDims": {
      const r = i("axis", s, e, t);
      return [a.expandDims(i("x", s, e, t), r)];
    }
    case "Squeeze": {
      const r = i("axis", s, e, t);
      return [a.squeeze(i("x", s, e, t), r)];
    }
    case "Reshape":
      return [a.reshape(i("x", s, e, t), i("shape", s, e, t))];
    case "EnsureShape":
      return [a.ensureShape(i("x", s, e, t), i("shape", s, e, t))];
    case "MirrorPad":
      return [a.mirrorPad(i("x", s, e, t), i("padding", s, e, t), i("mode", s, e, t))];
    case "PadV2":
    case "Pad":
      return [a.pad(i("x", s, e, t), i("padding", s, e, t), i("constantValue", s, e, t))];
    case "SpaceToBatchND": {
      const r = i("blockShape", s, e, t), n = i("paddings", s, e, t);
      return [a.spaceToBatchND(i("x", s, e, t), r, n)];
    }
    case "BatchToSpaceND": {
      const r = i("blockShape", s, e, t), n = i("crops", s, e, t);
      return [a.batchToSpaceND(i("x", s, e, t), r, n)];
    }
    case "DepthToSpace": {
      const r = i("blockSize", s, e, t), n = i("dataFormat", s, e, t).toUpperCase();
      return [a.depthToSpace(i("x", s, e, t), r, n)];
    }
    case "BroadcastTo":
      return [a.broadcastTo(i("x", s, e, t), i("shape", s, e, t))];
    case "BroadcastArgs":
      return [a.broadcastArgs(i("s0", s, e, t), i("s1", s, e, t))];
    default:
      throw TypeError(`Node type ${s.op} is not implemented`);
  }
};
function Ut2(s, e, t, a, r = D) {
  const n = ((u, o, l) => {
    switch (u.category) {
      case "arithmetic":
        return r(() => Kg2(u, o, l));
      case "basic_math":
        return r(() => Jg2(u, o, l));
      case "control":
        return eb2(u, o, l);
      case "convolution":
        return r(() => tb2(u, o, l));
      case "creation":
        return r(() => sb2(u, o, l));
      case "dynamic":
        return ab2(u, o, l);
      case "evaluation":
        return r(() => rb2(u, o, l));
      case "image":
        return r(() => ub2(u, o, l));
      case "graph":
        return r(() => nb2(u, o, l));
      case "logical":
        return r(() => lb2(u, o, l));
      case "matrices":
        return r(() => pb2(u, o, l));
      case "normalization":
        return r(() => mb2(u, o, l));
      case "ragged":
        return r(() => cb2(u, o, l));
      case "reduction":
        return r(() => db2(u, o, l));
      case "slice_join":
        return r(() => hb2(u, o, l));
      case "sparse":
        return r(() => fb2(u, o, l));
      case "spectral":
        return r(() => yb2(u, o, l));
      case "string":
        return r(() => gb2(u, o, l));
      case "transformation":
        return r(() => bb2(u, o, l));
      case "hash_table":
        return ob2(u, o, l, a);
      case "custom":
        const p = ri2(u.op);
        if (p && p.customExecutor)
          return p.customExecutor(new Gg2(u, o, l));
        throw TypeError(`Custom op ${u.op} is not registered.`);
      default:
        throw TypeError(`Unknown op '${u.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`);
    }
  })(s, e, t);
  return Ci(n) ? n.then((u) => [].concat(u)) : [].concat(n);
}
var qt2 = class {
  constructor(e = {}, t = {}, a = {}, r = {}, n) {
    this.weightMap = e, this.tensorArrayMap = t, this.tensorListMap = a, this.functionMap = r, this.parseNodeNameCache = n, this.rootContext = { id: 0, frameName: "", iterationId: 0 }, this.contexts = [this.rootContext], this.lastId = 0, this.generateCurrentContextIds();
  }
  newFrame(e, t) {
    return { id: e, frameName: t, iterationId: 0 };
  }
  /**
   * Set the current context
   * @param contexts: ExecutionContextInfo[] the current path of execution
   * frames
   */
  set currentContext(e) {
    this.contexts !== e && (this.contexts = e, this.generateCurrentContextIds());
  }
  get currentContext() {
    return this.contexts;
  }
  /**
   * Returns the current context in string format.
   */
  get currentContextId() {
    return this._currentContextIds[0];
  }
  /**
   * Returns the current context and all parent contexts in string format.
   * This allow access to the nodes in the current and parent frames.
   */
  get currentContextIds() {
    return this._currentContextIds;
  }
  generateCurrentContextIds() {
    const e = [];
    for (let t = 0; t < this.contexts.length - 1; t++) {
      const a = this.contexts.slice(0, this.contexts.length - t);
      e.push(this.contextIdforContexts(a));
    }
    e.push(""), this._currentContextIds = e;
  }
  contextIdforContexts(e) {
    return e ? e.map((t) => t.id === 0 && t.iterationId === 0 ? "" : `${t.frameName}-${t.iterationId}`).join("/") : "";
  }
  /**
   * Enter a new frame, a new context is pushed on the current context list.
   * @param frameId new frame id
   */
  enterFrame(e) {
    this.contexts && (this.lastId++, this.contexts = this.contexts.slice(), this.contexts.push(this.newFrame(this.lastId, e)), this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)));
  }
  /**
   * Exit the current frame, the last context is removed from the current
   * context list.
   */
  exitFrame() {
    if (this.contexts && this.contexts.length > 1)
      this.contexts = this.contexts.slice(), this.contexts.splice(-1), this.currentContextIds.shift();
    else
      throw new Error("Cannot exit frame, the context is empty");
  }
  /**
   * Enter the next iteration of a loop, the iteration id of last context is
   * increased.
   */
  nextIteration() {
    if (this.contexts && this.contexts.length > 0) {
      this.contexts = this.contexts.slice(), this.lastId++;
      const e = Object.assign({}, this.contexts[this.contexts.length - 1]);
      e.iterationId += 1, e.id = this.lastId, this.contexts.splice(-1, 1, e), this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
    } else
      throw new Error("Cannot increase frame iteration, the context is empty");
  }
  getWeight(e) {
    return this.weightMap[e];
  }
  addTensorArray(e) {
    this.tensorArrayMap[e.id] = e;
  }
  getTensorArray(e) {
    return this.tensorArrayMap[e];
  }
  addTensorList(e) {
    this.tensorListMap[e.id] = e;
  }
  getTensorList(e) {
    return this.tensorListMap[e];
  }
  dispose(e) {
    for (const t in this.tensorArrayMap)
      this.tensorArrayMap[t].clearAndClose(e);
    for (const t in this.tensorListMap)
      this.tensorListMap[t].clearAndClose(e);
  }
};
function Gt2(s, e, t, a) {
  const r = /* @__PURE__ */ new Set(), n = [];
  let u = null, o = null;
  const l = /* @__PURE__ */ new Set(), p = new Set(Object.keys(s).map((d) => $6(d)[0]));
  a = a || [];
  const m = new Set(a.map((d) => $6(d.name)[0])), c = [...e];
  for (; c.length > 0; ) {
    const d = c.pop();
    if ((G6(d) || Ab2(d) || Eb2(d)) && u == null && (u = d, o = u.children.map((h) => h.name).filter((h) => r.has(h))), r.add(d.name), t[d.name] == null && !p.has(d.name) && !m.has(d.name)) {
      if (d.inputs.length === 0) {
        n.push(d.name);
        continue;
      }
      d.inputs.forEach((h) => {
        l.has(h.name) || (l.add(h.name), c.push(h));
      });
    }
  }
  return { inputs: s, outputs: e, usedNodes: r, missingInputs: n, dynamicNode: u, syncInputs: o };
}
function Nb2(s, e) {
  const { usedNodes: t, inputs: a } = e, r = Object.keys(a).map((f) => $6(f)[0]).map((f) => s.nodes[f]), n = s.initNodes || [], u = (f) => t.has(typeof f == "string" ? f : f.name);
  function o(f) {
    return [...new Map(f.map((b) => [b.name, b])).values()];
  }
  const l = o([
    ...r,
    ...s.weights,
    ...n
  ]).filter(u), p = o([
    ...l,
    ...Object.values(s.nodes)
  ]).filter(u), m = new Map(p.map((f) => [f.name, f])), c = {};
  for (const f of p) {
    c[f.name] = c[f.name] || 0;
    for (const b of f.children)
      u(b) || (c[b.name] = Number.POSITIVE_INFINITY), c[b.name] = (c[b.name] || 0) + 1;
  }
  const d = Object.entries(c).filter(([, f]) => f === 0).map(([f]) => f), h = [...d];
  for (; d.length > 0; ) {
    const f = d.pop(), b = m.get(f);
    for (const O of b.children.filter(u))
      --c[O.name] === 0 && (h.push(O.name), d.push(O.name));
  }
  const N = h.map((f) => m.get(f)), g = wb2(N, l);
  return Tb2(g, l), g;
}
function wb2(s, e) {
  const t = new Map(s.map((u) => [u.name, u])), a = e.map((u) => u.name), r = new Set(a);
  for (; a.length > 0; ) {
    const u = a.pop(), o = t.get(u);
    for (const l of o.children)
      !t.has(l.name) || r.has(l.name) || (r.add(l.name), a.push(l.name));
  }
  return s.filter((u) => r.has(u.name));
}
var ge2 = class extends Error {
  constructor(e) {
    super(`NodesExecutionOrderError: ${e}`);
  }
};
function Tb2(s, e) {
  const t = new Map(s.map((o, l) => [o.name, l])), a = new Set(e.map((o) => o.name)), r = (o) => a.has(typeof o == "string" ? o : o.name), n = new Set(s.map((o) => o.name)), u = (o) => n.has(typeof o == "string" ? o : o.name);
  for (const o of s) {
    for (const l of o.children.filter(u)) {
      if (!t.has(l.name))
        throw new ge2(`Child ${l.name} of node ${o.name} is unreachable.`);
      if (t.get(o.name) > t.get(l.name))
        throw new ge2(`Node ${o.name} is scheduled to run after its child ${l.name}.`);
    }
    if (!r(o))
      for (const l of o.inputs) {
        if (!t.has(l.name))
          throw new ge2(`Input ${l.name} of node ${o.name} is unreachable.`);
        if (t.get(l.name) > t.get(o.name))
          throw new ge2(`Node ${o.name} is scheduled to run before its input ${l.name}.`);
      }
  }
}
function Sb2(s) {
  const e = new Map(s.map((o, l) => [o.name, l])), t = Number.MAX_SAFE_INTEGER, a = s.map((o, l) => G6(o) ? t : l), r = (o) => {
    const l = a[e.get(o.name)];
    return l ?? -1;
  }, n = s.map((o, l) => o.children.map(r).reduce((p, m) => Math.max(p, m), a[l])), u = /* @__PURE__ */ new Map();
  for (let o = 0; o < s.length; ++o) {
    const l = n[o];
    if (l === t)
      continue;
    const p = s[o], m = s[l];
    u.has(m.name) || u.set(m.name, []), u.get(m.name).push(p);
  }
  return u;
}
var vb2 = /* @__PURE__ */ new Set([
  "Switch",
  "Merge",
  "Enter",
  "Exit",
  "NextIteration",
  "StatelessIf",
  "StatelessWhile",
  "if",
  "While"
]);
var Ob2 = /* @__PURE__ */ new Set([
  "NonMaxSuppressionV2",
  "NonMaxSuppressionV3",
  "NonMaxSuppressionV5",
  "Where"
]);
var _b2 = /* @__PURE__ */ new Set([
  "HashTable",
  "HashTableV2",
  "LookupTableImport",
  "LookupTableImportV2",
  "LookupTableFind",
  "LookupTableFindV2",
  "LookupTableSize",
  "LookupTableSizeV2"
]);
function G6(s) {
  return vb2.has(s.op);
}
function Ab2(s) {
  return Ob2.has(s.op);
}
function Eb2(s) {
  return _b2.has(s.op);
}
var Ie2 = class _Ie {
  get weightIds() {
    return this.parent ? this.parent.weightIds : this._weightIds;
  }
  get functionExecutorMap() {
    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
  }
  get weightMap() {
    return this.parent ? this.parent.weightMap : this._weightMap;
  }
  set weightMap(e) {
    const t = Object.keys(e).map((a) => e[a].map((r) => r.id));
    this._weightIds = [].concat(...t), this._weightMap = e;
  }
  /**
   * Set `ResourceManager` shared by executors of a model.
   * @param resourceManager: `ResourceManager` of the `GraphModel`.
   */
  set resourceManager(e) {
    this._resourceManager = e;
  }
  get inputs() {
    return this._inputs.map((e) => ({
      name: e.name,
      shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,
      dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0
    }));
  }
  get outputs() {
    return this._outputs.map((e) => ({
      name: e.name,
      shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,
      dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0
    }));
  }
  get inputNodes() {
    return this._inputs.map((e) => e.signatureKey || e.name);
  }
  get outputNodes() {
    return this._outputs.map((e) => {
      const t = e.signatureKey || e.name;
      return e.defaultOutput ? `${t}:${e.defaultOutput}` : t;
    });
  }
  get functions() {
    return Object.keys(this._functions).reduce((e, t) => (e[t] = this._functions[t].signature, e), {});
  }
  /**
   *
   * @param graph Graph the model or function graph to be executed.
   * @param parent When building function exector you need to set the parent
   * executor. Since the weights and function executor maps are set at parant
   * level, that function executor can access the function maps and weight maps
   * through the parent.
   */
  constructor(e, t) {
    this.graph = e, this.parent = t, this.compiledMap = /* @__PURE__ */ new Map(), this.parseNodeNameCache = /* @__PURE__ */ new Map(), this._weightMap = {}, this.SEPARATOR = ",", this._functions = {}, this._functionExecutorMap = {}, this.keepIntermediateTensors = false, this._outputs = e.outputs, this._inputs = e.inputs, this._initNodes = e.initNodes, this._signature = e.signature, this._functions = e.functions, e.functions != null && Object.keys(e.functions).forEach((a) => {
      this._functionExecutorMap[a] = new _Ie(e.functions[a], this);
    });
  }
  getCompilationKey(e, t) {
    const a = e.map((n) => n.name).sort(), r = t.map((n) => n.name).sort();
    return a.join(this.SEPARATOR) + "--" + r.join(this.SEPARATOR);
  }
  /**
   * Compiles the inference graph and returns the minimal set of nodes that are
   * required for execution, in the correct execution order.
   * @returns {Object} compilation The compile result.
   * @returns {Node[]} compilation.orderedNodes Nodes in the correct execution
   *     order.
   * @returns {Map<string, Node[]>} compilation.nodeLiveUntilMap A map from node
   *     to disposable nodes after its execution. That is, for a node `x`,
   *     `nodeLiveUntilMap[x]` indicates all nodes whose intermediate
   *     tensors should be disposed after `x` is executed.
   */
  compile(e, t) {
    const a = Gt2(e, t, this.weightMap, this._initNodes), { missingInputs: r, dynamicNode: n, syncInputs: u } = a;
    if (n != null)
      throw new Error(`This execution contains the node '${n.name}', which has the dynamic op '${n.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${u}]`);
    if (r.length > 0) {
      const p = t.map((c) => c.name), m = Object.keys(e);
      throw new Error(`Cannot compute the outputs [${p}] from the provided inputs [${m}]. Missing the following inputs: [${r}]`);
    }
    const o = Nb2(this.graph, a), l = Sb2(o);
    return { orderedNodes: o, nodeLiveUntilMap: l };
  }
  cloneAndKeepTensor(e) {
    if (e == null)
      return null;
    const t = e.clone();
    return hn(t), t;
  }
  cloneTensorList(e) {
    return e ? e.map((a) => this.cloneAndKeepTensor(a)) : null;
  }
  cloneTensorMap(e) {
    return Object.fromEntries(Object.entries(e).map(([t, a]) => [t, this.cloneTensorList(a)]));
  }
  /**
   * Executes the inference for given input tensors.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs Optional. output node name from the Tensorflow model, if
   * no outputs are specified, the default outputs of the model would be used.
   * You can inspect intermediate nodes of the model by adding them to the
   * outputs array.
   */
  execute(e, t) {
    this.disposeIntermediateTensors(), e = this.mapInputs(e);
    const a = Object.keys(e).sort();
    this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t);
    const r = a.map((d) => this.graph.nodes[$6(d)[0]]), n = t.map((d) => $6(d)[0]), u = new Set(n);
    let o = n.map((d) => this.graph.nodes[d]);
    o.length === 0 && (o = this._outputs);
    const l = this.getCompilationKey(r, o);
    let p = this.compiledMap.get(l);
    p == null && (p = this.compile(e, o), this.compiledMap.set(l, p));
    try {
      this.keepIntermediateTensors = F().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (d) {
      this.keepIntermediateTensors = false, console.warn(d.message);
    }
    const m = {}, c = {};
    return D(() => {
      const d = new qt2(this.weightMap, m, c, this.functionExecutorMap, this.parseNodeNameCache), h = Object.assign({}, this.weightMap);
      this.keepIntermediateTensors && (this.clonedTensorsMap = this.cloneTensorMap(this.weightMap)), Object.keys(e).forEach((b) => {
        const [O, _6] = $6(b, d), T6 = [];
        T6[_6] = e[b], h[O] = T6, this.keepIntermediateTensors && (this.clonedTensorsMap[O] = this.cloneTensorList(T6));
      });
      const N = this.getFrozenTensorIds(h), { orderedNodes: g, nodeLiveUntilMap: f } = p;
      for (const b of g) {
        if (h[b.name])
          continue;
        const O = Ut2(b, h, d, this._resourceManager);
        if (Ci(O))
          throw new Error(`The execution of the op '${b.op}' returned a promise. Please use model.executeAsync() instead.`);
        h[b.name] = O, this.keepIntermediateTensors && (this.clonedTensorsMap[b.name] = this.cloneTensorList(O)), this.checkTensorForDisposalWithNodeLiveUntilInfo(b, h, d, N, u, f.get(b.name));
      }
      return this.parent == null && d.dispose(N), t.map((b) => E6(b, h, d));
    });
  }
  getFrozenTensorIds(e) {
    const t = [].concat.apply([], Object.keys(e).map((a) => e[a]).map((a) => a.map((r) => r.id)));
    return new Set(t);
  }
  checkTensorForDisposal(e, t, a, r, n, u, o) {
    if (!(G6(t) || u.has(e))) {
      for (const l of a[e])
        l != null && (o[l.id] = (o[l.id] || 0) + t.children.length);
      for (const l of t.inputs) {
        if (G6(l))
          continue;
        const p = Rt2(l.name, a, r);
        if (p != null)
          for (const m of p) {
            if (!m || m.kept || n.has(m.id))
              continue;
            const c = o[m.id];
            c === 1 ? (m.dispose(), delete o[m.id]) : c != null && o[m.id]--;
          }
      }
    }
  }
  checkTensorForDisposalWithNodeLiveUntilInfo(e, t, a, r, n, u) {
    function o(l) {
      return G6(l) || n.has(l.name);
    }
    if (!(G6(e) || u == null))
      for (const l of u) {
        if (o(l))
          continue;
        const p = Rt2(l.name, t, a);
        for (const m of p)
          !m || m.kept || r.has(m.id) || m.dispose();
      }
  }
  /**
   * Executes the inference for given input tensors in Async fashion.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs output node name from the Tensorflow model, if no outputs
   * are specified, the default outputs of the model would be used. You can
   * inspect intermediate nodes of the model by adding them to the outputs
   * array.
   */
  async executeAsync(e, t) {
    return this._executeAsync(e, t);
  }
  disposeIntermediateTensors() {
    this.clonedTensorsMap && (Object.values(this.clonedTensorsMap).forEach((e) => {
      for (const t of e)
        t && !t.isDisposed && t.dispose();
    }), this.clonedTensorsMap = null);
  }
  getIntermediateTensors() {
    return this.clonedTensorsMap;
  }
  /**
   * Executes the inference for given input tensors in Async fashion.
   * @param inputs Tensor map for the model inputs, keyed by the input node
   * names.
   * @param outputs Optional. output node name from the Tensorflow model,
   * if no outputs are specified, the default outputs of the model would be
   * used. You can inspect intermediate nodes of the model by adding them to
   * the outputs array.
   * @param isFunctionExecution Optional. Flag for executing a function.
   * @param tensorArrayMap Optional, global TensorArray map by id. Used for
   * function execution.
   * @param tensorArrayMap Optinal global TensorList map by id. Used for
   * function execution.
   */
  async _executeAsync(e, t, a = false, r = {}, n = {}) {
    this.disposeIntermediateTensors(), a || (e = this.mapInputs(e), this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t));
    try {
      this.keepIntermediateTensors = F().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (d) {
      this.keepIntermediateTensors = false, console.warn(d.message);
    }
    const u = new qt2(this.weightMap, r, n, this.functionExecutorMap, this.parseNodeNameCache);
    this.keepIntermediateTensors && (this.clonedTensorsMap = this.cloneTensorMap(this.weightMap));
    const o = await this.executeWithControlFlow(e, u, t, a), l = t.map((d) => E6(d, o, u)), p = l.map((d) => d.id), m = Object.keys(e).map((d) => e[d].id), c = /* @__PURE__ */ new Set([...p, ...m, ...this.weightIds]);
    return Object.values(o).forEach((d) => {
      d.forEach((h) => {
        h && !h.isDisposed && !c.has(h.id) && h.dispose();
      });
    }), this.parent == null && u.dispose(c), l;
  }
  async executeFunctionAsync(e, t, a) {
    const r = e.reduce((n, u, o) => (n[this.inputs[o].name] = u, n), {});
    return this._executeAsync(r, this.outputNodes, true, t, a);
  }
  /**
   * When there are control flow nodes in the graph, the graph execution use
   * ExecutionContext to keep track of the frames and loop iterators.
   * @param inputs placeholder tensors for the graph.
   * @param context the execution context object for current execution.
   * @param outputNames Optional. output node name from the Tensorflow model,
   * if no outputs are specified, the default outputs of the model would be
   * used. You can inspect intermediate nodes of the model by adding them to
   * the outputs array.
   * @param isFunctionExecution Flag for executing a function.
   */
  async executeWithControlFlow(e, t, a, r) {
    const n = Object.keys(e), u = n.map((T6) => this.graph.nodes[$6(T6)[0]]), o = a.map((T6) => $6(T6)[0]), l = new Set(o);
    let p = o.map((T6) => this.graph.nodes[T6]);
    p.length === 0 && (p = this._outputs);
    const { usedNodes: m, missingInputs: c, dynamicNode: d, syncInputs: h } = Gt2(e, p, this.weightMap, this._initNodes), N = [
      ...u,
      ...this.graph.weights,
      ...this._initNodes || []
    ].map((T6) => ({ node: T6, contexts: t.currentContext })), g = Object.assign({}, this.weightMap);
    Object.keys(e).forEach((T6) => {
      const [I, D6] = $6(T6), C6 = [];
      C6[D6] = e[T6], g[I] = C6;
    });
    const f = {}, b = this.getFrozenTensorIds(g), O = {};
    for (; N.length > 0; ) {
      const T6 = this.processStack(u, N, t, g, O, b, l, f, m);
      await Promise.all(T6);
    }
    d == null && !r && console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");
    const _6 = p.filter((T6) => !G6(T6) && !E6(T6.name, g, t)).map((T6) => T6.name);
    if (_6.length > 0) {
      let T6 = "";
      throw d != null && (T6 = `Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${h}]`), new Error(`Cannot compute the outputs [${_6}] from the provided inputs [${n}]. Consider providing the following inputs: [${c}]. ${T6}`);
    }
    return g;
  }
  processStack(e, t, a, r, n, u, o, l, p) {
    const m = [];
    for (; t.length > 0; ) {
      const c = t.pop();
      a.currentContext = c.contexts;
      let d = "";
      if (c.node.op === "Enter" && i("isConstant", c.node, r, a) && ([d] = B(c.node.name, a)), r[c.node.name] == null) {
        const h = Ut2(c.node, r, a, this._resourceManager);
        d || ([d] = B(c.node.name, a));
        const N = a.currentContext;
        Ci(h) ? m.push(h.then((g) => (r[d] = g, this.keepIntermediateTensors && (this.clonedTensorsMap[d] = this.cloneTensorList(g)), a.currentContext = N, this.checkTensorForDisposal(d, c.node, r, a, u, o, l), this.processChildNodes(c.node, t, a, r, n, p), g))) : (r[d] = h, this.keepIntermediateTensors && (this.clonedTensorsMap[d] = this.cloneTensorList(h)), this.checkTensorForDisposal(d, c.node, r, a, u, o, l), this.processChildNodes(c.node, t, a, r, n, p));
      } else
        this.processChildNodes(c.node, t, a, r, n, p);
    }
    return m;
  }
  processChildNodes(e, t, a, r, n, u) {
    e.children.forEach((o) => {
      const [l] = B(o.name, a);
      n[l] || !u.has(o.name) || (o.op === "Merge" ? o.inputNames.some((p) => !!E6(p, r, a)) && (n[l] = true, t.push({ contexts: a.currentContext, node: o })) : o.inputNames.every((p) => !!E6(p, r, a)) && (n[l] = true, t.push({ contexts: a.currentContext, node: o })));
    });
  }
  /**
   * Releases the memory used by the weight tensors.
   */
  dispose() {
    Object.keys(this.weightMap).forEach((e) => this.weightMap[e].forEach((t) => t.dispose()));
  }
  checkInputShapeAndType(e) {
    Object.keys(e).forEach((t) => {
      const a = e[t], [r] = $6(t), n = this.graph.nodes[r];
      if (n.attrParams.shape && n.attrParams.shape.value) {
        const u = n.attrParams.shape.value, o = u.length === a.shape.length && a.shape.every((l, p) => u[p] === -1 || u[p] === l);
        C(o, () => `The shape of dict['${n.name}'] provided in model.execute(dict) must be [${u}], but was [${a.shape}]`);
      }
      n.attrParams.dtype && n.attrParams.dtype.value && C(a.dtype === n.attrParams.dtype.value, () => `The dtype of dict['${n.name}'] provided in model.execute(dict) must be ${n.attrParams.dtype.value}, but was ${a.dtype}`);
    });
  }
  mapInputs(e) {
    var t, a;
    const r = {};
    for (const n in e) {
      const u = (a = (t = this._signature) === null || t === void 0 ? void 0 : t.inputs) === null || a === void 0 ? void 0 : a[n];
      u != null ? r[u.name] = e[n] : r[n] = e[n];
    }
    return r;
  }
  checkInputs(e) {
    const t = Object.keys(e).filter((a) => {
      const [r] = $6(a);
      return this.graph.nodes[r] == null;
    });
    if (t.length > 0)
      throw new Error(`The dict provided in model.execute(dict) has keys: [${t}] that are not part of graph`);
  }
  mapOutputs(e) {
    return e.map((t) => {
      var a, r;
      const n = (r = (a = this._signature) === null || a === void 0 ? void 0 : a.outputs) === null || r === void 0 ? void 0 : r[t];
      return n != null ? n.name : t;
    }, {});
  }
  checkOutputs(e) {
    e.forEach((t) => {
      const [a] = $6(t);
      if (!this.graph.nodes[a])
        throw new Error(`The output '${t}' is not found in the graph`);
    });
  }
};
var kb2 = class {
  constructor(e = {}, t = {}) {
    this.hashTableNameToHandle = e, this.hashTableMap = t;
  }
  /**
   * Register a `HashTable` in the resource manager.
   *
   * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,
   * where id is the table handle tensor's id.
   *
   * @param name Op node name that creates the `HashTable`.
   * @param hashTable The `HashTable` to be added to resource manager.
   */
  addHashTable(e, t) {
    this.hashTableNameToHandle[e] = t.handle, this.hashTableMap[t.id] = t;
  }
  /**
   * Get the table handle by node name.
   * @param name Op node name that creates the `HashTable`. This name is also
   *     used in the inputs list of lookup and import `HashTable` ops.
   */
  getHashTableHandleByName(e) {
    return this.hashTableNameToHandle[e];
  }
  /**
   * Get the actual `HashTable` by its handle tensor's id.
   * @param id The id of the handle tensor.
   */
  getHashTableById(e) {
    return this.hashTableMap[e];
  }
  /**
   * Dispose `ResourceManager`, including its hashTables and tensors in them.
   */
  dispose() {
    for (const e in this.hashTableMap)
      this.hashTableMap[e].clearAndClose(), delete this.hashTableMap[e];
    for (const e in this.hashTableNameToHandle)
      this.hashTableNameToHandle[e].dispose(), delete this.hashTableNameToHandle[e];
  }
};
var Ib2 = "?tfjs-format=file";
var $b2 = "model.json";
var Et = class {
  // Returns the version information for the tensorflow model GraphDef.
  get modelVersion() {
    return this.version;
  }
  get inputNodes() {
    return this.executor.inputNodes;
  }
  get outputNodes() {
    return this.executor.outputNodes;
  }
  get inputs() {
    return this.executor.inputs;
  }
  get outputs() {
    return this.executor.outputs;
  }
  get weights() {
    return this.executor.weightMap;
  }
  get metadata() {
    return this.artifacts.userDefinedMetadata;
  }
  get modelSignature() {
    return this.signature;
  }
  get modelStructuredOutputKeys() {
    return this.structuredOutputKeys;
  }
  /**
   * @param modelUrl url for the model, or an `io.IOHandler`.
   * @param weightManifestUrl url for the weight file generated by
   * scripts/convert.py script.
   * @param requestOption options for Request, which allows to send credentials
   * and custom headers.
   * @param onProgress Optional, progress callback function, fired periodically
   * before the load is completed.
   */
  constructor(e, t = {}, a = Tt2) {
    this.modelUrl = e, this.loadOptions = t, this.version = "n/a", this.io = a, t == null && (this.loadOptions = {}), this.resourceManager = new kb2();
  }
  findIOHandler() {
    const e = this.modelUrl;
    if (e.load != null)
      this.handler = e;
    else if (this.loadOptions.requestInit != null)
      this.handler = this.io.browserHTTPRequest(e, this.loadOptions);
    else {
      const t = this.io.getLoadHandlers(e, this.loadOptions);
      if (t.length === 0)
        t.push(this.io.browserHTTPRequest(e, this.loadOptions));
      else if (t.length > 1)
        throw new Error(`Found more than one (${t.length}) load handlers for URL '${[e]}'`);
      this.handler = t[0];
    }
  }
  /**
   * Loads the model and weight files, construct the in memory weight map and
   * compile the inference graph.
   */
  load() {
    if (this.findIOHandler(), this.handler.load == null)
      throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
    const e = this.handler.load();
    return Ci(e) ? e.then((t) => t.getWeightStream == null ? this.loadSync(t) : this.loadStreaming(t)) : this.loadSync(e);
  }
  /**
   * Synchronously construct the in memory weight map and
   * compile the inference graph.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  loadSync(e) {
    const t = this.io.decodeWeights(e.weightData, e.weightSpecs);
    return this.loadWithWeightMap(e, t);
  }
  async loadStreaming(e) {
    if (e.getWeightStream == null)
      throw new Error("Model artifacts missing streamWeights function");
    const t = await hQ(e.getWeightStream(), e.weightSpecs);
    return this.loadWithWeightMap(e, t);
  }
  loadWithWeightMap(e, t) {
    this.artifacts = e;
    const a = this.artifacts.modelTopology;
    let r = this.artifacts.signature;
    if (this.artifacts.userDefinedMetadata != null) {
      const n = this.artifacts.userDefinedMetadata;
      n.signature != null && (r = n.signature), n.structuredOutputKeys != null && (this.structuredOutputKeys = n.structuredOutputKeys);
    }
    if (this.signature = r, this.version = `${a.versions.producer}.${a.versions.minConsumer}`, this.executor = new Ie2(jt2.Instance.transformGraph(a, this.signature)), this.executor.weightMap = this.convertTensorMapToTensorsMap(t), this.executor.resourceManager = this.resourceManager, e.modelInitializer != null && e.modelInitializer.node != null) {
      const n = jt2.Instance.transformGraph(e.modelInitializer);
      this.initializer = new Ie2(n), this.initializer.weightMap = this.executor.weightMap, this.initializer.resourceManager = this.resourceManager, this.initializerSignature = e.initializerSignature;
    }
    return true;
  }
  /**
   * Save the configuration and/or weights of the GraphModel.
   *
   * An `IOHandler` is an object that has a `save` method of the proper
   * signature defined. The `save` method manages the storing or
   * transmission of serialized data ("artifacts") that represent the
   * model's topology and weights onto or via a specific medium, such as
   * file downloads, local storage, IndexedDB in the web browser and HTTP
   * requests to a server. TensorFlow.js provides `IOHandler`
   * implementations for a number of frequently used saving mediums, such as
   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`
   * for more details.
   *
   * This method also allows you to refer to certain types of `IOHandler`s
   * as URL-like string shortcuts, such as 'localstorage://' and
   * 'indexeddb://'.
   *
   * Example 1: Save `model`'s topology and weights to browser [local
   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);
   * then load it back.
   *
   * ```js
   * const modelUrl =
   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';
   * const model = await tf.loadGraphModel(modelUrl);
   * const zeros = tf.zeros([1, 224, 224, 3]);
   * model.predict(zeros).print();
   *
   * const saveResults = await model.save('localstorage://my-model-1');
   *
   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');
   * console.log('Prediction from loaded model:');
   * model.predict(zeros).print();
   * ```
   *
   * @param handlerOrURL An instance of `IOHandler` or a URL-like,
   * scheme-based string shortcut for `IOHandler`.
   * @param config Options for saving the model.
   * @returns A `Promise` of `SaveResult`, which summarizes the result of
   * the saving, such as byte sizes of the saved artifacts for the model's
   *   topology and weight values.
   *
   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
   */
  async save(e, t) {
    if (typeof e == "string") {
      const a = this.io.getSaveHandlers(e);
      if (a.length === 0)
        throw new Error(`Cannot find any save handlers for URL '${e}'`);
      if (a.length > 1)
        throw new Error(`Found more than one (${a.length}) save handlers for URL '${e}'`);
      e = a[0];
    }
    if (e.save == null)
      throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    return e.save(this.artifacts);
  }
  addStructuredOutputNames(e) {
    if (this.structuredOutputKeys) {
      const t = e instanceof Mt ? [e] : e, a = {};
      return t.forEach((r, n) => a[this.structuredOutputKeys[n]] = r), a;
    }
    return e;
  }
  /**
   * Execute the inference for the input tensors.
   *
   * @param input The input tensors, when there is single input for the model,
   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,
   * inputs params should be in either `tf.Tensor`[] if the input order is
   * fixed, or otherwise NamedTensorMap format.
   *
   * For model with multiple inputs, we recommend you use NamedTensorMap as the
   * input type, if you use `tf.Tensor`[], the order of the array needs to
   * follow the
   * order of inputNodes array. @see {@link GraphModel.inputNodes}
   *
   * You can also feed any intermediate nodes using the NamedTensorMap as the
   * input type. For example, given the graph
   *    InputNode => Intermediate => OutputNode,
   * you can execute the subgraph Intermediate => OutputNode by calling
   *    model.execute('IntermediateNode' : tf.tensor(...));
   *
   * This is useful for models that uses tf.dynamic_rnn, where the intermediate
   * state needs to be fed manually.
   *
   * For batch inference execution, the tensors for each input need to be
   * concatenated together. For example with mobilenet, the required input shape
   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
   * If we are provide a batched data of 100 images, the input tensor should be
   * in the shape of [100, 244, 244, 3].
   *
   * @param config Prediction configuration for specifying the batch size.
   * Currently the batch size option is ignored for graph model.
   *
   * @returns Inference result tensors. If the model is converted and it
   * originally had structured_outputs in tensorflow, then a NamedTensorMap
   * will be returned matching the structured_outputs. If no structured_outputs
   * are present, the output will be single `tf.Tensor` if the model has single
   * output node, otherwise Tensor[].
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  predict(e, t) {
    const a = this.execute(e, this.outputNodes);
    return this.addStructuredOutputNames(a);
  }
  /**
   * Execute the inference for the input tensors in async fashion, use this
   * method when your model contains control flow ops.
   *
   * @param input The input tensors, when there is single input for the model,
   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,
   * inputs params should be in either `tf.Tensor`[] if the input order is
   * fixed, or otherwise NamedTensorMap format.
   *
   * For model with multiple inputs, we recommend you use NamedTensorMap as the
   * input type, if you use `tf.Tensor`[], the order of the array needs to
   * follow the
   * order of inputNodes array. @see {@link GraphModel.inputNodes}
   *
   * You can also feed any intermediate nodes using the NamedTensorMap as the
   * input type. For example, given the graph
   *    InputNode => Intermediate => OutputNode,
   * you can execute the subgraph Intermediate => OutputNode by calling
   *    model.execute('IntermediateNode' : tf.tensor(...));
   *
   * This is useful for models that uses tf.dynamic_rnn, where the intermediate
   * state needs to be fed manually.
   *
   * For batch inference execution, the tensors for each input need to be
   * concatenated together. For example with mobilenet, the required input shape
   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].
   * If we are provide a batched data of 100 images, the input tensor should be
   * in the shape of [100, 244, 244, 3].
   *
   * @param config Prediction configuration for specifying the batch size.
   * Currently the batch size option is ignored for graph model.
   *
   * @returns A Promise of inference result tensors. If the model is converted
   * and it originally had structured_outputs in tensorflow, then a
   * NamedTensorMap will be returned matching the structured_outputs. If no
   * structured_outputs are present, the output will be single `tf.Tensor` if
   * the model has single output node, otherwise Tensor[].
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async predictAsync(e, t) {
    const a = await this.executeAsync(e, this.outputNodes);
    return this.addStructuredOutputNames(a);
  }
  normalizeInputs(e) {
    var t;
    if (!(e instanceof Mt) && !Array.isArray(e)) {
      const n = (t = this.signature) === null || t === void 0 ? void 0 : t.inputs;
      if (n != null)
        for (const u in n) {
          const o = n[u];
          o.resourceId != null && (e[u] = this.resourceIdToCapturedInput[o.resourceId]);
        }
      return e;
    }
    e = Array.isArray(e) ? e : [e];
    const a = Object.keys(this.resourceIdToCapturedInput).length;
    if (e.length + a !== this.inputNodes.length)
      throw new Error(`Input tensor count mismatch, the graph model has ${this.inputNodes.length - a} non-resource placeholders, while there are ${e.length} input tensors provided.`);
    let r = 0;
    return this.inputNodes.reduce((n, u) => {
      var o, l, p;
      const m = (p = (l = (o = this.signature) === null || o === void 0 ? void 0 : o.inputs) === null || l === void 0 ? void 0 : l[u]) === null || p === void 0 ? void 0 : p.resourceId;
      return m != null ? n[u] = this.resourceIdToCapturedInput[m] : n[u] = e[r++], n;
    }, {});
  }
  normalizeOutputs(e) {
    return e = e || this.outputNodes, Array.isArray(e) ? e : [e];
  }
  executeInitializerGraph() {
    return this.initializer == null ? [] : this.initializerSignature == null ? this.initializer.execute({}, []) : this.initializer.execute({}, Object.keys(this.initializerSignature.outputs));
  }
  async executeInitializerGraphAsync() {
    return this.initializer == null ? [] : this.initializerSignature == null ? this.initializer.executeAsync({}, []) : this.initializer.executeAsync({}, Object.keys(this.initializerSignature.outputs));
  }
  setResourceIdToCapturedInput(e) {
    if (this.resourceIdToCapturedInput = {}, this.initializerSignature) {
      const t = this.initializerSignature.outputs, a = Object.keys(t);
      for (let r = 0; r < a.length; r++) {
        const n = a[r], u = t[n];
        this.resourceIdToCapturedInput[u.resourceId] = e[r];
      }
    }
  }
  /**
   * Executes inference for the model for given input tensors.
   * @param inputs tensor, tensor array or tensor map of the inputs for the
   * model, keyed by the input node names.
   * @param outputs output node name from the TensorFlow model, if no
   * outputs are specified, the default outputs of the model would be used.
   * You can inspect intermediate nodes of the model by adding them to the
   * outputs array.
   *
   * @returns A single tensor if provided with a single output or no outputs
   * are provided and there is only one default output, otherwise return a
   * tensor array. The order of the tensor array is the same as the outputs
   * if provided, otherwise the order of outputNodes attribute of the model.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  execute(e, t) {
    this.resourceIdToCapturedInput == null && this.setResourceIdToCapturedInput(this.executeInitializerGraph()), e = this.normalizeInputs(e), t = this.normalizeOutputs(t);
    const a = this.executor.execute(e, t);
    return a.length > 1 ? a : a[0];
  }
  /**
   * Executes inference for the model for given input tensors in async
   * fashion, use this method when your model contains control flow ops.
   * @param inputs tensor, tensor array or tensor map of the inputs for the
   * model, keyed by the input node names.
   * @param outputs output node name from the TensorFlow model, if no outputs
   * are specified, the default outputs of the model would be used. You can
   * inspect intermediate nodes of the model by adding them to the outputs
   * array.
   *
   * @returns A Promise of single tensor if provided with a single output or
   * no outputs are provided and there is only one default output, otherwise
   * return a tensor map.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  async executeAsync(e, t) {
    this.resourceIdToCapturedInput == null && this.setResourceIdToCapturedInput(await this.executeInitializerGraphAsync()), e = this.normalizeInputs(e), t = this.normalizeOutputs(t);
    const a = await this.executor.executeAsync(e, t);
    return a.length > 1 ? a : a[0];
  }
  /**
   * Get intermediate tensors for model debugging mode (flag
   * KEEP_INTERMEDIATE_TENSORS is true).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  getIntermediateTensors() {
    return this.executor.getIntermediateTensors();
  }
  /**
   * Dispose intermediate tensors for model debugging mode (flag
   * KEEP_INTERMEDIATE_TENSORS is true).
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  disposeIntermediateTensors() {
    this.executor.disposeIntermediateTensors();
  }
  convertTensorMapToTensorsMap(e) {
    return Object.keys(e).reduce((t, a) => (t[a] = [e[a]], t), {});
  }
  /**
   * Releases the memory used by the weight tensors and resourceManager.
   *
   * @doc {heading: 'Models', subheading: 'Classes'}
   */
  dispose() {
    this.executor.dispose(), this.initializer && (this.initializer.dispose(), this.resourceIdToCapturedInput && xt(this.resourceIdToCapturedInput)), this.resourceManager.dispose();
  }
};
async function Db2(s, e = {}, t = Tt2) {
  if (s == null)
    throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
  e == null && (e = {}), e.fromTFHub && typeof s == "string" && (s = zb2(s));
  const a = new Et(s, e, t);
  return await a.load(), a;
}
function Cb2(s) {
  if (s == null)
    throw new Error("modelUrl in loadGraphModelSync() cannot be null. Please provide model artifacts or an IOHandler that loads the model");
  let e;
  if (s instanceof Array) {
    const [a, r] = s;
    if (!a)
      throw new Error("modelJSON must be the first element of the array");
    if (!r || !(r instanceof ArrayBuffer))
      throw new Error("An ArrayBuffer of weights must be the second element of the array");
    if (!("modelTopology" in a))
      throw new Error("Model JSON is missing 'modelTopology'");
    if (!("weightsManifest" in a))
      throw new Error("Model JSON is missing 'weightsManifest'");
    const n = km(a.weightsManifest), u = z2(a, n, r);
    e = Ee2(u);
  } else if ("load" in s)
    e = s;
  else if ("modelTopology" in s && "weightSpecs" in s && "weightData" in s)
    e = Ee2(s);
  else
    throw new Error("Unknown model format");
  const t = new Et(e);
  return t.load(), t;
}
function zb2(s) {
  return s.endsWith("/") || (s = s + "/"), `${s}${$b2}${Ib2}`;
}
var oi2 = "4.16.0";
var ui2 = class extends zf {
  /**
   * Create a `TextLineDataset`.
   *
   * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.
   */
  constructor(e) {
    super(), this.input = e;
  }
  async iterator() {
    return (await this.input.iterator()).decodeUTF8().split(`
`).map((r) => (r.endsWith("\r") && (r = r.slice(0, -1)), r));
  }
};
var be2 = '"';
var oe2 = Symbol("out");
var Kt2 = Symbol("field");
var Ne2 = Symbol("quote");
var Pe2 = Symbol("quoteafterquote");
var Jt = Symbol("quoteinquote");
var li2 = class extends zf {
  /**
   * Returns column names of the csv dataset. If `configuredColumnsOnly` is
   * true, return column names in `columnConfigs`. If `configuredColumnsOnly` is
   * false and `columnNames` is provided, `columnNames`. If
   * `configuredColumnsOnly` is false and `columnNames` is not provided, return
   * all column names parsed from the csv file. For example usage please go to
   * `tf.data.csv`.
   *
   * @doc {heading: 'Data', subheading: 'Classes'}
   */
  async columnNames() {
    return this.columnNamesValidated || await this.setColumnNames(), this.configuredColumnsOnly ? Object.keys(this.columnConfigs) : this.fullColumnNames;
  }
  /* 1) If `columnNames` is provided as string[], use this string[] as output
   * keys in corresponding order. The length must match the number of inferred
   * columns if `hasHeader` is true .
   * 2) If `columnNames` is not provided, parse header line as `columnNames` if
   * hasHeader is true. If `hasHeader` is false, throw an error.
   * 3) If `columnConfigs` is provided, all the keys in `columnConfigs` must
   * exist in parsed `columnNames`.
   */
  async setColumnNames() {
    const e = await this.maybeReadHeaderLine();
    if (!this.fullColumnNames && !e)
      throw new Error("Column names must be provided if there is no header line.");
    this.fullColumnNames && e && C(e.length === this.fullColumnNames.length, () => "The length of provided columnNames (" + this.fullColumnNames.length.toString() + ") does not match the length of the header line read from file (" + e.length.toString() + ")."), this.fullColumnNames || (this.fullColumnNames = e);
    const t = this.fullColumnNames.reduce((r, n) => (r[n] = r[n] + 1 || 1, r), {}), a = Object.keys(t).filter((r) => t[r] > 1);
    if (C(a.length === 0, () => "Duplicate column names found: " + a.toString()), this.columnConfigs) {
      for (const r of Object.keys(this.columnConfigs))
        if (this.fullColumnNames.indexOf(r) === -1)
          throw new Error('The key "' + r + '" provided in columnConfigs does not match any of the column names (' + this.fullColumnNames.toString() + ").");
    }
    this.columnNamesValidated = true;
  }
  async maybeReadHeaderLine() {
    if (this.hasHeader) {
      const t = await (await this.base.iterator()).next();
      if (t.done)
        throw new Error("No data was found for CSV parsing.");
      const a = t.value;
      return this.parseRow(a, false);
    } else
      return null;
  }
  /**
   * Create a `CSVDataset`.
   *
   * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.
   * @param csvConfig (Optional) A CSVConfig object that contains configurations
   *     of reading and decoding from CSV file(s).
   *
   *     hasHeader: (Optional) A boolean value that indicates whether the first
   *     row of provided CSV file is a header line with column names, and should
   *     not be included in the data. Defaults to `true`.
   *
   *     columnNames: (Optional) A list of strings that corresponds to
   *     the CSV column names, in order. If provided, it ignores the column
   *     names inferred from the header row. If not provided, infers the column
   *     names from the first row of the records. If hasHeader is false and
   *     columnNames is not provided, this method throws an error.
   *
   *     columnConfigs: (Optional) A dictionary whose key is column names, value
   *     is an object stating if this column is required, column's data type,
   *     default value, and if this column is label. If provided, keys must
   *     correspond to names provided in columnNames or inferred from the file
   *     header lines. If isLabel is true any column, returns an array of two
   *     items: the first item is a dict of features key/value pairs, the second
   *     item is a dict of labels key/value pairs. If no feature is marked as
   *     label, returns a dict of features only.
   *
   *     configuredColumnsOnly (Optional) If true, only columns provided in
   *     columnConfigs will be parsed and provided during iteration.
   *
   *     delimiter (Optional) The string used to parse each line of the input
   *     file. Defaults to `,`.
   */
  constructor(e, t) {
    super(), this.input = e, this.hasHeader = true, this.fullColumnNames = null, this.columnNamesValidated = false, this.columnConfigs = null, this.configuredColumnsOnly = false, this.delimiter = ",", this.delimWhitespace = false, this.base = new ui2(e), t || (t = {}), this.hasHeader = t.hasHeader !== false, this.fullColumnNames = t.columnNames, this.columnConfigs = t.columnConfigs, this.configuredColumnsOnly = t.configuredColumnsOnly, t.delimWhitespace ? (C(t.delimiter == null, () => "Delimiter should not be provided when delimWhitespace is true."), this.delimWhitespace = true, this.delimiter = " ") : this.delimiter = t.delimiter ? t.delimiter : ",";
  }
  async iterator() {
    this.columnNamesValidated || await this.setColumnNames();
    let e = await this.base.iterator();
    return this.hasHeader && (e = e.skip(1)), e.map((t) => this.makeDataElement(t));
  }
  makeDataElement(e) {
    const t = this.parseRow(e), a = {}, r = {};
    for (let n = 0; n < this.fullColumnNames.length; n++) {
      const u = this.fullColumnNames[n], o = this.columnConfigs ? this.columnConfigs[u] : null;
      if (!(this.configuredColumnsOnly && !o)) {
        const l = t[n];
        let p = null;
        if (l === "")
          if (o && o.default !== void 0)
            p = o.default;
          else {
            if (o && (o.required || o.isLabel))
              throw new Error(`Required column ${u} is empty in this line: ${e}`);
            p = void 0;
          }
        else {
          const m = Number(l);
          if (isNaN(m))
            o && o.dtype === "bool" ? p = this.getBoolean(l) : p = l;
          else if (!o || !o.dtype)
            p = m;
          else
            switch (o.dtype) {
              case "float32":
                p = m;
                break;
              case "int32":
                p = Math.floor(m);
                break;
              case "bool":
                p = this.getBoolean(l);
                break;
              default:
                p = m;
            }
        }
        o && o.isLabel ? r[u] = p : a[u] = p;
      }
    }
    return Object.keys(r).length === 0 ? a : { xs: a, ys: r };
  }
  getBoolean(e) {
    return e === "1" || e.toLowerCase() === "true" ? 1 : 0;
  }
  // adapted from https://beta.observablehq.com/@mbostock/streaming-csv
  parseRow(e, t = true) {
    const a = [];
    let r = 0;
    const n = e.length;
    let u = oe2;
    for (let o = 0; o < n; o++)
      switch (u) {
        case oe2:
          switch (e.charAt(o)) {
            case be2:
              r = o + 1, u = Ne2;
              break;
            case this.delimiter:
              if (r = o + 1, this.delimiter === " " && this.delimWhitespace)
                break;
              a.push(""), u = oe2;
              break;
            default:
              u = Kt2, r = o;
              break;
          }
          break;
        case Kt2:
          switch (e.charAt(o)) {
            case this.delimiter:
              a.push(e.substring(r, o)), u = oe2, r = o + 1;
              break;
          }
          break;
        case Ne2:
          switch (e.charAt(o)) {
            case be2:
              u = Pe2;
              break;
          }
          break;
        case Pe2:
          switch (e.charAt(o)) {
            case this.delimiter:
              a.push(e.substring(r, o - 1)), u = oe2, r = o + 1;
              break;
            case be2:
              u = Ne2;
              break;
            default:
              u = Jt;
              break;
          }
          break;
        case Jt:
          switch (e.charAt(o)) {
            case be2:
              u = Ne2;
              break;
          }
          break;
      }
    if (u === Pe2 ? a.push(e.substring(r, n - 1)) : a.push(e.substring(r)), t && a.length !== this.fullColumnNames.length)
      throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${a}`);
    return a;
  }
};
var kt2 = class _kt extends He {
  constructor(e) {
    super(), this.microphoneConfig = e, this.isClosed = false, this.fftSize = e.fftSize || 1024;
    const t = Math.log2(this.fftSize);
    if (this.fftSize < 0 || t < 4 || t > 14 || !Number.isInteger(t))
      throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);
    if (this.numFrames = e.numFramesPerSpectrogram || 43, this.sampleRateHz = e.sampleRateHz, this.columnTruncateLength = e.columnTruncateLength || this.fftSize, this.audioTrackConstraints = e.audioTrackConstraints, this.smoothingTimeConstant = e.smoothingTimeConstant || 0, this.includeSpectrogram = e.includeSpectrogram !== false, this.includeWaveform = e.includeWaveform === true, !this.includeSpectrogram && !this.includeWaveform)
      throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.");
  }
  summary() {
    return "microphone";
  }
  // Construct a MicrophoneIterator and start the audio stream.
  static async create(e = {}) {
    if (!F().get("IS_BROWSER"))
      throw new Error("microphone API is only supported in browser environment.");
    const t = new _kt(e);
    return await t.start(), t;
  }
  // Start the audio stream and FFT.
  async start() {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: this.audioTrackConstraints == null ? true : this.audioTrackConstraints,
        video: false
      });
    } catch (a) {
      throw new Error(`Error thrown while initializing video stream: ${a.message}`);
    }
    if (!this.stream)
      throw new Error("Could not obtain audio from microphone.");
    const e = (
      // tslint:disable-next-line:no-any
      window.AudioContext || window.webkitAudioContext
    );
    if (this.audioContext = new e(), !this.sampleRateHz)
      this.sampleRateHz = this.audioContext.sampleRate;
    else if (this.audioContext.sampleRate !== this.sampleRateHz)
      throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`);
    const t = this.audioContext.createMediaStreamSource(this.stream);
    this.analyser = this.audioContext.createAnalyser(), this.analyser.fftSize = this.fftSize * 2, this.analyser.smoothingTimeConstant = this.smoothingTimeConstant, t.connect(this.analyser), this.freqData = new Float32Array(this.fftSize), this.timeData = new Float32Array(this.fftSize);
  }
  async next() {
    if (this.isClosed)
      return { value: null, done: true };
    let e, t;
    const a = await this.getAudioData();
    if (this.includeSpectrogram) {
      const r = this.flattenQueue(a.freqDataQueue);
      e = this.getTensorFromAudioDataArray(r, [this.numFrames, this.columnTruncateLength, 1]);
    }
    if (this.includeWaveform) {
      const r = this.flattenQueue(a.timeDataQueue);
      t = this.getTensorFromAudioDataArray(r, [this.numFrames * this.fftSize, 1]);
    }
    return {
      value: { spectrogram: e, waveform: t },
      done: false
    };
  }
  // Capture one result from the audio stream, and extract the value from
  // iterator.next() result.
  async capture() {
    return (await this.next()).value;
  }
  async getAudioData() {
    const e = [], t = [];
    let a = 0;
    return new Promise((r) => {
      const n = setInterval(() => {
        this.includeSpectrogram && (this.analyser.getFloatFrequencyData(this.freqData), this.freqData[0] === -1 / 0 && r({ freqDataQueue: e, timeDataQueue: t }), e.push(this.freqData.slice(0, this.columnTruncateLength))), this.includeWaveform && (this.analyser.getFloatTimeDomainData(this.timeData), t.push(this.timeData.slice())), ++a === this.numFrames && (clearInterval(n), r({ freqDataQueue: e, timeDataQueue: t }));
      }, this.fftSize / this.sampleRateHz * 1e3);
    });
  }
  // Stop the audio stream and pause the iterator.
  stop() {
    this.isClosed || (this.isClosed = true, this.analyser.disconnect(), this.audioContext.close(), this.stream != null && this.stream.getTracks().length > 0 && this.stream.getTracks()[0].stop());
  }
  // Override toArray() function to prevent collecting.
  toArray() {
    throw new Error("Can not convert infinite audio stream to array.");
  }
  // Return audio sampling rate in Hz
  getSampleRate() {
    return this.sampleRateHz;
  }
  flattenQueue(e) {
    const t = e[0].length, a = new Float32Array(e.length * t);
    return e.forEach((r, n) => a.set(r, n * t)), a;
  }
  getTensorFromAudioDataArray(e, t) {
    const a = new Float32Array(X(t));
    return a.set(e, a.length - e.length), $e(a, t);
  }
};
var It = class _It extends He {
  constructor(e, t) {
    if (super(), this.webcamVideoElement = e, this.webcamConfig = t, this.isClosed = true, this.resize = false, this.needToResize())
      if (this.resize = true, this.cropSize = [this.webcamConfig.resizeHeight, this.webcamConfig.resizeWidth], this.cropBoxInd = Ze([0], "int32"), this.webcamConfig.centerCrop) {
        const a = this.webcamConfig.resizeWidth * 1 / this.webcamVideoElement.width, r = this.webcamConfig.resizeHeight * 1 / this.webcamVideoElement.height, n = (1 - a) / 2, u = (1 - r) / 2, o = n + a, l = r + u;
        this.cropBox = il([u, n, l, o], [1, 4]);
      } else
        this.cropBox = il([0, 0, 1, 1], [1, 4]);
  }
  summary() {
    return "webcam";
  }
  // Construct a WebcamIterator and start it's video stream.
  static async create(e, t = {}) {
    if (!F().get("IS_BROWSER"))
      throw new Error("tf.data.webcam is only supported in browser environment.");
    if (!e) {
      if (e = document.createElement("video"), !t.resizeWidth || !t.resizeHeight)
        throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");
      e.width = t.resizeWidth, e.height = t.resizeHeight;
    }
    const a = new _It(e, t);
    return await a.start(), a;
  }
  // Async function to start video stream.
  async start() {
    this.webcamConfig.facingMode && C(this.webcamConfig.facingMode === "user" || this.webcamConfig.facingMode === "environment", () => `Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`);
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        video: {
          deviceId: this.webcamConfig.deviceId,
          facingMode: this.webcamConfig.facingMode ? this.webcamConfig.facingMode : "user",
          width: this.webcamVideoElement.width,
          height: this.webcamVideoElement.height
        }
      });
    } catch (e) {
      throw e.message = `Error thrown while initializing video stream: ${e.message}`, e;
    }
    if (!this.stream)
      throw new Error("Could not obtain video from webcam.");
    try {
      this.webcamVideoElement.srcObject = this.stream;
    } catch (e) {
      console.log(e), this.webcamVideoElement.src = window.URL.createObjectURL(this.stream);
    }
    return this.webcamVideoElement.play(), this.isClosed = false, new Promise((e) => {
      this.webcamVideoElement.onloadedmetadata = () => {
        e();
      };
    });
  }
  async next() {
    if (this.isClosed)
      return { value: null, done: true };
    let e;
    try {
      e = P0(this.webcamVideoElement);
    } catch (t) {
      throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(t)}`);
    }
    if (this.resize)
      try {
        return { value: this.cropAndResizeFrame(e), done: false };
      } catch (t) {
        throw new Error(`Error thrown cropping the video: ${t.message}`);
      } finally {
        e.dispose();
      }
    else
      return { value: e, done: false };
  }
  needToResize() {
    return !!(this.webcamConfig.resizeWidth && this.webcamConfig.resizeHeight && (this.webcamVideoElement.width !== this.webcamConfig.resizeWidth || this.webcamVideoElement.height !== this.webcamConfig.resizeHeight));
  }
  // Cropping and resizing each frame based on config
  cropAndResizeFrame(e) {
    return D(() => {
      const t = Oe(tt(e, "float32"), 0);
      let a;
      a = fs.cropAndResize(t, this.cropBox, this.cropBoxInd, this.cropSize, "bilinear");
      const r = a.shape;
      return W(a, r.slice(1));
    });
  }
  // Capture one frame from the video stream, and extract the value from
  // iterator.next() result.
  async capture() {
    return (await this.next()).value;
  }
  // Stop the video stream and pause webcam iterator.
  stop() {
    this.stream.getTracks().forEach((t) => t.stop());
    try {
      this.webcamVideoElement.srcObject = null;
    } catch (t) {
      console.log(t), this.webcamVideoElement.src = null;
    }
    this.isClosed = true;
  }
  // Override toArray() function to prevent collecting.
  toArray() {
    throw new Error("Can not convert infinite video stream to array.");
  }
};
var pi2 = class {
};
var mi2 = class extends He {
  /**
   * Splits a string stream on a given separator.
   *
   * It is assumed that the incoming chunk boundaries have no semantic meaning,
   * so conceptually the incoming stream is treated simply as the concatenation
   * of its elements.
   *
   * The outgoing stream provides chunks corresponding to the results of the
   * standard string split() operation (even if such a chunk spanned incoming
   * chunks).  The separators are not included.
   *
   * A typical usage is to split a text file (represented as a stream with
   * arbitrary chunk boundaries) into lines.
   *
   * @param upstream A readable stream of strings that can be treated as
   *   concatenated.
   * @param separator A character to split on.
   */
  split(e) {
    return new xb2(this, e);
  }
};
var xb2 = class extends mi2 {
  constructor(e, t) {
    super(), this.upstream = e, this.impl = new Lb2(e, t);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var Lb2 = class extends Q3 {
  constructor(e, t) {
    super(), this.upstream = e, this.separator = t, this.carryover = "";
  }
  summary() {
    return `${this.upstream.summary()} -> Split('${this.separator}')`;
  }
  async pump() {
    const e = await this.upstream.next();
    if (e.done)
      return this.carryover === "" ? false : (this.outputQueue.push(this.carryover), this.carryover = "", true);
    const t = e.value.split(this.separator);
    t[0] = this.carryover + t[0];
    for (const a of t.slice(0, -1))
      this.outputQueue.push(a);
    return this.carryover = t[t.length - 1], true;
  }
};
var Pb2 = class extends He {
  /**
   * Decode a stream of UTF8-encoded byte arrays to a stream of strings.
   *
   * The byte arrays producetd from the ByteChunkIterator on which this is
   * called will be interpreted as concatenated.  No assumptions are made about
   * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a
   * character may span the boundary between chunks.  This naturally happens,
   * for instance, when reading fixed-size byte arrays from a file.
   */
  decodeUTF8() {
    return new Fb2(this);
  }
};
var Fb2 = class extends mi2 {
  constructor(e) {
    super(), this.upstream = e, this.impl = new Vb2(e);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var Vb2 = class extends Q3 {
  constructor(e) {
    if (super(), this.upstream = e, F().get("IS_BROWSER"))
      this.decoder = new TextDecoder("utf-8");
    else {
      const { StringDecoder: t } = require_string_decoder();
      this.decoder = new t("utf8");
    }
  }
  summary() {
    return `${this.upstream.summary()} -> Utf8`;
  }
  async pump() {
    const e = await this.upstream.next();
    let t;
    if (e.done)
      return false;
    t = e.value;
    let a;
    return F().get("IS_BROWSER") ? a = this.decoder.decode(t, { stream: true }) : a = this.decoder.write(Buffer.from(t.buffer)), this.outputQueue.push(a), true;
  }
};
var ci2 = class extends Pb2 {
  constructor(e, t = {}) {
    super(), this.file = e, this.options = t, C(e instanceof Uint8Array || (F().get("IS_BROWSER") ? e instanceof File || e instanceof Blob : false), () => "FileChunkIterator only supports File, Blob and Uint8Array right now."), this.offset = t.offset || 0, this.chunkSize = t.chunkSize || 1024 * 1024;
  }
  summary() {
    return `FileChunks ${this.file}`;
  }
  async next() {
    return this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size) ? { value: null, done: true } : { value: await new Promise((t, a) => {
      const r = this.offset + this.chunkSize;
      if (this.file instanceof Uint8Array)
        t(new Uint8Array(this.file.slice(this.offset, r)));
      else {
        const n = new FileReader();
        n.onload = (o) => {
          let l = n.result;
          if (l instanceof ArrayBuffer && (l = new Uint8Array(l)), !(l instanceof Uint8Array))
            return a(new TypeError("FileReader returned unknown type."));
          t(l);
        }, n.onabort = (o) => a(new Error("Aborted")), n.onerror = (o) => a(new Error(o.type));
        const u = this.file.slice(this.offset, r);
        n.readAsArrayBuffer(u);
      }
      this.offset = r;
    }), done: false };
  }
};
async function Rb2(s, e = {}, t) {
  let a, r;
  typeof s == "string" ? a = s : (a = s.url, r = jb2(s));
  const n = await (t || u2)(a, r);
  if (n.ok) {
    const u = new Uint8Array(await n.arrayBuffer());
    return new ci2(u, e);
  } else
    throw new Error(n.statusText);
}
var jb2 = (s) => ({
  method: s.method,
  headers: s.headers,
  body: s.body,
  mode: s.mode,
  credentials: s.credentials,
  cache: s.cache,
  redirect: s.redirect,
  referrer: s.referrer,
  integrity: s.integrity
});
function di2(s) {
  return typeof s == "string" && s.slice(0, 7) === "file://";
}
var hi2 = class extends pi2 {
  /**
   * Create a `FileDataSource`.
   *
   * @param input Local file path, or `File`/`Blob`/`Uint8Array` object to
   *     read. Local file only works in node environment.
   * @param options Options passed to the underlying `FileChunkIterator`s,
   *   such as {chunksize: 1024}.
   */
  constructor(e, t = {}) {
    super(), this.input = e, this.options = t;
  }
  async iterator() {
    if (di2(this.input) && F().get("IS_NODE")) {
      const e = require_fs();
      this.input = e.readFileSync(this.input.slice(7));
    }
    return new ci2(this.input, this.options);
  }
};
var fi2 = class extends pi2 {
  /**
   * Create a `URLDataSource`.
   *
   * @param url A source URL string, or a `Request` object.
   * @param options Options passed to the underlying `FileChunkIterator`s,
   *   such as {chunksize: 1024}.
   */
  constructor(e, t = {}) {
    super(), this.url = e, this.fileOptions = t;
  }
  // TODO(soergel): provide appropriate caching options.  Currently this
  // will download the URL anew for each call to iterator().  Since we have
  // to treat the downloaded file as a blob/buffer anyway, we may as well retain
  // it-- but that raises GC issues.  Also we may want a persistent disk cache.
  async iterator() {
    return di2(this.url) ? new hi2(this.url, this.fileOptions).iterator() : Rb2(this.url, this.fileOptions);
  }
};
function Bb2(s, e = {}) {
  return new li2(new fi2(s), e);
}
function Hb2(s) {
  const e = z3(s);
  return yn(async () => e);
}
function Wb2(s) {
  return yn(async () => {
    const e = await s();
    return z3(() => e.next());
  });
}
async function Ub2(s, e) {
  return It.create(s, e);
}
async function qb2(s) {
  return kt2.create(s);
}
var yi2 = "4.16.0";
var Gb2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  CSVDataset: li2,
  Dataset: zf,
  FileDataSource: hi2,
  TextLineDataset: ui2,
  URLDataSource: fi2,
  array: BQ,
  csv: Bb2,
  func: Hb2,
  generator: Wb2,
  microphone: qb2,
  version_data: yi2,
  webcam: Ub2,
  zip: HQ
}, Symbol.toStringTag, { value: "Module" }));
var gi2 = "4.16.0";
var bi2 = "4.16.0";
var Kb2 = "4.16.0";
var Jb2 = {
  "tfjs-core": Xn2,
  "tfjs-backend-cpu": gi2,
  "tfjs-backend-webgl": bi2,
  "tfjs-data": yi2,
  "tfjs-layers": jx,
  "tfjs-converter": oi2,
  tfjs: Kb2
};
var Qb2 = Object.freeze(Object.defineProperty({
  __proto__: null,
  Abs: Ul,
  Acos: vi,
  Acosh: Si,
  AdadeltaOptimizer: R0,
  AdagradOptimizer: $0,
  AdamOptimizer: G0,
  AdamaxOptimizer: E0,
  Add: Sr,
  AddN: qd,
  All: th,
  Any: eh,
  ArgMax: Yl,
  ArgMin: Ql,
  Asin: ki,
  Asinh: Ti,
  Atan: Ni,
  Atan2: $i,
  Atanh: Ri,
  AvgPool: Jl,
  AvgPool3D: jl,
  AvgPool3DGrad: sh,
  AvgPoolGrad: nh,
  BatchMatMul: ql,
  BatchToSpaceND: tc,
  Bincount: oh,
  BitwiseAnd: rh,
  BroadcastArgs: cb,
  BroadcastTo: JC,
  Callback: si2,
  CallbackList: CL,
  Cast: Gi,
  Ceil: Ei,
  ClipByValue: Li,
  Complex: ih,
  ComplexAbs: ec,
  Concat: nc,
  Conv2D: sc,
  Conv2DBackpropFilter: ah,
  Conv2DBackpropInput: oc,
  Conv3D: rc,
  Conv3DBackpropFilterV2: lh,
  Conv3DBackpropInputV2: ch,
  Cos: Mi,
  Cosh: Wi,
  CropAndResize: dh,
  Cumprod: uh,
  Cumsum: ic,
  CustomCallback: kL,
  DataStorage: qg,
  DenseBincount: hh,
  DepthToSpace: ph,
  DepthwiseConv2dNative: ac,
  DepthwiseConv2dNativeBackpropFilter: fh,
  DepthwiseConv2dNativeBackpropInput: mh,
  Diag: ub,
  Dilation2D: lc,
  Dilation2DBackpropFilter: ld,
  Dilation2DBackpropInput: ad,
  Draw: gh,
  get ENV() {
    return ab;
  },
  EarlyStopping: ai2,
  Einsum: bh,
  Elu: Fi,
  EluGrad: xh,
  Environment: BC,
  Equal: cc,
  Erf: Vi,
  Exp: zi,
  ExpandDims: uc,
  Expm1: Pi,
  FFT: yh,
  Fill: wh,
  FlipLeftRight: Ih,
  Floor: Ai,
  FloorDiv: Oi,
  FromPixels: cd,
  FusedBatchNorm: dc,
  FusedConv2D: gl,
  FusedDepthwiseConv2D: Cb,
  GPGPUContext: Au,
  GatherNd: db,
  GatherV2: hc,
  GraphModel: Et,
  Greater: pc,
  GreaterEqual: Xi,
  History: SL,
  IFFT: Ch,
  Identity: Ki,
  Imag: vh,
  InputSpec: de,
  IsFinite: Zi,
  IsInf: Bi,
  IsNan: Hi,
  KernelBackend: _d,
  LRN: wc,
  LRNGrad: Sh,
  LayerVariable: iL,
  LayersModel: ur,
  LeakyRelu: fc,
  Less: mc,
  LessEqual: gc,
  LinSpace: hb,
  Log: _i,
  Log1p: Ui,
  LogSoftmax: jC,
  LogicalAnd: bc,
  LogicalNot: xc,
  LogicalOr: yc,
  LogicalXor: XY,
  LowerBound: KY,
  MathBackendCPU: yu,
  MathBackendWebGL: Cu,
  MatrixBandPart: ZY,
  Max: Ic,
  MaxPool: Cc,
  MaxPool3D: vc,
  MaxPool3DGrad: Th,
  MaxPoolGrad: kh,
  MaxPoolWithArgmax: pb,
  Maximum: Yi,
  Mean: Sc,
  Min: kc,
  Minimum: Qi,
  MirrorPad: Tc,
  Mod: Ji,
  MomentumOptimizer: L0,
  Multinomial: fb,
  Multiply: ji,
  Neg: Nc,
  NonMaxSuppressionV3: Nh,
  NonMaxSuppressionV4: Rh,
  NonMaxSuppressionV5: $h,
  NotEqual: Rc,
  OP_SCOPE_SUFFIX: N2,
  OneHot: Gc,
  OnesLike: $c,
  Optimizer: eo,
  OptimizerConstructors: T$,
  Pack: Ec,
  PadV2: Lc,
  Pool: BY,
  Pow: qi,
  Prelu: Mc,
  Prod: Wc,
  RMSPropOptimizer: M0,
  RNN: no,
  RaggedGather: mb,
  RaggedRange: gb,
  RaggedTensorToTensor: bb,
  Range: Gh,
  get Rank() {
    return ym;
  },
  Real: Eh,
  RealDiv: Di,
  Reciprocal: ta,
  get Reduction() {
    return Ke;
  },
  Relu: ea,
  Relu6: na,
  Reshape: Dc,
  ResizeBilinear: Vc,
  ResizeBilinearGrad: Mh,
  ResizeNearestNeighbor: Fc,
  ResizeNearestNeighborGrad: Lh,
  Reverse: zc,
  RotateWithOffset: Hh,
  Round: sa,
  Rsqrt: oa,
  SGDOptimizer: Xp,
  ScatterNd: xb,
  SearchSorted: wb,
  Select: Pc,
  Selu: ra,
  Sequential: mi,
  Sigmoid: ca,
  Sign: la,
  Sin: ia,
  Sinh: aa,
  Slice: Ac,
  Softmax: Zc,
  Softplus: ua,
  SpaceToBatchND: Xc,
  SparseFillEmptyRows: Wh,
  SparseReshape: Dh,
  SparseSegmentMean: Fh,
  SparseSegmentSum: Vh,
  SparseToDense: Ib,
  SplitV: Kc,
  Sqrt: da,
  Square: zh,
  SquaredDifference: ha,
  StaticRegexReplace: Bc,
  Step: ba,
  StridedSlice: Ph,
  StringNGrams: Ah,
  StringSplit: Oh,
  StringToHashBucketFast: Xh,
  Sub: pa,
  Sum: Oc,
  SymbolicTensor: os,
  Tan: fa,
  Tanh: ma,
  Tensor: Mt,
  TensorBuffer: ve,
  TensorScatterUpdate: yb,
  Tile: ga,
  TopK: Kh,
  Transform: Zh,
  Transpose: ar,
  Unique: Bh,
  Unpack: Hc,
  UnsortedSegmentSum: _c,
  UpperBound: HY,
  Variable: yl,
  ZerosLike: Uc,
  _FusedMatMul: ml,
  abs: me,
  acos: gv,
  acosh: xv,
  add: U,
  addN: nn2,
  all: Qb,
  any: Id,
  argMax: ai,
  argMin: vv,
  asin: kv,
  asinh: Nv,
  atan: $v,
  atan2: Ev,
  atanh: Mv,
  avgPool: np,
  avgPool3d: Ov,
  backend: ps,
  backend_util: E$,
  basicLSTMCell: on2,
  batchNorm: Qc,
  batchNorm2d: Jv,
  batchNorm3d: qv,
  batchNorm4d: eS,
  batchToSpaceND: op,
  bincount: sS,
  bitwiseAnd: un2,
  booleanMaskAsync: Hn2,
  broadcastArgs: ln2,
  broadcastTo: ni,
  broadcast_util: wQ,
  browser: MQ,
  buffer: vt,
  callbacks: rg2,
  cast: tt,
  ceil: iS,
  clipByValue: fn,
  clone: yo,
  complex: vo,
  concat: Ge,
  concat1d: cS,
  concat2d: dS,
  concat3d: pS,
  concat4d: mS,
  constraints: Mh2,
  conv1d: Jb,
  conv2d: $o,
  conv2dTranspose: jb,
  conv3d: IS,
  conv3dTranspose: SS,
  copyRegisteredKernels: YY,
  cos: ip,
  cosh: t0,
  cosineWindow: v0,
  cumprod: vd,
  cumsum: e0,
  customGrad: Eo,
  data: Gb2,
  denseBincount: Tm,
  deprecationWarn: nQ,
  depthToSpace: ES,
  depthwiseConv2d: ap,
  deregisterOp: ig2,
  device_util: jY,
  diag: pn2,
  dilation2d: WS,
  disableDeprecationWarnings: eQ,
  dispose: xt,
  disposeVariables: sQ,
  div: ut,
  divNoNan: PS,
  dot: OS,
  dropout: bN,
  einsum: Or,
  elu: Jc,
  enableDebugMode: tQ,
  enableProdMode: qY,
  enclosingPowerOfTwo: xN,
  engine: Ot,
  ensureShape: mn2,
  env: F,
  equal: Tn,
  erf: BS,
  euclideanNorm: tk,
  exp: mn,
  expandDims: Oe,
  expm1: ok,
  eye: o0,
  fft: Gp,
  fill: Ca,
  findBackend: cQ,
  findBackendFactory: uQ,
  floor: qc,
  floorDiv: Yb,
  forceHalfFloat: sX,
  fused: Jn2,
  gather: cp,
  gatherND: Gn2,
  gather_util: WQ,
  getBackend: G2,
  getGradient: dm,
  getKernel: bl,
  getKernelsForBackend: ud,
  gpgpu_util: UQ,
  grad: IQ,
  grads: CQ,
  greater: rn,
  greaterEqual: Bo,
  ifft: kl,
  imag: up,
  image: fs,
  inTopKAsync: Kn2,
  initializers: yf2,
  input: Zn2,
  io: Tt2,
  irfft: b0,
  isFinite: pk,
  isInf: mk,
  isNaN: bk,
  keep: hn,
  kernel_impls: Jh2,
  layers: Ly2,
  leakyRelu: dp,
  less: Cl,
  lessEqual: Tr,
  linalg: e$,
  linspace: cn2,
  loadGraphModel: Db2,
  loadGraphModelSync: Cb2,
  loadLayersModel: VQ,
  localResponseNormalization: Ck,
  log: Nn,
  log1p: hp,
  logSigmoid: $k,
  logSoftmax: r0,
  logSumExp: pp,
  logicalAnd: ss,
  logicalNot: fp,
  logicalOr: i0,
  logicalXor: Vk,
  losses: $Q,
  lowerBound: dn2,
  matMul: Gt,
  math: Kh2,
  max: Pn,
  maxPool: mp,
  maxPool3d: Ak,
  maxPoolWithArgmax: hn2,
  maximum: qs,
  mean: oe,
  memory: wl,
  meshgrid: fn2,
  metrics: Zy2,
  min: Il,
  minimum: br,
  mirrorPad: Bk,
  mod: _k,
  model: gf2,
  models: Yy2,
  moments: gp,
  movingAverage: Wn2,
  mul: G,
  multiRNNCell: yn2,
  multinomial: gn2,
  neg: Yt,
  nextFrame: su,
  norm: jc,
  notEqual: ui,
  oneHot: a0,
  ones: ks,
  onesLike: Rn,
  op: L,
  outerProduct: bn2,
  pad: bp,
  pad1d: Nn2,
  pad2d: wn2,
  pad3d: Tn2,
  pad4d: Sn2,
  pool: sT,
  pow: gr,
  prelu: yp,
  print: lv,
  prod: iT,
  profile: oQ,
  raggedGather: vn2,
  raggedRange: On2,
  raggedTensorToTensor: _n2,
  rand: An2,
  randomGamma: In2,
  randomNormal: kT,
  randomStandardNormal: $n2,
  randomUniform: Sa,
  randomUniformInt: Dn2,
  range: di,
  ready: aQ,
  real: vl,
  reciprocal: $T,
  registerBackend: Pb,
  registerCallbackConstructor: Nf2,
  registerGradient: t2,
  registerKernel: sn,
  registerOp: ng2,
  regularizers: sg2,
  relu: Ts,
  relu6: c0,
  removeBackend: lQ,
  reshape: W,
  reverse: Lo,
  reverse1d: Cn2,
  reverse2d: zn2,
  reverse3d: xn2,
  reverse4d: Ln,
  rfft: Ep,
  round: u0,
  rsqrt: d0,
  scalar: gt,
  scatterND: Un2,
  scatter_util: TQ,
  searchSorted: Ce2,
  selu: h0,
  separableConv2d: p0,
  sequential: bf2,
  serialization: LQ,
  setBackend: iQ,
  setPlatform: dQ,
  setWebGLContext: EP,
  setdiff1dAsync: Pn2,
  shared: fW,
  sigmoid: kr,
  sign: zT,
  signal: RQ,
  sin: f0,
  sinh: m0,
  slice: Ft,
  slice1d: Np,
  slice2d: g0,
  slice3d: Rp,
  slice4d: Sl,
  slice_util: k$,
  softmax: $p,
  softplus: va,
  spaceToBatchND: xp,
  sparse: GQ,
  sparseToDense: qn2,
  spectral: NQ,
  split: pn,
  sqrt: Ve,
  square: Kt,
  squaredDifference: x0,
  squeeze: ka,
  stack: Xn,
  step: Ta,
  stridedSlice: nN,
  string: EQ,
  sub: it,
  sum: at,
  sumOutType: Yh,
  tan: oN,
  tanh: sp,
  tensor: $e,
  tensor1d: Ze,
  tensor2d: il,
  tensor3d: rN,
  tensor4d: Fn2,
  tensor5d: Vn2,
  tensor6d: Rn2,
  tensorScatterUpdate: jn2,
  tensor_util: JY,
  test_util: hh2,
  tidy: D,
  tile: Vn,
  time: rQ,
  topk: aN,
  train: tr,
  transpose: kt,
  truncatedNormal: w0,
  unique: uN,
  unregisterGradient: UY,
  unregisterKernel: _Y,
  unsortedSegmentSum: I0,
  unstack: Mo,
  upcastType: tn,
  upperBound: Bn2,
  util: QY,
  valueAndGrad: vQ,
  valueAndGrads: SQ,
  variable: pN,
  variableGrads: kk,
  version: Jb2,
  version_converter: oi2,
  version_core: Xn2,
  version_cpu: gi2,
  version_layers: jx,
  version_webgl: bi2,
  webgl: YQ,
  webgl_util: _Q,
  where: Ee,
  whereAsync: wt,
  zeros: be,
  zerosLike: Tt
}, Symbol.toStringTag, { value: "Module" }));
var Ni2 = new Matrix4();
Ni2.compose(new Vector3(), new Quaternion(), new Vector3(1e-3, 1e-3, 1e-3));
var Xb2 = new Matrix4().set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1);
var Zb2 = class {
  constructor({
    container: e,
    imageTargetSrc: t,
    maxTrack: a,
    uiLoading: r = "yes",
    uiScanning: n = "yes",
    uiError: u = "yes",
    filterMinCF: o = null,
    filterBeta: l = null,
    warmupTolerance: p = null,
    missTolerance: m = null,
    userDeviceId: c = null,
    environmentDeviceId: d = null
  }) {
    this.container = e, this.imageTargetSrc = t, this.maxTrack = a, this.filterMinCF = o, this.filterBeta = l, this.warmupTolerance = p, this.missTolerance = m, this.ui = new M({ uiLoading: r, uiScanning: n, uiError: u }), this.userDeviceId = c, this.environmentDeviceId = d, this.shouldFaceUser = false, this.scene = new Scene(), this.cssScene = new Scene(), this.renderer = new WebGLRenderer({ antialias: true, alpha: true }), this.cssRenderer = new CSS3DRenderer({ antialias: true }), this.renderer.outputEncoding = sRGBEncoding, this.renderer.setPixelRatio(window.devicePixelRatio), this.camera = new PerspectiveCamera(), this.anchors = [], this.renderer.domElement.style.position = "absolute", this.cssRenderer.domElement.style.position = "absolute", this.container.appendChild(this.renderer.domElement), this.container.appendChild(this.cssRenderer.domElement), window.addEventListener("resize", this.resize.bind(this));
  }
  async start() {
    this.ui.showLoading(), await this._startVideo(), await this._startAR();
  }
  stop() {
    this.controller.stopProcessVideo(), this.video.srcObject.getTracks().forEach(function(t) {
      t.stop();
    }), this.video.remove();
  }
  switchCamera() {
    this.shouldFaceUser = !this.shouldFaceUser, this.stop(), this.start();
  }
  addAnchor(e) {
    const t = new Group();
    t.visible = false, t.matrixAutoUpdate = false;
    const a = { group: t, targetIndex: e, onTargetFound: null, onTargetLost: null, onTargetUpdate: null, css: false, visible: false };
    return this.anchors.push(a), this.scene.add(t), a;
  }
  addCSSAnchor(e) {
    const t = new Group();
    t.visible = false, t.matrixAutoUpdate = false;
    const a = { group: t, targetIndex: e, onTargetFound: null, onTargetLost: null, onTargetUpdate: null, css: true, visible: false };
    return this.anchors.push(a), this.cssScene.add(t), a;
  }
  _startVideo() {
    return new Promise((e, t) => {
      if (this.video = document.createElement("video"), this.video.setAttribute("autoplay", ""), this.video.setAttribute("muted", ""), this.video.setAttribute("playsinline", ""), this.video.style.position = "absolute", this.video.style.top = "0px", this.video.style.left = "0px", this.video.style.zIndex = "-2", this.container.appendChild(this.video), !navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        this.ui.showCompatibility(), t();
        return;
      }
      const a = {
        audio: false,
        video: {}
      };
      this.shouldFaceUser ? this.userDeviceId ? a.video.deviceId = { exact: this.userDeviceId } : a.video.facingMode = "user" : this.environmentDeviceId ? a.video.deviceId = { exact: this.environmentDeviceId } : a.video.facingMode = "environment", navigator.mediaDevices.getUserMedia(a).then((r) => {
        this.video.addEventListener("loadedmetadata", () => {
          this.video.setAttribute("width", this.video.videoWidth), this.video.setAttribute("height", this.video.videoHeight), e();
        }), this.video.srcObject = r;
      }).catch((r) => {
        console.log("getUserMedia error", r), t();
      });
    });
  }
  _startAR() {
    return new Promise(async (e, t) => {
      const a = this.video;
      this.container, this.controller = new QQ({
        inputWidth: a.videoWidth,
        inputHeight: a.videoHeight,
        filterMinCF: this.filterMinCF,
        filterBeta: this.filterBeta,
        warmupTolerance: this.warmupTolerance,
        missTolerance: this.missTolerance,
        maxTrack: this.maxTrack,
        onUpdate: (n) => {
          if (n.type === "updateMatrix") {
            const { targetIndex: u, worldMatrix: o } = n;
            for (let p = 0; p < this.anchors.length; p++)
              if (this.anchors[p].targetIndex === u) {
                if (this.anchors[p].css ? this.anchors[p].group.children.forEach((m) => {
                  m.element.style.visibility = o === null ? "hidden" : "visible";
                }) : this.anchors[p].group.visible = o !== null, o !== null) {
                  let m = new Matrix4();
                  m.elements = [...o], m.multiply(this.postMatrixs[u]), this.anchors[p].css && m.multiply(Ni2), this.anchors[p].group.matrix = m;
                } else
                  this.anchors[p].group.matrix = Xb2;
                this.anchors[p].visible && o === null && (this.anchors[p].visible = false, this.anchors[p].onTargetLost && this.anchors[p].onTargetLost()), !this.anchors[p].visible && o !== null && (this.anchors[p].visible = true, this.anchors[p].onTargetFound && this.anchors[p].onTargetFound()), this.anchors[p].onTargetUpdate && this.anchors[p].onTargetUpdate();
              }
            this.anchors.reduce((p, m) => p || m.visible, false) ? this.ui.hideScanning() : this.ui.showScanning();
          }
        }
      }), this.resize();
      const { dimensions: r } = await this.controller.addImageTargets(this.imageTargetSrc);
      this.postMatrixs = [];
      for (let n = 0; n < r.length; n++) {
        const u = new Vector3(), o = new Quaternion(), l = new Vector3(), [p, m] = r[n];
        u.x = p / 2, u.y = p / 2 + (m - p) / 2, l.x = p, l.y = p, l.z = p;
        const c = new Matrix4();
        c.compose(u, o, l), this.postMatrixs.push(c);
      }
      await this.controller.dummyRun(this.video), this.ui.hideLoading(), this.ui.showScanning(), this.controller.processVideo(this.video), e();
    });
  }
  resize() {
    const { renderer: e, cssRenderer: t, camera: a, container: r, video: n } = this;
    if (!n)
      return;
    this.video.setAttribute("width", this.video.videoWidth), this.video.setAttribute("height", this.video.videoHeight);
    let u, o;
    const l = n.videoWidth / n.videoHeight, p = r.clientWidth / r.clientHeight;
    l > p ? (o = r.clientHeight, u = o * l) : (u = r.clientWidth, o = u / l);
    const m = this.controller.getProjectionMatrix(), c = this.controller.inputWidth / this.controller.inputHeight;
    let d;
    c > p ? d = this.video.width / this.controller.inputWidth : d = this.video.height / this.controller.inputHeight;
    let h, N;
    c > p ? (h = r.clientHeight, h *= d) : (N = r.clientWidth, h = N / this.controller.inputWidth * this.controller.inputHeight, h *= d);
    let g = r.clientHeight / h;
    const f = 2 * Math.atan(1 / m[5] * g) * 180 / Math.PI, b = m[14] / (m[10] - 1), O = m[14] / (m[10] + 1);
    m[5] / m[0], a.fov = f, a.near = b, a.far = O, a.aspect = r.clientWidth / r.clientHeight, a.updateProjectionMatrix(), n.style.top = -(o - r.clientHeight) / 2 + "px", n.style.left = -(u - r.clientWidth) / 2 + "px", n.style.width = u + "px", n.style.height = o + "px";
    const _6 = e.domElement, T6 = t.domElement;
    _6.style.position = "absolute", _6.style.left = 0, _6.style.top = 0, _6.style.width = r.clientWidth + "px", _6.style.height = r.clientHeight + "px", T6.style.position = "absolute", T6.style.left = 0, T6.style.top = 0, T6.style.width = r.clientWidth + "px", T6.style.height = r.clientHeight + "px", e.setSize(r.clientWidth, r.clientHeight), t.setSize(r.clientWidth, r.clientHeight);
  }
};
window.MINDAR || (window.MINDAR = {});
window.MINDAR.IMAGE || (window.MINDAR.IMAGE = {});
window.MINDAR.IMAGE.MindARThree = Zb2;
window.MINDAR.IMAGE.tf = Qb2;
export {
  Zb2 as MindARThree
};
/*! Bundled license information:

safe-buffer/index.js:
  (*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> *)

mind-ar/dist/controller-mGt1s8dJ.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
  (**
   * @license
   * Copyright 2020 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

mind-ar/dist/mindar-image-three.prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
*/
//# sourceMappingURL=mind-ar_dist_mindar-image-three__prod__js.js.map
